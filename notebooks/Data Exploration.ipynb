{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "13e13d7e-4a6d-473c-b714-5bb5c7768c99",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>playable</th>\n",
       "      <th>aoe_bool</th>\n",
       "      <th>...</th>\n",
       "      <th>support</th>\n",
       "      <th>mini_tank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>140 rows Ã— 58 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     playable  aoe_bool  ...  support  mini_tank\n",
       "0        True     False  ...    False      False\n",
       "1        True     False  ...    False      False\n",
       "..        ...       ...  ...      ...        ...\n",
       "138     False     False  ...    False      False\n",
       "139     False     False  ...     True      False\n",
       "\n",
       "[140 rows x 58 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import mixture\n",
    "\n",
    "pd.set_option('display.max_rows',5)\n",
    "pd.set_option('display.max_columns',5)\n",
    "\n",
    "path = \"cards_model.parquet\"\n",
    "path2 = 'cards.parquet'\n",
    "cards = pd.read_parquet(path)\n",
    "card_names = pd.read_parquet(path2)\n",
    "cards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "274e6838-a6c5-495d-9c98-ae65d48e6563",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7             Barbarian Hut\n",
       "13               Bomb Tower\n",
       "17                   Cannon\n",
       "19     Cannon Cart (broken)\n",
       "31         Elixir Collector\n",
       "45              Goblin Cage\n",
       "48             Goblin Drill\n",
       "51               Goblin Hut\n",
       "66            Inferno Tower\n",
       "82                   Mortar\n",
       "112                   Tesla\n",
       "115               Tombstone\n",
       "124                   X-Bow\n",
       "Name: name, dtype: string"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_col = list(cards.columns)\n",
    "engineered = ['damage_per_elixir','damage_per_second','damage_output','hp_per_elixir','damage_by_hitpoints','aoe_by_range', 'aoe_by_damage']\n",
    "original = list(filter(lambda x: x not in engineered, all_col))\n",
    "num_features = list(cards.select_dtypes(include=np.number).columns)\n",
    "bool_features = list(cards.select_dtypes(include=bool).columns)\n",
    "\n",
    "diff_features = {'all_col': all_col, 'engineered': engineered, 'original': original, 'num_features': num_features, 'bool_features': bool_features}\n",
    "\n",
    "def create_clusters(card_type, n_clusters, columns):\n",
    "    col_to_filter = f'is_{card_type}'.lower()\n",
    "    X = cards[cards[col_to_filter] == True][columns].copy()\n",
    "    X = X[list(filter(lambda x: x not in ['is_troop', 'is_spell', 'is_building'], list(X.columns)))]\n",
    "\n",
    "    Xs = StandardScaler().fit_transform(X)\n",
    "    \n",
    "    km = KMeans(n_clusters=n_clusters, n_init=10, random_state=42).fit(Xs)\n",
    "    labels_km = km.labels_ \n",
    "    sil_km = silhouette_score(Xs, labels_km) if len(set(labels_km)) > 1 else np.nan \n",
    "    sizes_km = {i:int(sum(labels_km==i)) for i in range(n_clusters)}\n",
    "\n",
    "    \n",
    "    gmm = mixture.GaussianMixture(\n",
    "        n_components=n_clusters,\n",
    "        n_init=10,\n",
    "        covariance_type='full', \n",
    "        means_init=km.cluster_centers_, \n",
    "        init_params='kmeans', \n",
    "        random_state=1, \n",
    "        reg_covar=1e-6,\n",
    "        weights_init=[1/n_clusters]*n_clusters\n",
    "        )\n",
    "\n",
    "    cluster_labels = gmm.fit_predict(Xs)\n",
    "    sil_gmm = silhouette_score(Xs, cluster_labels) if len(set(cluster_labels)) > 1 else np.nan\n",
    "    sizes_gmm = {i:int(sum(cluster_labels==i)) for i in range(n_clusters)}\n",
    "    cluster_probs = gmm.predict_proba(Xs) \n",
    "    \n",
    "    X['predict_gmm'] = cluster_labels \n",
    "    X['predict_km'] = labels_km\n",
    "\n",
    "    gmm_clusters = []\n",
    "    km_clusters = []\n",
    "    for i, j in enumerate(range(n_clusters)):\n",
    "        cluster_idxs = list(X[X['predict_gmm'] == i].index)\n",
    "\n",
    "        cluster_card_names = card_names.loc[cluster_idxs, 'name']\n",
    "\n",
    "        # Flatten & convert to string list\n",
    "        cluster_card_names = [str(name) for name in cluster_card_names.values.ravel()]\n",
    "\n",
    "        gmm_clusters.append(cluster_card_names)\n",
    "\n",
    "        cluster_jdxs = list(X[X['predict_km'] == i].index)\n",
    "\n",
    "        km_cluster_card_names = card_names.loc[cluster_jdxs, 'name']\n",
    "\n",
    "        # Flatten & convert to string list\n",
    "        km_cluster_card_names = [str(name) for name in km_cluster_card_names.values.ravel()]\n",
    "\n",
    "        km_clusters.append(km_cluster_card_names)\n",
    "        \n",
    "    return {'clusters': gmm_clusters, 'km_clusters': km_clusters,'sil_gmm': sil_gmm, 'sil_km': sil_km, 'gmm_labels': cluster_labels, 'km_labels': labels_km, 'gmm_probs': cluster_probs, 'cards': card_names.loc[X.index, 'name']}\n",
    "create_clusters('building', 3, all_col)['cards']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "af368e99-bf58-4f9a-8d43-8c0549af158a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def simulation(add_col=[]):\n",
    "    simulation = []\n",
    "    for k in range(3, 9):\n",
    "        for title, num_col in diff_features.items():\n",
    "            for col in num_col:\n",
    "                test_col = num_col.copy()\n",
    "                test_col.remove(col)\n",
    "                \n",
    "                \n",
    "            \n",
    "                sim_troop = create_clusters('troop', k, test_col + add_col)\n",
    "                sil_gmm_troop = sim_troop['sil_gmm']\n",
    "                sil_km_troop = sim_troop['sil_km']\n",
    "\n",
    "                sim_spell = create_clusters('spell', k, test_col + add_col)\n",
    "                sil_gmm_spell = sim_spell['sil_gmm']\n",
    "                sil_km_spell = sim_spell['sil_km']\n",
    "\n",
    "                sim_building = create_clusters('building', k, test_col + add_col)\n",
    "                sil_gmm_building = sim_building['sil_gmm']\n",
    "                sil_km_building = sim_building['sil_km']\n",
    "\n",
    "                simulation.append(\n",
    "                    {\n",
    "                    'gmm_troop':sil_gmm_troop, \n",
    "                    'km_troop': sil_km_troop, \n",
    "                    'gmm_spell': sil_gmm_spell, \n",
    "                    'km_spell':sil_km_spell, \n",
    "                    'gmm_building':sil_gmm_building, \n",
    "                    'km_building':sil_km_building, \n",
    "                    'K': k,\n",
    "                    'col': col,\n",
    "                    'og_col': title\n",
    "                    }\n",
    "                )\n",
    "    \n",
    "    simulation_df = pd.DataFrame(simulation)\n",
    "    \n",
    "    return simulation_df\n",
    "sim = simulation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f3b3fa0e-b48c-4366-8be6-7fdfa1b74827",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gmm_troop</th>\n",
       "      <th>km_troop</th>\n",
       "      <th>gmm_spell</th>\n",
       "      <th>km_spell</th>\n",
       "      <th>gmm_building</th>\n",
       "      <th>km_building</th>\n",
       "      <th>K</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>og_col</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>all_col</th>\n",
       "      <td>0.117448</td>\n",
       "      <td>0.145929</td>\n",
       "      <td>0.255945</td>\n",
       "      <td>0.255945</td>\n",
       "      <td>0.340280</td>\n",
       "      <td>0.340280</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bool_features</th>\n",
       "      <td>0.181814</td>\n",
       "      <td>0.187217</td>\n",
       "      <td>0.501942</td>\n",
       "      <td>0.513556</td>\n",
       "      <td>0.363711</td>\n",
       "      <td>0.373788</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>engineered</th>\n",
       "      <td>0.238237</td>\n",
       "      <td>0.399368</td>\n",
       "      <td>0.550887</td>\n",
       "      <td>0.550887</td>\n",
       "      <td>0.781330</td>\n",
       "      <td>0.781330</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_features</th>\n",
       "      <td>0.320096</td>\n",
       "      <td>0.248185</td>\n",
       "      <td>0.401957</td>\n",
       "      <td>0.422844</td>\n",
       "      <td>0.501335</td>\n",
       "      <td>0.501335</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>original</th>\n",
       "      <td>0.127619</td>\n",
       "      <td>0.152098</td>\n",
       "      <td>0.271665</td>\n",
       "      <td>0.272412</td>\n",
       "      <td>0.308411</td>\n",
       "      <td>0.304143</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               gmm_troop  km_troop  gmm_spell  km_spell  gmm_building  \\\n",
       "og_col                                                                  \n",
       "all_col         0.117448  0.145929   0.255945  0.255945      0.340280   \n",
       "bool_features   0.181814  0.187217   0.501942  0.513556      0.363711   \n",
       "engineered      0.238237  0.399368   0.550887  0.550887      0.781330   \n",
       "num_features    0.320096  0.248185   0.401957  0.422844      0.501335   \n",
       "original        0.127619  0.152098   0.271665  0.272412      0.308411   \n",
       "\n",
       "               km_building  K  \n",
       "og_col                         \n",
       "all_col           0.340280  8  \n",
       "bool_features     0.373788  8  \n",
       "engineered        0.781330  8  \n",
       "num_features      0.501335  8  \n",
       "original          0.304143  8  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sim.groupby('og_col').max(numeric_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "de62dae6-8aee-46ec-b401-36a74e59101e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gmm_troop</th>\n",
       "      <th>km_troop</th>\n",
       "      <th>gmm_spell</th>\n",
       "      <th>km_spell</th>\n",
       "      <th>gmm_building</th>\n",
       "      <th>km_building</th>\n",
       "      <th>K</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>og_col</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>all_col</th>\n",
       "      <td>-0.138748</td>\n",
       "      <td>0.079530</td>\n",
       "      <td>0.062831</td>\n",
       "      <td>0.170569</td>\n",
       "      <td>0.182532</td>\n",
       "      <td>0.182532</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bool_features</th>\n",
       "      <td>-0.037347</td>\n",
       "      <td>0.119097</td>\n",
       "      <td>0.163961</td>\n",
       "      <td>0.216218</td>\n",
       "      <td>0.198989</td>\n",
       "      <td>0.202590</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>engineered</th>\n",
       "      <td>-0.218974</td>\n",
       "      <td>0.200817</td>\n",
       "      <td>-0.118462</td>\n",
       "      <td>0.349300</td>\n",
       "      <td>0.266975</td>\n",
       "      <td>0.343044</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_features</th>\n",
       "      <td>-0.205450</td>\n",
       "      <td>0.121266</td>\n",
       "      <td>0.036177</td>\n",
       "      <td>0.268966</td>\n",
       "      <td>0.223007</td>\n",
       "      <td>0.223007</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>original</th>\n",
       "      <td>-0.115937</td>\n",
       "      <td>0.097108</td>\n",
       "      <td>0.070564</td>\n",
       "      <td>0.160120</td>\n",
       "      <td>0.181888</td>\n",
       "      <td>0.181888</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               gmm_troop  km_troop  gmm_spell  km_spell  gmm_building  \\\n",
       "og_col                                                                  \n",
       "all_col        -0.138748  0.079530   0.062831  0.170569      0.182532   \n",
       "bool_features  -0.037347  0.119097   0.163961  0.216218      0.198989   \n",
       "engineered     -0.218974  0.200817  -0.118462  0.349300      0.266975   \n",
       "num_features   -0.205450  0.121266   0.036177  0.268966      0.223007   \n",
       "original       -0.115937  0.097108   0.070564  0.160120      0.181888   \n",
       "\n",
       "               km_building  K  \n",
       "og_col                         \n",
       "all_col           0.182532  3  \n",
       "bool_features     0.202590  3  \n",
       "engineered        0.343044  3  \n",
       "num_features      0.223007  3  \n",
       "original          0.181888  3  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sim.groupby('og_col').min(numeric_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "46bcfceb-163f-4346-9f18-1c3bccf0cd23",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gmm_spell</th>\n",
       "      <th>col</th>\n",
       "      <th>og_col</th>\n",
       "      <th>K</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>237</th>\n",
       "      <td>0.550887</td>\n",
       "      <td>aoe_by_range</td>\n",
       "      <td>engineered</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>409</th>\n",
       "      <td>0.520646</td>\n",
       "      <td>hp_per_elixir</td>\n",
       "      <td>engineered</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>411</th>\n",
       "      <td>0.519276</td>\n",
       "      <td>aoe_by_range</td>\n",
       "      <td>engineered</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1036</th>\n",
       "      <td>0.501942</td>\n",
       "      <td>control_special</td>\n",
       "      <td>bool_features</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>0.496813</td>\n",
       "      <td>aoe_by_range</td>\n",
       "      <td>engineered</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1030</th>\n",
       "      <td>0.478967</td>\n",
       "      <td>has_friendly_buff</td>\n",
       "      <td>bool_features</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>856</th>\n",
       "      <td>0.475001</td>\n",
       "      <td>has_friendly_buff</td>\n",
       "      <td>bool_features</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1021</th>\n",
       "      <td>0.468887</td>\n",
       "      <td>has_periodic_spawn</td>\n",
       "      <td>bool_features</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>688</th>\n",
       "      <td>0.460809</td>\n",
       "      <td>control_special</td>\n",
       "      <td>bool_features</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>406</th>\n",
       "      <td>0.424232</td>\n",
       "      <td>damage_per_elixir</td>\n",
       "      <td>engineered</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>303</th>\n",
       "      <td>0.401957</td>\n",
       "      <td>hp_per_elixir</td>\n",
       "      <td>num_features</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>466</th>\n",
       "      <td>0.389297</td>\n",
       "      <td>elixircost</td>\n",
       "      <td>num_features</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>645</th>\n",
       "      <td>0.367936</td>\n",
       "      <td>attack_count</td>\n",
       "      <td>num_features</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>651</th>\n",
       "      <td>0.358724</td>\n",
       "      <td>hp_per_elixir</td>\n",
       "      <td>num_features</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>0.355502</td>\n",
       "      <td>hp_per_elixir</td>\n",
       "      <td>num_features</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>768</th>\n",
       "      <td>0.271665</td>\n",
       "      <td>elixircost</td>\n",
       "      <td>original</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>612</th>\n",
       "      <td>0.271169</td>\n",
       "      <td>has_periodic_spawn</td>\n",
       "      <td>original</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>961</th>\n",
       "      <td>0.270719</td>\n",
       "      <td>single_damage_type</td>\n",
       "      <td>original</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>803</th>\n",
       "      <td>0.268194</td>\n",
       "      <td>control_special</td>\n",
       "      <td>original</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>629</th>\n",
       "      <td>0.266143</td>\n",
       "      <td>control_special</td>\n",
       "      <td>original</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>905</th>\n",
       "      <td>0.255945</td>\n",
       "      <td>has_friendly_buff</td>\n",
       "      <td>all_col</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>545</th>\n",
       "      <td>0.226141</td>\n",
       "      <td>has_upon_breaking_spawn</td>\n",
       "      <td>all_col</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>570</th>\n",
       "      <td>0.221166</td>\n",
       "      <td>aoe_per_elixir</td>\n",
       "      <td>all_col</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>895</th>\n",
       "      <td>0.218471</td>\n",
       "      <td>has_periodic_spawn</td>\n",
       "      <td>all_col</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>877</th>\n",
       "      <td>0.217566</td>\n",
       "      <td>elixircost</td>\n",
       "      <td>all_col</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      gmm_spell                      col         og_col  K\n",
       "237    0.550887             aoe_by_range     engineered  4\n",
       "409    0.520646            hp_per_elixir     engineered  5\n",
       "411    0.519276             aoe_by_range     engineered  5\n",
       "1036   0.501942          control_special  bool_features  8\n",
       "63     0.496813             aoe_by_range     engineered  3\n",
       "1030   0.478967        has_friendly_buff  bool_features  8\n",
       "856    0.475001        has_friendly_buff  bool_features  7\n",
       "1021   0.468887       has_periodic_spawn  bool_features  8\n",
       "688    0.460809          control_special  bool_features  6\n",
       "406    0.424232        damage_per_elixir     engineered  5\n",
       "303    0.401957            hp_per_elixir   num_features  4\n",
       "466    0.389297               elixircost   num_features  5\n",
       "645    0.367936             attack_count   num_features  6\n",
       "651    0.358724            hp_per_elixir   num_features  6\n",
       "129    0.355502            hp_per_elixir   num_features  3\n",
       "768    0.271665               elixircost       original  7\n",
       "612    0.271169       has_periodic_spawn       original  6\n",
       "961    0.270719       single_damage_type       original  8\n",
       "803    0.268194          control_special       original  7\n",
       "629    0.266143          control_special       original  6\n",
       "905    0.255945        has_friendly_buff        all_col  8\n",
       "545    0.226141  has_upon_breaking_spawn        all_col  6\n",
       "570    0.221166           aoe_per_elixir        all_col  6\n",
       "895    0.218471       has_periodic_spawn        all_col  8\n",
       "877    0.217566               elixircost        all_col  8"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sim.sort_values('gmm_spell', ascending=False).groupby('og_col').head(5)[['gmm_spell', 'col', 'og_col', 'K']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d4e86146-c827-483c-a33c-a15150649618",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gmm_building</th>\n",
       "      <th>col</th>\n",
       "      <th>og_col</th>\n",
       "      <th>K</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>0.781330</td>\n",
       "      <td>hp_per_elixir</td>\n",
       "      <td>engineered</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>409</th>\n",
       "      <td>0.698454</td>\n",
       "      <td>hp_per_elixir</td>\n",
       "      <td>engineered</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233</th>\n",
       "      <td>0.672963</td>\n",
       "      <td>damage_per_second</td>\n",
       "      <td>engineered</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232</th>\n",
       "      <td>0.666140</td>\n",
       "      <td>damage_per_elixir</td>\n",
       "      <td>engineered</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>407</th>\n",
       "      <td>0.662429</td>\n",
       "      <td>damage_per_second</td>\n",
       "      <td>engineered</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>291</th>\n",
       "      <td>0.501335</td>\n",
       "      <td>can_evolve</td>\n",
       "      <td>num_features</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>292</th>\n",
       "      <td>0.483812</td>\n",
       "      <td>elixircost</td>\n",
       "      <td>num_features</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>293</th>\n",
       "      <td>0.462545</td>\n",
       "      <td>hit_speed</td>\n",
       "      <td>num_features</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>303</th>\n",
       "      <td>0.454709</td>\n",
       "      <td>hp_per_elixir</td>\n",
       "      <td>num_features</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>0.454658</td>\n",
       "      <td>hitpoints</td>\n",
       "      <td>num_features</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>310</th>\n",
       "      <td>0.363711</td>\n",
       "      <td>aoe_bool</td>\n",
       "      <td>bool_features</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1007</th>\n",
       "      <td>0.363058</td>\n",
       "      <td>death_damage_bool</td>\n",
       "      <td>bool_features</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>311</th>\n",
       "      <td>0.359645</td>\n",
       "      <td>death_damage_bool</td>\n",
       "      <td>bool_features</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>659</th>\n",
       "      <td>0.356988</td>\n",
       "      <td>death_damage_bool</td>\n",
       "      <td>bool_features</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>833</th>\n",
       "      <td>0.353401</td>\n",
       "      <td>death_damage_bool</td>\n",
       "      <td>bool_features</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209</th>\n",
       "      <td>0.340280</td>\n",
       "      <td>has_friendly_buff</td>\n",
       "      <td>all_col</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>383</th>\n",
       "      <td>0.329861</td>\n",
       "      <td>has_friendly_buff</td>\n",
       "      <td>all_col</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>0.328255</td>\n",
       "      <td>any_target</td>\n",
       "      <td>all_col</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>0.326902</td>\n",
       "      <td>can_evolve</td>\n",
       "      <td>all_col</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208</th>\n",
       "      <td>0.324159</td>\n",
       "      <td>special_attack_type</td>\n",
       "      <td>all_col</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>274</th>\n",
       "      <td>0.308411</td>\n",
       "      <td>has_friendly_buff</td>\n",
       "      <td>original</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246</th>\n",
       "      <td>0.304143</td>\n",
       "      <td>elixircost</td>\n",
       "      <td>original</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>283</th>\n",
       "      <td>0.297459</td>\n",
       "      <td>air_control</td>\n",
       "      <td>original</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>0.297026</td>\n",
       "      <td>can_evolve</td>\n",
       "      <td>original</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242</th>\n",
       "      <td>0.296378</td>\n",
       "      <td>death_damage_bool</td>\n",
       "      <td>original</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      gmm_building                  col         og_col  K\n",
       "235       0.781330        hp_per_elixir     engineered  4\n",
       "409       0.698454        hp_per_elixir     engineered  5\n",
       "233       0.672963    damage_per_second     engineered  4\n",
       "232       0.666140    damage_per_elixir     engineered  4\n",
       "407       0.662429    damage_per_second     engineered  5\n",
       "291       0.501335           can_evolve   num_features  4\n",
       "292       0.483812           elixircost   num_features  4\n",
       "293       0.462545            hit_speed   num_features  4\n",
       "303       0.454709        hp_per_elixir   num_features  4\n",
       "295       0.454658            hitpoints   num_features  4\n",
       "310       0.363711             aoe_bool  bool_features  4\n",
       "1007      0.363058    death_damage_bool  bool_features  8\n",
       "311       0.359645    death_damage_bool  bool_features  4\n",
       "659       0.356988    death_damage_bool  bool_features  6\n",
       "833       0.353401    death_damage_bool  bool_features  7\n",
       "209       0.340280    has_friendly_buff        all_col  4\n",
       "383       0.329861    has_friendly_buff        all_col  5\n",
       "194       0.328255           any_target        all_col  4\n",
       "180       0.326902           can_evolve        all_col  4\n",
       "208       0.324159  special_attack_type        all_col  4\n",
       "274       0.308411    has_friendly_buff       original  4\n",
       "246       0.304143           elixircost       original  4\n",
       "283       0.297459          air_control       original  4\n",
       "71        0.297026           can_evolve       original  3\n",
       "242       0.296378    death_damage_bool       original  4"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sim.sort_values('gmm_building', ascending=False).groupby('og_col').head(5)[['gmm_building', 'col', 'og_col', 'K']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1746cfbc-7ad5-44b1-9fdc-2614bd5e8144",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gmm_troop</th>\n",
       "      <th>col</th>\n",
       "      <th>og_col</th>\n",
       "      <th>K</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>0.320096</td>\n",
       "      <td>attack_count</td>\n",
       "      <td>num_features</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>0.252432</td>\n",
       "      <td>speed</td>\n",
       "      <td>num_features</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>0.238237</td>\n",
       "      <td>damage_per_second</td>\n",
       "      <td>engineered</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>0.225847</td>\n",
       "      <td>damage_by_hitpoints</td>\n",
       "      <td>engineered</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236</th>\n",
       "      <td>0.216522</td>\n",
       "      <td>damage_by_hitpoints</td>\n",
       "      <td>engineered</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>581</th>\n",
       "      <td>0.213485</td>\n",
       "      <td>damage_per_second</td>\n",
       "      <td>engineered</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>480</th>\n",
       "      <td>0.211469</td>\n",
       "      <td>aoe_by_damage</td>\n",
       "      <td>num_features</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>0.206269</td>\n",
       "      <td>aoe_by_range</td>\n",
       "      <td>num_features</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>0.203116</td>\n",
       "      <td>damage_per_elixir</td>\n",
       "      <td>engineered</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>0.201470</td>\n",
       "      <td>count</td>\n",
       "      <td>num_features</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1043</th>\n",
       "      <td>0.181814</td>\n",
       "      <td>mini_tank</td>\n",
       "      <td>bool_features</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500</th>\n",
       "      <td>0.172237</td>\n",
       "      <td>single_damage_type</td>\n",
       "      <td>bool_features</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>333</th>\n",
       "      <td>0.166453</td>\n",
       "      <td>special_attack_type</td>\n",
       "      <td>bool_features</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>673</th>\n",
       "      <td>0.164025</td>\n",
       "      <td>has_periodic_spawn</td>\n",
       "      <td>bool_features</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>841</th>\n",
       "      <td>0.163496</td>\n",
       "      <td>has_ability</td>\n",
       "      <td>bool_features</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>277</th>\n",
       "      <td>0.127619</td>\n",
       "      <td>no_attack</td>\n",
       "      <td>original</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>419</th>\n",
       "      <td>0.124848</td>\n",
       "      <td>can_evolve</td>\n",
       "      <td>original</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>634</th>\n",
       "      <td>0.124345</td>\n",
       "      <td>high_dps</td>\n",
       "      <td>original</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>417</th>\n",
       "      <td>0.122181</td>\n",
       "      <td>fly_bool</td>\n",
       "      <td>original</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>0.121182</td>\n",
       "      <td>aoe_bool</td>\n",
       "      <td>original</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>576</th>\n",
       "      <td>0.117448</td>\n",
       "      <td>high_dps</td>\n",
       "      <td>all_col</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.114821</td>\n",
       "      <td>has_periodic_spawn</td>\n",
       "      <td>all_col</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222</th>\n",
       "      <td>0.114397</td>\n",
       "      <td>aoe_per_elixir</td>\n",
       "      <td>all_col</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>358</th>\n",
       "      <td>0.114077</td>\n",
       "      <td>count</td>\n",
       "      <td>all_col</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>0.113998</td>\n",
       "      <td>aoe_by_range</td>\n",
       "      <td>all_col</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      gmm_troop                  col         og_col  K\n",
       "123    0.320096         attack_count   num_features  3\n",
       "299    0.252432                speed   num_features  4\n",
       "59     0.238237    damage_per_second     engineered  3\n",
       "62     0.225847  damage_by_hitpoints     engineered  3\n",
       "236    0.216522  damage_by_hitpoints     engineered  4\n",
       "581    0.213485    damage_per_second     engineered  6\n",
       "480    0.211469        aoe_by_damage   num_features  5\n",
       "131    0.206269         aoe_by_range   num_features  3\n",
       "58     0.203116    damage_per_elixir     engineered  3\n",
       "120    0.201470                count   num_features  3\n",
       "1043   0.181814            mini_tank  bool_features  8\n",
       "500    0.172237   single_damage_type  bool_features  5\n",
       "333    0.166453  special_attack_type  bool_features  4\n",
       "673    0.164025   has_periodic_spawn  bool_features  6\n",
       "841    0.163496          has_ability  bool_features  7\n",
       "277    0.127619            no_attack       original  4\n",
       "419    0.124848           can_evolve       original  5\n",
       "634    0.124345             high_dps       original  6\n",
       "417    0.122181             fly_bool       original  5\n",
       "66     0.121182             aoe_bool       original  3\n",
       "576    0.117448             high_dps        all_col  6\n",
       "25     0.114821   has_periodic_spawn        all_col  3\n",
       "222    0.114397       aoe_per_elixir        all_col  4\n",
       "358    0.114077                count        all_col  5\n",
       "45     0.113998         aoe_by_range        all_col  3"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sim.sort_values('gmm_troop', ascending=False).groupby('og_col').head(5)[['gmm_troop', 'col', 'og_col', 'K']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "39b7d3fc-d946-4ace-ad59-a57b85a944cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sns.lineplot(data=sim, x='K', y='gmm_troop', hue='og_col')\n",
    "plt.title(\"GMM Silhouette for Troop\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5f841113-51b1-4ef0-9e30-3887b1f81095",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.lineplot(data=sim, x='K', y='km_troop', hue='og_col')\n",
    "plt.title(\"KM Silhouette for Troop\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b8ca7fef-a9ba-4007-8752-0f30d94a7d3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.lineplot(data=sim, x='K', y='km_building', hue='og_col')\n",
    "plt.title(\"KM Silhouette for Building\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f05729fe-936a-4f98-ac82-654724c6942c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.lineplot(data=sim, x='K', y='gmm_building', hue='og_col')\n",
    "plt.title(\"GMM Silhouette for Building\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "94cb3a9e-27df-44dc-adb2-ff31518a988b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.lineplot(data=sim, x='K', y='km_spell', hue='og_col')\n",
    "plt.title(\"KM Silhouette for spell\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "32ccb670-1200-42d8-8991-8f0de5e66ab8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.lineplot(data=sim, x='K', y='gmm_spell', hue='og_col')\n",
    "plt.title(\"GMM Silhouette for Spell\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e2cd2733-b5bc-4687-8158-1ae09dd002a5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>gmm_troop</th>\n",
       "      <th>km_troop</th>\n",
       "      <th>gmm_spell</th>\n",
       "      <th>km_spell</th>\n",
       "      <th>gmm_building</th>\n",
       "      <th>km_building</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>og_col</th>\n",
       "      <th>K</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">all_col</th>\n",
       "      <th>3</th>\n",
       "      <td>0.061260</td>\n",
       "      <td>0.109120</td>\n",
       "      <td>0.100547</td>\n",
       "      <td>0.197973</td>\n",
       "      <td>0.298653</td>\n",
       "      <td>0.298653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.048633</td>\n",
       "      <td>0.110003</td>\n",
       "      <td>0.160162</td>\n",
       "      <td>0.189045</td>\n",
       "      <td>0.309983</td>\n",
       "      <td>0.315625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.033926</td>\n",
       "      <td>0.116842</td>\n",
       "      <td>0.181591</td>\n",
       "      <td>0.194222</td>\n",
       "      <td>0.306197</td>\n",
       "      <td>0.306197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.036807</td>\n",
       "      <td>0.115558</td>\n",
       "      <td>0.194815</td>\n",
       "      <td>0.205027</td>\n",
       "      <td>0.267661</td>\n",
       "      <td>0.267661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.019886</td>\n",
       "      <td>0.121924</td>\n",
       "      <td>0.185576</td>\n",
       "      <td>0.204109</td>\n",
       "      <td>0.252368</td>\n",
       "      <td>0.252368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.017193</td>\n",
       "      <td>0.119316</td>\n",
       "      <td>0.194091</td>\n",
       "      <td>0.197899</td>\n",
       "      <td>0.200209</td>\n",
       "      <td>0.200209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">bool_features</th>\n",
       "      <th>3</th>\n",
       "      <td>0.078640</td>\n",
       "      <td>0.143522</td>\n",
       "      <td>0.234302</td>\n",
       "      <td>0.249235</td>\n",
       "      <td>0.255259</td>\n",
       "      <td>0.345070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.055719</td>\n",
       "      <td>0.157227</td>\n",
       "      <td>0.220261</td>\n",
       "      <td>0.320401</td>\n",
       "      <td>0.279435</td>\n",
       "      <td>0.311880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.072281</td>\n",
       "      <td>0.156941</td>\n",
       "      <td>0.333282</td>\n",
       "      <td>0.345899</td>\n",
       "      <td>0.306709</td>\n",
       "      <td>0.313358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.075763</td>\n",
       "      <td>0.163864</td>\n",
       "      <td>0.385245</td>\n",
       "      <td>0.375266</td>\n",
       "      <td>0.300050</td>\n",
       "      <td>0.304126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.073131</td>\n",
       "      <td>0.168841</td>\n",
       "      <td>0.410991</td>\n",
       "      <td>0.413550</td>\n",
       "      <td>0.273117</td>\n",
       "      <td>0.301397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.082414</td>\n",
       "      <td>0.166582</td>\n",
       "      <td>0.414301</td>\n",
       "      <td>0.415712</td>\n",
       "      <td>0.263128</td>\n",
       "      <td>0.262491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">engineered</th>\n",
       "      <th>3</th>\n",
       "      <td>0.126717</td>\n",
       "      <td>0.240220</td>\n",
       "      <td>0.300715</td>\n",
       "      <td>0.396293</td>\n",
       "      <td>0.448241</td>\n",
       "      <td>0.526897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.121115</td>\n",
       "      <td>0.274322</td>\n",
       "      <td>0.221392</td>\n",
       "      <td>0.412036</td>\n",
       "      <td>0.642514</td>\n",
       "      <td>0.675272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.069195</td>\n",
       "      <td>0.265249</td>\n",
       "      <td>0.277769</td>\n",
       "      <td>0.450809</td>\n",
       "      <td>0.619573</td>\n",
       "      <td>0.639590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.081729</td>\n",
       "      <td>0.278086</td>\n",
       "      <td>0.224223</td>\n",
       "      <td>0.475773</td>\n",
       "      <td>0.552077</td>\n",
       "      <td>0.552077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.016154</td>\n",
       "      <td>0.267024</td>\n",
       "      <td>0.208513</td>\n",
       "      <td>0.442088</td>\n",
       "      <td>0.400408</td>\n",
       "      <td>0.460018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.054583</td>\n",
       "      <td>0.263978</td>\n",
       "      <td>0.174385</td>\n",
       "      <td>0.428799</td>\n",
       "      <td>0.364772</td>\n",
       "      <td>0.364772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">num_features</th>\n",
       "      <th>3</th>\n",
       "      <td>0.144218</td>\n",
       "      <td>0.215697</td>\n",
       "      <td>0.259560</td>\n",
       "      <td>0.322888</td>\n",
       "      <td>0.334146</td>\n",
       "      <td>0.352110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.120319</td>\n",
       "      <td>0.180067</td>\n",
       "      <td>0.277510</td>\n",
       "      <td>0.372419</td>\n",
       "      <td>0.443549</td>\n",
       "      <td>0.443549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.094090</td>\n",
       "      <td>0.148208</td>\n",
       "      <td>0.258873</td>\n",
       "      <td>0.354804</td>\n",
       "      <td>0.381136</td>\n",
       "      <td>0.381136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.057904</td>\n",
       "      <td>0.149158</td>\n",
       "      <td>0.269924</td>\n",
       "      <td>0.313807</td>\n",
       "      <td>0.318701</td>\n",
       "      <td>0.320122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.074587</td>\n",
       "      <td>0.155065</td>\n",
       "      <td>0.229377</td>\n",
       "      <td>0.300690</td>\n",
       "      <td>0.307400</td>\n",
       "      <td>0.306580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.063695</td>\n",
       "      <td>0.156262</td>\n",
       "      <td>0.214297</td>\n",
       "      <td>0.307021</td>\n",
       "      <td>0.251686</td>\n",
       "      <td>0.251686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">original</th>\n",
       "      <th>3</th>\n",
       "      <td>0.072559</td>\n",
       "      <td>0.117650</td>\n",
       "      <td>0.153511</td>\n",
       "      <td>0.189827</td>\n",
       "      <td>0.277305</td>\n",
       "      <td>0.278757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.034955</td>\n",
       "      <td>0.124183</td>\n",
       "      <td>0.167712</td>\n",
       "      <td>0.212895</td>\n",
       "      <td>0.275843</td>\n",
       "      <td>0.275237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.041021</td>\n",
       "      <td>0.129959</td>\n",
       "      <td>0.178212</td>\n",
       "      <td>0.204828</td>\n",
       "      <td>0.261946</td>\n",
       "      <td>0.264886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.005015</td>\n",
       "      <td>0.130865</td>\n",
       "      <td>0.241185</td>\n",
       "      <td>0.242140</td>\n",
       "      <td>0.239044</td>\n",
       "      <td>0.239044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.020906</td>\n",
       "      <td>0.127046</td>\n",
       "      <td>0.239334</td>\n",
       "      <td>0.244261</td>\n",
       "      <td>0.232876</td>\n",
       "      <td>0.232876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.031625</td>\n",
       "      <td>0.130726</td>\n",
       "      <td>0.209970</td>\n",
       "      <td>0.233186</td>\n",
       "      <td>0.198317</td>\n",
       "      <td>0.198317</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 gmm_troop  km_troop  gmm_spell  km_spell  gmm_building  \\\n",
       "og_col        K                                                           \n",
       "all_col       3   0.061260  0.109120   0.100547  0.197973      0.298653   \n",
       "              4   0.048633  0.110003   0.160162  0.189045      0.309983   \n",
       "              5   0.033926  0.116842   0.181591  0.194222      0.306197   \n",
       "              6   0.036807  0.115558   0.194815  0.205027      0.267661   \n",
       "              7   0.019886  0.121924   0.185576  0.204109      0.252368   \n",
       "              8   0.017193  0.119316   0.194091  0.197899      0.200209   \n",
       "bool_features 3   0.078640  0.143522   0.234302  0.249235      0.255259   \n",
       "              4   0.055719  0.157227   0.220261  0.320401      0.279435   \n",
       "              5   0.072281  0.156941   0.333282  0.345899      0.306709   \n",
       "              6   0.075763  0.163864   0.385245  0.375266      0.300050   \n",
       "              7   0.073131  0.168841   0.410991  0.413550      0.273117   \n",
       "              8   0.082414  0.166582   0.414301  0.415712      0.263128   \n",
       "engineered    3   0.126717  0.240220   0.300715  0.396293      0.448241   \n",
       "              4   0.121115  0.274322   0.221392  0.412036      0.642514   \n",
       "              5   0.069195  0.265249   0.277769  0.450809      0.619573   \n",
       "              6   0.081729  0.278086   0.224223  0.475773      0.552077   \n",
       "              7   0.016154  0.267024   0.208513  0.442088      0.400408   \n",
       "              8   0.054583  0.263978   0.174385  0.428799      0.364772   \n",
       "num_features  3   0.144218  0.215697   0.259560  0.322888      0.334146   \n",
       "              4   0.120319  0.180067   0.277510  0.372419      0.443549   \n",
       "              5   0.094090  0.148208   0.258873  0.354804      0.381136   \n",
       "              6   0.057904  0.149158   0.269924  0.313807      0.318701   \n",
       "              7   0.074587  0.155065   0.229377  0.300690      0.307400   \n",
       "              8   0.063695  0.156262   0.214297  0.307021      0.251686   \n",
       "original      3   0.072559  0.117650   0.153511  0.189827      0.277305   \n",
       "              4   0.034955  0.124183   0.167712  0.212895      0.275843   \n",
       "              5   0.041021  0.129959   0.178212  0.204828      0.261946   \n",
       "              6   0.005015  0.130865   0.241185  0.242140      0.239044   \n",
       "              7   0.020906  0.127046   0.239334  0.244261      0.232876   \n",
       "              8   0.031625  0.130726   0.209970  0.233186      0.198317   \n",
       "\n",
       "                 km_building  \n",
       "og_col        K               \n",
       "all_col       3     0.298653  \n",
       "              4     0.315625  \n",
       "              5     0.306197  \n",
       "              6     0.267661  \n",
       "              7     0.252368  \n",
       "              8     0.200209  \n",
       "bool_features 3     0.345070  \n",
       "              4     0.311880  \n",
       "              5     0.313358  \n",
       "              6     0.304126  \n",
       "              7     0.301397  \n",
       "              8     0.262491  \n",
       "engineered    3     0.526897  \n",
       "              4     0.675272  \n",
       "              5     0.639590  \n",
       "              6     0.552077  \n",
       "              7     0.460018  \n",
       "              8     0.364772  \n",
       "num_features  3     0.352110  \n",
       "              4     0.443549  \n",
       "              5     0.381136  \n",
       "              6     0.320122  \n",
       "              7     0.306580  \n",
       "              8     0.251686  \n",
       "original      3     0.278757  \n",
       "              4     0.275237  \n",
       "              5     0.264886  \n",
       "              6     0.239044  \n",
       "              7     0.232876  \n",
       "              8     0.198317  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sim.groupby(['og_col', 'K'])[\n",
    "    ['gmm_troop', 'km_troop', 'gmm_spell', 'km_spell', 'gmm_building', 'km_building']\n",
    "].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "85528196-5eba-4b2d-b807-3d732b22ce3e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">gmm_troop</th>\n",
       "      <th colspan=\"2\" halign=\"left\">km_troop</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>col</th>\n",
       "      <th>K</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">affected_crown</th>\n",
       "      <th>3</th>\n",
       "      <td>0.094126</td>\n",
       "      <td>0.008280</td>\n",
       "      <td>0.124799</td>\n",
       "      <td>0.020214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.069223</td>\n",
       "      <td>0.037659</td>\n",
       "      <td>0.133204</td>\n",
       "      <td>0.028431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.030792</td>\n",
       "      <td>0.035756</td>\n",
       "      <td>0.140777</td>\n",
       "      <td>0.017097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.030736</td>\n",
       "      <td>0.017356</td>\n",
       "      <td>0.146431</td>\n",
       "      <td>0.018452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.043191</td>\n",
       "      <td>0.041455</td>\n",
       "      <td>0.149410</td>\n",
       "      <td>0.026193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.045520</td>\n",
       "      <td>0.053020</td>\n",
       "      <td>0.131322</td>\n",
       "      <td>0.035580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">air_control</th>\n",
       "      <th>3</th>\n",
       "      <td>0.048843</td>\n",
       "      <td>0.044723</td>\n",
       "      <td>0.120676</td>\n",
       "      <td>0.018083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.016463</td>\n",
       "      <td>0.036054</td>\n",
       "      <td>0.133799</td>\n",
       "      <td>0.022673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.015743</td>\n",
       "      <td>0.047331</td>\n",
       "      <td>0.123658</td>\n",
       "      <td>0.007315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.032132</td>\n",
       "      <td>0.063110</td>\n",
       "      <td>0.137806</td>\n",
       "      <td>0.024282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-0.010683</td>\n",
       "      <td>0.047982</td>\n",
       "      <td>0.144042</td>\n",
       "      <td>0.027295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.035399</td>\n",
       "      <td>0.032943</td>\n",
       "      <td>0.146583</td>\n",
       "      <td>0.023434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">any_target</th>\n",
       "      <th>3</th>\n",
       "      <td>0.080361</td>\n",
       "      <td>0.023343</td>\n",
       "      <td>0.109444</td>\n",
       "      <td>0.012465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.033898</td>\n",
       "      <td>0.026000</td>\n",
       "      <td>0.118099</td>\n",
       "      <td>0.018233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.065076</td>\n",
       "      <td>0.019250</td>\n",
       "      <td>0.125828</td>\n",
       "      <td>0.016265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.025195</td>\n",
       "      <td>0.058495</td>\n",
       "      <td>0.129916</td>\n",
       "      <td>0.019937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.037686</td>\n",
       "      <td>0.053231</td>\n",
       "      <td>0.113771</td>\n",
       "      <td>0.037686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-0.030166</td>\n",
       "      <td>0.038779</td>\n",
       "      <td>0.133343</td>\n",
       "      <td>0.026435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">aoe_bool</th>\n",
       "      <th>3</th>\n",
       "      <td>0.064388</td>\n",
       "      <td>0.055798</td>\n",
       "      <td>0.127585</td>\n",
       "      <td>0.021016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.073929</td>\n",
       "      <td>0.018463</td>\n",
       "      <td>0.125580</td>\n",
       "      <td>0.024182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.016709</td>\n",
       "      <td>0.081311</td>\n",
       "      <td>0.142278</td>\n",
       "      <td>0.019615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.010192</td>\n",
       "      <td>0.097613</td>\n",
       "      <td>0.146507</td>\n",
       "      <td>0.031756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.054610</td>\n",
       "      <td>0.035457</td>\n",
       "      <td>0.149663</td>\n",
       "      <td>0.016180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.045572</td>\n",
       "      <td>0.057059</td>\n",
       "      <td>0.140079</td>\n",
       "      <td>0.028491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">aoe_by_damage</th>\n",
       "      <th>3</th>\n",
       "      <td>0.100059</td>\n",
       "      <td>0.055804</td>\n",
       "      <td>0.180112</td>\n",
       "      <td>0.054743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.063544</td>\n",
       "      <td>0.051580</td>\n",
       "      <td>0.174364</td>\n",
       "      <td>0.079882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.080181</td>\n",
       "      <td>0.117986</td>\n",
       "      <td>0.176884</td>\n",
       "      <td>0.057111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-0.046563</td>\n",
       "      <td>0.046565</td>\n",
       "      <td>0.175699</td>\n",
       "      <td>0.064230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.006029</td>\n",
       "      <td>0.135561</td>\n",
       "      <td>0.166035</td>\n",
       "      <td>0.050260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.032133</td>\n",
       "      <td>0.006325</td>\n",
       "      <td>0.169984</td>\n",
       "      <td>0.071133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">aoe_by_range</th>\n",
       "      <th>3</th>\n",
       "      <td>0.165719</td>\n",
       "      <td>0.047139</td>\n",
       "      <td>0.172907</td>\n",
       "      <td>0.067758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.056075</td>\n",
       "      <td>0.136134</td>\n",
       "      <td>0.161017</td>\n",
       "      <td>0.058812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.073548</td>\n",
       "      <td>0.066198</td>\n",
       "      <td>0.174858</td>\n",
       "      <td>0.060358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-0.043072</td>\n",
       "      <td>0.118946</td>\n",
       "      <td>0.165811</td>\n",
       "      <td>0.082756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.036591</td>\n",
       "      <td>0.060059</td>\n",
       "      <td>0.178533</td>\n",
       "      <td>0.062770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.036805</td>\n",
       "      <td>0.095696</td>\n",
       "      <td>0.180924</td>\n",
       "      <td>0.071318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">aoe_per_elixir</th>\n",
       "      <th>3</th>\n",
       "      <td>0.085487</td>\n",
       "      <td>0.030774</td>\n",
       "      <td>0.150879</td>\n",
       "      <td>0.066917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.073454</td>\n",
       "      <td>0.069309</td>\n",
       "      <td>0.124840</td>\n",
       "      <td>0.008265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.020414</td>\n",
       "      <td>0.061679</td>\n",
       "      <td>0.129167</td>\n",
       "      <td>0.007751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.043141</td>\n",
       "      <td>0.014311</td>\n",
       "      <td>0.142188</td>\n",
       "      <td>0.015065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.065467</td>\n",
       "      <td>0.089365</td>\n",
       "      <td>0.126196</td>\n",
       "      <td>0.015011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.083131</td>\n",
       "      <td>0.019143</td>\n",
       "      <td>0.137227</td>\n",
       "      <td>0.014154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">aoe_radius</th>\n",
       "      <th>3</th>\n",
       "      <td>0.079076</td>\n",
       "      <td>0.065682</td>\n",
       "      <td>0.149200</td>\n",
       "      <td>0.058189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.092485</td>\n",
       "      <td>0.065739</td>\n",
       "      <td>0.129380</td>\n",
       "      <td>0.012691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.040463</td>\n",
       "      <td>0.046285</td>\n",
       "      <td>0.142208</td>\n",
       "      <td>0.024325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-0.009554</td>\n",
       "      <td>0.143278</td>\n",
       "      <td>0.143503</td>\n",
       "      <td>0.012084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.079103</td>\n",
       "      <td>0.059993</td>\n",
       "      <td>0.125789</td>\n",
       "      <td>0.026364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.067830</td>\n",
       "      <td>0.046025</td>\n",
       "      <td>0.128673</td>\n",
       "      <td>0.013324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">attack_count</th>\n",
       "      <th>3</th>\n",
       "      <td>0.133584</td>\n",
       "      <td>0.161947</td>\n",
       "      <td>0.128658</td>\n",
       "      <td>0.013192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.079198</td>\n",
       "      <td>0.093078</td>\n",
       "      <td>0.129883</td>\n",
       "      <td>0.022146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.062360</td>\n",
       "      <td>0.046702</td>\n",
       "      <td>0.126084</td>\n",
       "      <td>0.025517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.071521</td>\n",
       "      <td>0.091191</td>\n",
       "      <td>0.126391</td>\n",
       "      <td>0.018459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.076852</td>\n",
       "      <td>0.081896</td>\n",
       "      <td>0.130984</td>\n",
       "      <td>0.018297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.052913</td>\n",
       "      <td>0.064331</td>\n",
       "      <td>0.143148</td>\n",
       "      <td>0.008717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">building_target</th>\n",
       "      <th>3</th>\n",
       "      <td>0.080361</td>\n",
       "      <td>0.023343</td>\n",
       "      <td>0.109444</td>\n",
       "      <td>0.012465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.033898</td>\n",
       "      <td>0.026000</td>\n",
       "      <td>0.118099</td>\n",
       "      <td>0.018233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.065076</td>\n",
       "      <td>0.019250</td>\n",
       "      <td>0.125828</td>\n",
       "      <td>0.016265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.025195</td>\n",
       "      <td>0.058495</td>\n",
       "      <td>0.129916</td>\n",
       "      <td>0.019937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.037686</td>\n",
       "      <td>0.053231</td>\n",
       "      <td>0.113771</td>\n",
       "      <td>0.037686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-0.030166</td>\n",
       "      <td>0.038779</td>\n",
       "      <td>0.133343</td>\n",
       "      <td>0.026435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">can_evolve</th>\n",
       "      <th>3</th>\n",
       "      <td>0.110575</td>\n",
       "      <td>0.080020</td>\n",
       "      <td>0.160145</td>\n",
       "      <td>0.075840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.094461</td>\n",
       "      <td>0.038175</td>\n",
       "      <td>0.151424</td>\n",
       "      <td>0.064106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.109285</td>\n",
       "      <td>0.053756</td>\n",
       "      <td>0.124993</td>\n",
       "      <td>0.011361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-0.005124</td>\n",
       "      <td>0.052602</td>\n",
       "      <td>0.144126</td>\n",
       "      <td>0.018577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.038299</td>\n",
       "      <td>0.022495</td>\n",
       "      <td>0.143059</td>\n",
       "      <td>0.015308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.051218</td>\n",
       "      <td>0.035864</td>\n",
       "      <td>0.139448</td>\n",
       "      <td>0.027140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">control_special</th>\n",
       "      <th>3</th>\n",
       "      <td>0.070653</td>\n",
       "      <td>0.029471</td>\n",
       "      <td>0.123866</td>\n",
       "      <td>0.019768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.074564</td>\n",
       "      <td>0.016448</td>\n",
       "      <td>0.132188</td>\n",
       "      <td>0.019782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.083479</td>\n",
       "      <td>0.056713</td>\n",
       "      <td>0.140854</td>\n",
       "      <td>0.019905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.045667</td>\n",
       "      <td>0.026755</td>\n",
       "      <td>0.138951</td>\n",
       "      <td>0.017568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-0.000771</td>\n",
       "      <td>0.045563</td>\n",
       "      <td>0.140668</td>\n",
       "      <td>0.020803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.032156</td>\n",
       "      <td>0.022693</td>\n",
       "      <td>0.139219</td>\n",
       "      <td>0.019586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">count</th>\n",
       "      <th>3</th>\n",
       "      <td>0.103725</td>\n",
       "      <td>0.085307</td>\n",
       "      <td>0.143328</td>\n",
       "      <td>0.050020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.031059</td>\n",
       "      <td>0.041615</td>\n",
       "      <td>0.131990</td>\n",
       "      <td>0.022645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.089107</td>\n",
       "      <td>0.021949</td>\n",
       "      <td>0.128717</td>\n",
       "      <td>0.012865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.102209</td>\n",
       "      <td>0.072344</td>\n",
       "      <td>0.122740</td>\n",
       "      <td>0.029362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.045974</td>\n",
       "      <td>0.038870</td>\n",
       "      <td>0.129941</td>\n",
       "      <td>0.024476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.047843</td>\n",
       "      <td>0.057746</td>\n",
       "      <td>0.129015</td>\n",
       "      <td>0.009661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">damage</th>\n",
       "      <th>3</th>\n",
       "      <td>0.048325</td>\n",
       "      <td>0.014134</td>\n",
       "      <td>0.152614</td>\n",
       "      <td>0.071159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.105626</td>\n",
       "      <td>0.077953</td>\n",
       "      <td>0.129587</td>\n",
       "      <td>0.013001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.060747</td>\n",
       "      <td>0.069484</td>\n",
       "      <td>0.130625</td>\n",
       "      <td>0.019266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.056990</td>\n",
       "      <td>0.015207</td>\n",
       "      <td>0.135885</td>\n",
       "      <td>0.007875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.044247</td>\n",
       "      <td>0.026939</td>\n",
       "      <td>0.140710</td>\n",
       "      <td>0.010509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.024670</td>\n",
       "      <td>0.033268</td>\n",
       "      <td>0.130513</td>\n",
       "      <td>0.028078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">damage_by_hitpoints</th>\n",
       "      <th>3</th>\n",
       "      <td>0.126995</td>\n",
       "      <td>0.088519</td>\n",
       "      <td>0.187489</td>\n",
       "      <td>0.071213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.147123</td>\n",
       "      <td>0.088133</td>\n",
       "      <td>0.190136</td>\n",
       "      <td>0.070952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.031608</td>\n",
       "      <td>0.055062</td>\n",
       "      <td>0.176205</td>\n",
       "      <td>0.087772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.010142</td>\n",
       "      <td>0.133430</td>\n",
       "      <td>0.170260</td>\n",
       "      <td>0.097274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.108938</td>\n",
       "      <td>0.050585</td>\n",
       "      <td>0.198824</td>\n",
       "      <td>0.081342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.047170</td>\n",
       "      <td>0.020880</td>\n",
       "      <td>0.178483</td>\n",
       "      <td>0.086593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">damage_output</th>\n",
       "      <th>3</th>\n",
       "      <td>0.108694</td>\n",
       "      <td>0.055228</td>\n",
       "      <td>0.190176</td>\n",
       "      <td>0.071772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.087892</td>\n",
       "      <td>0.039218</td>\n",
       "      <td>0.170265</td>\n",
       "      <td>0.084163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.033610</td>\n",
       "      <td>0.069081</td>\n",
       "      <td>0.181605</td>\n",
       "      <td>0.077598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.091087</td>\n",
       "      <td>0.061080</td>\n",
       "      <td>0.175118</td>\n",
       "      <td>0.104916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.007838</td>\n",
       "      <td>0.089238</td>\n",
       "      <td>0.187159</td>\n",
       "      <td>0.100960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.052043</td>\n",
       "      <td>0.060369</td>\n",
       "      <td>0.179300</td>\n",
       "      <td>0.097068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">damage_output_ps</th>\n",
       "      <th>3</th>\n",
       "      <td>0.032588</td>\n",
       "      <td>0.083197</td>\n",
       "      <td>0.127444</td>\n",
       "      <td>0.024996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.007478</td>\n",
       "      <td>0.026716</td>\n",
       "      <td>0.135389</td>\n",
       "      <td>0.027441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.103335</td>\n",
       "      <td>0.043228</td>\n",
       "      <td>0.128737</td>\n",
       "      <td>0.018788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.013272</td>\n",
       "      <td>0.043145</td>\n",
       "      <td>0.122988</td>\n",
       "      <td>0.025698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-0.015188</td>\n",
       "      <td>0.069949</td>\n",
       "      <td>0.129242</td>\n",
       "      <td>0.031973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-0.066056</td>\n",
       "      <td>0.124790</td>\n",
       "      <td>0.140471</td>\n",
       "      <td>0.023371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">damage_per_elixir</th>\n",
       "      <th>3</th>\n",
       "      <td>0.148524</td>\n",
       "      <td>0.083834</td>\n",
       "      <td>0.177318</td>\n",
       "      <td>0.061474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.086360</td>\n",
       "      <td>0.079900</td>\n",
       "      <td>0.212173</td>\n",
       "      <td>0.081280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.051430</td>\n",
       "      <td>0.071580</td>\n",
       "      <td>0.166794</td>\n",
       "      <td>0.060028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.118439</td>\n",
       "      <td>0.054004</td>\n",
       "      <td>0.183318</td>\n",
       "      <td>0.079158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.050193</td>\n",
       "      <td>0.073727</td>\n",
       "      <td>0.182659</td>\n",
       "      <td>0.084172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.061727</td>\n",
       "      <td>0.063862</td>\n",
       "      <td>0.172554</td>\n",
       "      <td>0.056261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">damage_per_second</th>\n",
       "      <th>3</th>\n",
       "      <td>0.111873</td>\n",
       "      <td>0.111188</td>\n",
       "      <td>0.190488</td>\n",
       "      <td>0.072512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.058122</td>\n",
       "      <td>0.127028</td>\n",
       "      <td>0.192879</td>\n",
       "      <td>0.072932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.148717</td>\n",
       "      <td>0.064975</td>\n",
       "      <td>0.175001</td>\n",
       "      <td>0.079769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.128311</td>\n",
       "      <td>0.120777</td>\n",
       "      <td>0.181681</td>\n",
       "      <td>0.085207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-0.035139</td>\n",
       "      <td>0.051355</td>\n",
       "      <td>0.197109</td>\n",
       "      <td>0.076079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.116651</td>\n",
       "      <td>0.063006</td>\n",
       "      <td>0.194952</td>\n",
       "      <td>0.078031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">death_damage_bool</th>\n",
       "      <th>3</th>\n",
       "      <td>0.042088</td>\n",
       "      <td>0.008504</td>\n",
       "      <td>0.127395</td>\n",
       "      <td>0.017617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.032412</td>\n",
       "      <td>0.026837</td>\n",
       "      <td>0.136445</td>\n",
       "      <td>0.026929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.059997</td>\n",
       "      <td>0.009074</td>\n",
       "      <td>0.143067</td>\n",
       "      <td>0.028308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.062146</td>\n",
       "      <td>0.052987</td>\n",
       "      <td>0.143760</td>\n",
       "      <td>0.032988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.034129</td>\n",
       "      <td>0.042233</td>\n",
       "      <td>0.142324</td>\n",
       "      <td>0.029545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.073213</td>\n",
       "      <td>0.015139</td>\n",
       "      <td>0.152396</td>\n",
       "      <td>0.026131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">dps_special</th>\n",
       "      <th>3</th>\n",
       "      <td>0.086334</td>\n",
       "      <td>0.053093</td>\n",
       "      <td>0.127543</td>\n",
       "      <td>0.014920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.086012</td>\n",
       "      <td>0.133494</td>\n",
       "      <td>0.022119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.058998</td>\n",
       "      <td>0.046268</td>\n",
       "      <td>0.140824</td>\n",
       "      <td>0.026162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.035547</td>\n",
       "      <td>0.016356</td>\n",
       "      <td>0.143127</td>\n",
       "      <td>0.021521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.043664</td>\n",
       "      <td>0.060361</td>\n",
       "      <td>0.154453</td>\n",
       "      <td>0.025570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.049857</td>\n",
       "      <td>0.021610</td>\n",
       "      <td>0.144330</td>\n",
       "      <td>0.005341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">elixircost</th>\n",
       "      <th>3</th>\n",
       "      <td>0.097466</td>\n",
       "      <td>0.007579</td>\n",
       "      <td>0.151371</td>\n",
       "      <td>0.083858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.081915</td>\n",
       "      <td>0.063156</td>\n",
       "      <td>0.156115</td>\n",
       "      <td>0.075181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.064042</td>\n",
       "      <td>0.076671</td>\n",
       "      <td>0.139022</td>\n",
       "      <td>0.054358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.030833</td>\n",
       "      <td>0.105095</td>\n",
       "      <td>0.125897</td>\n",
       "      <td>0.022846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.058145</td>\n",
       "      <td>0.053656</td>\n",
       "      <td>0.128647</td>\n",
       "      <td>0.022894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.022254</td>\n",
       "      <td>0.053646</td>\n",
       "      <td>0.131286</td>\n",
       "      <td>0.028795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">fly_bool</th>\n",
       "      <th>3</th>\n",
       "      <td>0.080208</td>\n",
       "      <td>0.046551</td>\n",
       "      <td>0.127525</td>\n",
       "      <td>0.021121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.047213</td>\n",
       "      <td>0.026420</td>\n",
       "      <td>0.134393</td>\n",
       "      <td>0.027968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.023315</td>\n",
       "      <td>0.107774</td>\n",
       "      <td>0.139463</td>\n",
       "      <td>0.016205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.054173</td>\n",
       "      <td>0.023724</td>\n",
       "      <td>0.144679</td>\n",
       "      <td>0.017051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.001501</td>\n",
       "      <td>0.057911</td>\n",
       "      <td>0.149560</td>\n",
       "      <td>0.021106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.050281</td>\n",
       "      <td>0.049261</td>\n",
       "      <td>0.138709</td>\n",
       "      <td>0.029855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">ground_dps</th>\n",
       "      <th>3</th>\n",
       "      <td>0.059654</td>\n",
       "      <td>0.026325</td>\n",
       "      <td>0.125173</td>\n",
       "      <td>0.018935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.023476</td>\n",
       "      <td>0.040014</td>\n",
       "      <td>0.132026</td>\n",
       "      <td>0.022892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-0.000300</td>\n",
       "      <td>0.044086</td>\n",
       "      <td>0.129516</td>\n",
       "      <td>0.020888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-0.007622</td>\n",
       "      <td>0.059831</td>\n",
       "      <td>0.144639</td>\n",
       "      <td>0.027558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.043584</td>\n",
       "      <td>0.024394</td>\n",
       "      <td>0.134551</td>\n",
       "      <td>0.034447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.067460</td>\n",
       "      <td>0.058817</td>\n",
       "      <td>0.132990</td>\n",
       "      <td>0.028600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">ground_target</th>\n",
       "      <th>3</th>\n",
       "      <td>0.086986</td>\n",
       "      <td>0.013722</td>\n",
       "      <td>0.113451</td>\n",
       "      <td>0.007446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.028192</td>\n",
       "      <td>0.048073</td>\n",
       "      <td>0.121113</td>\n",
       "      <td>0.018984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.052845</td>\n",
       "      <td>0.003653</td>\n",
       "      <td>0.118434</td>\n",
       "      <td>0.003932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.020289</td>\n",
       "      <td>0.055160</td>\n",
       "      <td>0.128837</td>\n",
       "      <td>0.031124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.003343</td>\n",
       "      <td>0.056316</td>\n",
       "      <td>0.129453</td>\n",
       "      <td>0.032136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.044314</td>\n",
       "      <td>0.004880</td>\n",
       "      <td>0.127776</td>\n",
       "      <td>0.023778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">has_ability</th>\n",
       "      <th>3</th>\n",
       "      <td>0.098320</td>\n",
       "      <td>0.047959</td>\n",
       "      <td>0.126065</td>\n",
       "      <td>0.016172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.042599</td>\n",
       "      <td>0.041362</td>\n",
       "      <td>0.133291</td>\n",
       "      <td>0.028957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.080169</td>\n",
       "      <td>0.029204</td>\n",
       "      <td>0.139724</td>\n",
       "      <td>0.018890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.059883</td>\n",
       "      <td>0.018449</td>\n",
       "      <td>0.128960</td>\n",
       "      <td>0.031881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.077422</td>\n",
       "      <td>0.075603</td>\n",
       "      <td>0.134229</td>\n",
       "      <td>0.047796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.049995</td>\n",
       "      <td>0.101149</td>\n",
       "      <td>0.152026</td>\n",
       "      <td>0.027863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">has_friendly_buff</th>\n",
       "      <th>3</th>\n",
       "      <td>0.052461</td>\n",
       "      <td>0.025348</td>\n",
       "      <td>0.127950</td>\n",
       "      <td>0.016654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.007903</td>\n",
       "      <td>0.083810</td>\n",
       "      <td>0.134253</td>\n",
       "      <td>0.032943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.057068</td>\n",
       "      <td>0.027289</td>\n",
       "      <td>0.139254</td>\n",
       "      <td>0.021209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.025192</td>\n",
       "      <td>0.018209</td>\n",
       "      <td>0.140897</td>\n",
       "      <td>0.031102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.051639</td>\n",
       "      <td>0.069165</td>\n",
       "      <td>0.142068</td>\n",
       "      <td>0.019435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.084019</td>\n",
       "      <td>0.024714</td>\n",
       "      <td>0.151723</td>\n",
       "      <td>0.016201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">has_lifetime</th>\n",
       "      <th>3</th>\n",
       "      <td>0.082037</td>\n",
       "      <td>0.035785</td>\n",
       "      <td>0.123964</td>\n",
       "      <td>0.021838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.053398</td>\n",
       "      <td>0.030614</td>\n",
       "      <td>0.131591</td>\n",
       "      <td>0.017933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-0.000552</td>\n",
       "      <td>0.084837</td>\n",
       "      <td>0.134218</td>\n",
       "      <td>0.023525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.029006</td>\n",
       "      <td>0.062468</td>\n",
       "      <td>0.140365</td>\n",
       "      <td>0.032618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-0.009025</td>\n",
       "      <td>0.008862</td>\n",
       "      <td>0.139697</td>\n",
       "      <td>0.030299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.051452</td>\n",
       "      <td>0.048963</td>\n",
       "      <td>0.142432</td>\n",
       "      <td>0.029165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">has_periodic_spawn</th>\n",
       "      <th>3</th>\n",
       "      <td>0.118932</td>\n",
       "      <td>0.021690</td>\n",
       "      <td>0.126164</td>\n",
       "      <td>0.017003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.038205</td>\n",
       "      <td>0.073946</td>\n",
       "      <td>0.132200</td>\n",
       "      <td>0.031029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.048112</td>\n",
       "      <td>0.036546</td>\n",
       "      <td>0.140083</td>\n",
       "      <td>0.017536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.091888</td>\n",
       "      <td>0.062547</td>\n",
       "      <td>0.142194</td>\n",
       "      <td>0.030642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.075952</td>\n",
       "      <td>0.048574</td>\n",
       "      <td>0.143817</td>\n",
       "      <td>0.032113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.054018</td>\n",
       "      <td>0.036204</td>\n",
       "      <td>0.147073</td>\n",
       "      <td>0.032799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">has_ranged_attack</th>\n",
       "      <th>3</th>\n",
       "      <td>0.079667</td>\n",
       "      <td>0.044183</td>\n",
       "      <td>0.112101</td>\n",
       "      <td>0.012662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.057937</td>\n",
       "      <td>0.025094</td>\n",
       "      <td>0.121623</td>\n",
       "      <td>0.028991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.064714</td>\n",
       "      <td>0.025406</td>\n",
       "      <td>0.129085</td>\n",
       "      <td>0.017340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.047901</td>\n",
       "      <td>0.045695</td>\n",
       "      <td>0.122351</td>\n",
       "      <td>0.001703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.045342</td>\n",
       "      <td>0.043546</td>\n",
       "      <td>0.138156</td>\n",
       "      <td>0.031297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.061083</td>\n",
       "      <td>0.085103</td>\n",
       "      <td>0.137132</td>\n",
       "      <td>0.033046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">has_upon_breaking_spawn</th>\n",
       "      <th>3</th>\n",
       "      <td>0.080121</td>\n",
       "      <td>0.026328</td>\n",
       "      <td>0.128925</td>\n",
       "      <td>0.017513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.053438</td>\n",
       "      <td>0.068959</td>\n",
       "      <td>0.137015</td>\n",
       "      <td>0.028076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.047207</td>\n",
       "      <td>0.015674</td>\n",
       "      <td>0.138226</td>\n",
       "      <td>0.029268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.053355</td>\n",
       "      <td>0.042608</td>\n",
       "      <td>0.141334</td>\n",
       "      <td>0.020721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.044670</td>\n",
       "      <td>0.042516</td>\n",
       "      <td>0.138492</td>\n",
       "      <td>0.036918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.072448</td>\n",
       "      <td>0.018133</td>\n",
       "      <td>0.140902</td>\n",
       "      <td>0.023525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">has_upon_death_spawn</th>\n",
       "      <th>3</th>\n",
       "      <td>0.044800</td>\n",
       "      <td>0.011315</td>\n",
       "      <td>0.125351</td>\n",
       "      <td>0.018266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.025228</td>\n",
       "      <td>0.019881</td>\n",
       "      <td>0.135169</td>\n",
       "      <td>0.029089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.049892</td>\n",
       "      <td>0.049059</td>\n",
       "      <td>0.136477</td>\n",
       "      <td>0.017138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.055283</td>\n",
       "      <td>0.058561</td>\n",
       "      <td>0.132960</td>\n",
       "      <td>0.014177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.048073</td>\n",
       "      <td>0.032586</td>\n",
       "      <td>0.149544</td>\n",
       "      <td>0.028575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.031617</td>\n",
       "      <td>0.079279</td>\n",
       "      <td>0.125346</td>\n",
       "      <td>0.020112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">high_dps</th>\n",
       "      <th>3</th>\n",
       "      <td>0.048135</td>\n",
       "      <td>0.027130</td>\n",
       "      <td>0.120473</td>\n",
       "      <td>0.009885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.020045</td>\n",
       "      <td>0.037435</td>\n",
       "      <td>0.135516</td>\n",
       "      <td>0.028849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.027598</td>\n",
       "      <td>0.024552</td>\n",
       "      <td>0.142836</td>\n",
       "      <td>0.024829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.112984</td>\n",
       "      <td>0.014133</td>\n",
       "      <td>0.142809</td>\n",
       "      <td>0.026323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.030747</td>\n",
       "      <td>0.052581</td>\n",
       "      <td>0.146184</td>\n",
       "      <td>0.026854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.051864</td>\n",
       "      <td>0.068657</td>\n",
       "      <td>0.136980</td>\n",
       "      <td>0.029222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">hit_speed</th>\n",
       "      <th>3</th>\n",
       "      <td>0.120313</td>\n",
       "      <td>0.064354</td>\n",
       "      <td>0.154917</td>\n",
       "      <td>0.073531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.113315</td>\n",
       "      <td>0.070181</td>\n",
       "      <td>0.125052</td>\n",
       "      <td>0.011499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.073036</td>\n",
       "      <td>0.047941</td>\n",
       "      <td>0.130220</td>\n",
       "      <td>0.024718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.004988</td>\n",
       "      <td>0.104731</td>\n",
       "      <td>0.135311</td>\n",
       "      <td>0.021004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.057842</td>\n",
       "      <td>0.080418</td>\n",
       "      <td>0.144359</td>\n",
       "      <td>0.016530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-0.017026</td>\n",
       "      <td>0.094879</td>\n",
       "      <td>0.150149</td>\n",
       "      <td>0.013430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">hitpoints</th>\n",
       "      <th>3</th>\n",
       "      <td>0.083833</td>\n",
       "      <td>0.045474</td>\n",
       "      <td>0.152278</td>\n",
       "      <td>0.065234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.006261</td>\n",
       "      <td>0.048099</td>\n",
       "      <td>0.149272</td>\n",
       "      <td>0.066107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.085427</td>\n",
       "      <td>0.072166</td>\n",
       "      <td>0.129301</td>\n",
       "      <td>0.010821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.029468</td>\n",
       "      <td>0.052472</td>\n",
       "      <td>0.128731</td>\n",
       "      <td>0.005023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.069413</td>\n",
       "      <td>0.063900</td>\n",
       "      <td>0.139088</td>\n",
       "      <td>0.027753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.069396</td>\n",
       "      <td>0.077816</td>\n",
       "      <td>0.131746</td>\n",
       "      <td>0.032157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">hp_per_elixir</th>\n",
       "      <th>3</th>\n",
       "      <td>-0.000792</td>\n",
       "      <td>0.200117</td>\n",
       "      <td>0.219463</td>\n",
       "      <td>0.111216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.157513</td>\n",
       "      <td>0.057939</td>\n",
       "      <td>0.245051</td>\n",
       "      <td>0.145270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.043325</td>\n",
       "      <td>0.115837</td>\n",
       "      <td>0.191405</td>\n",
       "      <td>0.125189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.099419</td>\n",
       "      <td>0.103049</td>\n",
       "      <td>0.185385</td>\n",
       "      <td>0.118587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.087853</td>\n",
       "      <td>0.036355</td>\n",
       "      <td>0.164806</td>\n",
       "      <td>0.068966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.053787</td>\n",
       "      <td>0.105900</td>\n",
       "      <td>0.173106</td>\n",
       "      <td>0.070286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">invisible</th>\n",
       "      <th>3</th>\n",
       "      <td>0.092126</td>\n",
       "      <td>0.016302</td>\n",
       "      <td>0.127755</td>\n",
       "      <td>0.020646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.048328</td>\n",
       "      <td>0.030441</td>\n",
       "      <td>0.126082</td>\n",
       "      <td>0.019801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.063217</td>\n",
       "      <td>0.055545</td>\n",
       "      <td>0.141761</td>\n",
       "      <td>0.021848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.059899</td>\n",
       "      <td>0.040267</td>\n",
       "      <td>0.142935</td>\n",
       "      <td>0.031978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.018508</td>\n",
       "      <td>0.112332</td>\n",
       "      <td>0.142545</td>\n",
       "      <td>0.032466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.022347</td>\n",
       "      <td>0.081244</td>\n",
       "      <td>0.139562</td>\n",
       "      <td>0.029589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">is_building</th>\n",
       "      <th>3</th>\n",
       "      <td>0.054129</td>\n",
       "      <td>0.010494</td>\n",
       "      <td>0.125038</td>\n",
       "      <td>0.015551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.045713</td>\n",
       "      <td>0.020409</td>\n",
       "      <td>0.133519</td>\n",
       "      <td>0.027296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.064365</td>\n",
       "      <td>0.026412</td>\n",
       "      <td>0.130724</td>\n",
       "      <td>0.024155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.044078</td>\n",
       "      <td>0.043935</td>\n",
       "      <td>0.139481</td>\n",
       "      <td>0.029821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.031902</td>\n",
       "      <td>0.005099</td>\n",
       "      <td>0.142664</td>\n",
       "      <td>0.027754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.025020</td>\n",
       "      <td>0.018133</td>\n",
       "      <td>0.134575</td>\n",
       "      <td>0.021700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">is_free_card</th>\n",
       "      <th>3</th>\n",
       "      <td>0.087365</td>\n",
       "      <td>0.013674</td>\n",
       "      <td>0.122289</td>\n",
       "      <td>0.023748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.026163</td>\n",
       "      <td>0.009403</td>\n",
       "      <td>0.121422</td>\n",
       "      <td>0.025425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.020068</td>\n",
       "      <td>0.040731</td>\n",
       "      <td>0.126163</td>\n",
       "      <td>0.024676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.022491</td>\n",
       "      <td>0.119884</td>\n",
       "      <td>0.132625</td>\n",
       "      <td>0.030204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.043899</td>\n",
       "      <td>0.028287</td>\n",
       "      <td>0.122421</td>\n",
       "      <td>0.011648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.011811</td>\n",
       "      <td>0.007447</td>\n",
       "      <td>0.121897</td>\n",
       "      <td>0.026934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">is_spawned</th>\n",
       "      <th>3</th>\n",
       "      <td>0.065212</td>\n",
       "      <td>0.063049</td>\n",
       "      <td>0.122434</td>\n",
       "      <td>0.025783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.065874</td>\n",
       "      <td>0.071524</td>\n",
       "      <td>0.127339</td>\n",
       "      <td>0.037102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.047910</td>\n",
       "      <td>0.024116</td>\n",
       "      <td>0.126794</td>\n",
       "      <td>0.026705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-0.017450</td>\n",
       "      <td>0.106860</td>\n",
       "      <td>0.137256</td>\n",
       "      <td>0.031461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-0.005125</td>\n",
       "      <td>0.090765</td>\n",
       "      <td>0.142669</td>\n",
       "      <td>0.029622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-0.013665</td>\n",
       "      <td>0.085643</td>\n",
       "      <td>0.132774</td>\n",
       "      <td>0.030637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">is_spell</th>\n",
       "      <th>3</th>\n",
       "      <td>0.054129</td>\n",
       "      <td>0.010494</td>\n",
       "      <td>0.125038</td>\n",
       "      <td>0.015551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.045713</td>\n",
       "      <td>0.020409</td>\n",
       "      <td>0.133519</td>\n",
       "      <td>0.027296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.064365</td>\n",
       "      <td>0.026412</td>\n",
       "      <td>0.130724</td>\n",
       "      <td>0.024155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.044078</td>\n",
       "      <td>0.043935</td>\n",
       "      <td>0.139481</td>\n",
       "      <td>0.029821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.031902</td>\n",
       "      <td>0.005099</td>\n",
       "      <td>0.142664</td>\n",
       "      <td>0.027754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.025020</td>\n",
       "      <td>0.018133</td>\n",
       "      <td>0.134575</td>\n",
       "      <td>0.021700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">is_tower_troop</th>\n",
       "      <th>3</th>\n",
       "      <td>0.054129</td>\n",
       "      <td>0.010494</td>\n",
       "      <td>0.125038</td>\n",
       "      <td>0.015551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.045713</td>\n",
       "      <td>0.020409</td>\n",
       "      <td>0.133519</td>\n",
       "      <td>0.027296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.064365</td>\n",
       "      <td>0.026412</td>\n",
       "      <td>0.130724</td>\n",
       "      <td>0.024155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.044078</td>\n",
       "      <td>0.043935</td>\n",
       "      <td>0.139481</td>\n",
       "      <td>0.029821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.031902</td>\n",
       "      <td>0.005099</td>\n",
       "      <td>0.142664</td>\n",
       "      <td>0.027754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.025020</td>\n",
       "      <td>0.018133</td>\n",
       "      <td>0.134575</td>\n",
       "      <td>0.021700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">is_troop</th>\n",
       "      <th>3</th>\n",
       "      <td>0.054129</td>\n",
       "      <td>0.010494</td>\n",
       "      <td>0.125038</td>\n",
       "      <td>0.015551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.045713</td>\n",
       "      <td>0.020409</td>\n",
       "      <td>0.133519</td>\n",
       "      <td>0.027296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.064365</td>\n",
       "      <td>0.026412</td>\n",
       "      <td>0.130724</td>\n",
       "      <td>0.024155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.044078</td>\n",
       "      <td>0.043935</td>\n",
       "      <td>0.139481</td>\n",
       "      <td>0.029821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.031902</td>\n",
       "      <td>0.005099</td>\n",
       "      <td>0.142664</td>\n",
       "      <td>0.027754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.025020</td>\n",
       "      <td>0.018133</td>\n",
       "      <td>0.134575</td>\n",
       "      <td>0.021700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">mini_tank</th>\n",
       "      <th>3</th>\n",
       "      <td>0.037140</td>\n",
       "      <td>0.020206</td>\n",
       "      <td>0.126638</td>\n",
       "      <td>0.020695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.058061</td>\n",
       "      <td>0.033165</td>\n",
       "      <td>0.130084</td>\n",
       "      <td>0.022276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.072799</td>\n",
       "      <td>0.046361</td>\n",
       "      <td>0.142201</td>\n",
       "      <td>0.021942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.047509</td>\n",
       "      <td>0.037370</td>\n",
       "      <td>0.140430</td>\n",
       "      <td>0.017018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.044959</td>\n",
       "      <td>0.040641</td>\n",
       "      <td>0.145709</td>\n",
       "      <td>0.030827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.063066</td>\n",
       "      <td>0.107660</td>\n",
       "      <td>0.143637</td>\n",
       "      <td>0.039879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">no_attack</th>\n",
       "      <th>3</th>\n",
       "      <td>0.110249</td>\n",
       "      <td>0.029936</td>\n",
       "      <td>0.123061</td>\n",
       "      <td>0.018521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.089875</td>\n",
       "      <td>0.033180</td>\n",
       "      <td>0.127991</td>\n",
       "      <td>0.015384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-0.001333</td>\n",
       "      <td>0.031910</td>\n",
       "      <td>0.125552</td>\n",
       "      <td>0.020379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.041524</td>\n",
       "      <td>0.039960</td>\n",
       "      <td>0.143831</td>\n",
       "      <td>0.021804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.039690</td>\n",
       "      <td>0.036207</td>\n",
       "      <td>0.137062</td>\n",
       "      <td>0.036772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.033951</td>\n",
       "      <td>0.020751</td>\n",
       "      <td>0.135786</td>\n",
       "      <td>0.016998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">no_hit_speed</th>\n",
       "      <th>3</th>\n",
       "      <td>0.079153</td>\n",
       "      <td>0.032624</td>\n",
       "      <td>0.127381</td>\n",
       "      <td>0.016623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.063074</td>\n",
       "      <td>0.027397</td>\n",
       "      <td>0.137991</td>\n",
       "      <td>0.027323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.028695</td>\n",
       "      <td>0.023607</td>\n",
       "      <td>0.137873</td>\n",
       "      <td>0.021016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.005183</td>\n",
       "      <td>0.068514</td>\n",
       "      <td>0.137011</td>\n",
       "      <td>0.037999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.031257</td>\n",
       "      <td>0.074501</td>\n",
       "      <td>0.153275</td>\n",
       "      <td>0.023895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.065645</td>\n",
       "      <td>0.026915</td>\n",
       "      <td>0.137162</td>\n",
       "      <td>0.018157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">no_hitpoints</th>\n",
       "      <th>3</th>\n",
       "      <td>0.048728</td>\n",
       "      <td>0.021772</td>\n",
       "      <td>0.123295</td>\n",
       "      <td>0.015816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.064675</td>\n",
       "      <td>0.054815</td>\n",
       "      <td>0.132303</td>\n",
       "      <td>0.017948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.003872</td>\n",
       "      <td>0.057824</td>\n",
       "      <td>0.140304</td>\n",
       "      <td>0.021265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.048959</td>\n",
       "      <td>0.069549</td>\n",
       "      <td>0.138577</td>\n",
       "      <td>0.020494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.042340</td>\n",
       "      <td>0.057722</td>\n",
       "      <td>0.146129</td>\n",
       "      <td>0.029145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.031703</td>\n",
       "      <td>0.061321</td>\n",
       "      <td>0.142190</td>\n",
       "      <td>0.025418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">playable</th>\n",
       "      <th>3</th>\n",
       "      <td>0.087365</td>\n",
       "      <td>0.013674</td>\n",
       "      <td>0.122289</td>\n",
       "      <td>0.023748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.026163</td>\n",
       "      <td>0.009403</td>\n",
       "      <td>0.121422</td>\n",
       "      <td>0.025425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.020068</td>\n",
       "      <td>0.040731</td>\n",
       "      <td>0.126163</td>\n",
       "      <td>0.024676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.022491</td>\n",
       "      <td>0.119884</td>\n",
       "      <td>0.132625</td>\n",
       "      <td>0.030204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.043899</td>\n",
       "      <td>0.028287</td>\n",
       "      <td>0.122421</td>\n",
       "      <td>0.011648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.011811</td>\n",
       "      <td>0.007447</td>\n",
       "      <td>0.121897</td>\n",
       "      <td>0.026934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">range</th>\n",
       "      <th>3</th>\n",
       "      <td>0.074990</td>\n",
       "      <td>0.057112</td>\n",
       "      <td>0.150114</td>\n",
       "      <td>0.076983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.042068</td>\n",
       "      <td>0.030186</td>\n",
       "      <td>0.145956</td>\n",
       "      <td>0.077197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.045895</td>\n",
       "      <td>0.083234</td>\n",
       "      <td>0.130062</td>\n",
       "      <td>0.013472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.085287</td>\n",
       "      <td>0.078597</td>\n",
       "      <td>0.127526</td>\n",
       "      <td>0.019318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.083781</td>\n",
       "      <td>0.062058</td>\n",
       "      <td>0.130889</td>\n",
       "      <td>0.028176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.028632</td>\n",
       "      <td>0.022179</td>\n",
       "      <td>0.137233</td>\n",
       "      <td>0.050702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">shield_bool</th>\n",
       "      <th>3</th>\n",
       "      <td>0.072835</td>\n",
       "      <td>0.039536</td>\n",
       "      <td>0.128235</td>\n",
       "      <td>0.020386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.046554</td>\n",
       "      <td>0.016101</td>\n",
       "      <td>0.129949</td>\n",
       "      <td>0.031566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.064170</td>\n",
       "      <td>0.069954</td>\n",
       "      <td>0.133085</td>\n",
       "      <td>0.025487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.077587</td>\n",
       "      <td>0.022327</td>\n",
       "      <td>0.125909</td>\n",
       "      <td>0.030592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.059730</td>\n",
       "      <td>0.033918</td>\n",
       "      <td>0.140381</td>\n",
       "      <td>0.030552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.030574</td>\n",
       "      <td>0.039127</td>\n",
       "      <td>0.135787</td>\n",
       "      <td>0.033669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">single_damage_type</th>\n",
       "      <th>3</th>\n",
       "      <td>0.074451</td>\n",
       "      <td>0.016365</td>\n",
       "      <td>0.120813</td>\n",
       "      <td>0.025379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.089820</td>\n",
       "      <td>0.029454</td>\n",
       "      <td>0.139135</td>\n",
       "      <td>0.026139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.077389</td>\n",
       "      <td>0.082172</td>\n",
       "      <td>0.141719</td>\n",
       "      <td>0.024503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.045565</td>\n",
       "      <td>0.044941</td>\n",
       "      <td>0.127681</td>\n",
       "      <td>0.011120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.062418</td>\n",
       "      <td>0.042733</td>\n",
       "      <td>0.133069</td>\n",
       "      <td>0.004200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.075518</td>\n",
       "      <td>0.077729</td>\n",
       "      <td>0.137339</td>\n",
       "      <td>0.044485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">spawn_bool</th>\n",
       "      <th>3</th>\n",
       "      <td>0.072760</td>\n",
       "      <td>0.030121</td>\n",
       "      <td>0.128304</td>\n",
       "      <td>0.016827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.023555</td>\n",
       "      <td>0.007850</td>\n",
       "      <td>0.137608</td>\n",
       "      <td>0.030718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.042402</td>\n",
       "      <td>0.024401</td>\n",
       "      <td>0.135517</td>\n",
       "      <td>0.013309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.004677</td>\n",
       "      <td>0.066977</td>\n",
       "      <td>0.140740</td>\n",
       "      <td>0.036138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.034364</td>\n",
       "      <td>0.039267</td>\n",
       "      <td>0.135692</td>\n",
       "      <td>0.016417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.056879</td>\n",
       "      <td>0.019513</td>\n",
       "      <td>0.145324</td>\n",
       "      <td>0.025875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">special_attack_type</th>\n",
       "      <th>3</th>\n",
       "      <td>0.111655</td>\n",
       "      <td>0.026570</td>\n",
       "      <td>0.123277</td>\n",
       "      <td>0.019807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.117020</td>\n",
       "      <td>0.046075</td>\n",
       "      <td>0.131285</td>\n",
       "      <td>0.019847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.044542</td>\n",
       "      <td>0.079961</td>\n",
       "      <td>0.141530</td>\n",
       "      <td>0.026101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.000739</td>\n",
       "      <td>0.022747</td>\n",
       "      <td>0.123591</td>\n",
       "      <td>0.027012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-0.004022</td>\n",
       "      <td>0.048350</td>\n",
       "      <td>0.129879</td>\n",
       "      <td>0.006179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.086124</td>\n",
       "      <td>0.010288</td>\n",
       "      <td>0.149015</td>\n",
       "      <td>0.019123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">special_damage</th>\n",
       "      <th>3</th>\n",
       "      <td>0.058727</td>\n",
       "      <td>0.028481</td>\n",
       "      <td>0.125138</td>\n",
       "      <td>0.019909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.045834</td>\n",
       "      <td>0.011373</td>\n",
       "      <td>0.137830</td>\n",
       "      <td>0.026144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.062601</td>\n",
       "      <td>0.068686</td>\n",
       "      <td>0.134484</td>\n",
       "      <td>0.014211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.040116</td>\n",
       "      <td>0.036921</td>\n",
       "      <td>0.144024</td>\n",
       "      <td>0.024608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.046099</td>\n",
       "      <td>0.064733</td>\n",
       "      <td>0.140092</td>\n",
       "      <td>0.034008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.055797</td>\n",
       "      <td>0.070975</td>\n",
       "      <td>0.142244</td>\n",
       "      <td>0.016543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">speed</th>\n",
       "      <th>3</th>\n",
       "      <td>0.126638</td>\n",
       "      <td>0.057769</td>\n",
       "      <td>0.145506</td>\n",
       "      <td>0.047199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.114368</td>\n",
       "      <td>0.122638</td>\n",
       "      <td>0.126766</td>\n",
       "      <td>0.021901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.056531</td>\n",
       "      <td>0.011722</td>\n",
       "      <td>0.137534</td>\n",
       "      <td>0.014143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.011674</td>\n",
       "      <td>0.061968</td>\n",
       "      <td>0.139994</td>\n",
       "      <td>0.023881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-0.018237</td>\n",
       "      <td>0.079992</td>\n",
       "      <td>0.140580</td>\n",
       "      <td>0.012808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.033542</td>\n",
       "      <td>0.040637</td>\n",
       "      <td>0.151876</td>\n",
       "      <td>0.015186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">support</th>\n",
       "      <th>3</th>\n",
       "      <td>0.078366</td>\n",
       "      <td>0.033022</td>\n",
       "      <td>0.119099</td>\n",
       "      <td>0.024591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.087649</td>\n",
       "      <td>0.017829</td>\n",
       "      <td>0.116254</td>\n",
       "      <td>0.013873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.048238</td>\n",
       "      <td>0.026521</td>\n",
       "      <td>0.130061</td>\n",
       "      <td>0.021115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.030812</td>\n",
       "      <td>0.014449</td>\n",
       "      <td>0.133038</td>\n",
       "      <td>0.023364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.057684</td>\n",
       "      <td>0.035099</td>\n",
       "      <td>0.143586</td>\n",
       "      <td>0.027475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.084593</td>\n",
       "      <td>0.042883</td>\n",
       "      <td>0.154108</td>\n",
       "      <td>0.028718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">win_con</th>\n",
       "      <th>3</th>\n",
       "      <td>0.071567</td>\n",
       "      <td>0.019511</td>\n",
       "      <td>0.124215</td>\n",
       "      <td>0.021002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.017550</td>\n",
       "      <td>0.088137</td>\n",
       "      <td>0.122897</td>\n",
       "      <td>0.025993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.057752</td>\n",
       "      <td>0.017540</td>\n",
       "      <td>0.133418</td>\n",
       "      <td>0.020858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.058080</td>\n",
       "      <td>0.009688</td>\n",
       "      <td>0.132817</td>\n",
       "      <td>0.015540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.030596</td>\n",
       "      <td>0.033770</td>\n",
       "      <td>0.141074</td>\n",
       "      <td>0.027198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.076564</td>\n",
       "      <td>0.039388</td>\n",
       "      <td>0.131300</td>\n",
       "      <td>0.029757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">win_con_dmg</th>\n",
       "      <th>3</th>\n",
       "      <td>0.028876</td>\n",
       "      <td>0.013813</td>\n",
       "      <td>0.125404</td>\n",
       "      <td>0.016251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.055810</td>\n",
       "      <td>0.047921</td>\n",
       "      <td>0.127994</td>\n",
       "      <td>0.027227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.021425</td>\n",
       "      <td>0.047407</td>\n",
       "      <td>0.136670</td>\n",
       "      <td>0.024695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.073109</td>\n",
       "      <td>0.042780</td>\n",
       "      <td>0.132587</td>\n",
       "      <td>0.016341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.025988</td>\n",
       "      <td>0.028044</td>\n",
       "      <td>0.131918</td>\n",
       "      <td>0.012545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.040785</td>\n",
       "      <td>0.033182</td>\n",
       "      <td>0.138181</td>\n",
       "      <td>0.031744</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          gmm_troop            km_troop          \n",
       "                               mean       std      mean       std\n",
       "col                     K                                        \n",
       "affected_crown          3  0.094126  0.008280  0.124799  0.020214\n",
       "                        4  0.069223  0.037659  0.133204  0.028431\n",
       "                        5  0.030792  0.035756  0.140777  0.017097\n",
       "                        6  0.030736  0.017356  0.146431  0.018452\n",
       "                        7  0.043191  0.041455  0.149410  0.026193\n",
       "                        8  0.045520  0.053020  0.131322  0.035580\n",
       "air_control             3  0.048843  0.044723  0.120676  0.018083\n",
       "                        4  0.016463  0.036054  0.133799  0.022673\n",
       "                        5  0.015743  0.047331  0.123658  0.007315\n",
       "                        6  0.032132  0.063110  0.137806  0.024282\n",
       "                        7 -0.010683  0.047982  0.144042  0.027295\n",
       "                        8  0.035399  0.032943  0.146583  0.023434\n",
       "any_target              3  0.080361  0.023343  0.109444  0.012465\n",
       "                        4  0.033898  0.026000  0.118099  0.018233\n",
       "                        5  0.065076  0.019250  0.125828  0.016265\n",
       "                        6  0.025195  0.058495  0.129916  0.019937\n",
       "                        7  0.037686  0.053231  0.113771  0.037686\n",
       "                        8 -0.030166  0.038779  0.133343  0.026435\n",
       "aoe_bool                3  0.064388  0.055798  0.127585  0.021016\n",
       "                        4  0.073929  0.018463  0.125580  0.024182\n",
       "                        5  0.016709  0.081311  0.142278  0.019615\n",
       "                        6  0.010192  0.097613  0.146507  0.031756\n",
       "                        7  0.054610  0.035457  0.149663  0.016180\n",
       "                        8  0.045572  0.057059  0.140079  0.028491\n",
       "aoe_by_damage           3  0.100059  0.055804  0.180112  0.054743\n",
       "                        4  0.063544  0.051580  0.174364  0.079882\n",
       "                        5  0.080181  0.117986  0.176884  0.057111\n",
       "                        6 -0.046563  0.046565  0.175699  0.064230\n",
       "                        7  0.006029  0.135561  0.166035  0.050260\n",
       "                        8  0.032133  0.006325  0.169984  0.071133\n",
       "aoe_by_range            3  0.165719  0.047139  0.172907  0.067758\n",
       "                        4  0.056075  0.136134  0.161017  0.058812\n",
       "                        5  0.073548  0.066198  0.174858  0.060358\n",
       "                        6 -0.043072  0.118946  0.165811  0.082756\n",
       "                        7  0.036591  0.060059  0.178533  0.062770\n",
       "                        8  0.036805  0.095696  0.180924  0.071318\n",
       "aoe_per_elixir          3  0.085487  0.030774  0.150879  0.066917\n",
       "                        4  0.073454  0.069309  0.124840  0.008265\n",
       "                        5  0.020414  0.061679  0.129167  0.007751\n",
       "                        6  0.043141  0.014311  0.142188  0.015065\n",
       "                        7  0.065467  0.089365  0.126196  0.015011\n",
       "                        8  0.083131  0.019143  0.137227  0.014154\n",
       "aoe_radius              3  0.079076  0.065682  0.149200  0.058189\n",
       "                        4  0.092485  0.065739  0.129380  0.012691\n",
       "                        5  0.040463  0.046285  0.142208  0.024325\n",
       "                        6 -0.009554  0.143278  0.143503  0.012084\n",
       "                        7  0.079103  0.059993  0.125789  0.026364\n",
       "                        8  0.067830  0.046025  0.128673  0.013324\n",
       "attack_count            3  0.133584  0.161947  0.128658  0.013192\n",
       "                        4  0.079198  0.093078  0.129883  0.022146\n",
       "                        5  0.062360  0.046702  0.126084  0.025517\n",
       "                        6  0.071521  0.091191  0.126391  0.018459\n",
       "                        7  0.076852  0.081896  0.130984  0.018297\n",
       "                        8  0.052913  0.064331  0.143148  0.008717\n",
       "building_target         3  0.080361  0.023343  0.109444  0.012465\n",
       "                        4  0.033898  0.026000  0.118099  0.018233\n",
       "                        5  0.065076  0.019250  0.125828  0.016265\n",
       "                        6  0.025195  0.058495  0.129916  0.019937\n",
       "                        7  0.037686  0.053231  0.113771  0.037686\n",
       "                        8 -0.030166  0.038779  0.133343  0.026435\n",
       "can_evolve              3  0.110575  0.080020  0.160145  0.075840\n",
       "                        4  0.094461  0.038175  0.151424  0.064106\n",
       "                        5  0.109285  0.053756  0.124993  0.011361\n",
       "                        6 -0.005124  0.052602  0.144126  0.018577\n",
       "                        7  0.038299  0.022495  0.143059  0.015308\n",
       "                        8  0.051218  0.035864  0.139448  0.027140\n",
       "control_special         3  0.070653  0.029471  0.123866  0.019768\n",
       "                        4  0.074564  0.016448  0.132188  0.019782\n",
       "                        5  0.083479  0.056713  0.140854  0.019905\n",
       "                        6  0.045667  0.026755  0.138951  0.017568\n",
       "                        7 -0.000771  0.045563  0.140668  0.020803\n",
       "                        8  0.032156  0.022693  0.139219  0.019586\n",
       "count                   3  0.103725  0.085307  0.143328  0.050020\n",
       "                        4  0.031059  0.041615  0.131990  0.022645\n",
       "                        5  0.089107  0.021949  0.128717  0.012865\n",
       "                        6  0.102209  0.072344  0.122740  0.029362\n",
       "                        7  0.045974  0.038870  0.129941  0.024476\n",
       "                        8  0.047843  0.057746  0.129015  0.009661\n",
       "damage                  3  0.048325  0.014134  0.152614  0.071159\n",
       "                        4  0.105626  0.077953  0.129587  0.013001\n",
       "                        5  0.060747  0.069484  0.130625  0.019266\n",
       "                        6  0.056990  0.015207  0.135885  0.007875\n",
       "                        7  0.044247  0.026939  0.140710  0.010509\n",
       "                        8  0.024670  0.033268  0.130513  0.028078\n",
       "damage_by_hitpoints     3  0.126995  0.088519  0.187489  0.071213\n",
       "                        4  0.147123  0.088133  0.190136  0.070952\n",
       "                        5  0.031608  0.055062  0.176205  0.087772\n",
       "                        6  0.010142  0.133430  0.170260  0.097274\n",
       "                        7  0.108938  0.050585  0.198824  0.081342\n",
       "                        8  0.047170  0.020880  0.178483  0.086593\n",
       "damage_output           3  0.108694  0.055228  0.190176  0.071772\n",
       "                        4  0.087892  0.039218  0.170265  0.084163\n",
       "                        5  0.033610  0.069081  0.181605  0.077598\n",
       "                        6  0.091087  0.061080  0.175118  0.104916\n",
       "                        7  0.007838  0.089238  0.187159  0.100960\n",
       "                        8  0.052043  0.060369  0.179300  0.097068\n",
       "damage_output_ps        3  0.032588  0.083197  0.127444  0.024996\n",
       "                        4  0.007478  0.026716  0.135389  0.027441\n",
       "                        5  0.103335  0.043228  0.128737  0.018788\n",
       "                        6  0.013272  0.043145  0.122988  0.025698\n",
       "                        7 -0.015188  0.069949  0.129242  0.031973\n",
       "                        8 -0.066056  0.124790  0.140471  0.023371\n",
       "damage_per_elixir       3  0.148524  0.083834  0.177318  0.061474\n",
       "                        4  0.086360  0.079900  0.212173  0.081280\n",
       "                        5  0.051430  0.071580  0.166794  0.060028\n",
       "                        6  0.118439  0.054004  0.183318  0.079158\n",
       "                        7  0.050193  0.073727  0.182659  0.084172\n",
       "                        8  0.061727  0.063862  0.172554  0.056261\n",
       "damage_per_second       3  0.111873  0.111188  0.190488  0.072512\n",
       "                        4  0.058122  0.127028  0.192879  0.072932\n",
       "                        5  0.148717  0.064975  0.175001  0.079769\n",
       "                        6  0.128311  0.120777  0.181681  0.085207\n",
       "                        7 -0.035139  0.051355  0.197109  0.076079\n",
       "                        8  0.116651  0.063006  0.194952  0.078031\n",
       "death_damage_bool       3  0.042088  0.008504  0.127395  0.017617\n",
       "                        4  0.032412  0.026837  0.136445  0.026929\n",
       "                        5  0.059997  0.009074  0.143067  0.028308\n",
       "                        6  0.062146  0.052987  0.143760  0.032988\n",
       "                        7  0.034129  0.042233  0.142324  0.029545\n",
       "                        8  0.073213  0.015139  0.152396  0.026131\n",
       "dps_special             3  0.086334  0.053093  0.127543  0.014920\n",
       "                        4  0.058824  0.086012  0.133494  0.022119\n",
       "                        5  0.058998  0.046268  0.140824  0.026162\n",
       "                        6  0.035547  0.016356  0.143127  0.021521\n",
       "                        7  0.043664  0.060361  0.154453  0.025570\n",
       "                        8  0.049857  0.021610  0.144330  0.005341\n",
       "elixircost              3  0.097466  0.007579  0.151371  0.083858\n",
       "                        4  0.081915  0.063156  0.156115  0.075181\n",
       "                        5  0.064042  0.076671  0.139022  0.054358\n",
       "                        6  0.030833  0.105095  0.125897  0.022846\n",
       "                        7  0.058145  0.053656  0.128647  0.022894\n",
       "                        8  0.022254  0.053646  0.131286  0.028795\n",
       "fly_bool                3  0.080208  0.046551  0.127525  0.021121\n",
       "                        4  0.047213  0.026420  0.134393  0.027968\n",
       "                        5  0.023315  0.107774  0.139463  0.016205\n",
       "                        6  0.054173  0.023724  0.144679  0.017051\n",
       "                        7  0.001501  0.057911  0.149560  0.021106\n",
       "                        8  0.050281  0.049261  0.138709  0.029855\n",
       "ground_dps              3  0.059654  0.026325  0.125173  0.018935\n",
       "                        4 -0.023476  0.040014  0.132026  0.022892\n",
       "                        5 -0.000300  0.044086  0.129516  0.020888\n",
       "                        6 -0.007622  0.059831  0.144639  0.027558\n",
       "                        7  0.043584  0.024394  0.134551  0.034447\n",
       "                        8  0.067460  0.058817  0.132990  0.028600\n",
       "ground_target           3  0.086986  0.013722  0.113451  0.007446\n",
       "                        4  0.028192  0.048073  0.121113  0.018984\n",
       "                        5  0.052845  0.003653  0.118434  0.003932\n",
       "                        6  0.020289  0.055160  0.128837  0.031124\n",
       "                        7  0.003343  0.056316  0.129453  0.032136\n",
       "                        8  0.044314  0.004880  0.127776  0.023778\n",
       "has_ability             3  0.098320  0.047959  0.126065  0.016172\n",
       "                        4  0.042599  0.041362  0.133291  0.028957\n",
       "                        5  0.080169  0.029204  0.139724  0.018890\n",
       "                        6  0.059883  0.018449  0.128960  0.031881\n",
       "                        7  0.077422  0.075603  0.134229  0.047796\n",
       "                        8  0.049995  0.101149  0.152026  0.027863\n",
       "has_friendly_buff       3  0.052461  0.025348  0.127950  0.016654\n",
       "                        4  0.007903  0.083810  0.134253  0.032943\n",
       "                        5  0.057068  0.027289  0.139254  0.021209\n",
       "                        6  0.025192  0.018209  0.140897  0.031102\n",
       "                        7  0.051639  0.069165  0.142068  0.019435\n",
       "                        8  0.084019  0.024714  0.151723  0.016201\n",
       "has_lifetime            3  0.082037  0.035785  0.123964  0.021838\n",
       "                        4  0.053398  0.030614  0.131591  0.017933\n",
       "                        5 -0.000552  0.084837  0.134218  0.023525\n",
       "                        6  0.029006  0.062468  0.140365  0.032618\n",
       "                        7 -0.009025  0.008862  0.139697  0.030299\n",
       "                        8  0.051452  0.048963  0.142432  0.029165\n",
       "has_periodic_spawn      3  0.118932  0.021690  0.126164  0.017003\n",
       "                        4  0.038205  0.073946  0.132200  0.031029\n",
       "                        5  0.048112  0.036546  0.140083  0.017536\n",
       "                        6  0.091888  0.062547  0.142194  0.030642\n",
       "                        7  0.075952  0.048574  0.143817  0.032113\n",
       "                        8  0.054018  0.036204  0.147073  0.032799\n",
       "has_ranged_attack       3  0.079667  0.044183  0.112101  0.012662\n",
       "                        4  0.057937  0.025094  0.121623  0.028991\n",
       "                        5  0.064714  0.025406  0.129085  0.017340\n",
       "                        6  0.047901  0.045695  0.122351  0.001703\n",
       "                        7  0.045342  0.043546  0.138156  0.031297\n",
       "                        8  0.061083  0.085103  0.137132  0.033046\n",
       "has_upon_breaking_spawn 3  0.080121  0.026328  0.128925  0.017513\n",
       "                        4  0.053438  0.068959  0.137015  0.028076\n",
       "                        5  0.047207  0.015674  0.138226  0.029268\n",
       "                        6  0.053355  0.042608  0.141334  0.020721\n",
       "                        7  0.044670  0.042516  0.138492  0.036918\n",
       "                        8  0.072448  0.018133  0.140902  0.023525\n",
       "has_upon_death_spawn    3  0.044800  0.011315  0.125351  0.018266\n",
       "                        4  0.025228  0.019881  0.135169  0.029089\n",
       "                        5  0.049892  0.049059  0.136477  0.017138\n",
       "                        6  0.055283  0.058561  0.132960  0.014177\n",
       "                        7  0.048073  0.032586  0.149544  0.028575\n",
       "                        8  0.031617  0.079279  0.125346  0.020112\n",
       "high_dps                3  0.048135  0.027130  0.120473  0.009885\n",
       "                        4  0.020045  0.037435  0.135516  0.028849\n",
       "                        5  0.027598  0.024552  0.142836  0.024829\n",
       "                        6  0.112984  0.014133  0.142809  0.026323\n",
       "                        7  0.030747  0.052581  0.146184  0.026854\n",
       "                        8  0.051864  0.068657  0.136980  0.029222\n",
       "hit_speed               3  0.120313  0.064354  0.154917  0.073531\n",
       "                        4  0.113315  0.070181  0.125052  0.011499\n",
       "                        5  0.073036  0.047941  0.130220  0.024718\n",
       "                        6  0.004988  0.104731  0.135311  0.021004\n",
       "                        7  0.057842  0.080418  0.144359  0.016530\n",
       "                        8 -0.017026  0.094879  0.150149  0.013430\n",
       "hitpoints               3  0.083833  0.045474  0.152278  0.065234\n",
       "                        4 -0.006261  0.048099  0.149272  0.066107\n",
       "                        5  0.085427  0.072166  0.129301  0.010821\n",
       "                        6  0.029468  0.052472  0.128731  0.005023\n",
       "                        7  0.069413  0.063900  0.139088  0.027753\n",
       "                        8  0.069396  0.077816  0.131746  0.032157\n",
       "hp_per_elixir           3 -0.000792  0.200117  0.219463  0.111216\n",
       "                        4  0.157513  0.057939  0.245051  0.145270\n",
       "                        5  0.043325  0.115837  0.191405  0.125189\n",
       "                        6  0.099419  0.103049  0.185385  0.118587\n",
       "                        7  0.087853  0.036355  0.164806  0.068966\n",
       "                        8  0.053787  0.105900  0.173106  0.070286\n",
       "invisible               3  0.092126  0.016302  0.127755  0.020646\n",
       "                        4  0.048328  0.030441  0.126082  0.019801\n",
       "                        5  0.063217  0.055545  0.141761  0.021848\n",
       "                        6  0.059899  0.040267  0.142935  0.031978\n",
       "                        7  0.018508  0.112332  0.142545  0.032466\n",
       "                        8  0.022347  0.081244  0.139562  0.029589\n",
       "is_building             3  0.054129  0.010494  0.125038  0.015551\n",
       "                        4  0.045713  0.020409  0.133519  0.027296\n",
       "                        5  0.064365  0.026412  0.130724  0.024155\n",
       "                        6  0.044078  0.043935  0.139481  0.029821\n",
       "                        7  0.031902  0.005099  0.142664  0.027754\n",
       "                        8  0.025020  0.018133  0.134575  0.021700\n",
       "is_free_card            3  0.087365  0.013674  0.122289  0.023748\n",
       "                        4  0.026163  0.009403  0.121422  0.025425\n",
       "                        5  0.020068  0.040731  0.126163  0.024676\n",
       "                        6  0.022491  0.119884  0.132625  0.030204\n",
       "                        7  0.043899  0.028287  0.122421  0.011648\n",
       "                        8  0.011811  0.007447  0.121897  0.026934\n",
       "is_spawned              3  0.065212  0.063049  0.122434  0.025783\n",
       "                        4  0.065874  0.071524  0.127339  0.037102\n",
       "                        5  0.047910  0.024116  0.126794  0.026705\n",
       "                        6 -0.017450  0.106860  0.137256  0.031461\n",
       "                        7 -0.005125  0.090765  0.142669  0.029622\n",
       "                        8 -0.013665  0.085643  0.132774  0.030637\n",
       "is_spell                3  0.054129  0.010494  0.125038  0.015551\n",
       "                        4  0.045713  0.020409  0.133519  0.027296\n",
       "                        5  0.064365  0.026412  0.130724  0.024155\n",
       "                        6  0.044078  0.043935  0.139481  0.029821\n",
       "                        7  0.031902  0.005099  0.142664  0.027754\n",
       "                        8  0.025020  0.018133  0.134575  0.021700\n",
       "is_tower_troop          3  0.054129  0.010494  0.125038  0.015551\n",
       "                        4  0.045713  0.020409  0.133519  0.027296\n",
       "                        5  0.064365  0.026412  0.130724  0.024155\n",
       "                        6  0.044078  0.043935  0.139481  0.029821\n",
       "                        7  0.031902  0.005099  0.142664  0.027754\n",
       "                        8  0.025020  0.018133  0.134575  0.021700\n",
       "is_troop                3  0.054129  0.010494  0.125038  0.015551\n",
       "                        4  0.045713  0.020409  0.133519  0.027296\n",
       "                        5  0.064365  0.026412  0.130724  0.024155\n",
       "                        6  0.044078  0.043935  0.139481  0.029821\n",
       "                        7  0.031902  0.005099  0.142664  0.027754\n",
       "                        8  0.025020  0.018133  0.134575  0.021700\n",
       "mini_tank               3  0.037140  0.020206  0.126638  0.020695\n",
       "                        4  0.058061  0.033165  0.130084  0.022276\n",
       "                        5  0.072799  0.046361  0.142201  0.021942\n",
       "                        6  0.047509  0.037370  0.140430  0.017018\n",
       "                        7  0.044959  0.040641  0.145709  0.030827\n",
       "                        8  0.063066  0.107660  0.143637  0.039879\n",
       "no_attack               3  0.110249  0.029936  0.123061  0.018521\n",
       "                        4  0.089875  0.033180  0.127991  0.015384\n",
       "                        5 -0.001333  0.031910  0.125552  0.020379\n",
       "                        6  0.041524  0.039960  0.143831  0.021804\n",
       "                        7  0.039690  0.036207  0.137062  0.036772\n",
       "                        8  0.033951  0.020751  0.135786  0.016998\n",
       "no_hit_speed            3  0.079153  0.032624  0.127381  0.016623\n",
       "                        4  0.063074  0.027397  0.137991  0.027323\n",
       "                        5  0.028695  0.023607  0.137873  0.021016\n",
       "                        6  0.005183  0.068514  0.137011  0.037999\n",
       "                        7  0.031257  0.074501  0.153275  0.023895\n",
       "                        8  0.065645  0.026915  0.137162  0.018157\n",
       "no_hitpoints            3  0.048728  0.021772  0.123295  0.015816\n",
       "                        4  0.064675  0.054815  0.132303  0.017948\n",
       "                        5  0.003872  0.057824  0.140304  0.021265\n",
       "                        6  0.048959  0.069549  0.138577  0.020494\n",
       "                        7  0.042340  0.057722  0.146129  0.029145\n",
       "                        8  0.031703  0.061321  0.142190  0.025418\n",
       "playable                3  0.087365  0.013674  0.122289  0.023748\n",
       "                        4  0.026163  0.009403  0.121422  0.025425\n",
       "                        5  0.020068  0.040731  0.126163  0.024676\n",
       "                        6  0.022491  0.119884  0.132625  0.030204\n",
       "                        7  0.043899  0.028287  0.122421  0.011648\n",
       "                        8  0.011811  0.007447  0.121897  0.026934\n",
       "range                   3  0.074990  0.057112  0.150114  0.076983\n",
       "                        4  0.042068  0.030186  0.145956  0.077197\n",
       "                        5  0.045895  0.083234  0.130062  0.013472\n",
       "                        6  0.085287  0.078597  0.127526  0.019318\n",
       "                        7  0.083781  0.062058  0.130889  0.028176\n",
       "                        8  0.028632  0.022179  0.137233  0.050702\n",
       "shield_bool             3  0.072835  0.039536  0.128235  0.020386\n",
       "                        4  0.046554  0.016101  0.129949  0.031566\n",
       "                        5  0.064170  0.069954  0.133085  0.025487\n",
       "                        6  0.077587  0.022327  0.125909  0.030592\n",
       "                        7  0.059730  0.033918  0.140381  0.030552\n",
       "                        8  0.030574  0.039127  0.135787  0.033669\n",
       "single_damage_type      3  0.074451  0.016365  0.120813  0.025379\n",
       "                        4  0.089820  0.029454  0.139135  0.026139\n",
       "                        5  0.077389  0.082172  0.141719  0.024503\n",
       "                        6  0.045565  0.044941  0.127681  0.011120\n",
       "                        7  0.062418  0.042733  0.133069  0.004200\n",
       "                        8  0.075518  0.077729  0.137339  0.044485\n",
       "spawn_bool              3  0.072760  0.030121  0.128304  0.016827\n",
       "                        4  0.023555  0.007850  0.137608  0.030718\n",
       "                        5  0.042402  0.024401  0.135517  0.013309\n",
       "                        6  0.004677  0.066977  0.140740  0.036138\n",
       "                        7  0.034364  0.039267  0.135692  0.016417\n",
       "                        8  0.056879  0.019513  0.145324  0.025875\n",
       "special_attack_type     3  0.111655  0.026570  0.123277  0.019807\n",
       "                        4  0.117020  0.046075  0.131285  0.019847\n",
       "                        5  0.044542  0.079961  0.141530  0.026101\n",
       "                        6  0.000739  0.022747  0.123591  0.027012\n",
       "                        7 -0.004022  0.048350  0.129879  0.006179\n",
       "                        8  0.086124  0.010288  0.149015  0.019123\n",
       "special_damage          3  0.058727  0.028481  0.125138  0.019909\n",
       "                        4  0.045834  0.011373  0.137830  0.026144\n",
       "                        5  0.062601  0.068686  0.134484  0.014211\n",
       "                        6  0.040116  0.036921  0.144024  0.024608\n",
       "                        7  0.046099  0.064733  0.140092  0.034008\n",
       "                        8  0.055797  0.070975  0.142244  0.016543\n",
       "speed                   3  0.126638  0.057769  0.145506  0.047199\n",
       "                        4  0.114368  0.122638  0.126766  0.021901\n",
       "                        5  0.056531  0.011722  0.137534  0.014143\n",
       "                        6  0.011674  0.061968  0.139994  0.023881\n",
       "                        7 -0.018237  0.079992  0.140580  0.012808\n",
       "                        8  0.033542  0.040637  0.151876  0.015186\n",
       "support                 3  0.078366  0.033022  0.119099  0.024591\n",
       "                        4  0.087649  0.017829  0.116254  0.013873\n",
       "                        5  0.048238  0.026521  0.130061  0.021115\n",
       "                        6  0.030812  0.014449  0.133038  0.023364\n",
       "                        7  0.057684  0.035099  0.143586  0.027475\n",
       "                        8  0.084593  0.042883  0.154108  0.028718\n",
       "win_con                 3  0.071567  0.019511  0.124215  0.021002\n",
       "                        4 -0.017550  0.088137  0.122897  0.025993\n",
       "                        5  0.057752  0.017540  0.133418  0.020858\n",
       "                        6  0.058080  0.009688  0.132817  0.015540\n",
       "                        7  0.030596  0.033770  0.141074  0.027198\n",
       "                        8  0.076564  0.039388  0.131300  0.029757\n",
       "win_con_dmg             3  0.028876  0.013813  0.125404  0.016251\n",
       "                        4  0.055810  0.047921  0.127994  0.027227\n",
       "                        5  0.021425  0.047407  0.136670  0.024695\n",
       "                        6  0.073109  0.042780  0.132587  0.016341\n",
       "                        7  0.025988  0.028044  0.131918  0.012545\n",
       "                        8  0.040785  0.033182  0.138181  0.031744"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sim.groupby(['col', 'K']).agg({'gmm_troop': ['mean', 'std'], 'km_troop': ['mean', 'std']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b3031ab4-772e-406b-af5a-d3fcade4d802",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">gmm_spell</th>\n",
       "      <th colspan=\"2\" halign=\"left\">km_spell</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>col</th>\n",
       "      <th>K</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">affected_crown</th>\n",
       "      <th>3</th>\n",
       "      <td>0.138686</td>\n",
       "      <td>0.044009</td>\n",
       "      <td>0.187460</td>\n",
       "      <td>0.025032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.188749</td>\n",
       "      <td>0.072113</td>\n",
       "      <td>0.226947</td>\n",
       "      <td>0.072607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.244867</td>\n",
       "      <td>0.099078</td>\n",
       "      <td>0.239425</td>\n",
       "      <td>0.093986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.270288</td>\n",
       "      <td>0.100357</td>\n",
       "      <td>0.275674</td>\n",
       "      <td>0.094733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.256897</td>\n",
       "      <td>0.134264</td>\n",
       "      <td>0.274707</td>\n",
       "      <td>0.118895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.273843</td>\n",
       "      <td>0.119563</td>\n",
       "      <td>0.273002</td>\n",
       "      <td>0.120578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">air_control</th>\n",
       "      <th>3</th>\n",
       "      <td>0.153863</td>\n",
       "      <td>0.085098</td>\n",
       "      <td>0.207707</td>\n",
       "      <td>0.025780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.169765</td>\n",
       "      <td>0.003567</td>\n",
       "      <td>0.240889</td>\n",
       "      <td>0.069265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.226818</td>\n",
       "      <td>0.090737</td>\n",
       "      <td>0.241187</td>\n",
       "      <td>0.084910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.278958</td>\n",
       "      <td>0.092142</td>\n",
       "      <td>0.271354</td>\n",
       "      <td>0.083002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.280188</td>\n",
       "      <td>0.115289</td>\n",
       "      <td>0.287638</td>\n",
       "      <td>0.106429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.264643</td>\n",
       "      <td>0.124961</td>\n",
       "      <td>0.277459</td>\n",
       "      <td>0.114905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">any_target</th>\n",
       "      <th>3</th>\n",
       "      <td>0.153863</td>\n",
       "      <td>0.085098</td>\n",
       "      <td>0.207707</td>\n",
       "      <td>0.025780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.169765</td>\n",
       "      <td>0.003567</td>\n",
       "      <td>0.240889</td>\n",
       "      <td>0.069265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.226818</td>\n",
       "      <td>0.090737</td>\n",
       "      <td>0.241187</td>\n",
       "      <td>0.084910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.278958</td>\n",
       "      <td>0.092142</td>\n",
       "      <td>0.271354</td>\n",
       "      <td>0.083002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.280188</td>\n",
       "      <td>0.115289</td>\n",
       "      <td>0.287638</td>\n",
       "      <td>0.106429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.264643</td>\n",
       "      <td>0.124961</td>\n",
       "      <td>0.277459</td>\n",
       "      <td>0.114905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">aoe_bool</th>\n",
       "      <th>3</th>\n",
       "      <td>0.184535</td>\n",
       "      <td>0.056828</td>\n",
       "      <td>0.227512</td>\n",
       "      <td>0.036142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.227074</td>\n",
       "      <td>0.075593</td>\n",
       "      <td>0.252768</td>\n",
       "      <td>0.080316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.246722</td>\n",
       "      <td>0.135133</td>\n",
       "      <td>0.272915</td>\n",
       "      <td>0.102928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.265259</td>\n",
       "      <td>0.090838</td>\n",
       "      <td>0.281466</td>\n",
       "      <td>0.117486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.256782</td>\n",
       "      <td>0.110285</td>\n",
       "      <td>0.263967</td>\n",
       "      <td>0.129607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.293481</td>\n",
       "      <td>0.125139</td>\n",
       "      <td>0.300665</td>\n",
       "      <td>0.118047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">aoe_by_damage</th>\n",
       "      <th>3</th>\n",
       "      <td>0.279093</td>\n",
       "      <td>0.081564</td>\n",
       "      <td>0.286520</td>\n",
       "      <td>0.083200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.253035</td>\n",
       "      <td>0.143334</td>\n",
       "      <td>0.304328</td>\n",
       "      <td>0.108161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.166672</td>\n",
       "      <td>0.123682</td>\n",
       "      <td>0.325137</td>\n",
       "      <td>0.124528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.174629</td>\n",
       "      <td>0.147134</td>\n",
       "      <td>0.327749</td>\n",
       "      <td>0.134740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.217242</td>\n",
       "      <td>0.031639</td>\n",
       "      <td>0.305809</td>\n",
       "      <td>0.125223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.144112</td>\n",
       "      <td>0.052752</td>\n",
       "      <td>0.309131</td>\n",
       "      <td>0.129905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">aoe_by_range</th>\n",
       "      <th>3</th>\n",
       "      <td>0.228539</td>\n",
       "      <td>0.233126</td>\n",
       "      <td>0.328012</td>\n",
       "      <td>0.151065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.340909</td>\n",
       "      <td>0.192609</td>\n",
       "      <td>0.366913</td>\n",
       "      <td>0.179497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.315952</td>\n",
       "      <td>0.180548</td>\n",
       "      <td>0.356488</td>\n",
       "      <td>0.160371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.274172</td>\n",
       "      <td>0.060852</td>\n",
       "      <td>0.337611</td>\n",
       "      <td>0.148437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.269159</td>\n",
       "      <td>0.095590</td>\n",
       "      <td>0.306814</td>\n",
       "      <td>0.116405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.209207</td>\n",
       "      <td>0.021154</td>\n",
       "      <td>0.307684</td>\n",
       "      <td>0.094665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">aoe_per_elixir</th>\n",
       "      <th>3</th>\n",
       "      <td>0.208986</td>\n",
       "      <td>0.084176</td>\n",
       "      <td>0.226137</td>\n",
       "      <td>0.069113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.194701</td>\n",
       "      <td>0.060488</td>\n",
       "      <td>0.256510</td>\n",
       "      <td>0.102518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.144451</td>\n",
       "      <td>0.063708</td>\n",
       "      <td>0.262173</td>\n",
       "      <td>0.091890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.243434</td>\n",
       "      <td>0.021087</td>\n",
       "      <td>0.266872</td>\n",
       "      <td>0.055866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.242560</td>\n",
       "      <td>0.029311</td>\n",
       "      <td>0.259791</td>\n",
       "      <td>0.047340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.240328</td>\n",
       "      <td>0.041750</td>\n",
       "      <td>0.247079</td>\n",
       "      <td>0.040354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">aoe_radius</th>\n",
       "      <th>3</th>\n",
       "      <td>0.129129</td>\n",
       "      <td>0.063145</td>\n",
       "      <td>0.224290</td>\n",
       "      <td>0.050696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.214561</td>\n",
       "      <td>0.073477</td>\n",
       "      <td>0.250974</td>\n",
       "      <td>0.092498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.211012</td>\n",
       "      <td>0.040305</td>\n",
       "      <td>0.257918</td>\n",
       "      <td>0.082032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.249788</td>\n",
       "      <td>0.034688</td>\n",
       "      <td>0.256075</td>\n",
       "      <td>0.035119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.226827</td>\n",
       "      <td>0.061839</td>\n",
       "      <td>0.249099</td>\n",
       "      <td>0.044922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.220210</td>\n",
       "      <td>0.038774</td>\n",
       "      <td>0.263056</td>\n",
       "      <td>0.054472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">attack_count</th>\n",
       "      <th>3</th>\n",
       "      <td>0.183464</td>\n",
       "      <td>0.070055</td>\n",
       "      <td>0.252466</td>\n",
       "      <td>0.086925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.205856</td>\n",
       "      <td>0.063417</td>\n",
       "      <td>0.285640</td>\n",
       "      <td>0.119548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.225756</td>\n",
       "      <td>0.061988</td>\n",
       "      <td>0.258835</td>\n",
       "      <td>0.091906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.246498</td>\n",
       "      <td>0.107457</td>\n",
       "      <td>0.265717</td>\n",
       "      <td>0.088768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.200769</td>\n",
       "      <td>0.013846</td>\n",
       "      <td>0.273571</td>\n",
       "      <td>0.078962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.224900</td>\n",
       "      <td>0.039150</td>\n",
       "      <td>0.270686</td>\n",
       "      <td>0.101750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">building_target</th>\n",
       "      <th>3</th>\n",
       "      <td>0.153863</td>\n",
       "      <td>0.085098</td>\n",
       "      <td>0.207707</td>\n",
       "      <td>0.025780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.169765</td>\n",
       "      <td>0.003567</td>\n",
       "      <td>0.240889</td>\n",
       "      <td>0.069265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.226818</td>\n",
       "      <td>0.090737</td>\n",
       "      <td>0.241187</td>\n",
       "      <td>0.084910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.278958</td>\n",
       "      <td>0.092142</td>\n",
       "      <td>0.271354</td>\n",
       "      <td>0.083002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.280188</td>\n",
       "      <td>0.115289</td>\n",
       "      <td>0.287638</td>\n",
       "      <td>0.106429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.264643</td>\n",
       "      <td>0.124961</td>\n",
       "      <td>0.277459</td>\n",
       "      <td>0.114905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">can_evolve</th>\n",
       "      <th>3</th>\n",
       "      <td>0.128134</td>\n",
       "      <td>0.058613</td>\n",
       "      <td>0.258684</td>\n",
       "      <td>0.087056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.107464</td>\n",
       "      <td>0.069263</td>\n",
       "      <td>0.245818</td>\n",
       "      <td>0.059598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.173621</td>\n",
       "      <td>0.008098</td>\n",
       "      <td>0.236423</td>\n",
       "      <td>0.036965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.198058</td>\n",
       "      <td>0.059604</td>\n",
       "      <td>0.246442</td>\n",
       "      <td>0.038724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.218834</td>\n",
       "      <td>0.011072</td>\n",
       "      <td>0.245543</td>\n",
       "      <td>0.032098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.224531</td>\n",
       "      <td>0.033541</td>\n",
       "      <td>0.251219</td>\n",
       "      <td>0.065092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">control_special</th>\n",
       "      <th>3</th>\n",
       "      <td>0.199571</td>\n",
       "      <td>0.048724</td>\n",
       "      <td>0.249182</td>\n",
       "      <td>0.095829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.214969</td>\n",
       "      <td>0.095942</td>\n",
       "      <td>0.246598</td>\n",
       "      <td>0.051659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.254043</td>\n",
       "      <td>0.077957</td>\n",
       "      <td>0.277291</td>\n",
       "      <td>0.084361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.311284</td>\n",
       "      <td>0.132837</td>\n",
       "      <td>0.294435</td>\n",
       "      <td>0.104591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.304158</td>\n",
       "      <td>0.139175</td>\n",
       "      <td>0.329582</td>\n",
       "      <td>0.162238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.315393</td>\n",
       "      <td>0.162767</td>\n",
       "      <td>0.321750</td>\n",
       "      <td>0.158787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">count</th>\n",
       "      <th>3</th>\n",
       "      <td>0.185740</td>\n",
       "      <td>0.133068</td>\n",
       "      <td>0.236779</td>\n",
       "      <td>0.075964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.207761</td>\n",
       "      <td>0.069360</td>\n",
       "      <td>0.257523</td>\n",
       "      <td>0.097659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.208930</td>\n",
       "      <td>0.060424</td>\n",
       "      <td>0.244965</td>\n",
       "      <td>0.091453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.254065</td>\n",
       "      <td>0.050841</td>\n",
       "      <td>0.252793</td>\n",
       "      <td>0.052609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.202450</td>\n",
       "      <td>0.039219</td>\n",
       "      <td>0.248096</td>\n",
       "      <td>0.041251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.200290</td>\n",
       "      <td>0.013500</td>\n",
       "      <td>0.238531</td>\n",
       "      <td>0.048938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">damage</th>\n",
       "      <th>3</th>\n",
       "      <td>0.148476</td>\n",
       "      <td>0.057529</td>\n",
       "      <td>0.227102</td>\n",
       "      <td>0.079143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.197855</td>\n",
       "      <td>0.080394</td>\n",
       "      <td>0.249251</td>\n",
       "      <td>0.102865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.214999</td>\n",
       "      <td>0.056209</td>\n",
       "      <td>0.251361</td>\n",
       "      <td>0.090535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.181246</td>\n",
       "      <td>0.070420</td>\n",
       "      <td>0.249732</td>\n",
       "      <td>0.057993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.227863</td>\n",
       "      <td>0.039606</td>\n",
       "      <td>0.237164</td>\n",
       "      <td>0.032943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.187227</td>\n",
       "      <td>0.027002</td>\n",
       "      <td>0.239040</td>\n",
       "      <td>0.044722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">damage_by_hitpoints</th>\n",
       "      <th>3</th>\n",
       "      <td>0.246394</td>\n",
       "      <td>0.159359</td>\n",
       "      <td>0.290096</td>\n",
       "      <td>0.081928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.146878</td>\n",
       "      <td>0.152238</td>\n",
       "      <td>0.304749</td>\n",
       "      <td>0.101477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.176991</td>\n",
       "      <td>0.106821</td>\n",
       "      <td>0.323643</td>\n",
       "      <td>0.121961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.226932</td>\n",
       "      <td>0.073528</td>\n",
       "      <td>0.335842</td>\n",
       "      <td>0.147986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.204495</td>\n",
       "      <td>0.042737</td>\n",
       "      <td>0.320677</td>\n",
       "      <td>0.131723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.182225</td>\n",
       "      <td>0.039951</td>\n",
       "      <td>0.313466</td>\n",
       "      <td>0.129180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">damage_output</th>\n",
       "      <th>3</th>\n",
       "      <td>0.207644</td>\n",
       "      <td>0.143533</td>\n",
       "      <td>0.298114</td>\n",
       "      <td>0.088801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.155122</td>\n",
       "      <td>0.067137</td>\n",
       "      <td>0.313718</td>\n",
       "      <td>0.110010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.189367</td>\n",
       "      <td>0.114484</td>\n",
       "      <td>0.333561</td>\n",
       "      <td>0.126337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.247858</td>\n",
       "      <td>0.053574</td>\n",
       "      <td>0.338732</td>\n",
       "      <td>0.137164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.212489</td>\n",
       "      <td>0.065480</td>\n",
       "      <td>0.337193</td>\n",
       "      <td>0.148132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.221321</td>\n",
       "      <td>0.025457</td>\n",
       "      <td>0.333674</td>\n",
       "      <td>0.133769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">damage_output_ps</th>\n",
       "      <th>3</th>\n",
       "      <td>0.185740</td>\n",
       "      <td>0.133068</td>\n",
       "      <td>0.236779</td>\n",
       "      <td>0.075964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.207761</td>\n",
       "      <td>0.069360</td>\n",
       "      <td>0.257523</td>\n",
       "      <td>0.097659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.208930</td>\n",
       "      <td>0.060424</td>\n",
       "      <td>0.244965</td>\n",
       "      <td>0.091453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.254065</td>\n",
       "      <td>0.050841</td>\n",
       "      <td>0.252793</td>\n",
       "      <td>0.052609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.202450</td>\n",
       "      <td>0.039219</td>\n",
       "      <td>0.248096</td>\n",
       "      <td>0.041251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.200290</td>\n",
       "      <td>0.013500</td>\n",
       "      <td>0.238531</td>\n",
       "      <td>0.048938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">damage_per_elixir</th>\n",
       "      <th>3</th>\n",
       "      <td>0.115843</td>\n",
       "      <td>0.220354</td>\n",
       "      <td>0.295746</td>\n",
       "      <td>0.094304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.250811</td>\n",
       "      <td>0.081152</td>\n",
       "      <td>0.331484</td>\n",
       "      <td>0.135047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.276374</td>\n",
       "      <td>0.145636</td>\n",
       "      <td>0.351823</td>\n",
       "      <td>0.152343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.158278</td>\n",
       "      <td>0.027462</td>\n",
       "      <td>0.314808</td>\n",
       "      <td>0.145708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.129017</td>\n",
       "      <td>0.214688</td>\n",
       "      <td>0.315013</td>\n",
       "      <td>0.110048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.151284</td>\n",
       "      <td>0.067892</td>\n",
       "      <td>0.294252</td>\n",
       "      <td>0.113679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">damage_per_second</th>\n",
       "      <th>3</th>\n",
       "      <td>0.246394</td>\n",
       "      <td>0.159359</td>\n",
       "      <td>0.290096</td>\n",
       "      <td>0.081928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.146878</td>\n",
       "      <td>0.152238</td>\n",
       "      <td>0.304749</td>\n",
       "      <td>0.101477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.176991</td>\n",
       "      <td>0.106821</td>\n",
       "      <td>0.323643</td>\n",
       "      <td>0.121961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.226932</td>\n",
       "      <td>0.073528</td>\n",
       "      <td>0.335842</td>\n",
       "      <td>0.147986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.204495</td>\n",
       "      <td>0.042737</td>\n",
       "      <td>0.320677</td>\n",
       "      <td>0.131723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.182225</td>\n",
       "      <td>0.039951</td>\n",
       "      <td>0.313466</td>\n",
       "      <td>0.129180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">death_damage_bool</th>\n",
       "      <th>3</th>\n",
       "      <td>0.153863</td>\n",
       "      <td>0.085098</td>\n",
       "      <td>0.207707</td>\n",
       "      <td>0.025780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.169765</td>\n",
       "      <td>0.003567</td>\n",
       "      <td>0.240889</td>\n",
       "      <td>0.069265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.226818</td>\n",
       "      <td>0.090737</td>\n",
       "      <td>0.241187</td>\n",
       "      <td>0.084910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.278958</td>\n",
       "      <td>0.092142</td>\n",
       "      <td>0.271354</td>\n",
       "      <td>0.083002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.280188</td>\n",
       "      <td>0.115289</td>\n",
       "      <td>0.287638</td>\n",
       "      <td>0.106429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.264643</td>\n",
       "      <td>0.124961</td>\n",
       "      <td>0.277459</td>\n",
       "      <td>0.114905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">dps_special</th>\n",
       "      <th>3</th>\n",
       "      <td>0.157740</td>\n",
       "      <td>0.143347</td>\n",
       "      <td>0.232075</td>\n",
       "      <td>0.102566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.199048</td>\n",
       "      <td>0.135391</td>\n",
       "      <td>0.241945</td>\n",
       "      <td>0.095626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.211004</td>\n",
       "      <td>0.130274</td>\n",
       "      <td>0.251483</td>\n",
       "      <td>0.098446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.239717</td>\n",
       "      <td>0.130729</td>\n",
       "      <td>0.259841</td>\n",
       "      <td>0.113446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.255067</td>\n",
       "      <td>0.113772</td>\n",
       "      <td>0.255067</td>\n",
       "      <td>0.113772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.275713</td>\n",
       "      <td>0.098720</td>\n",
       "      <td>0.283091</td>\n",
       "      <td>0.092219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">elixircost</th>\n",
       "      <th>3</th>\n",
       "      <td>0.213173</td>\n",
       "      <td>0.101220</td>\n",
       "      <td>0.244788</td>\n",
       "      <td>0.073142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.231658</td>\n",
       "      <td>0.096876</td>\n",
       "      <td>0.271306</td>\n",
       "      <td>0.112423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.250899</td>\n",
       "      <td>0.119979</td>\n",
       "      <td>0.270326</td>\n",
       "      <td>0.103694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.236263</td>\n",
       "      <td>0.082255</td>\n",
       "      <td>0.275947</td>\n",
       "      <td>0.086215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.277654</td>\n",
       "      <td>0.066635</td>\n",
       "      <td>0.276315</td>\n",
       "      <td>0.068560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.204094</td>\n",
       "      <td>0.065308</td>\n",
       "      <td>0.264303</td>\n",
       "      <td>0.078767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">fly_bool</th>\n",
       "      <th>3</th>\n",
       "      <td>0.153863</td>\n",
       "      <td>0.085098</td>\n",
       "      <td>0.207707</td>\n",
       "      <td>0.025780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.169765</td>\n",
       "      <td>0.003567</td>\n",
       "      <td>0.240889</td>\n",
       "      <td>0.069265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.226818</td>\n",
       "      <td>0.090737</td>\n",
       "      <td>0.241187</td>\n",
       "      <td>0.084910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.278958</td>\n",
       "      <td>0.092142</td>\n",
       "      <td>0.271354</td>\n",
       "      <td>0.083002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.280188</td>\n",
       "      <td>0.115289</td>\n",
       "      <td>0.287638</td>\n",
       "      <td>0.106429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.264643</td>\n",
       "      <td>0.124961</td>\n",
       "      <td>0.277459</td>\n",
       "      <td>0.114905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">ground_dps</th>\n",
       "      <th>3</th>\n",
       "      <td>0.153863</td>\n",
       "      <td>0.085098</td>\n",
       "      <td>0.207707</td>\n",
       "      <td>0.025780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.169765</td>\n",
       "      <td>0.003567</td>\n",
       "      <td>0.240889</td>\n",
       "      <td>0.069265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.226818</td>\n",
       "      <td>0.090737</td>\n",
       "      <td>0.241187</td>\n",
       "      <td>0.084910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.278958</td>\n",
       "      <td>0.092142</td>\n",
       "      <td>0.271354</td>\n",
       "      <td>0.083002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.280188</td>\n",
       "      <td>0.115289</td>\n",
       "      <td>0.287638</td>\n",
       "      <td>0.106429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.264643</td>\n",
       "      <td>0.124961</td>\n",
       "      <td>0.277459</td>\n",
       "      <td>0.114905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">ground_target</th>\n",
       "      <th>3</th>\n",
       "      <td>0.153863</td>\n",
       "      <td>0.085098</td>\n",
       "      <td>0.207707</td>\n",
       "      <td>0.025780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.169765</td>\n",
       "      <td>0.003567</td>\n",
       "      <td>0.240889</td>\n",
       "      <td>0.069265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.226818</td>\n",
       "      <td>0.090737</td>\n",
       "      <td>0.241187</td>\n",
       "      <td>0.084910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.278958</td>\n",
       "      <td>0.092142</td>\n",
       "      <td>0.271354</td>\n",
       "      <td>0.083002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.280188</td>\n",
       "      <td>0.115289</td>\n",
       "      <td>0.287638</td>\n",
       "      <td>0.106429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.264643</td>\n",
       "      <td>0.124961</td>\n",
       "      <td>0.277459</td>\n",
       "      <td>0.114905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">has_ability</th>\n",
       "      <th>3</th>\n",
       "      <td>0.153863</td>\n",
       "      <td>0.085098</td>\n",
       "      <td>0.207707</td>\n",
       "      <td>0.025780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.169765</td>\n",
       "      <td>0.003567</td>\n",
       "      <td>0.240889</td>\n",
       "      <td>0.069265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.226818</td>\n",
       "      <td>0.090737</td>\n",
       "      <td>0.241187</td>\n",
       "      <td>0.084910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.278958</td>\n",
       "      <td>0.092142</td>\n",
       "      <td>0.271354</td>\n",
       "      <td>0.083002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.280188</td>\n",
       "      <td>0.115289</td>\n",
       "      <td>0.287638</td>\n",
       "      <td>0.106429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.264643</td>\n",
       "      <td>0.124961</td>\n",
       "      <td>0.277459</td>\n",
       "      <td>0.114905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">has_friendly_buff</th>\n",
       "      <th>3</th>\n",
       "      <td>0.199591</td>\n",
       "      <td>0.065271</td>\n",
       "      <td>0.230988</td>\n",
       "      <td>0.036171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.213183</td>\n",
       "      <td>0.060569</td>\n",
       "      <td>0.252789</td>\n",
       "      <td>0.091755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.279693</td>\n",
       "      <td>0.102006</td>\n",
       "      <td>0.292383</td>\n",
       "      <td>0.125245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.297289</td>\n",
       "      <td>0.133840</td>\n",
       "      <td>0.311086</td>\n",
       "      <td>0.119865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.309553</td>\n",
       "      <td>0.145024</td>\n",
       "      <td>0.328085</td>\n",
       "      <td>0.140605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.325507</td>\n",
       "      <td>0.133094</td>\n",
       "      <td>0.331499</td>\n",
       "      <td>0.127724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">has_lifetime</th>\n",
       "      <th>3</th>\n",
       "      <td>0.153863</td>\n",
       "      <td>0.085098</td>\n",
       "      <td>0.207707</td>\n",
       "      <td>0.025780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.169765</td>\n",
       "      <td>0.003567</td>\n",
       "      <td>0.240889</td>\n",
       "      <td>0.069265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.226818</td>\n",
       "      <td>0.090737</td>\n",
       "      <td>0.241187</td>\n",
       "      <td>0.084910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.278958</td>\n",
       "      <td>0.092142</td>\n",
       "      <td>0.271354</td>\n",
       "      <td>0.083002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.280188</td>\n",
       "      <td>0.115289</td>\n",
       "      <td>0.287638</td>\n",
       "      <td>0.106429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.264643</td>\n",
       "      <td>0.124961</td>\n",
       "      <td>0.277459</td>\n",
       "      <td>0.114905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">has_periodic_spawn</th>\n",
       "      <th>3</th>\n",
       "      <td>0.181906</td>\n",
       "      <td>0.050237</td>\n",
       "      <td>0.225873</td>\n",
       "      <td>0.029110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.240118</td>\n",
       "      <td>0.074638</td>\n",
       "      <td>0.258534</td>\n",
       "      <td>0.082998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.266332</td>\n",
       "      <td>0.085979</td>\n",
       "      <td>0.270575</td>\n",
       "      <td>0.090689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.282379</td>\n",
       "      <td>0.097810</td>\n",
       "      <td>0.298273</td>\n",
       "      <td>0.090524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.304755</td>\n",
       "      <td>0.124724</td>\n",
       "      <td>0.316123</td>\n",
       "      <td>0.115130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.316134</td>\n",
       "      <td>0.133990</td>\n",
       "      <td>0.328483</td>\n",
       "      <td>0.121625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">has_ranged_attack</th>\n",
       "      <th>3</th>\n",
       "      <td>0.153863</td>\n",
       "      <td>0.085098</td>\n",
       "      <td>0.207707</td>\n",
       "      <td>0.025780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.169765</td>\n",
       "      <td>0.003567</td>\n",
       "      <td>0.240889</td>\n",
       "      <td>0.069265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.226818</td>\n",
       "      <td>0.090737</td>\n",
       "      <td>0.241187</td>\n",
       "      <td>0.084910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.278958</td>\n",
       "      <td>0.092142</td>\n",
       "      <td>0.271354</td>\n",
       "      <td>0.083002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.280188</td>\n",
       "      <td>0.115289</td>\n",
       "      <td>0.287638</td>\n",
       "      <td>0.106429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.264643</td>\n",
       "      <td>0.124961</td>\n",
       "      <td>0.277459</td>\n",
       "      <td>0.114905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">has_upon_breaking_spawn</th>\n",
       "      <th>3</th>\n",
       "      <td>0.142908</td>\n",
       "      <td>0.083114</td>\n",
       "      <td>0.202244</td>\n",
       "      <td>0.035320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.172358</td>\n",
       "      <td>0.034872</td>\n",
       "      <td>0.220452</td>\n",
       "      <td>0.043969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.212549</td>\n",
       "      <td>0.062029</td>\n",
       "      <td>0.240676</td>\n",
       "      <td>0.047061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.257491</td>\n",
       "      <td>0.056681</td>\n",
       "      <td>0.255306</td>\n",
       "      <td>0.052897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.269456</td>\n",
       "      <td>0.132227</td>\n",
       "      <td>0.287473</td>\n",
       "      <td>0.117393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.293774</td>\n",
       "      <td>0.133561</td>\n",
       "      <td>0.289484</td>\n",
       "      <td>0.126289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">has_upon_death_spawn</th>\n",
       "      <th>3</th>\n",
       "      <td>0.153863</td>\n",
       "      <td>0.085098</td>\n",
       "      <td>0.207707</td>\n",
       "      <td>0.025780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.169765</td>\n",
       "      <td>0.003567</td>\n",
       "      <td>0.240889</td>\n",
       "      <td>0.069265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.226818</td>\n",
       "      <td>0.090737</td>\n",
       "      <td>0.241187</td>\n",
       "      <td>0.084910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.278958</td>\n",
       "      <td>0.092142</td>\n",
       "      <td>0.271354</td>\n",
       "      <td>0.083002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.280188</td>\n",
       "      <td>0.115289</td>\n",
       "      <td>0.287638</td>\n",
       "      <td>0.106429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.264643</td>\n",
       "      <td>0.124961</td>\n",
       "      <td>0.277459</td>\n",
       "      <td>0.114905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">high_dps</th>\n",
       "      <th>3</th>\n",
       "      <td>0.138615</td>\n",
       "      <td>0.103507</td>\n",
       "      <td>0.204901</td>\n",
       "      <td>0.038626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.203490</td>\n",
       "      <td>0.074877</td>\n",
       "      <td>0.222198</td>\n",
       "      <td>0.073126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.223037</td>\n",
       "      <td>0.083023</td>\n",
       "      <td>0.241160</td>\n",
       "      <td>0.066440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.239816</td>\n",
       "      <td>0.118775</td>\n",
       "      <td>0.247359</td>\n",
       "      <td>0.112051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.248301</td>\n",
       "      <td>0.107070</td>\n",
       "      <td>0.249007</td>\n",
       "      <td>0.106499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.223328</td>\n",
       "      <td>0.076703</td>\n",
       "      <td>0.257362</td>\n",
       "      <td>0.106471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">hit_speed</th>\n",
       "      <th>3</th>\n",
       "      <td>0.185740</td>\n",
       "      <td>0.133068</td>\n",
       "      <td>0.236779</td>\n",
       "      <td>0.075964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.207761</td>\n",
       "      <td>0.069360</td>\n",
       "      <td>0.257523</td>\n",
       "      <td>0.097659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.208930</td>\n",
       "      <td>0.060424</td>\n",
       "      <td>0.244965</td>\n",
       "      <td>0.091453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.254065</td>\n",
       "      <td>0.050841</td>\n",
       "      <td>0.252793</td>\n",
       "      <td>0.052609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.202450</td>\n",
       "      <td>0.039219</td>\n",
       "      <td>0.248096</td>\n",
       "      <td>0.041251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.200290</td>\n",
       "      <td>0.013500</td>\n",
       "      <td>0.238531</td>\n",
       "      <td>0.048938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">hitpoints</th>\n",
       "      <th>3</th>\n",
       "      <td>0.185740</td>\n",
       "      <td>0.133068</td>\n",
       "      <td>0.236779</td>\n",
       "      <td>0.075964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.207761</td>\n",
       "      <td>0.069360</td>\n",
       "      <td>0.257523</td>\n",
       "      <td>0.097659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.208930</td>\n",
       "      <td>0.060424</td>\n",
       "      <td>0.244965</td>\n",
       "      <td>0.091453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.254065</td>\n",
       "      <td>0.050841</td>\n",
       "      <td>0.252793</td>\n",
       "      <td>0.052609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.202450</td>\n",
       "      <td>0.039219</td>\n",
       "      <td>0.248096</td>\n",
       "      <td>0.041251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.200290</td>\n",
       "      <td>0.013500</td>\n",
       "      <td>0.238531</td>\n",
       "      <td>0.048938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">hp_per_elixir</th>\n",
       "      <th>3</th>\n",
       "      <td>0.266551</td>\n",
       "      <td>0.111445</td>\n",
       "      <td>0.347452</td>\n",
       "      <td>0.134822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.218166</td>\n",
       "      <td>0.165194</td>\n",
       "      <td>0.343464</td>\n",
       "      <td>0.139377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.351620</td>\n",
       "      <td>0.166055</td>\n",
       "      <td>0.330605</td>\n",
       "      <td>0.123481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.218870</td>\n",
       "      <td>0.133499</td>\n",
       "      <td>0.321147</td>\n",
       "      <td>0.102911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.262402</td>\n",
       "      <td>0.059252</td>\n",
       "      <td>0.304137</td>\n",
       "      <td>0.093214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.281955</td>\n",
       "      <td>0.066702</td>\n",
       "      <td>0.305832</td>\n",
       "      <td>0.084246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">invisible</th>\n",
       "      <th>3</th>\n",
       "      <td>0.153863</td>\n",
       "      <td>0.085098</td>\n",
       "      <td>0.207707</td>\n",
       "      <td>0.025780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.169765</td>\n",
       "      <td>0.003567</td>\n",
       "      <td>0.240889</td>\n",
       "      <td>0.069265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.226818</td>\n",
       "      <td>0.090737</td>\n",
       "      <td>0.241187</td>\n",
       "      <td>0.084910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.278958</td>\n",
       "      <td>0.092142</td>\n",
       "      <td>0.271354</td>\n",
       "      <td>0.083002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.280188</td>\n",
       "      <td>0.115289</td>\n",
       "      <td>0.287638</td>\n",
       "      <td>0.106429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.264643</td>\n",
       "      <td>0.124961</td>\n",
       "      <td>0.277459</td>\n",
       "      <td>0.114905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">is_building</th>\n",
       "      <th>3</th>\n",
       "      <td>0.153863</td>\n",
       "      <td>0.085098</td>\n",
       "      <td>0.207707</td>\n",
       "      <td>0.025780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.169765</td>\n",
       "      <td>0.003567</td>\n",
       "      <td>0.240889</td>\n",
       "      <td>0.069265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.226818</td>\n",
       "      <td>0.090737</td>\n",
       "      <td>0.241187</td>\n",
       "      <td>0.084910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.278958</td>\n",
       "      <td>0.092142</td>\n",
       "      <td>0.271354</td>\n",
       "      <td>0.083002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.280188</td>\n",
       "      <td>0.115289</td>\n",
       "      <td>0.287638</td>\n",
       "      <td>0.106429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.264643</td>\n",
       "      <td>0.124961</td>\n",
       "      <td>0.277459</td>\n",
       "      <td>0.114905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">is_free_card</th>\n",
       "      <th>3</th>\n",
       "      <td>0.153863</td>\n",
       "      <td>0.085098</td>\n",
       "      <td>0.207707</td>\n",
       "      <td>0.025780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.169765</td>\n",
       "      <td>0.003567</td>\n",
       "      <td>0.240889</td>\n",
       "      <td>0.069265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.226818</td>\n",
       "      <td>0.090737</td>\n",
       "      <td>0.241187</td>\n",
       "      <td>0.084910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.278958</td>\n",
       "      <td>0.092142</td>\n",
       "      <td>0.271354</td>\n",
       "      <td>0.083002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.280188</td>\n",
       "      <td>0.115289</td>\n",
       "      <td>0.287638</td>\n",
       "      <td>0.106429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.264643</td>\n",
       "      <td>0.124961</td>\n",
       "      <td>0.277459</td>\n",
       "      <td>0.114905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">is_spawned</th>\n",
       "      <th>3</th>\n",
       "      <td>0.189624</td>\n",
       "      <td>0.073401</td>\n",
       "      <td>0.219853</td>\n",
       "      <td>0.027867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.212238</td>\n",
       "      <td>0.097244</td>\n",
       "      <td>0.249677</td>\n",
       "      <td>0.085384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.226147</td>\n",
       "      <td>0.064479</td>\n",
       "      <td>0.251941</td>\n",
       "      <td>0.094836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.267403</td>\n",
       "      <td>0.118555</td>\n",
       "      <td>0.281747</td>\n",
       "      <td>0.106949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.289954</td>\n",
       "      <td>0.101467</td>\n",
       "      <td>0.281887</td>\n",
       "      <td>0.105217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.271858</td>\n",
       "      <td>0.128163</td>\n",
       "      <td>0.271774</td>\n",
       "      <td>0.128249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">is_spell</th>\n",
       "      <th>3</th>\n",
       "      <td>0.153863</td>\n",
       "      <td>0.085098</td>\n",
       "      <td>0.207707</td>\n",
       "      <td>0.025780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.169765</td>\n",
       "      <td>0.003567</td>\n",
       "      <td>0.240889</td>\n",
       "      <td>0.069265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.226818</td>\n",
       "      <td>0.090737</td>\n",
       "      <td>0.241187</td>\n",
       "      <td>0.084910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.278958</td>\n",
       "      <td>0.092142</td>\n",
       "      <td>0.271354</td>\n",
       "      <td>0.083002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.280188</td>\n",
       "      <td>0.115289</td>\n",
       "      <td>0.287638</td>\n",
       "      <td>0.106429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.264643</td>\n",
       "      <td>0.124961</td>\n",
       "      <td>0.277459</td>\n",
       "      <td>0.114905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">is_tower_troop</th>\n",
       "      <th>3</th>\n",
       "      <td>0.153863</td>\n",
       "      <td>0.085098</td>\n",
       "      <td>0.207707</td>\n",
       "      <td>0.025780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.169765</td>\n",
       "      <td>0.003567</td>\n",
       "      <td>0.240889</td>\n",
       "      <td>0.069265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.226818</td>\n",
       "      <td>0.090737</td>\n",
       "      <td>0.241187</td>\n",
       "      <td>0.084910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.278958</td>\n",
       "      <td>0.092142</td>\n",
       "      <td>0.271354</td>\n",
       "      <td>0.083002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.280188</td>\n",
       "      <td>0.115289</td>\n",
       "      <td>0.287638</td>\n",
       "      <td>0.106429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.264643</td>\n",
       "      <td>0.124961</td>\n",
       "      <td>0.277459</td>\n",
       "      <td>0.114905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">is_troop</th>\n",
       "      <th>3</th>\n",
       "      <td>0.153863</td>\n",
       "      <td>0.085098</td>\n",
       "      <td>0.207707</td>\n",
       "      <td>0.025780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.169765</td>\n",
       "      <td>0.003567</td>\n",
       "      <td>0.240889</td>\n",
       "      <td>0.069265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.226818</td>\n",
       "      <td>0.090737</td>\n",
       "      <td>0.241187</td>\n",
       "      <td>0.084910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.278958</td>\n",
       "      <td>0.092142</td>\n",
       "      <td>0.271354</td>\n",
       "      <td>0.083002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.280188</td>\n",
       "      <td>0.115289</td>\n",
       "      <td>0.287638</td>\n",
       "      <td>0.106429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.264643</td>\n",
       "      <td>0.124961</td>\n",
       "      <td>0.277459</td>\n",
       "      <td>0.114905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">mini_tank</th>\n",
       "      <th>3</th>\n",
       "      <td>0.153863</td>\n",
       "      <td>0.085098</td>\n",
       "      <td>0.207707</td>\n",
       "      <td>0.025780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.169765</td>\n",
       "      <td>0.003567</td>\n",
       "      <td>0.240889</td>\n",
       "      <td>0.069265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.226818</td>\n",
       "      <td>0.090737</td>\n",
       "      <td>0.241187</td>\n",
       "      <td>0.084910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.278958</td>\n",
       "      <td>0.092142</td>\n",
       "      <td>0.271354</td>\n",
       "      <td>0.083002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.280188</td>\n",
       "      <td>0.115289</td>\n",
       "      <td>0.287638</td>\n",
       "      <td>0.106429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.264643</td>\n",
       "      <td>0.124961</td>\n",
       "      <td>0.277459</td>\n",
       "      <td>0.114905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">no_attack</th>\n",
       "      <th>3</th>\n",
       "      <td>0.158440</td>\n",
       "      <td>0.079845</td>\n",
       "      <td>0.214306</td>\n",
       "      <td>0.033435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.162612</td>\n",
       "      <td>0.066656</td>\n",
       "      <td>0.216318</td>\n",
       "      <td>0.052721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.219861</td>\n",
       "      <td>0.100154</td>\n",
       "      <td>0.239948</td>\n",
       "      <td>0.071167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.260638</td>\n",
       "      <td>0.101009</td>\n",
       "      <td>0.267208</td>\n",
       "      <td>0.092930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.270721</td>\n",
       "      <td>0.108001</td>\n",
       "      <td>0.276567</td>\n",
       "      <td>0.104227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.267389</td>\n",
       "      <td>0.117658</td>\n",
       "      <td>0.268606</td>\n",
       "      <td>0.116201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">no_hit_speed</th>\n",
       "      <th>3</th>\n",
       "      <td>0.153863</td>\n",
       "      <td>0.085098</td>\n",
       "      <td>0.207707</td>\n",
       "      <td>0.025780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.169765</td>\n",
       "      <td>0.003567</td>\n",
       "      <td>0.240889</td>\n",
       "      <td>0.069265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.226818</td>\n",
       "      <td>0.090737</td>\n",
       "      <td>0.241187</td>\n",
       "      <td>0.084910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.278958</td>\n",
       "      <td>0.092142</td>\n",
       "      <td>0.271354</td>\n",
       "      <td>0.083002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.280188</td>\n",
       "      <td>0.115289</td>\n",
       "      <td>0.287638</td>\n",
       "      <td>0.106429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.264643</td>\n",
       "      <td>0.124961</td>\n",
       "      <td>0.277459</td>\n",
       "      <td>0.114905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">no_hitpoints</th>\n",
       "      <th>3</th>\n",
       "      <td>0.153863</td>\n",
       "      <td>0.085098</td>\n",
       "      <td>0.207707</td>\n",
       "      <td>0.025780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.169765</td>\n",
       "      <td>0.003567</td>\n",
       "      <td>0.240889</td>\n",
       "      <td>0.069265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.226818</td>\n",
       "      <td>0.090737</td>\n",
       "      <td>0.241187</td>\n",
       "      <td>0.084910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.278958</td>\n",
       "      <td>0.092142</td>\n",
       "      <td>0.271354</td>\n",
       "      <td>0.083002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.280188</td>\n",
       "      <td>0.115289</td>\n",
       "      <td>0.287638</td>\n",
       "      <td>0.106429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.264643</td>\n",
       "      <td>0.124961</td>\n",
       "      <td>0.277459</td>\n",
       "      <td>0.114905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">playable</th>\n",
       "      <th>3</th>\n",
       "      <td>0.153863</td>\n",
       "      <td>0.085098</td>\n",
       "      <td>0.207707</td>\n",
       "      <td>0.025780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.169765</td>\n",
       "      <td>0.003567</td>\n",
       "      <td>0.240889</td>\n",
       "      <td>0.069265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.226818</td>\n",
       "      <td>0.090737</td>\n",
       "      <td>0.241187</td>\n",
       "      <td>0.084910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.278958</td>\n",
       "      <td>0.092142</td>\n",
       "      <td>0.271354</td>\n",
       "      <td>0.083002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.280188</td>\n",
       "      <td>0.115289</td>\n",
       "      <td>0.287638</td>\n",
       "      <td>0.106429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.264643</td>\n",
       "      <td>0.124961</td>\n",
       "      <td>0.277459</td>\n",
       "      <td>0.114905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">range</th>\n",
       "      <th>3</th>\n",
       "      <td>0.185740</td>\n",
       "      <td>0.133068</td>\n",
       "      <td>0.236779</td>\n",
       "      <td>0.075964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.207761</td>\n",
       "      <td>0.069360</td>\n",
       "      <td>0.257523</td>\n",
       "      <td>0.097659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.208930</td>\n",
       "      <td>0.060424</td>\n",
       "      <td>0.244965</td>\n",
       "      <td>0.091453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.254065</td>\n",
       "      <td>0.050841</td>\n",
       "      <td>0.252793</td>\n",
       "      <td>0.052609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.202450</td>\n",
       "      <td>0.039219</td>\n",
       "      <td>0.248096</td>\n",
       "      <td>0.041251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.200290</td>\n",
       "      <td>0.013500</td>\n",
       "      <td>0.238531</td>\n",
       "      <td>0.048938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">shield_bool</th>\n",
       "      <th>3</th>\n",
       "      <td>0.153863</td>\n",
       "      <td>0.085098</td>\n",
       "      <td>0.207707</td>\n",
       "      <td>0.025780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.169765</td>\n",
       "      <td>0.003567</td>\n",
       "      <td>0.240889</td>\n",
       "      <td>0.069265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.226818</td>\n",
       "      <td>0.090737</td>\n",
       "      <td>0.241187</td>\n",
       "      <td>0.084910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.278958</td>\n",
       "      <td>0.092142</td>\n",
       "      <td>0.271354</td>\n",
       "      <td>0.083002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.280188</td>\n",
       "      <td>0.115289</td>\n",
       "      <td>0.287638</td>\n",
       "      <td>0.106429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.264643</td>\n",
       "      <td>0.124961</td>\n",
       "      <td>0.277459</td>\n",
       "      <td>0.114905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">single_damage_type</th>\n",
       "      <th>3</th>\n",
       "      <td>0.171004</td>\n",
       "      <td>0.062671</td>\n",
       "      <td>0.214100</td>\n",
       "      <td>0.013687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.196139</td>\n",
       "      <td>0.088272</td>\n",
       "      <td>0.234808</td>\n",
       "      <td>0.053593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.245699</td>\n",
       "      <td>0.089315</td>\n",
       "      <td>0.261820</td>\n",
       "      <td>0.082757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.230893</td>\n",
       "      <td>0.123128</td>\n",
       "      <td>0.261241</td>\n",
       "      <td>0.105113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.250235</td>\n",
       "      <td>0.139768</td>\n",
       "      <td>0.266671</td>\n",
       "      <td>0.126239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.282642</td>\n",
       "      <td>0.111610</td>\n",
       "      <td>0.297346</td>\n",
       "      <td>0.092011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">spawn_bool</th>\n",
       "      <th>3</th>\n",
       "      <td>0.166346</td>\n",
       "      <td>0.060626</td>\n",
       "      <td>0.207153</td>\n",
       "      <td>0.028569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.227261</td>\n",
       "      <td>0.096262</td>\n",
       "      <td>0.241893</td>\n",
       "      <td>0.082142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.252181</td>\n",
       "      <td>0.096469</td>\n",
       "      <td>0.259782</td>\n",
       "      <td>0.088205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.281097</td>\n",
       "      <td>0.108786</td>\n",
       "      <td>0.286326</td>\n",
       "      <td>0.103289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.267641</td>\n",
       "      <td>0.128380</td>\n",
       "      <td>0.285650</td>\n",
       "      <td>0.111047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.279615</td>\n",
       "      <td>0.120993</td>\n",
       "      <td>0.278662</td>\n",
       "      <td>0.122138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">special_attack_type</th>\n",
       "      <th>3</th>\n",
       "      <td>0.175773</td>\n",
       "      <td>0.032161</td>\n",
       "      <td>0.253561</td>\n",
       "      <td>0.086749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.233794</td>\n",
       "      <td>0.075314</td>\n",
       "      <td>0.265960</td>\n",
       "      <td>0.084430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.250395</td>\n",
       "      <td>0.079944</td>\n",
       "      <td>0.277275</td>\n",
       "      <td>0.083955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.265901</td>\n",
       "      <td>0.125691</td>\n",
       "      <td>0.274293</td>\n",
       "      <td>0.113187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.269705</td>\n",
       "      <td>0.145297</td>\n",
       "      <td>0.282676</td>\n",
       "      <td>0.135521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.274827</td>\n",
       "      <td>0.141031</td>\n",
       "      <td>0.277801</td>\n",
       "      <td>0.137831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">special_damage</th>\n",
       "      <th>3</th>\n",
       "      <td>0.177247</td>\n",
       "      <td>0.069897</td>\n",
       "      <td>0.201102</td>\n",
       "      <td>0.030727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.214450</td>\n",
       "      <td>0.108252</td>\n",
       "      <td>0.247899</td>\n",
       "      <td>0.078907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.250569</td>\n",
       "      <td>0.082676</td>\n",
       "      <td>0.261915</td>\n",
       "      <td>0.077721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.287171</td>\n",
       "      <td>0.104388</td>\n",
       "      <td>0.278564</td>\n",
       "      <td>0.112262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.277057</td>\n",
       "      <td>0.131165</td>\n",
       "      <td>0.285736</td>\n",
       "      <td>0.122075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.279296</td>\n",
       "      <td>0.132423</td>\n",
       "      <td>0.282815</td>\n",
       "      <td>0.128134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">speed</th>\n",
       "      <th>3</th>\n",
       "      <td>0.185740</td>\n",
       "      <td>0.133068</td>\n",
       "      <td>0.236779</td>\n",
       "      <td>0.075964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.207761</td>\n",
       "      <td>0.069360</td>\n",
       "      <td>0.257523</td>\n",
       "      <td>0.097659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.208930</td>\n",
       "      <td>0.060424</td>\n",
       "      <td>0.244965</td>\n",
       "      <td>0.091453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.254065</td>\n",
       "      <td>0.050841</td>\n",
       "      <td>0.252793</td>\n",
       "      <td>0.052609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.202450</td>\n",
       "      <td>0.039219</td>\n",
       "      <td>0.248096</td>\n",
       "      <td>0.041251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.200290</td>\n",
       "      <td>0.013500</td>\n",
       "      <td>0.238531</td>\n",
       "      <td>0.048938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">support</th>\n",
       "      <th>3</th>\n",
       "      <td>0.154117</td>\n",
       "      <td>0.054111</td>\n",
       "      <td>0.218773</td>\n",
       "      <td>0.025807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.194816</td>\n",
       "      <td>0.033789</td>\n",
       "      <td>0.225212</td>\n",
       "      <td>0.049571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.205679</td>\n",
       "      <td>0.065109</td>\n",
       "      <td>0.253916</td>\n",
       "      <td>0.074101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.248490</td>\n",
       "      <td>0.095126</td>\n",
       "      <td>0.281672</td>\n",
       "      <td>0.101288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.275332</td>\n",
       "      <td>0.111076</td>\n",
       "      <td>0.283711</td>\n",
       "      <td>0.104640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.272356</td>\n",
       "      <td>0.121403</td>\n",
       "      <td>0.274015</td>\n",
       "      <td>0.119526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">win_con</th>\n",
       "      <th>3</th>\n",
       "      <td>0.153863</td>\n",
       "      <td>0.085098</td>\n",
       "      <td>0.207707</td>\n",
       "      <td>0.025780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.169765</td>\n",
       "      <td>0.003567</td>\n",
       "      <td>0.240889</td>\n",
       "      <td>0.069265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.226818</td>\n",
       "      <td>0.090737</td>\n",
       "      <td>0.241187</td>\n",
       "      <td>0.084910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.278958</td>\n",
       "      <td>0.092142</td>\n",
       "      <td>0.271354</td>\n",
       "      <td>0.083002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.280188</td>\n",
       "      <td>0.115289</td>\n",
       "      <td>0.287638</td>\n",
       "      <td>0.106429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.264643</td>\n",
       "      <td>0.124961</td>\n",
       "      <td>0.277459</td>\n",
       "      <td>0.114905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">win_con_dmg</th>\n",
       "      <th>3</th>\n",
       "      <td>0.153863</td>\n",
       "      <td>0.085098</td>\n",
       "      <td>0.207707</td>\n",
       "      <td>0.025780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.169765</td>\n",
       "      <td>0.003567</td>\n",
       "      <td>0.240889</td>\n",
       "      <td>0.069265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.226818</td>\n",
       "      <td>0.090737</td>\n",
       "      <td>0.241187</td>\n",
       "      <td>0.084910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.278958</td>\n",
       "      <td>0.092142</td>\n",
       "      <td>0.271354</td>\n",
       "      <td>0.083002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.280188</td>\n",
       "      <td>0.115289</td>\n",
       "      <td>0.287638</td>\n",
       "      <td>0.106429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.264643</td>\n",
       "      <td>0.124961</td>\n",
       "      <td>0.277459</td>\n",
       "      <td>0.114905</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          gmm_spell            km_spell          \n",
       "                               mean       std      mean       std\n",
       "col                     K                                        \n",
       "affected_crown          3  0.138686  0.044009  0.187460  0.025032\n",
       "                        4  0.188749  0.072113  0.226947  0.072607\n",
       "                        5  0.244867  0.099078  0.239425  0.093986\n",
       "                        6  0.270288  0.100357  0.275674  0.094733\n",
       "                        7  0.256897  0.134264  0.274707  0.118895\n",
       "                        8  0.273843  0.119563  0.273002  0.120578\n",
       "air_control             3  0.153863  0.085098  0.207707  0.025780\n",
       "                        4  0.169765  0.003567  0.240889  0.069265\n",
       "                        5  0.226818  0.090737  0.241187  0.084910\n",
       "                        6  0.278958  0.092142  0.271354  0.083002\n",
       "                        7  0.280188  0.115289  0.287638  0.106429\n",
       "                        8  0.264643  0.124961  0.277459  0.114905\n",
       "any_target              3  0.153863  0.085098  0.207707  0.025780\n",
       "                        4  0.169765  0.003567  0.240889  0.069265\n",
       "                        5  0.226818  0.090737  0.241187  0.084910\n",
       "                        6  0.278958  0.092142  0.271354  0.083002\n",
       "                        7  0.280188  0.115289  0.287638  0.106429\n",
       "                        8  0.264643  0.124961  0.277459  0.114905\n",
       "aoe_bool                3  0.184535  0.056828  0.227512  0.036142\n",
       "                        4  0.227074  0.075593  0.252768  0.080316\n",
       "                        5  0.246722  0.135133  0.272915  0.102928\n",
       "                        6  0.265259  0.090838  0.281466  0.117486\n",
       "                        7  0.256782  0.110285  0.263967  0.129607\n",
       "                        8  0.293481  0.125139  0.300665  0.118047\n",
       "aoe_by_damage           3  0.279093  0.081564  0.286520  0.083200\n",
       "                        4  0.253035  0.143334  0.304328  0.108161\n",
       "                        5  0.166672  0.123682  0.325137  0.124528\n",
       "                        6  0.174629  0.147134  0.327749  0.134740\n",
       "                        7  0.217242  0.031639  0.305809  0.125223\n",
       "                        8  0.144112  0.052752  0.309131  0.129905\n",
       "aoe_by_range            3  0.228539  0.233126  0.328012  0.151065\n",
       "                        4  0.340909  0.192609  0.366913  0.179497\n",
       "                        5  0.315952  0.180548  0.356488  0.160371\n",
       "                        6  0.274172  0.060852  0.337611  0.148437\n",
       "                        7  0.269159  0.095590  0.306814  0.116405\n",
       "                        8  0.209207  0.021154  0.307684  0.094665\n",
       "aoe_per_elixir          3  0.208986  0.084176  0.226137  0.069113\n",
       "                        4  0.194701  0.060488  0.256510  0.102518\n",
       "                        5  0.144451  0.063708  0.262173  0.091890\n",
       "                        6  0.243434  0.021087  0.266872  0.055866\n",
       "                        7  0.242560  0.029311  0.259791  0.047340\n",
       "                        8  0.240328  0.041750  0.247079  0.040354\n",
       "aoe_radius              3  0.129129  0.063145  0.224290  0.050696\n",
       "                        4  0.214561  0.073477  0.250974  0.092498\n",
       "                        5  0.211012  0.040305  0.257918  0.082032\n",
       "                        6  0.249788  0.034688  0.256075  0.035119\n",
       "                        7  0.226827  0.061839  0.249099  0.044922\n",
       "                        8  0.220210  0.038774  0.263056  0.054472\n",
       "attack_count            3  0.183464  0.070055  0.252466  0.086925\n",
       "                        4  0.205856  0.063417  0.285640  0.119548\n",
       "                        5  0.225756  0.061988  0.258835  0.091906\n",
       "                        6  0.246498  0.107457  0.265717  0.088768\n",
       "                        7  0.200769  0.013846  0.273571  0.078962\n",
       "                        8  0.224900  0.039150  0.270686  0.101750\n",
       "building_target         3  0.153863  0.085098  0.207707  0.025780\n",
       "                        4  0.169765  0.003567  0.240889  0.069265\n",
       "                        5  0.226818  0.090737  0.241187  0.084910\n",
       "                        6  0.278958  0.092142  0.271354  0.083002\n",
       "                        7  0.280188  0.115289  0.287638  0.106429\n",
       "                        8  0.264643  0.124961  0.277459  0.114905\n",
       "can_evolve              3  0.128134  0.058613  0.258684  0.087056\n",
       "                        4  0.107464  0.069263  0.245818  0.059598\n",
       "                        5  0.173621  0.008098  0.236423  0.036965\n",
       "                        6  0.198058  0.059604  0.246442  0.038724\n",
       "                        7  0.218834  0.011072  0.245543  0.032098\n",
       "                        8  0.224531  0.033541  0.251219  0.065092\n",
       "control_special         3  0.199571  0.048724  0.249182  0.095829\n",
       "                        4  0.214969  0.095942  0.246598  0.051659\n",
       "                        5  0.254043  0.077957  0.277291  0.084361\n",
       "                        6  0.311284  0.132837  0.294435  0.104591\n",
       "                        7  0.304158  0.139175  0.329582  0.162238\n",
       "                        8  0.315393  0.162767  0.321750  0.158787\n",
       "count                   3  0.185740  0.133068  0.236779  0.075964\n",
       "                        4  0.207761  0.069360  0.257523  0.097659\n",
       "                        5  0.208930  0.060424  0.244965  0.091453\n",
       "                        6  0.254065  0.050841  0.252793  0.052609\n",
       "                        7  0.202450  0.039219  0.248096  0.041251\n",
       "                        8  0.200290  0.013500  0.238531  0.048938\n",
       "damage                  3  0.148476  0.057529  0.227102  0.079143\n",
       "                        4  0.197855  0.080394  0.249251  0.102865\n",
       "                        5  0.214999  0.056209  0.251361  0.090535\n",
       "                        6  0.181246  0.070420  0.249732  0.057993\n",
       "                        7  0.227863  0.039606  0.237164  0.032943\n",
       "                        8  0.187227  0.027002  0.239040  0.044722\n",
       "damage_by_hitpoints     3  0.246394  0.159359  0.290096  0.081928\n",
       "                        4  0.146878  0.152238  0.304749  0.101477\n",
       "                        5  0.176991  0.106821  0.323643  0.121961\n",
       "                        6  0.226932  0.073528  0.335842  0.147986\n",
       "                        7  0.204495  0.042737  0.320677  0.131723\n",
       "                        8  0.182225  0.039951  0.313466  0.129180\n",
       "damage_output           3  0.207644  0.143533  0.298114  0.088801\n",
       "                        4  0.155122  0.067137  0.313718  0.110010\n",
       "                        5  0.189367  0.114484  0.333561  0.126337\n",
       "                        6  0.247858  0.053574  0.338732  0.137164\n",
       "                        7  0.212489  0.065480  0.337193  0.148132\n",
       "                        8  0.221321  0.025457  0.333674  0.133769\n",
       "damage_output_ps        3  0.185740  0.133068  0.236779  0.075964\n",
       "                        4  0.207761  0.069360  0.257523  0.097659\n",
       "                        5  0.208930  0.060424  0.244965  0.091453\n",
       "                        6  0.254065  0.050841  0.252793  0.052609\n",
       "                        7  0.202450  0.039219  0.248096  0.041251\n",
       "                        8  0.200290  0.013500  0.238531  0.048938\n",
       "damage_per_elixir       3  0.115843  0.220354  0.295746  0.094304\n",
       "                        4  0.250811  0.081152  0.331484  0.135047\n",
       "                        5  0.276374  0.145636  0.351823  0.152343\n",
       "                        6  0.158278  0.027462  0.314808  0.145708\n",
       "                        7  0.129017  0.214688  0.315013  0.110048\n",
       "                        8  0.151284  0.067892  0.294252  0.113679\n",
       "damage_per_second       3  0.246394  0.159359  0.290096  0.081928\n",
       "                        4  0.146878  0.152238  0.304749  0.101477\n",
       "                        5  0.176991  0.106821  0.323643  0.121961\n",
       "                        6  0.226932  0.073528  0.335842  0.147986\n",
       "                        7  0.204495  0.042737  0.320677  0.131723\n",
       "                        8  0.182225  0.039951  0.313466  0.129180\n",
       "death_damage_bool       3  0.153863  0.085098  0.207707  0.025780\n",
       "                        4  0.169765  0.003567  0.240889  0.069265\n",
       "                        5  0.226818  0.090737  0.241187  0.084910\n",
       "                        6  0.278958  0.092142  0.271354  0.083002\n",
       "                        7  0.280188  0.115289  0.287638  0.106429\n",
       "                        8  0.264643  0.124961  0.277459  0.114905\n",
       "dps_special             3  0.157740  0.143347  0.232075  0.102566\n",
       "                        4  0.199048  0.135391  0.241945  0.095626\n",
       "                        5  0.211004  0.130274  0.251483  0.098446\n",
       "                        6  0.239717  0.130729  0.259841  0.113446\n",
       "                        7  0.255067  0.113772  0.255067  0.113772\n",
       "                        8  0.275713  0.098720  0.283091  0.092219\n",
       "elixircost              3  0.213173  0.101220  0.244788  0.073142\n",
       "                        4  0.231658  0.096876  0.271306  0.112423\n",
       "                        5  0.250899  0.119979  0.270326  0.103694\n",
       "                        6  0.236263  0.082255  0.275947  0.086215\n",
       "                        7  0.277654  0.066635  0.276315  0.068560\n",
       "                        8  0.204094  0.065308  0.264303  0.078767\n",
       "fly_bool                3  0.153863  0.085098  0.207707  0.025780\n",
       "                        4  0.169765  0.003567  0.240889  0.069265\n",
       "                        5  0.226818  0.090737  0.241187  0.084910\n",
       "                        6  0.278958  0.092142  0.271354  0.083002\n",
       "                        7  0.280188  0.115289  0.287638  0.106429\n",
       "                        8  0.264643  0.124961  0.277459  0.114905\n",
       "ground_dps              3  0.153863  0.085098  0.207707  0.025780\n",
       "                        4  0.169765  0.003567  0.240889  0.069265\n",
       "                        5  0.226818  0.090737  0.241187  0.084910\n",
       "                        6  0.278958  0.092142  0.271354  0.083002\n",
       "                        7  0.280188  0.115289  0.287638  0.106429\n",
       "                        8  0.264643  0.124961  0.277459  0.114905\n",
       "ground_target           3  0.153863  0.085098  0.207707  0.025780\n",
       "                        4  0.169765  0.003567  0.240889  0.069265\n",
       "                        5  0.226818  0.090737  0.241187  0.084910\n",
       "                        6  0.278958  0.092142  0.271354  0.083002\n",
       "                        7  0.280188  0.115289  0.287638  0.106429\n",
       "                        8  0.264643  0.124961  0.277459  0.114905\n",
       "has_ability             3  0.153863  0.085098  0.207707  0.025780\n",
       "                        4  0.169765  0.003567  0.240889  0.069265\n",
       "                        5  0.226818  0.090737  0.241187  0.084910\n",
       "                        6  0.278958  0.092142  0.271354  0.083002\n",
       "                        7  0.280188  0.115289  0.287638  0.106429\n",
       "                        8  0.264643  0.124961  0.277459  0.114905\n",
       "has_friendly_buff       3  0.199591  0.065271  0.230988  0.036171\n",
       "                        4  0.213183  0.060569  0.252789  0.091755\n",
       "                        5  0.279693  0.102006  0.292383  0.125245\n",
       "                        6  0.297289  0.133840  0.311086  0.119865\n",
       "                        7  0.309553  0.145024  0.328085  0.140605\n",
       "                        8  0.325507  0.133094  0.331499  0.127724\n",
       "has_lifetime            3  0.153863  0.085098  0.207707  0.025780\n",
       "                        4  0.169765  0.003567  0.240889  0.069265\n",
       "                        5  0.226818  0.090737  0.241187  0.084910\n",
       "                        6  0.278958  0.092142  0.271354  0.083002\n",
       "                        7  0.280188  0.115289  0.287638  0.106429\n",
       "                        8  0.264643  0.124961  0.277459  0.114905\n",
       "has_periodic_spawn      3  0.181906  0.050237  0.225873  0.029110\n",
       "                        4  0.240118  0.074638  0.258534  0.082998\n",
       "                        5  0.266332  0.085979  0.270575  0.090689\n",
       "                        6  0.282379  0.097810  0.298273  0.090524\n",
       "                        7  0.304755  0.124724  0.316123  0.115130\n",
       "                        8  0.316134  0.133990  0.328483  0.121625\n",
       "has_ranged_attack       3  0.153863  0.085098  0.207707  0.025780\n",
       "                        4  0.169765  0.003567  0.240889  0.069265\n",
       "                        5  0.226818  0.090737  0.241187  0.084910\n",
       "                        6  0.278958  0.092142  0.271354  0.083002\n",
       "                        7  0.280188  0.115289  0.287638  0.106429\n",
       "                        8  0.264643  0.124961  0.277459  0.114905\n",
       "has_upon_breaking_spawn 3  0.142908  0.083114  0.202244  0.035320\n",
       "                        4  0.172358  0.034872  0.220452  0.043969\n",
       "                        5  0.212549  0.062029  0.240676  0.047061\n",
       "                        6  0.257491  0.056681  0.255306  0.052897\n",
       "                        7  0.269456  0.132227  0.287473  0.117393\n",
       "                        8  0.293774  0.133561  0.289484  0.126289\n",
       "has_upon_death_spawn    3  0.153863  0.085098  0.207707  0.025780\n",
       "                        4  0.169765  0.003567  0.240889  0.069265\n",
       "                        5  0.226818  0.090737  0.241187  0.084910\n",
       "                        6  0.278958  0.092142  0.271354  0.083002\n",
       "                        7  0.280188  0.115289  0.287638  0.106429\n",
       "                        8  0.264643  0.124961  0.277459  0.114905\n",
       "high_dps                3  0.138615  0.103507  0.204901  0.038626\n",
       "                        4  0.203490  0.074877  0.222198  0.073126\n",
       "                        5  0.223037  0.083023  0.241160  0.066440\n",
       "                        6  0.239816  0.118775  0.247359  0.112051\n",
       "                        7  0.248301  0.107070  0.249007  0.106499\n",
       "                        8  0.223328  0.076703  0.257362  0.106471\n",
       "hit_speed               3  0.185740  0.133068  0.236779  0.075964\n",
       "                        4  0.207761  0.069360  0.257523  0.097659\n",
       "                        5  0.208930  0.060424  0.244965  0.091453\n",
       "                        6  0.254065  0.050841  0.252793  0.052609\n",
       "                        7  0.202450  0.039219  0.248096  0.041251\n",
       "                        8  0.200290  0.013500  0.238531  0.048938\n",
       "hitpoints               3  0.185740  0.133068  0.236779  0.075964\n",
       "                        4  0.207761  0.069360  0.257523  0.097659\n",
       "                        5  0.208930  0.060424  0.244965  0.091453\n",
       "                        6  0.254065  0.050841  0.252793  0.052609\n",
       "                        7  0.202450  0.039219  0.248096  0.041251\n",
       "                        8  0.200290  0.013500  0.238531  0.048938\n",
       "hp_per_elixir           3  0.266551  0.111445  0.347452  0.134822\n",
       "                        4  0.218166  0.165194  0.343464  0.139377\n",
       "                        5  0.351620  0.166055  0.330605  0.123481\n",
       "                        6  0.218870  0.133499  0.321147  0.102911\n",
       "                        7  0.262402  0.059252  0.304137  0.093214\n",
       "                        8  0.281955  0.066702  0.305832  0.084246\n",
       "invisible               3  0.153863  0.085098  0.207707  0.025780\n",
       "                        4  0.169765  0.003567  0.240889  0.069265\n",
       "                        5  0.226818  0.090737  0.241187  0.084910\n",
       "                        6  0.278958  0.092142  0.271354  0.083002\n",
       "                        7  0.280188  0.115289  0.287638  0.106429\n",
       "                        8  0.264643  0.124961  0.277459  0.114905\n",
       "is_building             3  0.153863  0.085098  0.207707  0.025780\n",
       "                        4  0.169765  0.003567  0.240889  0.069265\n",
       "                        5  0.226818  0.090737  0.241187  0.084910\n",
       "                        6  0.278958  0.092142  0.271354  0.083002\n",
       "                        7  0.280188  0.115289  0.287638  0.106429\n",
       "                        8  0.264643  0.124961  0.277459  0.114905\n",
       "is_free_card            3  0.153863  0.085098  0.207707  0.025780\n",
       "                        4  0.169765  0.003567  0.240889  0.069265\n",
       "                        5  0.226818  0.090737  0.241187  0.084910\n",
       "                        6  0.278958  0.092142  0.271354  0.083002\n",
       "                        7  0.280188  0.115289  0.287638  0.106429\n",
       "                        8  0.264643  0.124961  0.277459  0.114905\n",
       "is_spawned              3  0.189624  0.073401  0.219853  0.027867\n",
       "                        4  0.212238  0.097244  0.249677  0.085384\n",
       "                        5  0.226147  0.064479  0.251941  0.094836\n",
       "                        6  0.267403  0.118555  0.281747  0.106949\n",
       "                        7  0.289954  0.101467  0.281887  0.105217\n",
       "                        8  0.271858  0.128163  0.271774  0.128249\n",
       "is_spell                3  0.153863  0.085098  0.207707  0.025780\n",
       "                        4  0.169765  0.003567  0.240889  0.069265\n",
       "                        5  0.226818  0.090737  0.241187  0.084910\n",
       "                        6  0.278958  0.092142  0.271354  0.083002\n",
       "                        7  0.280188  0.115289  0.287638  0.106429\n",
       "                        8  0.264643  0.124961  0.277459  0.114905\n",
       "is_tower_troop          3  0.153863  0.085098  0.207707  0.025780\n",
       "                        4  0.169765  0.003567  0.240889  0.069265\n",
       "                        5  0.226818  0.090737  0.241187  0.084910\n",
       "                        6  0.278958  0.092142  0.271354  0.083002\n",
       "                        7  0.280188  0.115289  0.287638  0.106429\n",
       "                        8  0.264643  0.124961  0.277459  0.114905\n",
       "is_troop                3  0.153863  0.085098  0.207707  0.025780\n",
       "                        4  0.169765  0.003567  0.240889  0.069265\n",
       "                        5  0.226818  0.090737  0.241187  0.084910\n",
       "                        6  0.278958  0.092142  0.271354  0.083002\n",
       "                        7  0.280188  0.115289  0.287638  0.106429\n",
       "                        8  0.264643  0.124961  0.277459  0.114905\n",
       "mini_tank               3  0.153863  0.085098  0.207707  0.025780\n",
       "                        4  0.169765  0.003567  0.240889  0.069265\n",
       "                        5  0.226818  0.090737  0.241187  0.084910\n",
       "                        6  0.278958  0.092142  0.271354  0.083002\n",
       "                        7  0.280188  0.115289  0.287638  0.106429\n",
       "                        8  0.264643  0.124961  0.277459  0.114905\n",
       "no_attack               3  0.158440  0.079845  0.214306  0.033435\n",
       "                        4  0.162612  0.066656  0.216318  0.052721\n",
       "                        5  0.219861  0.100154  0.239948  0.071167\n",
       "                        6  0.260638  0.101009  0.267208  0.092930\n",
       "                        7  0.270721  0.108001  0.276567  0.104227\n",
       "                        8  0.267389  0.117658  0.268606  0.116201\n",
       "no_hit_speed            3  0.153863  0.085098  0.207707  0.025780\n",
       "                        4  0.169765  0.003567  0.240889  0.069265\n",
       "                        5  0.226818  0.090737  0.241187  0.084910\n",
       "                        6  0.278958  0.092142  0.271354  0.083002\n",
       "                        7  0.280188  0.115289  0.287638  0.106429\n",
       "                        8  0.264643  0.124961  0.277459  0.114905\n",
       "no_hitpoints            3  0.153863  0.085098  0.207707  0.025780\n",
       "                        4  0.169765  0.003567  0.240889  0.069265\n",
       "                        5  0.226818  0.090737  0.241187  0.084910\n",
       "                        6  0.278958  0.092142  0.271354  0.083002\n",
       "                        7  0.280188  0.115289  0.287638  0.106429\n",
       "                        8  0.264643  0.124961  0.277459  0.114905\n",
       "playable                3  0.153863  0.085098  0.207707  0.025780\n",
       "                        4  0.169765  0.003567  0.240889  0.069265\n",
       "                        5  0.226818  0.090737  0.241187  0.084910\n",
       "                        6  0.278958  0.092142  0.271354  0.083002\n",
       "                        7  0.280188  0.115289  0.287638  0.106429\n",
       "                        8  0.264643  0.124961  0.277459  0.114905\n",
       "range                   3  0.185740  0.133068  0.236779  0.075964\n",
       "                        4  0.207761  0.069360  0.257523  0.097659\n",
       "                        5  0.208930  0.060424  0.244965  0.091453\n",
       "                        6  0.254065  0.050841  0.252793  0.052609\n",
       "                        7  0.202450  0.039219  0.248096  0.041251\n",
       "                        8  0.200290  0.013500  0.238531  0.048938\n",
       "shield_bool             3  0.153863  0.085098  0.207707  0.025780\n",
       "                        4  0.169765  0.003567  0.240889  0.069265\n",
       "                        5  0.226818  0.090737  0.241187  0.084910\n",
       "                        6  0.278958  0.092142  0.271354  0.083002\n",
       "                        7  0.280188  0.115289  0.287638  0.106429\n",
       "                        8  0.264643  0.124961  0.277459  0.114905\n",
       "single_damage_type      3  0.171004  0.062671  0.214100  0.013687\n",
       "                        4  0.196139  0.088272  0.234808  0.053593\n",
       "                        5  0.245699  0.089315  0.261820  0.082757\n",
       "                        6  0.230893  0.123128  0.261241  0.105113\n",
       "                        7  0.250235  0.139768  0.266671  0.126239\n",
       "                        8  0.282642  0.111610  0.297346  0.092011\n",
       "spawn_bool              3  0.166346  0.060626  0.207153  0.028569\n",
       "                        4  0.227261  0.096262  0.241893  0.082142\n",
       "                        5  0.252181  0.096469  0.259782  0.088205\n",
       "                        6  0.281097  0.108786  0.286326  0.103289\n",
       "                        7  0.267641  0.128380  0.285650  0.111047\n",
       "                        8  0.279615  0.120993  0.278662  0.122138\n",
       "special_attack_type     3  0.175773  0.032161  0.253561  0.086749\n",
       "                        4  0.233794  0.075314  0.265960  0.084430\n",
       "                        5  0.250395  0.079944  0.277275  0.083955\n",
       "                        6  0.265901  0.125691  0.274293  0.113187\n",
       "                        7  0.269705  0.145297  0.282676  0.135521\n",
       "                        8  0.274827  0.141031  0.277801  0.137831\n",
       "special_damage          3  0.177247  0.069897  0.201102  0.030727\n",
       "                        4  0.214450  0.108252  0.247899  0.078907\n",
       "                        5  0.250569  0.082676  0.261915  0.077721\n",
       "                        6  0.287171  0.104388  0.278564  0.112262\n",
       "                        7  0.277057  0.131165  0.285736  0.122075\n",
       "                        8  0.279296  0.132423  0.282815  0.128134\n",
       "speed                   3  0.185740  0.133068  0.236779  0.075964\n",
       "                        4  0.207761  0.069360  0.257523  0.097659\n",
       "                        5  0.208930  0.060424  0.244965  0.091453\n",
       "                        6  0.254065  0.050841  0.252793  0.052609\n",
       "                        7  0.202450  0.039219  0.248096  0.041251\n",
       "                        8  0.200290  0.013500  0.238531  0.048938\n",
       "support                 3  0.154117  0.054111  0.218773  0.025807\n",
       "                        4  0.194816  0.033789  0.225212  0.049571\n",
       "                        5  0.205679  0.065109  0.253916  0.074101\n",
       "                        6  0.248490  0.095126  0.281672  0.101288\n",
       "                        7  0.275332  0.111076  0.283711  0.104640\n",
       "                        8  0.272356  0.121403  0.274015  0.119526\n",
       "win_con                 3  0.153863  0.085098  0.207707  0.025780\n",
       "                        4  0.169765  0.003567  0.240889  0.069265\n",
       "                        5  0.226818  0.090737  0.241187  0.084910\n",
       "                        6  0.278958  0.092142  0.271354  0.083002\n",
       "                        7  0.280188  0.115289  0.287638  0.106429\n",
       "                        8  0.264643  0.124961  0.277459  0.114905\n",
       "win_con_dmg             3  0.153863  0.085098  0.207707  0.025780\n",
       "                        4  0.169765  0.003567  0.240889  0.069265\n",
       "                        5  0.226818  0.090737  0.241187  0.084910\n",
       "                        6  0.278958  0.092142  0.271354  0.083002\n",
       "                        7  0.280188  0.115289  0.287638  0.106429\n",
       "                        8  0.264643  0.124961  0.277459  0.114905"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sim.groupby(['col', 'K']).agg({'gmm_spell': ['mean', 'std'], 'km_spell': ['mean', 'std']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b150d90c-9d8e-430c-be95-19556ad0c300",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">gmm_building</th>\n",
       "      <th colspan=\"2\" halign=\"left\">km_building</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>col</th>\n",
       "      <th>K</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">affected_crown</th>\n",
       "      <th>3</th>\n",
       "      <td>0.276063</td>\n",
       "      <td>0.037904</td>\n",
       "      <td>0.317661</td>\n",
       "      <td>0.035941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.283669</td>\n",
       "      <td>0.040745</td>\n",
       "      <td>0.310357</td>\n",
       "      <td>0.021676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.277462</td>\n",
       "      <td>0.024232</td>\n",
       "      <td>0.279732</td>\n",
       "      <td>0.028038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.255512</td>\n",
       "      <td>0.015445</td>\n",
       "      <td>0.255512</td>\n",
       "      <td>0.015445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.227350</td>\n",
       "      <td>0.022887</td>\n",
       "      <td>0.243840</td>\n",
       "      <td>0.047660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.215071</td>\n",
       "      <td>0.033305</td>\n",
       "      <td>0.215071</td>\n",
       "      <td>0.033305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">air_control</th>\n",
       "      <th>3</th>\n",
       "      <td>0.302319</td>\n",
       "      <td>0.016955</td>\n",
       "      <td>0.310023</td>\n",
       "      <td>0.029025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.313351</td>\n",
       "      <td>0.013827</td>\n",
       "      <td>0.312872</td>\n",
       "      <td>0.033104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.278114</td>\n",
       "      <td>0.033707</td>\n",
       "      <td>0.278114</td>\n",
       "      <td>0.033707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.280608</td>\n",
       "      <td>0.021473</td>\n",
       "      <td>0.279008</td>\n",
       "      <td>0.019039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.247580</td>\n",
       "      <td>0.022943</td>\n",
       "      <td>0.250454</td>\n",
       "      <td>0.024000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.222259</td>\n",
       "      <td>0.021125</td>\n",
       "      <td>0.222259</td>\n",
       "      <td>0.021125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">any_target</th>\n",
       "      <th>3</th>\n",
       "      <td>0.266780</td>\n",
       "      <td>0.038567</td>\n",
       "      <td>0.303061</td>\n",
       "      <td>0.027318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.277490</td>\n",
       "      <td>0.051786</td>\n",
       "      <td>0.296680</td>\n",
       "      <td>0.027381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.275872</td>\n",
       "      <td>0.037461</td>\n",
       "      <td>0.295006</td>\n",
       "      <td>0.021510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.274542</td>\n",
       "      <td>0.020862</td>\n",
       "      <td>0.274542</td>\n",
       "      <td>0.020862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.260733</td>\n",
       "      <td>0.029861</td>\n",
       "      <td>0.260733</td>\n",
       "      <td>0.029861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.218738</td>\n",
       "      <td>0.031651</td>\n",
       "      <td>0.218738</td>\n",
       "      <td>0.031651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">aoe_bool</th>\n",
       "      <th>3</th>\n",
       "      <td>0.290350</td>\n",
       "      <td>0.025555</td>\n",
       "      <td>0.304410</td>\n",
       "      <td>0.057742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.287848</td>\n",
       "      <td>0.066374</td>\n",
       "      <td>0.308819</td>\n",
       "      <td>0.047751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.297225</td>\n",
       "      <td>0.047393</td>\n",
       "      <td>0.297225</td>\n",
       "      <td>0.047393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.278035</td>\n",
       "      <td>0.059866</td>\n",
       "      <td>0.278035</td>\n",
       "      <td>0.059866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.270116</td>\n",
       "      <td>0.062578</td>\n",
       "      <td>0.270116</td>\n",
       "      <td>0.062578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.231270</td>\n",
       "      <td>0.073309</td>\n",
       "      <td>0.231270</td>\n",
       "      <td>0.073309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">aoe_by_damage</th>\n",
       "      <th>3</th>\n",
       "      <td>0.328229</td>\n",
       "      <td>0.032723</td>\n",
       "      <td>0.383883</td>\n",
       "      <td>0.121659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.470417</td>\n",
       "      <td>0.174641</td>\n",
       "      <td>0.470417</td>\n",
       "      <td>0.174641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.436434</td>\n",
       "      <td>0.179270</td>\n",
       "      <td>0.436434</td>\n",
       "      <td>0.179270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.377467</td>\n",
       "      <td>0.155510</td>\n",
       "      <td>0.377467</td>\n",
       "      <td>0.155510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.344932</td>\n",
       "      <td>0.117378</td>\n",
       "      <td>0.344932</td>\n",
       "      <td>0.117378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.263285</td>\n",
       "      <td>0.074940</td>\n",
       "      <td>0.263285</td>\n",
       "      <td>0.074940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">aoe_by_range</th>\n",
       "      <th>3</th>\n",
       "      <td>0.342124</td>\n",
       "      <td>0.058068</td>\n",
       "      <td>0.375992</td>\n",
       "      <td>0.114591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.439929</td>\n",
       "      <td>0.200352</td>\n",
       "      <td>0.463926</td>\n",
       "      <td>0.165918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.437247</td>\n",
       "      <td>0.168132</td>\n",
       "      <td>0.437247</td>\n",
       "      <td>0.168132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.373687</td>\n",
       "      <td>0.151137</td>\n",
       "      <td>0.373687</td>\n",
       "      <td>0.151137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.341152</td>\n",
       "      <td>0.113236</td>\n",
       "      <td>0.341152</td>\n",
       "      <td>0.113236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.262546</td>\n",
       "      <td>0.075965</td>\n",
       "      <td>0.262546</td>\n",
       "      <td>0.075965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">aoe_per_elixir</th>\n",
       "      <th>3</th>\n",
       "      <td>0.297024</td>\n",
       "      <td>0.035505</td>\n",
       "      <td>0.293842</td>\n",
       "      <td>0.039911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.314338</td>\n",
       "      <td>0.109563</td>\n",
       "      <td>0.338312</td>\n",
       "      <td>0.092232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.304968</td>\n",
       "      <td>0.056767</td>\n",
       "      <td>0.304968</td>\n",
       "      <td>0.056767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.268756</td>\n",
       "      <td>0.042471</td>\n",
       "      <td>0.268756</td>\n",
       "      <td>0.042471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.260979</td>\n",
       "      <td>0.044448</td>\n",
       "      <td>0.260979</td>\n",
       "      <td>0.044448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.211156</td>\n",
       "      <td>0.035860</td>\n",
       "      <td>0.211156</td>\n",
       "      <td>0.035860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">aoe_radius</th>\n",
       "      <th>3</th>\n",
       "      <td>0.297024</td>\n",
       "      <td>0.035505</td>\n",
       "      <td>0.293842</td>\n",
       "      <td>0.039911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.314338</td>\n",
       "      <td>0.109563</td>\n",
       "      <td>0.338312</td>\n",
       "      <td>0.092232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.304968</td>\n",
       "      <td>0.056767</td>\n",
       "      <td>0.304968</td>\n",
       "      <td>0.056767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.268756</td>\n",
       "      <td>0.042471</td>\n",
       "      <td>0.268756</td>\n",
       "      <td>0.042471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.260979</td>\n",
       "      <td>0.044448</td>\n",
       "      <td>0.260979</td>\n",
       "      <td>0.044448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.211156</td>\n",
       "      <td>0.035860</td>\n",
       "      <td>0.211156</td>\n",
       "      <td>0.035860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">attack_count</th>\n",
       "      <th>3</th>\n",
       "      <td>0.307743</td>\n",
       "      <td>0.042009</td>\n",
       "      <td>0.307743</td>\n",
       "      <td>0.042009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.326896</td>\n",
       "      <td>0.076338</td>\n",
       "      <td>0.331255</td>\n",
       "      <td>0.070635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.301784</td>\n",
       "      <td>0.047728</td>\n",
       "      <td>0.301784</td>\n",
       "      <td>0.047728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.257213</td>\n",
       "      <td>0.029333</td>\n",
       "      <td>0.257213</td>\n",
       "      <td>0.029333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.240046</td>\n",
       "      <td>0.015218</td>\n",
       "      <td>0.249691</td>\n",
       "      <td>0.029991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.214721</td>\n",
       "      <td>0.032700</td>\n",
       "      <td>0.214721</td>\n",
       "      <td>0.032700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">building_target</th>\n",
       "      <th>3</th>\n",
       "      <td>0.259394</td>\n",
       "      <td>0.052979</td>\n",
       "      <td>0.300165</td>\n",
       "      <td>0.020131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.273144</td>\n",
       "      <td>0.047094</td>\n",
       "      <td>0.290716</td>\n",
       "      <td>0.023479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.272979</td>\n",
       "      <td>0.038483</td>\n",
       "      <td>0.292629</td>\n",
       "      <td>0.022059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.258498</td>\n",
       "      <td>0.014284</td>\n",
       "      <td>0.258498</td>\n",
       "      <td>0.014284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.254118</td>\n",
       "      <td>0.042466</td>\n",
       "      <td>0.254118</td>\n",
       "      <td>0.042466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.215738</td>\n",
       "      <td>0.037141</td>\n",
       "      <td>0.215738</td>\n",
       "      <td>0.037141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">can_evolve</th>\n",
       "      <th>3</th>\n",
       "      <td>0.317795</td>\n",
       "      <td>0.022746</td>\n",
       "      <td>0.330351</td>\n",
       "      <td>0.043657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.371963</td>\n",
       "      <td>0.113745</td>\n",
       "      <td>0.371963</td>\n",
       "      <td>0.113745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.343652</td>\n",
       "      <td>0.081153</td>\n",
       "      <td>0.343652</td>\n",
       "      <td>0.081153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.282498</td>\n",
       "      <td>0.049362</td>\n",
       "      <td>0.282498</td>\n",
       "      <td>0.049362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.295845</td>\n",
       "      <td>0.060616</td>\n",
       "      <td>0.270496</td>\n",
       "      <td>0.020469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.231597</td>\n",
       "      <td>0.013957</td>\n",
       "      <td>0.231597</td>\n",
       "      <td>0.013957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">control_special</th>\n",
       "      <th>3</th>\n",
       "      <td>0.315119</td>\n",
       "      <td>0.032961</td>\n",
       "      <td>0.315119</td>\n",
       "      <td>0.032961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.279287</td>\n",
       "      <td>0.042935</td>\n",
       "      <td>0.307101</td>\n",
       "      <td>0.021465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.277561</td>\n",
       "      <td>0.035072</td>\n",
       "      <td>0.277561</td>\n",
       "      <td>0.035072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.250699</td>\n",
       "      <td>0.020582</td>\n",
       "      <td>0.250699</td>\n",
       "      <td>0.020582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.237303</td>\n",
       "      <td>0.018921</td>\n",
       "      <td>0.253840</td>\n",
       "      <td>0.043012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.215688</td>\n",
       "      <td>0.036974</td>\n",
       "      <td>0.215688</td>\n",
       "      <td>0.036974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">count</th>\n",
       "      <th>3</th>\n",
       "      <td>0.306121</td>\n",
       "      <td>0.031329</td>\n",
       "      <td>0.306121</td>\n",
       "      <td>0.031329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.344961</td>\n",
       "      <td>0.089489</td>\n",
       "      <td>0.344961</td>\n",
       "      <td>0.089489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.319107</td>\n",
       "      <td>0.062499</td>\n",
       "      <td>0.319107</td>\n",
       "      <td>0.062499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.271900</td>\n",
       "      <td>0.039515</td>\n",
       "      <td>0.271900</td>\n",
       "      <td>0.039515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.264544</td>\n",
       "      <td>0.041030</td>\n",
       "      <td>0.264544</td>\n",
       "      <td>0.041030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.214721</td>\n",
       "      <td>0.032700</td>\n",
       "      <td>0.214721</td>\n",
       "      <td>0.032700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">damage</th>\n",
       "      <th>3</th>\n",
       "      <td>0.300849</td>\n",
       "      <td>0.026796</td>\n",
       "      <td>0.300849</td>\n",
       "      <td>0.026796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.335677</td>\n",
       "      <td>0.082694</td>\n",
       "      <td>0.335677</td>\n",
       "      <td>0.082694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.312142</td>\n",
       "      <td>0.054085</td>\n",
       "      <td>0.312142</td>\n",
       "      <td>0.054085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.264797</td>\n",
       "      <td>0.036409</td>\n",
       "      <td>0.264797</td>\n",
       "      <td>0.036409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.261455</td>\n",
       "      <td>0.037583</td>\n",
       "      <td>0.261455</td>\n",
       "      <td>0.037583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.213825</td>\n",
       "      <td>0.030923</td>\n",
       "      <td>0.213825</td>\n",
       "      <td>0.030923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">damage_by_hitpoints</th>\n",
       "      <th>3</th>\n",
       "      <td>0.361852</td>\n",
       "      <td>0.082058</td>\n",
       "      <td>0.361852</td>\n",
       "      <td>0.082058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.460095</td>\n",
       "      <td>0.173539</td>\n",
       "      <td>0.460095</td>\n",
       "      <td>0.173539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.432637</td>\n",
       "      <td>0.175374</td>\n",
       "      <td>0.432637</td>\n",
       "      <td>0.175374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.372053</td>\n",
       "      <td>0.155708</td>\n",
       "      <td>0.372053</td>\n",
       "      <td>0.155708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.345401</td>\n",
       "      <td>0.116231</td>\n",
       "      <td>0.345401</td>\n",
       "      <td>0.116231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.275609</td>\n",
       "      <td>0.090929</td>\n",
       "      <td>0.275609</td>\n",
       "      <td>0.090929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">damage_output</th>\n",
       "      <th>3</th>\n",
       "      <td>0.411806</td>\n",
       "      <td>0.170395</td>\n",
       "      <td>0.426120</td>\n",
       "      <td>0.161412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.374633</td>\n",
       "      <td>0.066784</td>\n",
       "      <td>0.451068</td>\n",
       "      <td>0.186474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.347945</td>\n",
       "      <td>0.082712</td>\n",
       "      <td>0.394651</td>\n",
       "      <td>0.160168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.355763</td>\n",
       "      <td>0.139366</td>\n",
       "      <td>0.345393</td>\n",
       "      <td>0.146483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.289791</td>\n",
       "      <td>0.085002</td>\n",
       "      <td>0.300300</td>\n",
       "      <td>0.078083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.266126</td>\n",
       "      <td>0.084731</td>\n",
       "      <td>0.266126</td>\n",
       "      <td>0.084731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">damage_output_ps</th>\n",
       "      <th>3</th>\n",
       "      <td>0.291317</td>\n",
       "      <td>0.041581</td>\n",
       "      <td>0.297489</td>\n",
       "      <td>0.050734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.337544</td>\n",
       "      <td>0.096308</td>\n",
       "      <td>0.337544</td>\n",
       "      <td>0.096308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.314007</td>\n",
       "      <td>0.067649</td>\n",
       "      <td>0.314007</td>\n",
       "      <td>0.067649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.267592</td>\n",
       "      <td>0.041390</td>\n",
       "      <td>0.267592</td>\n",
       "      <td>0.041390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.263794</td>\n",
       "      <td>0.038467</td>\n",
       "      <td>0.263794</td>\n",
       "      <td>0.038467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.214147</td>\n",
       "      <td>0.030414</td>\n",
       "      <td>0.214147</td>\n",
       "      <td>0.030414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">damage_per_elixir</th>\n",
       "      <th>3</th>\n",
       "      <td>0.332547</td>\n",
       "      <td>0.033200</td>\n",
       "      <td>0.371788</td>\n",
       "      <td>0.097883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.469183</td>\n",
       "      <td>0.181394</td>\n",
       "      <td>0.469183</td>\n",
       "      <td>0.181394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.440070</td>\n",
       "      <td>0.180612</td>\n",
       "      <td>0.440070</td>\n",
       "      <td>0.180612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.381818</td>\n",
       "      <td>0.160294</td>\n",
       "      <td>0.381818</td>\n",
       "      <td>0.160294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.286961</td>\n",
       "      <td>0.027112</td>\n",
       "      <td>0.350955</td>\n",
       "      <td>0.122248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.279372</td>\n",
       "      <td>0.092661</td>\n",
       "      <td>0.279372</td>\n",
       "      <td>0.092661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">damage_per_second</th>\n",
       "      <th>3</th>\n",
       "      <td>0.379683</td>\n",
       "      <td>0.104782</td>\n",
       "      <td>0.379683</td>\n",
       "      <td>0.104782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.470466</td>\n",
       "      <td>0.186019</td>\n",
       "      <td>0.470466</td>\n",
       "      <td>0.186019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.442716</td>\n",
       "      <td>0.193061</td>\n",
       "      <td>0.442716</td>\n",
       "      <td>0.193061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.379670</td>\n",
       "      <td>0.164845</td>\n",
       "      <td>0.379670</td>\n",
       "      <td>0.164845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.275934</td>\n",
       "      <td>0.032368</td>\n",
       "      <td>0.351031</td>\n",
       "      <td>0.126285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.265193</td>\n",
       "      <td>0.076774</td>\n",
       "      <td>0.265193</td>\n",
       "      <td>0.076774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">death_damage_bool</th>\n",
       "      <th>3</th>\n",
       "      <td>0.291537</td>\n",
       "      <td>0.044469</td>\n",
       "      <td>0.322365</td>\n",
       "      <td>0.046268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.305795</td>\n",
       "      <td>0.049814</td>\n",
       "      <td>0.325524</td>\n",
       "      <td>0.038619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.294206</td>\n",
       "      <td>0.073989</td>\n",
       "      <td>0.316005</td>\n",
       "      <td>0.037804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.302762</td>\n",
       "      <td>0.047531</td>\n",
       "      <td>0.302762</td>\n",
       "      <td>0.047531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.291615</td>\n",
       "      <td>0.053977</td>\n",
       "      <td>0.291615</td>\n",
       "      <td>0.053977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.264435</td>\n",
       "      <td>0.085422</td>\n",
       "      <td>0.264435</td>\n",
       "      <td>0.085422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">dps_special</th>\n",
       "      <th>3</th>\n",
       "      <td>0.264470</td>\n",
       "      <td>0.043456</td>\n",
       "      <td>0.307013</td>\n",
       "      <td>0.032800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.298750</td>\n",
       "      <td>0.021631</td>\n",
       "      <td>0.298750</td>\n",
       "      <td>0.021631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.294018</td>\n",
       "      <td>0.026443</td>\n",
       "      <td>0.294018</td>\n",
       "      <td>0.026443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.269050</td>\n",
       "      <td>0.034994</td>\n",
       "      <td>0.269050</td>\n",
       "      <td>0.034994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.244623</td>\n",
       "      <td>0.010625</td>\n",
       "      <td>0.261113</td>\n",
       "      <td>0.035259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.216669</td>\n",
       "      <td>0.036072</td>\n",
       "      <td>0.216669</td>\n",
       "      <td>0.036072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">elixircost</th>\n",
       "      <th>3</th>\n",
       "      <td>0.324169</td>\n",
       "      <td>0.043021</td>\n",
       "      <td>0.324169</td>\n",
       "      <td>0.043021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.368455</td>\n",
       "      <td>0.100122</td>\n",
       "      <td>0.368455</td>\n",
       "      <td>0.100122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.340947</td>\n",
       "      <td>0.076109</td>\n",
       "      <td>0.340947</td>\n",
       "      <td>0.076109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.303242</td>\n",
       "      <td>0.056164</td>\n",
       "      <td>0.303242</td>\n",
       "      <td>0.056164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.260060</td>\n",
       "      <td>0.013138</td>\n",
       "      <td>0.260060</td>\n",
       "      <td>0.013138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.214782</td>\n",
       "      <td>0.007731</td>\n",
       "      <td>0.214782</td>\n",
       "      <td>0.007731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">fly_bool</th>\n",
       "      <th>3</th>\n",
       "      <td>0.264470</td>\n",
       "      <td>0.043456</td>\n",
       "      <td>0.307013</td>\n",
       "      <td>0.032800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.298750</td>\n",
       "      <td>0.021631</td>\n",
       "      <td>0.298750</td>\n",
       "      <td>0.021631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.294018</td>\n",
       "      <td>0.026443</td>\n",
       "      <td>0.294018</td>\n",
       "      <td>0.026443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.268714</td>\n",
       "      <td>0.034468</td>\n",
       "      <td>0.268714</td>\n",
       "      <td>0.034468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.244623</td>\n",
       "      <td>0.010625</td>\n",
       "      <td>0.261113</td>\n",
       "      <td>0.035259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.216669</td>\n",
       "      <td>0.036072</td>\n",
       "      <td>0.216669</td>\n",
       "      <td>0.036072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">ground_dps</th>\n",
       "      <th>3</th>\n",
       "      <td>0.267805</td>\n",
       "      <td>0.041025</td>\n",
       "      <td>0.306866</td>\n",
       "      <td>0.029835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.272841</td>\n",
       "      <td>0.053720</td>\n",
       "      <td>0.298147</td>\n",
       "      <td>0.020277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.297292</td>\n",
       "      <td>0.023035</td>\n",
       "      <td>0.297292</td>\n",
       "      <td>0.023035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.277173</td>\n",
       "      <td>0.040068</td>\n",
       "      <td>0.277173</td>\n",
       "      <td>0.040068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.269406</td>\n",
       "      <td>0.042366</td>\n",
       "      <td>0.269406</td>\n",
       "      <td>0.042366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.227099</td>\n",
       "      <td>0.045771</td>\n",
       "      <td>0.227099</td>\n",
       "      <td>0.045771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">ground_target</th>\n",
       "      <th>3</th>\n",
       "      <td>0.259394</td>\n",
       "      <td>0.052979</td>\n",
       "      <td>0.300165</td>\n",
       "      <td>0.020131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.273144</td>\n",
       "      <td>0.047094</td>\n",
       "      <td>0.290716</td>\n",
       "      <td>0.023479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.272979</td>\n",
       "      <td>0.038483</td>\n",
       "      <td>0.292629</td>\n",
       "      <td>0.022059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.258498</td>\n",
       "      <td>0.014284</td>\n",
       "      <td>0.258498</td>\n",
       "      <td>0.014284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.254118</td>\n",
       "      <td>0.042466</td>\n",
       "      <td>0.254118</td>\n",
       "      <td>0.042466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.215738</td>\n",
       "      <td>0.037141</td>\n",
       "      <td>0.215738</td>\n",
       "      <td>0.037141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">has_ability</th>\n",
       "      <th>3</th>\n",
       "      <td>0.264470</td>\n",
       "      <td>0.043456</td>\n",
       "      <td>0.307013</td>\n",
       "      <td>0.032800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.298750</td>\n",
       "      <td>0.021631</td>\n",
       "      <td>0.298750</td>\n",
       "      <td>0.021631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.294018</td>\n",
       "      <td>0.026443</td>\n",
       "      <td>0.294018</td>\n",
       "      <td>0.026443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.269050</td>\n",
       "      <td>0.034994</td>\n",
       "      <td>0.269050</td>\n",
       "      <td>0.034994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.244623</td>\n",
       "      <td>0.010625</td>\n",
       "      <td>0.261113</td>\n",
       "      <td>0.035259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.216669</td>\n",
       "      <td>0.036072</td>\n",
       "      <td>0.216669</td>\n",
       "      <td>0.036072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">has_friendly_buff</th>\n",
       "      <th>3</th>\n",
       "      <td>0.282803</td>\n",
       "      <td>0.038565</td>\n",
       "      <td>0.324705</td>\n",
       "      <td>0.036004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.299645</td>\n",
       "      <td>0.045653</td>\n",
       "      <td>0.321096</td>\n",
       "      <td>0.025270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.320168</td>\n",
       "      <td>0.028109</td>\n",
       "      <td>0.320168</td>\n",
       "      <td>0.028109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.295135</td>\n",
       "      <td>0.038085</td>\n",
       "      <td>0.295135</td>\n",
       "      <td>0.038085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.273928</td>\n",
       "      <td>0.016969</td>\n",
       "      <td>0.273928</td>\n",
       "      <td>0.016969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.225011</td>\n",
       "      <td>0.022155</td>\n",
       "      <td>0.225242</td>\n",
       "      <td>0.021795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">has_lifetime</th>\n",
       "      <th>3</th>\n",
       "      <td>0.264470</td>\n",
       "      <td>0.043456</td>\n",
       "      <td>0.307013</td>\n",
       "      <td>0.032800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.298750</td>\n",
       "      <td>0.021631</td>\n",
       "      <td>0.298750</td>\n",
       "      <td>0.021631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.294018</td>\n",
       "      <td>0.026443</td>\n",
       "      <td>0.294018</td>\n",
       "      <td>0.026443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.269050</td>\n",
       "      <td>0.034994</td>\n",
       "      <td>0.269050</td>\n",
       "      <td>0.034994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.244623</td>\n",
       "      <td>0.010625</td>\n",
       "      <td>0.261113</td>\n",
       "      <td>0.035259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.216669</td>\n",
       "      <td>0.036072</td>\n",
       "      <td>0.216669</td>\n",
       "      <td>0.036072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">has_periodic_spawn</th>\n",
       "      <th>3</th>\n",
       "      <td>0.304107</td>\n",
       "      <td>0.018961</td>\n",
       "      <td>0.317663</td>\n",
       "      <td>0.041310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.284685</td>\n",
       "      <td>0.036164</td>\n",
       "      <td>0.311362</td>\n",
       "      <td>0.025548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.316017</td>\n",
       "      <td>0.035399</td>\n",
       "      <td>0.316017</td>\n",
       "      <td>0.035399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.269519</td>\n",
       "      <td>0.016924</td>\n",
       "      <td>0.269519</td>\n",
       "      <td>0.016924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.288555</td>\n",
       "      <td>0.053911</td>\n",
       "      <td>0.288555</td>\n",
       "      <td>0.053911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.240589</td>\n",
       "      <td>0.058314</td>\n",
       "      <td>0.240589</td>\n",
       "      <td>0.058314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">has_ranged_attack</th>\n",
       "      <th>3</th>\n",
       "      <td>0.305841</td>\n",
       "      <td>0.030121</td>\n",
       "      <td>0.311289</td>\n",
       "      <td>0.039300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.305351</td>\n",
       "      <td>0.024136</td>\n",
       "      <td>0.305351</td>\n",
       "      <td>0.024136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.284655</td>\n",
       "      <td>0.025935</td>\n",
       "      <td>0.310392</td>\n",
       "      <td>0.031772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.284299</td>\n",
       "      <td>0.045265</td>\n",
       "      <td>0.284299</td>\n",
       "      <td>0.045265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.283559</td>\n",
       "      <td>0.055302</td>\n",
       "      <td>0.283559</td>\n",
       "      <td>0.055302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.244160</td>\n",
       "      <td>0.052526</td>\n",
       "      <td>0.244160</td>\n",
       "      <td>0.052526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">has_upon_breaking_spawn</th>\n",
       "      <th>3</th>\n",
       "      <td>0.264470</td>\n",
       "      <td>0.043456</td>\n",
       "      <td>0.307013</td>\n",
       "      <td>0.032800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.298750</td>\n",
       "      <td>0.021631</td>\n",
       "      <td>0.298750</td>\n",
       "      <td>0.021631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.294018</td>\n",
       "      <td>0.026443</td>\n",
       "      <td>0.294018</td>\n",
       "      <td>0.026443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.269050</td>\n",
       "      <td>0.034994</td>\n",
       "      <td>0.269050</td>\n",
       "      <td>0.034994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.244623</td>\n",
       "      <td>0.010625</td>\n",
       "      <td>0.261113</td>\n",
       "      <td>0.035259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.216669</td>\n",
       "      <td>0.036072</td>\n",
       "      <td>0.216669</td>\n",
       "      <td>0.036072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">has_upon_death_spawn</th>\n",
       "      <th>3</th>\n",
       "      <td>0.287842</td>\n",
       "      <td>0.010066</td>\n",
       "      <td>0.303768</td>\n",
       "      <td>0.033336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.270899</td>\n",
       "      <td>0.043836</td>\n",
       "      <td>0.297781</td>\n",
       "      <td>0.021998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.300809</td>\n",
       "      <td>0.027058</td>\n",
       "      <td>0.300809</td>\n",
       "      <td>0.027058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.254353</td>\n",
       "      <td>0.014701</td>\n",
       "      <td>0.275540</td>\n",
       "      <td>0.037217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.262758</td>\n",
       "      <td>0.025215</td>\n",
       "      <td>0.262758</td>\n",
       "      <td>0.025215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.204111</td>\n",
       "      <td>0.037935</td>\n",
       "      <td>0.204111</td>\n",
       "      <td>0.037935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">high_dps</th>\n",
       "      <th>3</th>\n",
       "      <td>0.297257</td>\n",
       "      <td>0.019740</td>\n",
       "      <td>0.308058</td>\n",
       "      <td>0.036970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.295900</td>\n",
       "      <td>0.022567</td>\n",
       "      <td>0.295900</td>\n",
       "      <td>0.022567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.295240</td>\n",
       "      <td>0.026588</td>\n",
       "      <td>0.295240</td>\n",
       "      <td>0.026588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.275859</td>\n",
       "      <td>0.035563</td>\n",
       "      <td>0.275859</td>\n",
       "      <td>0.035563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.265311</td>\n",
       "      <td>0.041482</td>\n",
       "      <td>0.265311</td>\n",
       "      <td>0.041482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.223358</td>\n",
       "      <td>0.046833</td>\n",
       "      <td>0.223358</td>\n",
       "      <td>0.046833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">hit_speed</th>\n",
       "      <th>3</th>\n",
       "      <td>0.276710</td>\n",
       "      <td>0.044337</td>\n",
       "      <td>0.319058</td>\n",
       "      <td>0.045420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.352706</td>\n",
       "      <td>0.097714</td>\n",
       "      <td>0.352706</td>\n",
       "      <td>0.097714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.321581</td>\n",
       "      <td>0.059656</td>\n",
       "      <td>0.321581</td>\n",
       "      <td>0.059656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.299936</td>\n",
       "      <td>0.071321</td>\n",
       "      <td>0.299936</td>\n",
       "      <td>0.071321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.269915</td>\n",
       "      <td>0.034523</td>\n",
       "      <td>0.269915</td>\n",
       "      <td>0.034523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.220246</td>\n",
       "      <td>0.026048</td>\n",
       "      <td>0.220246</td>\n",
       "      <td>0.026048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">hitpoints</th>\n",
       "      <th>3</th>\n",
       "      <td>0.302095</td>\n",
       "      <td>0.011819</td>\n",
       "      <td>0.323296</td>\n",
       "      <td>0.046005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.348010</td>\n",
       "      <td>0.093373</td>\n",
       "      <td>0.348010</td>\n",
       "      <td>0.093373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.326400</td>\n",
       "      <td>0.063548</td>\n",
       "      <td>0.326400</td>\n",
       "      <td>0.063548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.267685</td>\n",
       "      <td>0.010657</td>\n",
       "      <td>0.287054</td>\n",
       "      <td>0.042142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.284003</td>\n",
       "      <td>0.051490</td>\n",
       "      <td>0.284003</td>\n",
       "      <td>0.051490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.219060</td>\n",
       "      <td>0.006329</td>\n",
       "      <td>0.219060</td>\n",
       "      <td>0.006329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">hp_per_elixir</th>\n",
       "      <th>3</th>\n",
       "      <td>0.356488</td>\n",
       "      <td>0.084776</td>\n",
       "      <td>0.433235</td>\n",
       "      <td>0.164739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.519226</td>\n",
       "      <td>0.236539</td>\n",
       "      <td>0.519226</td>\n",
       "      <td>0.236539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.469100</td>\n",
       "      <td>0.203108</td>\n",
       "      <td>0.469100</td>\n",
       "      <td>0.203108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.391074</td>\n",
       "      <td>0.154834</td>\n",
       "      <td>0.391074</td>\n",
       "      <td>0.154834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.341283</td>\n",
       "      <td>0.090011</td>\n",
       "      <td>0.341283</td>\n",
       "      <td>0.090011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.304734</td>\n",
       "      <td>0.098069</td>\n",
       "      <td>0.304734</td>\n",
       "      <td>0.098069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">invisible</th>\n",
       "      <th>3</th>\n",
       "      <td>0.264470</td>\n",
       "      <td>0.043456</td>\n",
       "      <td>0.307013</td>\n",
       "      <td>0.032800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.298750</td>\n",
       "      <td>0.021631</td>\n",
       "      <td>0.298750</td>\n",
       "      <td>0.021631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.294018</td>\n",
       "      <td>0.026443</td>\n",
       "      <td>0.294018</td>\n",
       "      <td>0.026443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.269050</td>\n",
       "      <td>0.034994</td>\n",
       "      <td>0.269050</td>\n",
       "      <td>0.034994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.244623</td>\n",
       "      <td>0.010625</td>\n",
       "      <td>0.261113</td>\n",
       "      <td>0.035259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.216669</td>\n",
       "      <td>0.036072</td>\n",
       "      <td>0.216669</td>\n",
       "      <td>0.036072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">is_building</th>\n",
       "      <th>3</th>\n",
       "      <td>0.264470</td>\n",
       "      <td>0.043456</td>\n",
       "      <td>0.307013</td>\n",
       "      <td>0.032800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.298750</td>\n",
       "      <td>0.021631</td>\n",
       "      <td>0.298750</td>\n",
       "      <td>0.021631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.294018</td>\n",
       "      <td>0.026443</td>\n",
       "      <td>0.294018</td>\n",
       "      <td>0.026443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.269050</td>\n",
       "      <td>0.034994</td>\n",
       "      <td>0.269050</td>\n",
       "      <td>0.034994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.244623</td>\n",
       "      <td>0.010625</td>\n",
       "      <td>0.261113</td>\n",
       "      <td>0.035259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.216669</td>\n",
       "      <td>0.036072</td>\n",
       "      <td>0.216669</td>\n",
       "      <td>0.036072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">is_free_card</th>\n",
       "      <th>3</th>\n",
       "      <td>0.264976</td>\n",
       "      <td>0.050885</td>\n",
       "      <td>0.315183</td>\n",
       "      <td>0.038315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.277836</td>\n",
       "      <td>0.044844</td>\n",
       "      <td>0.309743</td>\n",
       "      <td>0.024946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.293885</td>\n",
       "      <td>0.053779</td>\n",
       "      <td>0.307976</td>\n",
       "      <td>0.029921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.279973</td>\n",
       "      <td>0.046160</td>\n",
       "      <td>0.279973</td>\n",
       "      <td>0.046160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.262414</td>\n",
       "      <td>0.012281</td>\n",
       "      <td>0.262414</td>\n",
       "      <td>0.012281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.231024</td>\n",
       "      <td>0.018228</td>\n",
       "      <td>0.226763</td>\n",
       "      <td>0.010913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">is_spawned</th>\n",
       "      <th>3</th>\n",
       "      <td>0.264470</td>\n",
       "      <td>0.043456</td>\n",
       "      <td>0.307013</td>\n",
       "      <td>0.032800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.298750</td>\n",
       "      <td>0.021631</td>\n",
       "      <td>0.298750</td>\n",
       "      <td>0.021631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.294018</td>\n",
       "      <td>0.026443</td>\n",
       "      <td>0.294018</td>\n",
       "      <td>0.026443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.269050</td>\n",
       "      <td>0.034994</td>\n",
       "      <td>0.269050</td>\n",
       "      <td>0.034994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.244623</td>\n",
       "      <td>0.010625</td>\n",
       "      <td>0.261113</td>\n",
       "      <td>0.035259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.216669</td>\n",
       "      <td>0.036072</td>\n",
       "      <td>0.216669</td>\n",
       "      <td>0.036072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">is_spell</th>\n",
       "      <th>3</th>\n",
       "      <td>0.264470</td>\n",
       "      <td>0.043456</td>\n",
       "      <td>0.307013</td>\n",
       "      <td>0.032800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.298750</td>\n",
       "      <td>0.021631</td>\n",
       "      <td>0.298750</td>\n",
       "      <td>0.021631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.294018</td>\n",
       "      <td>0.026443</td>\n",
       "      <td>0.294018</td>\n",
       "      <td>0.026443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.269050</td>\n",
       "      <td>0.034994</td>\n",
       "      <td>0.269050</td>\n",
       "      <td>0.034994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.244623</td>\n",
       "      <td>0.010625</td>\n",
       "      <td>0.261113</td>\n",
       "      <td>0.035259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.216669</td>\n",
       "      <td>0.036072</td>\n",
       "      <td>0.216669</td>\n",
       "      <td>0.036072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">is_tower_troop</th>\n",
       "      <th>3</th>\n",
       "      <td>0.264470</td>\n",
       "      <td>0.043456</td>\n",
       "      <td>0.307013</td>\n",
       "      <td>0.032800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.298750</td>\n",
       "      <td>0.021631</td>\n",
       "      <td>0.298750</td>\n",
       "      <td>0.021631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.294018</td>\n",
       "      <td>0.026443</td>\n",
       "      <td>0.294018</td>\n",
       "      <td>0.026443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.269050</td>\n",
       "      <td>0.034994</td>\n",
       "      <td>0.269050</td>\n",
       "      <td>0.034994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.244623</td>\n",
       "      <td>0.010625</td>\n",
       "      <td>0.261113</td>\n",
       "      <td>0.035259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.216669</td>\n",
       "      <td>0.036072</td>\n",
       "      <td>0.216669</td>\n",
       "      <td>0.036072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">is_troop</th>\n",
       "      <th>3</th>\n",
       "      <td>0.264470</td>\n",
       "      <td>0.043456</td>\n",
       "      <td>0.307013</td>\n",
       "      <td>0.032800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.298750</td>\n",
       "      <td>0.021631</td>\n",
       "      <td>0.298750</td>\n",
       "      <td>0.021631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.294018</td>\n",
       "      <td>0.026443</td>\n",
       "      <td>0.294018</td>\n",
       "      <td>0.026443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.269050</td>\n",
       "      <td>0.034994</td>\n",
       "      <td>0.269050</td>\n",
       "      <td>0.034994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.244623</td>\n",
       "      <td>0.010625</td>\n",
       "      <td>0.261113</td>\n",
       "      <td>0.035259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.216669</td>\n",
       "      <td>0.036072</td>\n",
       "      <td>0.216669</td>\n",
       "      <td>0.036072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">mini_tank</th>\n",
       "      <th>3</th>\n",
       "      <td>0.264470</td>\n",
       "      <td>0.043456</td>\n",
       "      <td>0.307013</td>\n",
       "      <td>0.032800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.298750</td>\n",
       "      <td>0.021631</td>\n",
       "      <td>0.298750</td>\n",
       "      <td>0.021631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.294018</td>\n",
       "      <td>0.026443</td>\n",
       "      <td>0.294018</td>\n",
       "      <td>0.026443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.269050</td>\n",
       "      <td>0.034994</td>\n",
       "      <td>0.269050</td>\n",
       "      <td>0.034994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.244623</td>\n",
       "      <td>0.010625</td>\n",
       "      <td>0.261113</td>\n",
       "      <td>0.035259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.216669</td>\n",
       "      <td>0.036072</td>\n",
       "      <td>0.216669</td>\n",
       "      <td>0.036072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">no_attack</th>\n",
       "      <th>3</th>\n",
       "      <td>0.291672</td>\n",
       "      <td>0.016007</td>\n",
       "      <td>0.302447</td>\n",
       "      <td>0.033112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.265569</td>\n",
       "      <td>0.044328</td>\n",
       "      <td>0.296895</td>\n",
       "      <td>0.022245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.285670</td>\n",
       "      <td>0.026532</td>\n",
       "      <td>0.285670</td>\n",
       "      <td>0.026532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.260587</td>\n",
       "      <td>0.034411</td>\n",
       "      <td>0.260587</td>\n",
       "      <td>0.034411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.255702</td>\n",
       "      <td>0.039976</td>\n",
       "      <td>0.255702</td>\n",
       "      <td>0.039976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.216669</td>\n",
       "      <td>0.036072</td>\n",
       "      <td>0.216669</td>\n",
       "      <td>0.036072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">no_hit_speed</th>\n",
       "      <th>3</th>\n",
       "      <td>0.285210</td>\n",
       "      <td>0.016229</td>\n",
       "      <td>0.295224</td>\n",
       "      <td>0.032034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.293690</td>\n",
       "      <td>0.027540</td>\n",
       "      <td>0.289450</td>\n",
       "      <td>0.022063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.292220</td>\n",
       "      <td>0.025311</td>\n",
       "      <td>0.292220</td>\n",
       "      <td>0.025311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.266145</td>\n",
       "      <td>0.035757</td>\n",
       "      <td>0.266145</td>\n",
       "      <td>0.035757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.243597</td>\n",
       "      <td>0.011177</td>\n",
       "      <td>0.260087</td>\n",
       "      <td>0.036139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.216669</td>\n",
       "      <td>0.036072</td>\n",
       "      <td>0.216669</td>\n",
       "      <td>0.036072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">no_hitpoints</th>\n",
       "      <th>3</th>\n",
       "      <td>0.264470</td>\n",
       "      <td>0.043456</td>\n",
       "      <td>0.307013</td>\n",
       "      <td>0.032800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.298750</td>\n",
       "      <td>0.021631</td>\n",
       "      <td>0.298750</td>\n",
       "      <td>0.021631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.294018</td>\n",
       "      <td>0.026443</td>\n",
       "      <td>0.294018</td>\n",
       "      <td>0.026443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.269050</td>\n",
       "      <td>0.034994</td>\n",
       "      <td>0.269050</td>\n",
       "      <td>0.034994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.244623</td>\n",
       "      <td>0.010625</td>\n",
       "      <td>0.261113</td>\n",
       "      <td>0.035259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.216669</td>\n",
       "      <td>0.036072</td>\n",
       "      <td>0.216669</td>\n",
       "      <td>0.036072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">playable</th>\n",
       "      <th>3</th>\n",
       "      <td>0.264976</td>\n",
       "      <td>0.050885</td>\n",
       "      <td>0.315183</td>\n",
       "      <td>0.038315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.277836</td>\n",
       "      <td>0.044844</td>\n",
       "      <td>0.309743</td>\n",
       "      <td>0.024946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.293885</td>\n",
       "      <td>0.053779</td>\n",
       "      <td>0.307976</td>\n",
       "      <td>0.029921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.279973</td>\n",
       "      <td>0.046160</td>\n",
       "      <td>0.279973</td>\n",
       "      <td>0.046160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.262414</td>\n",
       "      <td>0.012281</td>\n",
       "      <td>0.262414</td>\n",
       "      <td>0.012281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.231024</td>\n",
       "      <td>0.018228</td>\n",
       "      <td>0.226763</td>\n",
       "      <td>0.010913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">range</th>\n",
       "      <th>3</th>\n",
       "      <td>0.295666</td>\n",
       "      <td>0.028284</td>\n",
       "      <td>0.310725</td>\n",
       "      <td>0.053663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.346511</td>\n",
       "      <td>0.095225</td>\n",
       "      <td>0.339900</td>\n",
       "      <td>0.098581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.321061</td>\n",
       "      <td>0.064621</td>\n",
       "      <td>0.321061</td>\n",
       "      <td>0.064621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.283966</td>\n",
       "      <td>0.063755</td>\n",
       "      <td>0.283966</td>\n",
       "      <td>0.063755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.265225</td>\n",
       "      <td>0.046205</td>\n",
       "      <td>0.265225</td>\n",
       "      <td>0.046205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.218566</td>\n",
       "      <td>0.036718</td>\n",
       "      <td>0.218566</td>\n",
       "      <td>0.036718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">shield_bool</th>\n",
       "      <th>3</th>\n",
       "      <td>0.264470</td>\n",
       "      <td>0.043456</td>\n",
       "      <td>0.307013</td>\n",
       "      <td>0.032800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.298750</td>\n",
       "      <td>0.021631</td>\n",
       "      <td>0.298750</td>\n",
       "      <td>0.021631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.294018</td>\n",
       "      <td>0.026443</td>\n",
       "      <td>0.294018</td>\n",
       "      <td>0.026443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.269050</td>\n",
       "      <td>0.034994</td>\n",
       "      <td>0.269050</td>\n",
       "      <td>0.034994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.244623</td>\n",
       "      <td>0.010625</td>\n",
       "      <td>0.261113</td>\n",
       "      <td>0.035259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.216669</td>\n",
       "      <td>0.036072</td>\n",
       "      <td>0.216669</td>\n",
       "      <td>0.036072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">single_damage_type</th>\n",
       "      <th>3</th>\n",
       "      <td>0.290144</td>\n",
       "      <td>0.013482</td>\n",
       "      <td>0.301579</td>\n",
       "      <td>0.031285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.294106</td>\n",
       "      <td>0.021300</td>\n",
       "      <td>0.294106</td>\n",
       "      <td>0.021300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.294802</td>\n",
       "      <td>0.025556</td>\n",
       "      <td>0.294802</td>\n",
       "      <td>0.025556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.270698</td>\n",
       "      <td>0.032361</td>\n",
       "      <td>0.270698</td>\n",
       "      <td>0.032361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.243398</td>\n",
       "      <td>0.011520</td>\n",
       "      <td>0.259889</td>\n",
       "      <td>0.036381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.216470</td>\n",
       "      <td>0.036250</td>\n",
       "      <td>0.216470</td>\n",
       "      <td>0.036250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">spawn_bool</th>\n",
       "      <th>3</th>\n",
       "      <td>0.287842</td>\n",
       "      <td>0.010066</td>\n",
       "      <td>0.303768</td>\n",
       "      <td>0.033336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.270899</td>\n",
       "      <td>0.043836</td>\n",
       "      <td>0.297781</td>\n",
       "      <td>0.021998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.300809</td>\n",
       "      <td>0.027058</td>\n",
       "      <td>0.300809</td>\n",
       "      <td>0.027058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.254353</td>\n",
       "      <td>0.014701</td>\n",
       "      <td>0.275540</td>\n",
       "      <td>0.037217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.262758</td>\n",
       "      <td>0.025215</td>\n",
       "      <td>0.262758</td>\n",
       "      <td>0.025215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.204111</td>\n",
       "      <td>0.037935</td>\n",
       "      <td>0.204111</td>\n",
       "      <td>0.037935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">special_attack_type</th>\n",
       "      <th>3</th>\n",
       "      <td>0.303557</td>\n",
       "      <td>0.024541</td>\n",
       "      <td>0.303557</td>\n",
       "      <td>0.024541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.285178</td>\n",
       "      <td>0.038214</td>\n",
       "      <td>0.309750</td>\n",
       "      <td>0.032175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.294385</td>\n",
       "      <td>0.024854</td>\n",
       "      <td>0.294385</td>\n",
       "      <td>0.024854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.263054</td>\n",
       "      <td>0.017577</td>\n",
       "      <td>0.275261</td>\n",
       "      <td>0.033512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.229113</td>\n",
       "      <td>0.014455</td>\n",
       "      <td>0.247498</td>\n",
       "      <td>0.045995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.214071</td>\n",
       "      <td>0.038578</td>\n",
       "      <td>0.214071</td>\n",
       "      <td>0.038578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">special_damage</th>\n",
       "      <th>3</th>\n",
       "      <td>0.315119</td>\n",
       "      <td>0.032961</td>\n",
       "      <td>0.315119</td>\n",
       "      <td>0.032961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.279287</td>\n",
       "      <td>0.042935</td>\n",
       "      <td>0.307101</td>\n",
       "      <td>0.021465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.277561</td>\n",
       "      <td>0.035072</td>\n",
       "      <td>0.277561</td>\n",
       "      <td>0.035072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.250699</td>\n",
       "      <td>0.020582</td>\n",
       "      <td>0.250699</td>\n",
       "      <td>0.020582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.237303</td>\n",
       "      <td>0.018921</td>\n",
       "      <td>0.253840</td>\n",
       "      <td>0.043012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.215688</td>\n",
       "      <td>0.036974</td>\n",
       "      <td>0.215688</td>\n",
       "      <td>0.036974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">speed</th>\n",
       "      <th>3</th>\n",
       "      <td>0.306121</td>\n",
       "      <td>0.031329</td>\n",
       "      <td>0.306121</td>\n",
       "      <td>0.031329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.344961</td>\n",
       "      <td>0.089489</td>\n",
       "      <td>0.344961</td>\n",
       "      <td>0.089489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.319107</td>\n",
       "      <td>0.062499</td>\n",
       "      <td>0.319107</td>\n",
       "      <td>0.062499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.271900</td>\n",
       "      <td>0.039515</td>\n",
       "      <td>0.271900</td>\n",
       "      <td>0.039515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.264544</td>\n",
       "      <td>0.041030</td>\n",
       "      <td>0.264544</td>\n",
       "      <td>0.041030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.214721</td>\n",
       "      <td>0.032700</td>\n",
       "      <td>0.214721</td>\n",
       "      <td>0.032700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">support</th>\n",
       "      <th>3</th>\n",
       "      <td>0.291672</td>\n",
       "      <td>0.016007</td>\n",
       "      <td>0.302447</td>\n",
       "      <td>0.033112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.265569</td>\n",
       "      <td>0.044328</td>\n",
       "      <td>0.296895</td>\n",
       "      <td>0.022245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.285670</td>\n",
       "      <td>0.026532</td>\n",
       "      <td>0.285670</td>\n",
       "      <td>0.026532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.260587</td>\n",
       "      <td>0.034411</td>\n",
       "      <td>0.260587</td>\n",
       "      <td>0.034411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.255702</td>\n",
       "      <td>0.039976</td>\n",
       "      <td>0.255702</td>\n",
       "      <td>0.039976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.216669</td>\n",
       "      <td>0.036072</td>\n",
       "      <td>0.216669</td>\n",
       "      <td>0.036072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">win_con</th>\n",
       "      <th>3</th>\n",
       "      <td>0.264470</td>\n",
       "      <td>0.043456</td>\n",
       "      <td>0.307013</td>\n",
       "      <td>0.032800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.298750</td>\n",
       "      <td>0.021631</td>\n",
       "      <td>0.298750</td>\n",
       "      <td>0.021631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.294018</td>\n",
       "      <td>0.026443</td>\n",
       "      <td>0.294018</td>\n",
       "      <td>0.026443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.269050</td>\n",
       "      <td>0.034994</td>\n",
       "      <td>0.269050</td>\n",
       "      <td>0.034994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.244623</td>\n",
       "      <td>0.010625</td>\n",
       "      <td>0.261113</td>\n",
       "      <td>0.035259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.216669</td>\n",
       "      <td>0.036072</td>\n",
       "      <td>0.216669</td>\n",
       "      <td>0.036072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">win_con_dmg</th>\n",
       "      <th>3</th>\n",
       "      <td>0.264470</td>\n",
       "      <td>0.043456</td>\n",
       "      <td>0.307013</td>\n",
       "      <td>0.032800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.298750</td>\n",
       "      <td>0.021631</td>\n",
       "      <td>0.298750</td>\n",
       "      <td>0.021631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.294018</td>\n",
       "      <td>0.026443</td>\n",
       "      <td>0.294018</td>\n",
       "      <td>0.026443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.269050</td>\n",
       "      <td>0.034994</td>\n",
       "      <td>0.269050</td>\n",
       "      <td>0.034994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.244623</td>\n",
       "      <td>0.010625</td>\n",
       "      <td>0.261113</td>\n",
       "      <td>0.035259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.216669</td>\n",
       "      <td>0.036072</td>\n",
       "      <td>0.216669</td>\n",
       "      <td>0.036072</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          gmm_building           km_building          \n",
       "                                  mean       std        mean       std\n",
       "col                     K                                             \n",
       "affected_crown          3     0.276063  0.037904    0.317661  0.035941\n",
       "                        4     0.283669  0.040745    0.310357  0.021676\n",
       "                        5     0.277462  0.024232    0.279732  0.028038\n",
       "                        6     0.255512  0.015445    0.255512  0.015445\n",
       "                        7     0.227350  0.022887    0.243840  0.047660\n",
       "                        8     0.215071  0.033305    0.215071  0.033305\n",
       "air_control             3     0.302319  0.016955    0.310023  0.029025\n",
       "                        4     0.313351  0.013827    0.312872  0.033104\n",
       "                        5     0.278114  0.033707    0.278114  0.033707\n",
       "                        6     0.280608  0.021473    0.279008  0.019039\n",
       "                        7     0.247580  0.022943    0.250454  0.024000\n",
       "                        8     0.222259  0.021125    0.222259  0.021125\n",
       "any_target              3     0.266780  0.038567    0.303061  0.027318\n",
       "                        4     0.277490  0.051786    0.296680  0.027381\n",
       "                        5     0.275872  0.037461    0.295006  0.021510\n",
       "                        6     0.274542  0.020862    0.274542  0.020862\n",
       "                        7     0.260733  0.029861    0.260733  0.029861\n",
       "                        8     0.218738  0.031651    0.218738  0.031651\n",
       "aoe_bool                3     0.290350  0.025555    0.304410  0.057742\n",
       "                        4     0.287848  0.066374    0.308819  0.047751\n",
       "                        5     0.297225  0.047393    0.297225  0.047393\n",
       "                        6     0.278035  0.059866    0.278035  0.059866\n",
       "                        7     0.270116  0.062578    0.270116  0.062578\n",
       "                        8     0.231270  0.073309    0.231270  0.073309\n",
       "aoe_by_damage           3     0.328229  0.032723    0.383883  0.121659\n",
       "                        4     0.470417  0.174641    0.470417  0.174641\n",
       "                        5     0.436434  0.179270    0.436434  0.179270\n",
       "                        6     0.377467  0.155510    0.377467  0.155510\n",
       "                        7     0.344932  0.117378    0.344932  0.117378\n",
       "                        8     0.263285  0.074940    0.263285  0.074940\n",
       "aoe_by_range            3     0.342124  0.058068    0.375992  0.114591\n",
       "                        4     0.439929  0.200352    0.463926  0.165918\n",
       "                        5     0.437247  0.168132    0.437247  0.168132\n",
       "                        6     0.373687  0.151137    0.373687  0.151137\n",
       "                        7     0.341152  0.113236    0.341152  0.113236\n",
       "                        8     0.262546  0.075965    0.262546  0.075965\n",
       "aoe_per_elixir          3     0.297024  0.035505    0.293842  0.039911\n",
       "                        4     0.314338  0.109563    0.338312  0.092232\n",
       "                        5     0.304968  0.056767    0.304968  0.056767\n",
       "                        6     0.268756  0.042471    0.268756  0.042471\n",
       "                        7     0.260979  0.044448    0.260979  0.044448\n",
       "                        8     0.211156  0.035860    0.211156  0.035860\n",
       "aoe_radius              3     0.297024  0.035505    0.293842  0.039911\n",
       "                        4     0.314338  0.109563    0.338312  0.092232\n",
       "                        5     0.304968  0.056767    0.304968  0.056767\n",
       "                        6     0.268756  0.042471    0.268756  0.042471\n",
       "                        7     0.260979  0.044448    0.260979  0.044448\n",
       "                        8     0.211156  0.035860    0.211156  0.035860\n",
       "attack_count            3     0.307743  0.042009    0.307743  0.042009\n",
       "                        4     0.326896  0.076338    0.331255  0.070635\n",
       "                        5     0.301784  0.047728    0.301784  0.047728\n",
       "                        6     0.257213  0.029333    0.257213  0.029333\n",
       "                        7     0.240046  0.015218    0.249691  0.029991\n",
       "                        8     0.214721  0.032700    0.214721  0.032700\n",
       "building_target         3     0.259394  0.052979    0.300165  0.020131\n",
       "                        4     0.273144  0.047094    0.290716  0.023479\n",
       "                        5     0.272979  0.038483    0.292629  0.022059\n",
       "                        6     0.258498  0.014284    0.258498  0.014284\n",
       "                        7     0.254118  0.042466    0.254118  0.042466\n",
       "                        8     0.215738  0.037141    0.215738  0.037141\n",
       "can_evolve              3     0.317795  0.022746    0.330351  0.043657\n",
       "                        4     0.371963  0.113745    0.371963  0.113745\n",
       "                        5     0.343652  0.081153    0.343652  0.081153\n",
       "                        6     0.282498  0.049362    0.282498  0.049362\n",
       "                        7     0.295845  0.060616    0.270496  0.020469\n",
       "                        8     0.231597  0.013957    0.231597  0.013957\n",
       "control_special         3     0.315119  0.032961    0.315119  0.032961\n",
       "                        4     0.279287  0.042935    0.307101  0.021465\n",
       "                        5     0.277561  0.035072    0.277561  0.035072\n",
       "                        6     0.250699  0.020582    0.250699  0.020582\n",
       "                        7     0.237303  0.018921    0.253840  0.043012\n",
       "                        8     0.215688  0.036974    0.215688  0.036974\n",
       "count                   3     0.306121  0.031329    0.306121  0.031329\n",
       "                        4     0.344961  0.089489    0.344961  0.089489\n",
       "                        5     0.319107  0.062499    0.319107  0.062499\n",
       "                        6     0.271900  0.039515    0.271900  0.039515\n",
       "                        7     0.264544  0.041030    0.264544  0.041030\n",
       "                        8     0.214721  0.032700    0.214721  0.032700\n",
       "damage                  3     0.300849  0.026796    0.300849  0.026796\n",
       "                        4     0.335677  0.082694    0.335677  0.082694\n",
       "                        5     0.312142  0.054085    0.312142  0.054085\n",
       "                        6     0.264797  0.036409    0.264797  0.036409\n",
       "                        7     0.261455  0.037583    0.261455  0.037583\n",
       "                        8     0.213825  0.030923    0.213825  0.030923\n",
       "damage_by_hitpoints     3     0.361852  0.082058    0.361852  0.082058\n",
       "                        4     0.460095  0.173539    0.460095  0.173539\n",
       "                        5     0.432637  0.175374    0.432637  0.175374\n",
       "                        6     0.372053  0.155708    0.372053  0.155708\n",
       "                        7     0.345401  0.116231    0.345401  0.116231\n",
       "                        8     0.275609  0.090929    0.275609  0.090929\n",
       "damage_output           3     0.411806  0.170395    0.426120  0.161412\n",
       "                        4     0.374633  0.066784    0.451068  0.186474\n",
       "                        5     0.347945  0.082712    0.394651  0.160168\n",
       "                        6     0.355763  0.139366    0.345393  0.146483\n",
       "                        7     0.289791  0.085002    0.300300  0.078083\n",
       "                        8     0.266126  0.084731    0.266126  0.084731\n",
       "damage_output_ps        3     0.291317  0.041581    0.297489  0.050734\n",
       "                        4     0.337544  0.096308    0.337544  0.096308\n",
       "                        5     0.314007  0.067649    0.314007  0.067649\n",
       "                        6     0.267592  0.041390    0.267592  0.041390\n",
       "                        7     0.263794  0.038467    0.263794  0.038467\n",
       "                        8     0.214147  0.030414    0.214147  0.030414\n",
       "damage_per_elixir       3     0.332547  0.033200    0.371788  0.097883\n",
       "                        4     0.469183  0.181394    0.469183  0.181394\n",
       "                        5     0.440070  0.180612    0.440070  0.180612\n",
       "                        6     0.381818  0.160294    0.381818  0.160294\n",
       "                        7     0.286961  0.027112    0.350955  0.122248\n",
       "                        8     0.279372  0.092661    0.279372  0.092661\n",
       "damage_per_second       3     0.379683  0.104782    0.379683  0.104782\n",
       "                        4     0.470466  0.186019    0.470466  0.186019\n",
       "                        5     0.442716  0.193061    0.442716  0.193061\n",
       "                        6     0.379670  0.164845    0.379670  0.164845\n",
       "                        7     0.275934  0.032368    0.351031  0.126285\n",
       "                        8     0.265193  0.076774    0.265193  0.076774\n",
       "death_damage_bool       3     0.291537  0.044469    0.322365  0.046268\n",
       "                        4     0.305795  0.049814    0.325524  0.038619\n",
       "                        5     0.294206  0.073989    0.316005  0.037804\n",
       "                        6     0.302762  0.047531    0.302762  0.047531\n",
       "                        7     0.291615  0.053977    0.291615  0.053977\n",
       "                        8     0.264435  0.085422    0.264435  0.085422\n",
       "dps_special             3     0.264470  0.043456    0.307013  0.032800\n",
       "                        4     0.298750  0.021631    0.298750  0.021631\n",
       "                        5     0.294018  0.026443    0.294018  0.026443\n",
       "                        6     0.269050  0.034994    0.269050  0.034994\n",
       "                        7     0.244623  0.010625    0.261113  0.035259\n",
       "                        8     0.216669  0.036072    0.216669  0.036072\n",
       "elixircost              3     0.324169  0.043021    0.324169  0.043021\n",
       "                        4     0.368455  0.100122    0.368455  0.100122\n",
       "                        5     0.340947  0.076109    0.340947  0.076109\n",
       "                        6     0.303242  0.056164    0.303242  0.056164\n",
       "                        7     0.260060  0.013138    0.260060  0.013138\n",
       "                        8     0.214782  0.007731    0.214782  0.007731\n",
       "fly_bool                3     0.264470  0.043456    0.307013  0.032800\n",
       "                        4     0.298750  0.021631    0.298750  0.021631\n",
       "                        5     0.294018  0.026443    0.294018  0.026443\n",
       "                        6     0.268714  0.034468    0.268714  0.034468\n",
       "                        7     0.244623  0.010625    0.261113  0.035259\n",
       "                        8     0.216669  0.036072    0.216669  0.036072\n",
       "ground_dps              3     0.267805  0.041025    0.306866  0.029835\n",
       "                        4     0.272841  0.053720    0.298147  0.020277\n",
       "                        5     0.297292  0.023035    0.297292  0.023035\n",
       "                        6     0.277173  0.040068    0.277173  0.040068\n",
       "                        7     0.269406  0.042366    0.269406  0.042366\n",
       "                        8     0.227099  0.045771    0.227099  0.045771\n",
       "ground_target           3     0.259394  0.052979    0.300165  0.020131\n",
       "                        4     0.273144  0.047094    0.290716  0.023479\n",
       "                        5     0.272979  0.038483    0.292629  0.022059\n",
       "                        6     0.258498  0.014284    0.258498  0.014284\n",
       "                        7     0.254118  0.042466    0.254118  0.042466\n",
       "                        8     0.215738  0.037141    0.215738  0.037141\n",
       "has_ability             3     0.264470  0.043456    0.307013  0.032800\n",
       "                        4     0.298750  0.021631    0.298750  0.021631\n",
       "                        5     0.294018  0.026443    0.294018  0.026443\n",
       "                        6     0.269050  0.034994    0.269050  0.034994\n",
       "                        7     0.244623  0.010625    0.261113  0.035259\n",
       "                        8     0.216669  0.036072    0.216669  0.036072\n",
       "has_friendly_buff       3     0.282803  0.038565    0.324705  0.036004\n",
       "                        4     0.299645  0.045653    0.321096  0.025270\n",
       "                        5     0.320168  0.028109    0.320168  0.028109\n",
       "                        6     0.295135  0.038085    0.295135  0.038085\n",
       "                        7     0.273928  0.016969    0.273928  0.016969\n",
       "                        8     0.225011  0.022155    0.225242  0.021795\n",
       "has_lifetime            3     0.264470  0.043456    0.307013  0.032800\n",
       "                        4     0.298750  0.021631    0.298750  0.021631\n",
       "                        5     0.294018  0.026443    0.294018  0.026443\n",
       "                        6     0.269050  0.034994    0.269050  0.034994\n",
       "                        7     0.244623  0.010625    0.261113  0.035259\n",
       "                        8     0.216669  0.036072    0.216669  0.036072\n",
       "has_periodic_spawn      3     0.304107  0.018961    0.317663  0.041310\n",
       "                        4     0.284685  0.036164    0.311362  0.025548\n",
       "                        5     0.316017  0.035399    0.316017  0.035399\n",
       "                        6     0.269519  0.016924    0.269519  0.016924\n",
       "                        7     0.288555  0.053911    0.288555  0.053911\n",
       "                        8     0.240589  0.058314    0.240589  0.058314\n",
       "has_ranged_attack       3     0.305841  0.030121    0.311289  0.039300\n",
       "                        4     0.305351  0.024136    0.305351  0.024136\n",
       "                        5     0.284655  0.025935    0.310392  0.031772\n",
       "                        6     0.284299  0.045265    0.284299  0.045265\n",
       "                        7     0.283559  0.055302    0.283559  0.055302\n",
       "                        8     0.244160  0.052526    0.244160  0.052526\n",
       "has_upon_breaking_spawn 3     0.264470  0.043456    0.307013  0.032800\n",
       "                        4     0.298750  0.021631    0.298750  0.021631\n",
       "                        5     0.294018  0.026443    0.294018  0.026443\n",
       "                        6     0.269050  0.034994    0.269050  0.034994\n",
       "                        7     0.244623  0.010625    0.261113  0.035259\n",
       "                        8     0.216669  0.036072    0.216669  0.036072\n",
       "has_upon_death_spawn    3     0.287842  0.010066    0.303768  0.033336\n",
       "                        4     0.270899  0.043836    0.297781  0.021998\n",
       "                        5     0.300809  0.027058    0.300809  0.027058\n",
       "                        6     0.254353  0.014701    0.275540  0.037217\n",
       "                        7     0.262758  0.025215    0.262758  0.025215\n",
       "                        8     0.204111  0.037935    0.204111  0.037935\n",
       "high_dps                3     0.297257  0.019740    0.308058  0.036970\n",
       "                        4     0.295900  0.022567    0.295900  0.022567\n",
       "                        5     0.295240  0.026588    0.295240  0.026588\n",
       "                        6     0.275859  0.035563    0.275859  0.035563\n",
       "                        7     0.265311  0.041482    0.265311  0.041482\n",
       "                        8     0.223358  0.046833    0.223358  0.046833\n",
       "hit_speed               3     0.276710  0.044337    0.319058  0.045420\n",
       "                        4     0.352706  0.097714    0.352706  0.097714\n",
       "                        5     0.321581  0.059656    0.321581  0.059656\n",
       "                        6     0.299936  0.071321    0.299936  0.071321\n",
       "                        7     0.269915  0.034523    0.269915  0.034523\n",
       "                        8     0.220246  0.026048    0.220246  0.026048\n",
       "hitpoints               3     0.302095  0.011819    0.323296  0.046005\n",
       "                        4     0.348010  0.093373    0.348010  0.093373\n",
       "                        5     0.326400  0.063548    0.326400  0.063548\n",
       "                        6     0.267685  0.010657    0.287054  0.042142\n",
       "                        7     0.284003  0.051490    0.284003  0.051490\n",
       "                        8     0.219060  0.006329    0.219060  0.006329\n",
       "hp_per_elixir           3     0.356488  0.084776    0.433235  0.164739\n",
       "                        4     0.519226  0.236539    0.519226  0.236539\n",
       "                        5     0.469100  0.203108    0.469100  0.203108\n",
       "                        6     0.391074  0.154834    0.391074  0.154834\n",
       "                        7     0.341283  0.090011    0.341283  0.090011\n",
       "                        8     0.304734  0.098069    0.304734  0.098069\n",
       "invisible               3     0.264470  0.043456    0.307013  0.032800\n",
       "                        4     0.298750  0.021631    0.298750  0.021631\n",
       "                        5     0.294018  0.026443    0.294018  0.026443\n",
       "                        6     0.269050  0.034994    0.269050  0.034994\n",
       "                        7     0.244623  0.010625    0.261113  0.035259\n",
       "                        8     0.216669  0.036072    0.216669  0.036072\n",
       "is_building             3     0.264470  0.043456    0.307013  0.032800\n",
       "                        4     0.298750  0.021631    0.298750  0.021631\n",
       "                        5     0.294018  0.026443    0.294018  0.026443\n",
       "                        6     0.269050  0.034994    0.269050  0.034994\n",
       "                        7     0.244623  0.010625    0.261113  0.035259\n",
       "                        8     0.216669  0.036072    0.216669  0.036072\n",
       "is_free_card            3     0.264976  0.050885    0.315183  0.038315\n",
       "                        4     0.277836  0.044844    0.309743  0.024946\n",
       "                        5     0.293885  0.053779    0.307976  0.029921\n",
       "                        6     0.279973  0.046160    0.279973  0.046160\n",
       "                        7     0.262414  0.012281    0.262414  0.012281\n",
       "                        8     0.231024  0.018228    0.226763  0.010913\n",
       "is_spawned              3     0.264470  0.043456    0.307013  0.032800\n",
       "                        4     0.298750  0.021631    0.298750  0.021631\n",
       "                        5     0.294018  0.026443    0.294018  0.026443\n",
       "                        6     0.269050  0.034994    0.269050  0.034994\n",
       "                        7     0.244623  0.010625    0.261113  0.035259\n",
       "                        8     0.216669  0.036072    0.216669  0.036072\n",
       "is_spell                3     0.264470  0.043456    0.307013  0.032800\n",
       "                        4     0.298750  0.021631    0.298750  0.021631\n",
       "                        5     0.294018  0.026443    0.294018  0.026443\n",
       "                        6     0.269050  0.034994    0.269050  0.034994\n",
       "                        7     0.244623  0.010625    0.261113  0.035259\n",
       "                        8     0.216669  0.036072    0.216669  0.036072\n",
       "is_tower_troop          3     0.264470  0.043456    0.307013  0.032800\n",
       "                        4     0.298750  0.021631    0.298750  0.021631\n",
       "                        5     0.294018  0.026443    0.294018  0.026443\n",
       "                        6     0.269050  0.034994    0.269050  0.034994\n",
       "                        7     0.244623  0.010625    0.261113  0.035259\n",
       "                        8     0.216669  0.036072    0.216669  0.036072\n",
       "is_troop                3     0.264470  0.043456    0.307013  0.032800\n",
       "                        4     0.298750  0.021631    0.298750  0.021631\n",
       "                        5     0.294018  0.026443    0.294018  0.026443\n",
       "                        6     0.269050  0.034994    0.269050  0.034994\n",
       "                        7     0.244623  0.010625    0.261113  0.035259\n",
       "                        8     0.216669  0.036072    0.216669  0.036072\n",
       "mini_tank               3     0.264470  0.043456    0.307013  0.032800\n",
       "                        4     0.298750  0.021631    0.298750  0.021631\n",
       "                        5     0.294018  0.026443    0.294018  0.026443\n",
       "                        6     0.269050  0.034994    0.269050  0.034994\n",
       "                        7     0.244623  0.010625    0.261113  0.035259\n",
       "                        8     0.216669  0.036072    0.216669  0.036072\n",
       "no_attack               3     0.291672  0.016007    0.302447  0.033112\n",
       "                        4     0.265569  0.044328    0.296895  0.022245\n",
       "                        5     0.285670  0.026532    0.285670  0.026532\n",
       "                        6     0.260587  0.034411    0.260587  0.034411\n",
       "                        7     0.255702  0.039976    0.255702  0.039976\n",
       "                        8     0.216669  0.036072    0.216669  0.036072\n",
       "no_hit_speed            3     0.285210  0.016229    0.295224  0.032034\n",
       "                        4     0.293690  0.027540    0.289450  0.022063\n",
       "                        5     0.292220  0.025311    0.292220  0.025311\n",
       "                        6     0.266145  0.035757    0.266145  0.035757\n",
       "                        7     0.243597  0.011177    0.260087  0.036139\n",
       "                        8     0.216669  0.036072    0.216669  0.036072\n",
       "no_hitpoints            3     0.264470  0.043456    0.307013  0.032800\n",
       "                        4     0.298750  0.021631    0.298750  0.021631\n",
       "                        5     0.294018  0.026443    0.294018  0.026443\n",
       "                        6     0.269050  0.034994    0.269050  0.034994\n",
       "                        7     0.244623  0.010625    0.261113  0.035259\n",
       "                        8     0.216669  0.036072    0.216669  0.036072\n",
       "playable                3     0.264976  0.050885    0.315183  0.038315\n",
       "                        4     0.277836  0.044844    0.309743  0.024946\n",
       "                        5     0.293885  0.053779    0.307976  0.029921\n",
       "                        6     0.279973  0.046160    0.279973  0.046160\n",
       "                        7     0.262414  0.012281    0.262414  0.012281\n",
       "                        8     0.231024  0.018228    0.226763  0.010913\n",
       "range                   3     0.295666  0.028284    0.310725  0.053663\n",
       "                        4     0.346511  0.095225    0.339900  0.098581\n",
       "                        5     0.321061  0.064621    0.321061  0.064621\n",
       "                        6     0.283966  0.063755    0.283966  0.063755\n",
       "                        7     0.265225  0.046205    0.265225  0.046205\n",
       "                        8     0.218566  0.036718    0.218566  0.036718\n",
       "shield_bool             3     0.264470  0.043456    0.307013  0.032800\n",
       "                        4     0.298750  0.021631    0.298750  0.021631\n",
       "                        5     0.294018  0.026443    0.294018  0.026443\n",
       "                        6     0.269050  0.034994    0.269050  0.034994\n",
       "                        7     0.244623  0.010625    0.261113  0.035259\n",
       "                        8     0.216669  0.036072    0.216669  0.036072\n",
       "single_damage_type      3     0.290144  0.013482    0.301579  0.031285\n",
       "                        4     0.294106  0.021300    0.294106  0.021300\n",
       "                        5     0.294802  0.025556    0.294802  0.025556\n",
       "                        6     0.270698  0.032361    0.270698  0.032361\n",
       "                        7     0.243398  0.011520    0.259889  0.036381\n",
       "                        8     0.216470  0.036250    0.216470  0.036250\n",
       "spawn_bool              3     0.287842  0.010066    0.303768  0.033336\n",
       "                        4     0.270899  0.043836    0.297781  0.021998\n",
       "                        5     0.300809  0.027058    0.300809  0.027058\n",
       "                        6     0.254353  0.014701    0.275540  0.037217\n",
       "                        7     0.262758  0.025215    0.262758  0.025215\n",
       "                        8     0.204111  0.037935    0.204111  0.037935\n",
       "special_attack_type     3     0.303557  0.024541    0.303557  0.024541\n",
       "                        4     0.285178  0.038214    0.309750  0.032175\n",
       "                        5     0.294385  0.024854    0.294385  0.024854\n",
       "                        6     0.263054  0.017577    0.275261  0.033512\n",
       "                        7     0.229113  0.014455    0.247498  0.045995\n",
       "                        8     0.214071  0.038578    0.214071  0.038578\n",
       "special_damage          3     0.315119  0.032961    0.315119  0.032961\n",
       "                        4     0.279287  0.042935    0.307101  0.021465\n",
       "                        5     0.277561  0.035072    0.277561  0.035072\n",
       "                        6     0.250699  0.020582    0.250699  0.020582\n",
       "                        7     0.237303  0.018921    0.253840  0.043012\n",
       "                        8     0.215688  0.036974    0.215688  0.036974\n",
       "speed                   3     0.306121  0.031329    0.306121  0.031329\n",
       "                        4     0.344961  0.089489    0.344961  0.089489\n",
       "                        5     0.319107  0.062499    0.319107  0.062499\n",
       "                        6     0.271900  0.039515    0.271900  0.039515\n",
       "                        7     0.264544  0.041030    0.264544  0.041030\n",
       "                        8     0.214721  0.032700    0.214721  0.032700\n",
       "support                 3     0.291672  0.016007    0.302447  0.033112\n",
       "                        4     0.265569  0.044328    0.296895  0.022245\n",
       "                        5     0.285670  0.026532    0.285670  0.026532\n",
       "                        6     0.260587  0.034411    0.260587  0.034411\n",
       "                        7     0.255702  0.039976    0.255702  0.039976\n",
       "                        8     0.216669  0.036072    0.216669  0.036072\n",
       "win_con                 3     0.264470  0.043456    0.307013  0.032800\n",
       "                        4     0.298750  0.021631    0.298750  0.021631\n",
       "                        5     0.294018  0.026443    0.294018  0.026443\n",
       "                        6     0.269050  0.034994    0.269050  0.034994\n",
       "                        7     0.244623  0.010625    0.261113  0.035259\n",
       "                        8     0.216669  0.036072    0.216669  0.036072\n",
       "win_con_dmg             3     0.264470  0.043456    0.307013  0.032800\n",
       "                        4     0.298750  0.021631    0.298750  0.021631\n",
       "                        5     0.294018  0.026443    0.294018  0.026443\n",
       "                        6     0.269050  0.034994    0.269050  0.034994\n",
       "                        7     0.244623  0.010625    0.261113  0.035259\n",
       "                        8     0.216669  0.036072    0.216669  0.036072"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sim.groupby(['col', 'K']).agg({'gmm_building': ['mean', 'std'], 'km_building': ['mean', 'std']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "435f3863-2ef3-43e9-9a0b-4026d08fcf45",
   "metadata": {},
   "outputs": [],
   "source": [
    "troop_important = sim[sim['og_col'] == 'num_features'].sort_values('gmm_troop').head(10)['col'].tolist()\n",
    "\n",
    "# spell\n",
    "spell_important = sim[sim['og_col'] == 'engineered'].sort_values('gmm_spell').head(10)['col'].tolist()\n",
    "\n",
    "# building\n",
    "building_important = sim[sim['og_col'] == 'engineered'].sort_values('gmm_building').head(10)['col'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6ee9efc6-ee26-4f1d-abbd-944d4bde49fd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "col\n",
       "damage_output_ps           0.012572\n",
       "air_control                0.022983\n",
       "ground_dps                 0.023217\n",
       "is_spawned                 0.023793\n",
       "has_lifetime               0.034386\n",
       "playable                   0.035299\n",
       "is_free_card               0.035299\n",
       "any_target                 0.035342\n",
       "building_target            0.035342\n",
       "spawn_bool                 0.039106\n",
       "aoe_by_damage              0.039231\n",
       "ground_target              0.039328\n",
       "no_hitpoints               0.040046\n",
       "win_con_dmg                0.040999\n",
       "has_upon_death_spawn       0.042482\n",
       "fly_bool                   0.042782\n",
       "is_building                0.044201\n",
       "is_spell                   0.044201\n",
       "is_troop                   0.044201\n",
       "is_tower_troop             0.044201\n",
       "aoe_bool                   0.044233\n",
       "no_hit_speed               0.045501\n",
       "win_con                    0.046168\n",
       "has_friendly_buff          0.046380\n",
       "high_dps                   0.048562\n",
       "death_damage_bool          0.050664\n",
       "invisible                  0.050738\n",
       "control_special            0.050958\n",
       "special_damage             0.051529\n",
       "affected_crown             0.052265\n",
       "no_attack                  0.052326\n",
       "mini_tank                  0.053922\n",
       "speed                      0.054086\n",
       "aoe_by_range               0.054277\n",
       "hitpoints                  0.055213\n",
       "dps_special                0.055537\n",
       "damage                     0.056768\n",
       "aoe_radius                 0.058234\n",
       "has_upon_breaking_spawn    0.058540\n",
       "shield_bool                0.058575\n",
       "hit_speed                  0.058745\n",
       "elixircost                 0.059109\n",
       "special_attack_type        0.059343\n",
       "has_ranged_attack          0.059441\n",
       "range                      0.060109\n",
       "aoe_per_elixir             0.061849\n",
       "damage_output              0.063528\n",
       "support                    0.064557\n",
       "can_evolve                 0.066453\n",
       "has_ability                0.068065\n",
       "count                      0.069986\n",
       "single_damage_type         0.070860\n",
       "has_periodic_spawn         0.071184\n",
       "hp_per_elixir              0.073517\n",
       "damage_by_hitpoints        0.078663\n",
       "attack_count               0.079404\n",
       "damage_per_elixir          0.086112\n",
       "damage_per_second          0.088089\n",
       "Name: gmm_troop, dtype: float64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sim.groupby('col')['gmm_troop'].mean().sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6a3a82fb-7258-4d2e-b51e-746a622102cf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "col\n",
       "can_evolve                 0.175107\n",
       "damage_per_elixir          0.180268\n",
       "damage                     0.192944\n",
       "damage_per_second          0.197319\n",
       "damage_by_hitpoints        0.197319\n",
       "damage_output              0.205633\n",
       "aoe_by_damage              0.205797\n",
       "aoe_radius                 0.208588\n",
       "damage_output_ps           0.209873\n",
       "hitpoints                  0.209873\n",
       "speed                      0.209873\n",
       "range                      0.209873\n",
       "hit_speed                  0.209873\n",
       "count                      0.209873\n",
       "aoe_per_elixir             0.212410\n",
       "high_dps                   0.212765\n",
       "attack_count               0.214540\n",
       "dps_special                0.223048\n",
       "no_attack                  0.223277\n",
       "has_upon_breaking_spawn    0.224756\n",
       "support                    0.225132\n",
       "affected_crown             0.228888\n",
       "invisible                  0.229039\n",
       "is_building                0.229039\n",
       "is_free_card               0.229039\n",
       "playable                   0.229039\n",
       "no_hitpoints               0.229039\n",
       "is_troop                   0.229039\n",
       "mini_tank                  0.229039\n",
       "no_hit_speed               0.229039\n",
       "shield_bool                0.229039\n",
       "is_spell                   0.229039\n",
       "is_tower_troop             0.229039\n",
       "win_con_dmg                0.229039\n",
       "has_ranged_attack          0.229039\n",
       "air_control                0.229039\n",
       "any_target                 0.229039\n",
       "building_target            0.229039\n",
       "has_upon_death_spawn       0.229039\n",
       "fly_bool                   0.229039\n",
       "ground_dps                 0.229039\n",
       "death_damage_bool          0.229039\n",
       "has_ability                0.229039\n",
       "has_lifetime               0.229039\n",
       "win_con                    0.229039\n",
       "ground_target              0.229039\n",
       "single_damage_type         0.229435\n",
       "elixircost                 0.235624\n",
       "is_spawned                 0.242871\n",
       "special_attack_type        0.245066\n",
       "aoe_bool                   0.245642\n",
       "spawn_bool                 0.245690\n",
       "special_damage             0.247632\n",
       "has_periodic_spawn         0.265271\n",
       "control_special            0.266570\n",
       "hp_per_elixir              0.266594\n",
       "has_friendly_buff          0.270803\n",
       "aoe_by_range               0.272990\n",
       "Name: gmm_spell, dtype: float64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sim.groupby('col')['gmm_spell'].mean().sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5e4262f0-481a-4c18-a509-8fd178a1708a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "col\n",
       "ground_target              0.255645\n",
       "building_target            0.255645\n",
       "affected_crown             0.255854\n",
       "any_target                 0.262359\n",
       "special_damage             0.262609\n",
       "control_special            0.262609\n",
       "no_attack                  0.262645\n",
       "support                    0.262645\n",
       "spawn_bool                 0.263462\n",
       "has_upon_death_spawn       0.263462\n",
       "fly_bool                   0.264541\n",
       "no_hitpoints               0.264597\n",
       "has_ability                0.264597\n",
       "has_lifetime               0.264597\n",
       "win_con                    0.264597\n",
       "has_upon_breaking_spawn    0.264597\n",
       "is_spawned                 0.264597\n",
       "is_building                0.264597\n",
       "shield_bool                0.264597\n",
       "is_tower_troop             0.264597\n",
       "is_troop                   0.264597\n",
       "mini_tank                  0.264597\n",
       "invisible                  0.264597\n",
       "is_spell                   0.264597\n",
       "win_con_dmg                0.264597\n",
       "dps_special                0.264597\n",
       "special_attack_type        0.264893\n",
       "no_hit_speed               0.266255\n",
       "single_damage_type         0.268270\n",
       "is_free_card               0.268351\n",
       "playable                   0.268351\n",
       "ground_dps                 0.268603\n",
       "air_control                0.274039\n",
       "attack_count               0.274734\n",
       "high_dps                   0.275488\n",
       "aoe_bool                   0.275807\n",
       "aoe_per_elixir             0.276203\n",
       "aoe_radius                 0.276203\n",
       "damage_output_ps           0.281400\n",
       "damage                     0.281458\n",
       "has_friendly_buff          0.282782\n",
       "has_periodic_spawn         0.283912\n",
       "has_ranged_attack          0.284644\n",
       "speed                      0.286893\n",
       "count                      0.286893\n",
       "range                      0.288499\n",
       "hit_speed                  0.290182\n",
       "hitpoints                  0.291209\n",
       "death_damage_bool          0.291725\n",
       "elixircost                 0.301943\n",
       "can_evolve                 0.307225\n",
       "damage_output              0.341011\n",
       "damage_per_elixir          0.364992\n",
       "aoe_by_range               0.366114\n",
       "damage_per_second          0.368944\n",
       "aoe_by_damage              0.370127\n",
       "damage_by_hitpoints        0.374608\n",
       "hp_per_elixir              0.396984\n",
       "Name: gmm_building, dtype: float64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sim.groupby('col')['gmm_building'].mean().sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b8578d0e-982c-4797-b57d-e1307e99b62c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gmm_troop</th>\n",
       "      <th>km_troop</th>\n",
       "      <th>gmm_spell</th>\n",
       "      <th>km_spell</th>\n",
       "      <th>gmm_building</th>\n",
       "      <th>km_building</th>\n",
       "      <th>K</th>\n",
       "      <th>col</th>\n",
       "      <th>og_col</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.100037</td>\n",
       "      <td>0.101809</td>\n",
       "      <td>0.062831</td>\n",
       "      <td>0.196593</td>\n",
       "      <td>0.303626</td>\n",
       "      <td>0.303626</td>\n",
       "      <td>3</td>\n",
       "      <td>playable</td>\n",
       "      <td>all_col</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.062340</td>\n",
       "      <td>0.110193</td>\n",
       "      <td>0.211933</td>\n",
       "      <td>0.211933</td>\n",
       "      <td>0.289034</td>\n",
       "      <td>0.289034</td>\n",
       "      <td>3</td>\n",
       "      <td>aoe_bool</td>\n",
       "      <td>all_col</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.056719</td>\n",
       "      <td>0.110700</td>\n",
       "      <td>0.075182</td>\n",
       "      <td>0.205529</td>\n",
       "      <td>0.290237</td>\n",
       "      <td>0.290237</td>\n",
       "      <td>3</td>\n",
       "      <td>aoe_radius</td>\n",
       "      <td>all_col</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.035059</td>\n",
       "      <td>0.114044</td>\n",
       "      <td>0.062831</td>\n",
       "      <td>0.196593</td>\n",
       "      <td>0.309203</td>\n",
       "      <td>0.309203</td>\n",
       "      <td>3</td>\n",
       "      <td>death_damage_bool</td>\n",
       "      <td>all_col</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.040841</td>\n",
       "      <td>0.111170</td>\n",
       "      <td>0.062831</td>\n",
       "      <td>0.196593</td>\n",
       "      <td>0.298635</td>\n",
       "      <td>0.298635</td>\n",
       "      <td>3</td>\n",
       "      <td>fly_bool</td>\n",
       "      <td>all_col</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.054749</td>\n",
       "      <td>0.114876</td>\n",
       "      <td>0.168812</td>\n",
       "      <td>0.196606</td>\n",
       "      <td>0.294232</td>\n",
       "      <td>0.294232</td>\n",
       "      <td>3</td>\n",
       "      <td>spawn_bool</td>\n",
       "      <td>all_col</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.084860</td>\n",
       "      <td>0.110139</td>\n",
       "      <td>0.141692</td>\n",
       "      <td>0.212579</td>\n",
       "      <td>0.314256</td>\n",
       "      <td>0.314256</td>\n",
       "      <td>3</td>\n",
       "      <td>can_evolve</td>\n",
       "      <td>all_col</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.097165</td>\n",
       "      <td>0.101387</td>\n",
       "      <td>0.142337</td>\n",
       "      <td>0.206865</td>\n",
       "      <td>0.308941</td>\n",
       "      <td>0.308941</td>\n",
       "      <td>3</td>\n",
       "      <td>elixircost</td>\n",
       "      <td>all_col</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.092766</td>\n",
       "      <td>0.115080</td>\n",
       "      <td>0.062831</td>\n",
       "      <td>0.196593</td>\n",
       "      <td>0.301437</td>\n",
       "      <td>0.301437</td>\n",
       "      <td>3</td>\n",
       "      <td>hit_speed</td>\n",
       "      <td>all_col</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.034007</td>\n",
       "      <td>0.106351</td>\n",
       "      <td>0.195995</td>\n",
       "      <td>0.183295</td>\n",
       "      <td>0.305407</td>\n",
       "      <td>0.305407</td>\n",
       "      <td>3</td>\n",
       "      <td>special_damage</td>\n",
       "      <td>all_col</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.044282</td>\n",
       "      <td>0.104321</td>\n",
       "      <td>0.062831</td>\n",
       "      <td>0.196593</td>\n",
       "      <td>0.298635</td>\n",
       "      <td>0.298635</td>\n",
       "      <td>3</td>\n",
       "      <td>count</td>\n",
       "      <td>all_col</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.048145</td>\n",
       "      <td>0.112099</td>\n",
       "      <td>0.062831</td>\n",
       "      <td>0.196593</td>\n",
       "      <td>0.305311</td>\n",
       "      <td>0.305311</td>\n",
       "      <td>3</td>\n",
       "      <td>hitpoints</td>\n",
       "      <td>all_col</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.027239</td>\n",
       "      <td>0.113499</td>\n",
       "      <td>0.062831</td>\n",
       "      <td>0.196593</td>\n",
       "      <td>0.298635</td>\n",
       "      <td>0.298635</td>\n",
       "      <td>3</td>\n",
       "      <td>shield_bool</td>\n",
       "      <td>all_col</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.064645</td>\n",
       "      <td>0.105246</td>\n",
       "      <td>0.191919</td>\n",
       "      <td>0.191919</td>\n",
       "      <td>0.297216</td>\n",
       "      <td>0.297216</td>\n",
       "      <td>3</td>\n",
       "      <td>damage</td>\n",
       "      <td>all_col</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.052031</td>\n",
       "      <td>0.117405</td>\n",
       "      <td>0.119865</td>\n",
       "      <td>0.206207</td>\n",
       "      <td>0.293146</td>\n",
       "      <td>0.293146</td>\n",
       "      <td>3</td>\n",
       "      <td>attack_count</td>\n",
       "      <td>all_col</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.038947</td>\n",
       "      <td>0.099117</td>\n",
       "      <td>0.062831</td>\n",
       "      <td>0.196593</td>\n",
       "      <td>0.289131</td>\n",
       "      <td>0.289131</td>\n",
       "      <td>3</td>\n",
       "      <td>range</td>\n",
       "      <td>all_col</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.086173</td>\n",
       "      <td>0.108281</td>\n",
       "      <td>0.164229</td>\n",
       "      <td>0.170569</td>\n",
       "      <td>0.305534</td>\n",
       "      <td>0.305534</td>\n",
       "      <td>3</td>\n",
       "      <td>affected_crown</td>\n",
       "      <td>all_col</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.081734</td>\n",
       "      <td>0.106841</td>\n",
       "      <td>0.062831</td>\n",
       "      <td>0.196593</td>\n",
       "      <td>0.298635</td>\n",
       "      <td>0.298635</td>\n",
       "      <td>3</td>\n",
       "      <td>has_lifetime</td>\n",
       "      <td>all_col</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.073947</td>\n",
       "      <td>0.115919</td>\n",
       "      <td>0.062831</td>\n",
       "      <td>0.196593</td>\n",
       "      <td>0.298635</td>\n",
       "      <td>0.298635</td>\n",
       "      <td>3</td>\n",
       "      <td>invisible</td>\n",
       "      <td>all_col</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.047314</td>\n",
       "      <td>0.112191</td>\n",
       "      <td>0.062831</td>\n",
       "      <td>0.196593</td>\n",
       "      <td>0.298635</td>\n",
       "      <td>0.298635</td>\n",
       "      <td>3</td>\n",
       "      <td>has_ability</td>\n",
       "      <td>all_col</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.060326</td>\n",
       "      <td>0.100080</td>\n",
       "      <td>0.062831</td>\n",
       "      <td>0.196593</td>\n",
       "      <td>0.298061</td>\n",
       "      <td>0.298061</td>\n",
       "      <td>3</td>\n",
       "      <td>any_target</td>\n",
       "      <td>all_col</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.060326</td>\n",
       "      <td>0.100080</td>\n",
       "      <td>0.062831</td>\n",
       "      <td>0.196593</td>\n",
       "      <td>0.297973</td>\n",
       "      <td>0.297973</td>\n",
       "      <td>3</td>\n",
       "      <td>building_target</td>\n",
       "      <td>all_col</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.101762</td>\n",
       "      <td>0.105216</td>\n",
       "      <td>0.062831</td>\n",
       "      <td>0.196593</td>\n",
       "      <td>0.297973</td>\n",
       "      <td>0.297973</td>\n",
       "      <td>3</td>\n",
       "      <td>ground_target</td>\n",
       "      <td>all_col</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.049734</td>\n",
       "      <td>0.113567</td>\n",
       "      <td>0.078776</td>\n",
       "      <td>0.188895</td>\n",
       "      <td>0.298635</td>\n",
       "      <td>0.298635</td>\n",
       "      <td>3</td>\n",
       "      <td>has_upon_breaking_spawn</td>\n",
       "      <td>all_col</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.034046</td>\n",
       "      <td>0.110214</td>\n",
       "      <td>0.062831</td>\n",
       "      <td>0.196593</td>\n",
       "      <td>0.294232</td>\n",
       "      <td>0.294232</td>\n",
       "      <td>3</td>\n",
       "      <td>has_upon_death_spawn</td>\n",
       "      <td>all_col</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.114821</td>\n",
       "      <td>0.118159</td>\n",
       "      <td>0.213373</td>\n",
       "      <td>0.213373</td>\n",
       "      <td>0.302838</td>\n",
       "      <td>0.302838</td>\n",
       "      <td>3</td>\n",
       "      <td>has_periodic_spawn</td>\n",
       "      <td>all_col</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.055701</td>\n",
       "      <td>0.095201</td>\n",
       "      <td>0.164355</td>\n",
       "      <td>0.211537</td>\n",
       "      <td>0.293041</td>\n",
       "      <td>0.293041</td>\n",
       "      <td>3</td>\n",
       "      <td>single_damage_type</td>\n",
       "      <td>all_col</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.045117</td>\n",
       "      <td>0.111977</td>\n",
       "      <td>0.062831</td>\n",
       "      <td>0.196593</td>\n",
       "      <td>0.298635</td>\n",
       "      <td>0.298635</td>\n",
       "      <td>3</td>\n",
       "      <td>is_troop</td>\n",
       "      <td>all_col</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.045117</td>\n",
       "      <td>0.111977</td>\n",
       "      <td>0.062831</td>\n",
       "      <td>0.196593</td>\n",
       "      <td>0.298635</td>\n",
       "      <td>0.298635</td>\n",
       "      <td>3</td>\n",
       "      <td>is_spell</td>\n",
       "      <td>all_col</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.045117</td>\n",
       "      <td>0.111977</td>\n",
       "      <td>0.062831</td>\n",
       "      <td>0.196593</td>\n",
       "      <td>0.298635</td>\n",
       "      <td>0.298635</td>\n",
       "      <td>3</td>\n",
       "      <td>is_building</td>\n",
       "      <td>all_col</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.045117</td>\n",
       "      <td>0.111977</td>\n",
       "      <td>0.062831</td>\n",
       "      <td>0.196593</td>\n",
       "      <td>0.298635</td>\n",
       "      <td>0.298635</td>\n",
       "      <td>3</td>\n",
       "      <td>is_tower_troop</td>\n",
       "      <td>all_col</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.029134</td>\n",
       "      <td>0.116375</td>\n",
       "      <td>0.168548</td>\n",
       "      <td>0.208661</td>\n",
       "      <td>0.298635</td>\n",
       "      <td>0.298635</td>\n",
       "      <td>3</td>\n",
       "      <td>is_spawned</td>\n",
       "      <td>all_col</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.104153</td>\n",
       "      <td>0.114854</td>\n",
       "      <td>0.062831</td>\n",
       "      <td>0.196593</td>\n",
       "      <td>0.298635</td>\n",
       "      <td>0.298635</td>\n",
       "      <td>3</td>\n",
       "      <td>speed</td>\n",
       "      <td>all_col</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.065812</td>\n",
       "      <td>0.099128</td>\n",
       "      <td>0.062831</td>\n",
       "      <td>0.196593</td>\n",
       "      <td>0.297040</td>\n",
       "      <td>0.297040</td>\n",
       "      <td>3</td>\n",
       "      <td>has_ranged_attack</td>\n",
       "      <td>all_col</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.090829</td>\n",
       "      <td>0.109798</td>\n",
       "      <td>0.163398</td>\n",
       "      <td>0.207380</td>\n",
       "      <td>0.299783</td>\n",
       "      <td>0.299783</td>\n",
       "      <td>3</td>\n",
       "      <td>special_attack_type</td>\n",
       "      <td>all_col</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.049132</td>\n",
       "      <td>0.114477</td>\n",
       "      <td>0.139334</td>\n",
       "      <td>0.213835</td>\n",
       "      <td>0.313071</td>\n",
       "      <td>0.313071</td>\n",
       "      <td>3</td>\n",
       "      <td>has_friendly_buff</td>\n",
       "      <td>all_col</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.100037</td>\n",
       "      <td>0.101809</td>\n",
       "      <td>0.062831</td>\n",
       "      <td>0.196593</td>\n",
       "      <td>0.303626</td>\n",
       "      <td>0.303626</td>\n",
       "      <td>3</td>\n",
       "      <td>is_free_card</td>\n",
       "      <td>all_col</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.043611</td>\n",
       "      <td>0.113980</td>\n",
       "      <td>0.062831</td>\n",
       "      <td>0.196593</td>\n",
       "      <td>0.286797</td>\n",
       "      <td>0.286797</td>\n",
       "      <td>3</td>\n",
       "      <td>no_hit_speed</td>\n",
       "      <td>all_col</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.079762</td>\n",
       "      <td>0.112477</td>\n",
       "      <td>0.112732</td>\n",
       "      <td>0.200056</td>\n",
       "      <td>0.293146</td>\n",
       "      <td>0.293146</td>\n",
       "      <td>3</td>\n",
       "      <td>no_attack</td>\n",
       "      <td>all_col</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0.055088</td>\n",
       "      <td>0.112943</td>\n",
       "      <td>0.062831</td>\n",
       "      <td>0.196593</td>\n",
       "      <td>0.298635</td>\n",
       "      <td>0.298635</td>\n",
       "      <td>3</td>\n",
       "      <td>no_hitpoints</td>\n",
       "      <td>all_col</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0.051997</td>\n",
       "      <td>0.107561</td>\n",
       "      <td>0.147079</td>\n",
       "      <td>0.192018</td>\n",
       "      <td>0.298946</td>\n",
       "      <td>0.298946</td>\n",
       "      <td>3</td>\n",
       "      <td>damage_per_elixir</td>\n",
       "      <td>all_col</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0.029025</td>\n",
       "      <td>0.106955</td>\n",
       "      <td>0.062831</td>\n",
       "      <td>0.196593</td>\n",
       "      <td>0.294527</td>\n",
       "      <td>0.294527</td>\n",
       "      <td>3</td>\n",
       "      <td>damage_per_second</td>\n",
       "      <td>all_col</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0.045049</td>\n",
       "      <td>0.114034</td>\n",
       "      <td>0.166616</td>\n",
       "      <td>0.197958</td>\n",
       "      <td>0.299470</td>\n",
       "      <td>0.299470</td>\n",
       "      <td>3</td>\n",
       "      <td>damage_output</td>\n",
       "      <td>all_col</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0.042387</td>\n",
       "      <td>0.103179</td>\n",
       "      <td>0.141541</td>\n",
       "      <td>0.207821</td>\n",
       "      <td>0.303454</td>\n",
       "      <td>0.303454</td>\n",
       "      <td>3</td>\n",
       "      <td>hp_per_elixir</td>\n",
       "      <td>all_col</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>0.055057</td>\n",
       "      <td>0.106570</td>\n",
       "      <td>0.062831</td>\n",
       "      <td>0.196593</td>\n",
       "      <td>0.298016</td>\n",
       "      <td>0.298016</td>\n",
       "      <td>3</td>\n",
       "      <td>damage_by_hitpoints</td>\n",
       "      <td>all_col</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>0.113998</td>\n",
       "      <td>0.096147</td>\n",
       "      <td>0.075182</td>\n",
       "      <td>0.205529</td>\n",
       "      <td>0.289315</td>\n",
       "      <td>0.289315</td>\n",
       "      <td>3</td>\n",
       "      <td>aoe_by_range</td>\n",
       "      <td>all_col</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>0.036152</td>\n",
       "      <td>0.117122</td>\n",
       "      <td>0.195294</td>\n",
       "      <td>0.195294</td>\n",
       "      <td>0.291683</td>\n",
       "      <td>0.291683</td>\n",
       "      <td>3</td>\n",
       "      <td>aoe_by_damage</td>\n",
       "      <td>all_col</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>0.092391</td>\n",
       "      <td>0.112364</td>\n",
       "      <td>0.062831</td>\n",
       "      <td>0.196593</td>\n",
       "      <td>0.298635</td>\n",
       "      <td>0.298635</td>\n",
       "      <td>3</td>\n",
       "      <td>win_con</td>\n",
       "      <td>all_col</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>0.112357</td>\n",
       "      <td>0.108330</td>\n",
       "      <td>0.167061</td>\n",
       "      <td>0.188712</td>\n",
       "      <td>0.290237</td>\n",
       "      <td>0.290237</td>\n",
       "      <td>3</td>\n",
       "      <td>aoe_per_elixir</td>\n",
       "      <td>all_col</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>0.036747</td>\n",
       "      <td>0.107812</td>\n",
       "      <td>0.171329</td>\n",
       "      <td>0.189742</td>\n",
       "      <td>0.305407</td>\n",
       "      <td>0.305407</td>\n",
       "      <td>3</td>\n",
       "      <td>control_special</td>\n",
       "      <td>all_col</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>0.077235</td>\n",
       "      <td>0.115209</td>\n",
       "      <td>0.079474</td>\n",
       "      <td>0.186587</td>\n",
       "      <td>0.298635</td>\n",
       "      <td>0.298635</td>\n",
       "      <td>3</td>\n",
       "      <td>dps_special</td>\n",
       "      <td>all_col</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>0.047161</td>\n",
       "      <td>0.109228</td>\n",
       "      <td>0.062831</td>\n",
       "      <td>0.196593</td>\n",
       "      <td>0.303539</td>\n",
       "      <td>0.303539</td>\n",
       "      <td>3</td>\n",
       "      <td>air_control</td>\n",
       "      <td>all_col</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>0.081228</td>\n",
       "      <td>0.112854</td>\n",
       "      <td>0.062831</td>\n",
       "      <td>0.196593</td>\n",
       "      <td>0.301109</td>\n",
       "      <td>0.301109</td>\n",
       "      <td>3</td>\n",
       "      <td>ground_dps</td>\n",
       "      <td>all_col</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>0.030494</td>\n",
       "      <td>0.109627</td>\n",
       "      <td>0.062831</td>\n",
       "      <td>0.196593</td>\n",
       "      <td>0.298635</td>\n",
       "      <td>0.298635</td>\n",
       "      <td>3</td>\n",
       "      <td>win_con_dmg</td>\n",
       "      <td>all_col</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>0.060032</td>\n",
       "      <td>0.109786</td>\n",
       "      <td>0.084474</td>\n",
       "      <td>0.189142</td>\n",
       "      <td>0.298007</td>\n",
       "      <td>0.298007</td>\n",
       "      <td>3</td>\n",
       "      <td>high_dps</td>\n",
       "      <td>all_col</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>0.047135</td>\n",
       "      <td>0.105350</td>\n",
       "      <td>0.062831</td>\n",
       "      <td>0.196593</td>\n",
       "      <td>0.295283</td>\n",
       "      <td>0.295283</td>\n",
       "      <td>3</td>\n",
       "      <td>damage_output_ps</td>\n",
       "      <td>all_col</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>0.045123</td>\n",
       "      <td>0.102547</td>\n",
       "      <td>0.140592</td>\n",
       "      <td>0.209416</td>\n",
       "      <td>0.293146</td>\n",
       "      <td>0.293146</td>\n",
       "      <td>3</td>\n",
       "      <td>support</td>\n",
       "      <td>all_col</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>0.051795</td>\n",
       "      <td>0.107345</td>\n",
       "      <td>0.062831</td>\n",
       "      <td>0.196593</td>\n",
       "      <td>0.298635</td>\n",
       "      <td>0.298635</td>\n",
       "      <td>3</td>\n",
       "      <td>mini_tank</td>\n",
       "      <td>all_col</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>0.203116</td>\n",
       "      <td>0.200817</td>\n",
       "      <td>-0.118462</td>\n",
       "      <td>0.376307</td>\n",
       "      <td>0.365330</td>\n",
       "      <td>0.483052</td>\n",
       "      <td>3</td>\n",
       "      <td>damage_per_elixir</td>\n",
       "      <td>engineered</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>0.238237</td>\n",
       "      <td>0.227292</td>\n",
       "      <td>0.349300</td>\n",
       "      <td>0.349300</td>\n",
       "      <td>0.496696</td>\n",
       "      <td>0.496696</td>\n",
       "      <td>3</td>\n",
       "      <td>damage_per_second</td>\n",
       "      <td>engineered</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>0.137030</td>\n",
       "      <td>0.256585</td>\n",
       "      <td>0.367224</td>\n",
       "      <td>0.367224</td>\n",
       "      <td>0.607867</td>\n",
       "      <td>0.607867</td>\n",
       "      <td>3</td>\n",
       "      <td>damage_output</td>\n",
       "      <td>engineered</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>-0.218974</td>\n",
       "      <td>0.324801</td>\n",
       "      <td>0.302610</td>\n",
       "      <td>0.476886</td>\n",
       "      <td>0.454261</td>\n",
       "      <td>0.618569</td>\n",
       "      <td>3</td>\n",
       "      <td>hp_per_elixir</td>\n",
       "      <td>engineered</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>0.225847</td>\n",
       "      <td>0.240614</td>\n",
       "      <td>0.349300</td>\n",
       "      <td>0.349300</td>\n",
       "      <td>0.454409</td>\n",
       "      <td>0.454409</td>\n",
       "      <td>3</td>\n",
       "      <td>damage_by_hitpoints</td>\n",
       "      <td>engineered</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>0.176890</td>\n",
       "      <td>0.224405</td>\n",
       "      <td>0.496813</td>\n",
       "      <td>0.496813</td>\n",
       "      <td>0.404310</td>\n",
       "      <td>0.505912</td>\n",
       "      <td>3</td>\n",
       "      <td>aoe_by_range</td>\n",
       "      <td>engineered</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>0.124872</td>\n",
       "      <td>0.207028</td>\n",
       "      <td>0.358222</td>\n",
       "      <td>0.358222</td>\n",
       "      <td>0.354810</td>\n",
       "      <td>0.521772</td>\n",
       "      <td>3</td>\n",
       "      <td>aoe_by_damage</td>\n",
       "      <td>engineered</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>0.072872</td>\n",
       "      <td>0.116738</td>\n",
       "      <td>0.167337</td>\n",
       "      <td>0.189348</td>\n",
       "      <td>0.283977</td>\n",
       "      <td>0.283977</td>\n",
       "      <td>3</td>\n",
       "      <td>playable</td>\n",
       "      <td>original</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>0.121182</td>\n",
       "      <td>0.121625</td>\n",
       "      <td>0.119199</td>\n",
       "      <td>0.201773</td>\n",
       "      <td>0.265478</td>\n",
       "      <td>0.255912</td>\n",
       "      <td>3</td>\n",
       "      <td>aoe_bool</td>\n",
       "      <td>original</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>0.027491</td>\n",
       "      <td>0.120760</td>\n",
       "      <td>0.198583</td>\n",
       "      <td>0.185648</td>\n",
       "      <td>0.265403</td>\n",
       "      <td>0.255856</td>\n",
       "      <td>3</td>\n",
       "      <td>aoe_radius</td>\n",
       "      <td>original</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>0.051542</td>\n",
       "      <td>0.120779</td>\n",
       "      <td>0.167337</td>\n",
       "      <td>0.189348</td>\n",
       "      <td>0.240949</td>\n",
       "      <td>0.284104</td>\n",
       "      <td>3</td>\n",
       "      <td>death_damage_bool</td>\n",
       "      <td>original</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>0.068196</td>\n",
       "      <td>0.120036</td>\n",
       "      <td>0.167337</td>\n",
       "      <td>0.189348</td>\n",
       "      <td>0.279214</td>\n",
       "      <td>0.279214</td>\n",
       "      <td>3</td>\n",
       "      <td>fly_bool</td>\n",
       "      <td>original</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>0.107533</td>\n",
       "      <td>0.122857</td>\n",
       "      <td>0.104524</td>\n",
       "      <td>0.185357</td>\n",
       "      <td>0.276239</td>\n",
       "      <td>0.276239</td>\n",
       "      <td>3</td>\n",
       "      <td>spawn_bool</td>\n",
       "      <td>original</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>0.046575</td>\n",
       "      <td>0.122889</td>\n",
       "      <td>0.178781</td>\n",
       "      <td>0.204377</td>\n",
       "      <td>0.297026</td>\n",
       "      <td>0.297026</td>\n",
       "      <td>3</td>\n",
       "      <td>can_evolve</td>\n",
       "      <td>original</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>0.090041</td>\n",
       "      <td>0.104541</td>\n",
       "      <td>0.168079</td>\n",
       "      <td>0.198395</td>\n",
       "      <td>0.290833</td>\n",
       "      <td>0.290833</td>\n",
       "      <td>3</td>\n",
       "      <td>elixircost</td>\n",
       "      <td>original</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>0.074318</td>\n",
       "      <td>0.109901</td>\n",
       "      <td>0.167337</td>\n",
       "      <td>0.189348</td>\n",
       "      <td>0.225523</td>\n",
       "      <td>0.285088</td>\n",
       "      <td>3</td>\n",
       "      <td>hit_speed</td>\n",
       "      <td>original</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>0.089871</td>\n",
       "      <td>0.123058</td>\n",
       "      <td>0.099888</td>\n",
       "      <td>0.183428</td>\n",
       "      <td>0.288105</td>\n",
       "      <td>0.288105</td>\n",
       "      <td>3</td>\n",
       "      <td>special_damage</td>\n",
       "      <td>original</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>0.065422</td>\n",
       "      <td>0.125942</td>\n",
       "      <td>0.167337</td>\n",
       "      <td>0.189348</td>\n",
       "      <td>0.279214</td>\n",
       "      <td>0.279214</td>\n",
       "      <td>3</td>\n",
       "      <td>count</td>\n",
       "      <td>original</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>0.068319</td>\n",
       "      <td>0.117190</td>\n",
       "      <td>0.167337</td>\n",
       "      <td>0.189348</td>\n",
       "      <td>0.289000</td>\n",
       "      <td>0.289000</td>\n",
       "      <td>3</td>\n",
       "      <td>hitpoints</td>\n",
       "      <td>original</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>0.097603</td>\n",
       "      <td>0.119704</td>\n",
       "      <td>0.167337</td>\n",
       "      <td>0.189348</td>\n",
       "      <td>0.279214</td>\n",
       "      <td>0.279214</td>\n",
       "      <td>3</td>\n",
       "      <td>shield_bool</td>\n",
       "      <td>original</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>0.040057</td>\n",
       "      <td>0.118153</td>\n",
       "      <td>0.170277</td>\n",
       "      <td>0.171650</td>\n",
       "      <td>0.276056</td>\n",
       "      <td>0.276056</td>\n",
       "      <td>3</td>\n",
       "      <td>damage</td>\n",
       "      <td>original</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>0.028625</td>\n",
       "      <td>0.125393</td>\n",
       "      <td>0.171973</td>\n",
       "      <td>0.198453</td>\n",
       "      <td>0.274979</td>\n",
       "      <td>0.274979</td>\n",
       "      <td>3</td>\n",
       "      <td>attack_count</td>\n",
       "      <td>original</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>0.045184</td>\n",
       "      <td>0.112558</td>\n",
       "      <td>0.167337</td>\n",
       "      <td>0.189348</td>\n",
       "      <td>0.271222</td>\n",
       "      <td>0.271222</td>\n",
       "      <td>3</td>\n",
       "      <td>range</td>\n",
       "      <td>original</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>0.102699</td>\n",
       "      <td>0.118776</td>\n",
       "      <td>0.087869</td>\n",
       "      <td>0.175591</td>\n",
       "      <td>0.289352</td>\n",
       "      <td>0.289352</td>\n",
       "      <td>3</td>\n",
       "      <td>affected_crown</td>\n",
       "      <td>original</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>0.046404</td>\n",
       "      <td>0.116495</td>\n",
       "      <td>0.167337</td>\n",
       "      <td>0.189348</td>\n",
       "      <td>0.279214</td>\n",
       "      <td>0.279214</td>\n",
       "      <td>3</td>\n",
       "      <td>has_lifetime</td>\n",
       "      <td>original</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>0.096984</td>\n",
       "      <td>0.115751</td>\n",
       "      <td>0.167337</td>\n",
       "      <td>0.189348</td>\n",
       "      <td>0.279214</td>\n",
       "      <td>0.279214</td>\n",
       "      <td>3</td>\n",
       "      <td>invisible</td>\n",
       "      <td>original</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>0.105142</td>\n",
       "      <td>0.122176</td>\n",
       "      <td>0.167337</td>\n",
       "      <td>0.189348</td>\n",
       "      <td>0.279214</td>\n",
       "      <td>0.279214</td>\n",
       "      <td>3</td>\n",
       "      <td>has_ability</td>\n",
       "      <td>original</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>0.074764</td>\n",
       "      <td>0.104661</td>\n",
       "      <td>0.167337</td>\n",
       "      <td>0.189348</td>\n",
       "      <td>0.278589</td>\n",
       "      <td>0.278589</td>\n",
       "      <td>3</td>\n",
       "      <td>any_target</td>\n",
       "      <td>original</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>0.074764</td>\n",
       "      <td>0.104661</td>\n",
       "      <td>0.167337</td>\n",
       "      <td>0.189348</td>\n",
       "      <td>0.281220</td>\n",
       "      <td>0.281220</td>\n",
       "      <td>3</td>\n",
       "      <td>building_target</td>\n",
       "      <td>original</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>0.084551</td>\n",
       "      <td>0.115426</td>\n",
       "      <td>0.167337</td>\n",
       "      <td>0.189348</td>\n",
       "      <td>0.281220</td>\n",
       "      <td>0.281220</td>\n",
       "      <td>3</td>\n",
       "      <td>ground_target</td>\n",
       "      <td>original</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>0.094505</td>\n",
       "      <td>0.125212</td>\n",
       "      <td>0.113141</td>\n",
       "      <td>0.175544</td>\n",
       "      <td>0.279214</td>\n",
       "      <td>0.279214</td>\n",
       "      <td>3</td>\n",
       "      <td>has_upon_breaking_spawn</td>\n",
       "      <td>original</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>0.056602</td>\n",
       "      <td>0.120200</td>\n",
       "      <td>0.167337</td>\n",
       "      <td>0.189348</td>\n",
       "      <td>0.276239</td>\n",
       "      <td>0.276239</td>\n",
       "      <td>3</td>\n",
       "      <td>has_upon_death_spawn</td>\n",
       "      <td>original</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>0.099591</td>\n",
       "      <td>0.114642</td>\n",
       "      <td>0.123969</td>\n",
       "      <td>0.205100</td>\n",
       "      <td>0.285812</td>\n",
       "      <td>0.285812</td>\n",
       "      <td>3</td>\n",
       "      <td>has_periodic_spawn</td>\n",
       "      <td>original</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>0.081793</td>\n",
       "      <td>0.121287</td>\n",
       "      <td>0.111922</td>\n",
       "      <td>0.201875</td>\n",
       "      <td>0.275449</td>\n",
       "      <td>0.275449</td>\n",
       "      <td>3</td>\n",
       "      <td>single_damage_type</td>\n",
       "      <td>original</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>0.065651</td>\n",
       "      <td>0.120897</td>\n",
       "      <td>0.167337</td>\n",
       "      <td>0.189348</td>\n",
       "      <td>0.279214</td>\n",
       "      <td>0.279214</td>\n",
       "      <td>3</td>\n",
       "      <td>is_troop</td>\n",
       "      <td>original</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>0.065651</td>\n",
       "      <td>0.120897</td>\n",
       "      <td>0.167337</td>\n",
       "      <td>0.189348</td>\n",
       "      <td>0.279214</td>\n",
       "      <td>0.279214</td>\n",
       "      <td>3</td>\n",
       "      <td>is_spell</td>\n",
       "      <td>original</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>0.065651</td>\n",
       "      <td>0.120897</td>\n",
       "      <td>0.167337</td>\n",
       "      <td>0.189348</td>\n",
       "      <td>0.279214</td>\n",
       "      <td>0.279214</td>\n",
       "      <td>3</td>\n",
       "      <td>is_building</td>\n",
       "      <td>original</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>0.065651</td>\n",
       "      <td>0.120897</td>\n",
       "      <td>0.167337</td>\n",
       "      <td>0.189348</td>\n",
       "      <td>0.279214</td>\n",
       "      <td>0.279214</td>\n",
       "      <td>3</td>\n",
       "      <td>is_tower_troop</td>\n",
       "      <td>original</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.028489</td>\n",
       "      <td>0.100220</td>\n",
       "      <td>0.129067</td>\n",
       "      <td>0.199322</td>\n",
       "      <td>0.279214</td>\n",
       "      <td>0.279214</td>\n",
       "      <td>3</td>\n",
       "      <td>is_spawned</td>\n",
       "      <td>original</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>0.083493</td>\n",
       "      <td>0.121804</td>\n",
       "      <td>0.167337</td>\n",
       "      <td>0.189348</td>\n",
       "      <td>0.279214</td>\n",
       "      <td>0.279214</td>\n",
       "      <td>3</td>\n",
       "      <td>speed</td>\n",
       "      <td>original</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>0.044072</td>\n",
       "      <td>0.112747</td>\n",
       "      <td>0.167337</td>\n",
       "      <td>0.189348</td>\n",
       "      <td>0.281101</td>\n",
       "      <td>0.281101</td>\n",
       "      <td>3</td>\n",
       "      <td>has_ranged_attack</td>\n",
       "      <td>original</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>0.102556</td>\n",
       "      <td>0.114016</td>\n",
       "      <td>0.151637</td>\n",
       "      <td>0.199671</td>\n",
       "      <td>0.281121</td>\n",
       "      <td>0.281121</td>\n",
       "      <td>3</td>\n",
       "      <td>special_attack_type</td>\n",
       "      <td>original</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>0.028942</td>\n",
       "      <td>0.122802</td>\n",
       "      <td>0.190514</td>\n",
       "      <td>0.206585</td>\n",
       "      <td>0.295956</td>\n",
       "      <td>0.295956</td>\n",
       "      <td>3</td>\n",
       "      <td>has_friendly_buff</td>\n",
       "      <td>original</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>0.072872</td>\n",
       "      <td>0.116738</td>\n",
       "      <td>0.167337</td>\n",
       "      <td>0.189348</td>\n",
       "      <td>0.283977</td>\n",
       "      <td>0.283977</td>\n",
       "      <td>3</td>\n",
       "      <td>is_free_card</td>\n",
       "      <td>original</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>0.107737</td>\n",
       "      <td>0.122180</td>\n",
       "      <td>0.167337</td>\n",
       "      <td>0.189348</td>\n",
       "      <td>0.268246</td>\n",
       "      <td>0.268246</td>\n",
       "      <td>3</td>\n",
       "      <td>no_hit_speed</td>\n",
       "      <td>original</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>0.111382</td>\n",
       "      <td>0.112258</td>\n",
       "      <td>0.111952</td>\n",
       "      <td>0.190356</td>\n",
       "      <td>0.274979</td>\n",
       "      <td>0.274979</td>\n",
       "      <td>3</td>\n",
       "      <td>no_attack</td>\n",
       "      <td>original</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>0.066611</td>\n",
       "      <td>0.115442</td>\n",
       "      <td>0.167337</td>\n",
       "      <td>0.189348</td>\n",
       "      <td>0.279214</td>\n",
       "      <td>0.279214</td>\n",
       "      <td>3</td>\n",
       "      <td>no_hitpoints</td>\n",
       "      <td>original</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>0.068600</td>\n",
       "      <td>0.111817</td>\n",
       "      <td>0.167337</td>\n",
       "      <td>0.189348</td>\n",
       "      <td>0.279214</td>\n",
       "      <td>0.279214</td>\n",
       "      <td>3</td>\n",
       "      <td>win_con</td>\n",
       "      <td>original</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>0.051913</td>\n",
       "      <td>0.116296</td>\n",
       "      <td>0.154005</td>\n",
       "      <td>0.183808</td>\n",
       "      <td>0.265403</td>\n",
       "      <td>0.255856</td>\n",
       "      <td>3</td>\n",
       "      <td>aoe_per_elixir</td>\n",
       "      <td>original</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>0.085090</td>\n",
       "      <td>0.117841</td>\n",
       "      <td>0.171551</td>\n",
       "      <td>0.198072</td>\n",
       "      <td>0.288105</td>\n",
       "      <td>0.288105</td>\n",
       "      <td>3</td>\n",
       "      <td>control_special</td>\n",
       "      <td>original</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>0.038378</td>\n",
       "      <td>0.123295</td>\n",
       "      <td>0.070564</td>\n",
       "      <td>0.160120</td>\n",
       "      <td>0.279214</td>\n",
       "      <td>0.279214</td>\n",
       "      <td>3</td>\n",
       "      <td>dps_special</td>\n",
       "      <td>original</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>0.094384</td>\n",
       "      <td>0.111277</td>\n",
       "      <td>0.167337</td>\n",
       "      <td>0.189348</td>\n",
       "      <td>0.284787</td>\n",
       "      <td>0.284787</td>\n",
       "      <td>3</td>\n",
       "      <td>air_control</td>\n",
       "      <td>original</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>0.067411</td>\n",
       "      <td>0.115689</td>\n",
       "      <td>0.167337</td>\n",
       "      <td>0.189348</td>\n",
       "      <td>0.280329</td>\n",
       "      <td>0.280329</td>\n",
       "      <td>3</td>\n",
       "      <td>ground_dps</td>\n",
       "      <td>original</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>0.041809</td>\n",
       "      <td>0.124493</td>\n",
       "      <td>0.167337</td>\n",
       "      <td>0.189348</td>\n",
       "      <td>0.279214</td>\n",
       "      <td>0.279214</td>\n",
       "      <td>3</td>\n",
       "      <td>win_con_dmg</td>\n",
       "      <td>original</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>0.067284</td>\n",
       "      <td>0.122343</td>\n",
       "      <td>0.073406</td>\n",
       "      <td>0.176645</td>\n",
       "      <td>0.277153</td>\n",
       "      <td>0.277153</td>\n",
       "      <td>3</td>\n",
       "      <td>high_dps</td>\n",
       "      <td>original</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>0.107552</td>\n",
       "      <td>0.122408</td>\n",
       "      <td>0.167337</td>\n",
       "      <td>0.189348</td>\n",
       "      <td>0.247894</td>\n",
       "      <td>0.247894</td>\n",
       "      <td>3</td>\n",
       "      <td>damage_output_ps</td>\n",
       "      <td>original</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>0.111163</td>\n",
       "      <td>0.107395</td>\n",
       "      <td>0.108052</td>\n",
       "      <td>0.198949</td>\n",
       "      <td>0.274979</td>\n",
       "      <td>0.274979</td>\n",
       "      <td>3</td>\n",
       "      <td>support</td>\n",
       "      <td>original</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>0.045536</td>\n",
       "      <td>0.124075</td>\n",
       "      <td>0.167337</td>\n",
       "      <td>0.189348</td>\n",
       "      <td>0.279214</td>\n",
       "      <td>0.279214</td>\n",
       "      <td>3</td>\n",
       "      <td>mini_tank</td>\n",
       "      <td>original</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>0.153018</td>\n",
       "      <td>0.216140</td>\n",
       "      <td>0.113623</td>\n",
       "      <td>0.281693</td>\n",
       "      <td>0.335433</td>\n",
       "      <td>0.335433</td>\n",
       "      <td>3</td>\n",
       "      <td>aoe_radius</td>\n",
       "      <td>num_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>0.200291</td>\n",
       "      <td>0.247407</td>\n",
       "      <td>0.063930</td>\n",
       "      <td>0.359095</td>\n",
       "      <td>0.342103</td>\n",
       "      <td>0.379770</td>\n",
       "      <td>3</td>\n",
       "      <td>can_evolve</td>\n",
       "      <td>num_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>0.105191</td>\n",
       "      <td>0.248185</td>\n",
       "      <td>0.329103</td>\n",
       "      <td>0.329103</td>\n",
       "      <td>0.372733</td>\n",
       "      <td>0.372733</td>\n",
       "      <td>3</td>\n",
       "      <td>elixircost</td>\n",
       "      <td>num_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>0.193856</td>\n",
       "      <td>0.239770</td>\n",
       "      <td>0.327051</td>\n",
       "      <td>0.324395</td>\n",
       "      <td>0.303170</td>\n",
       "      <td>0.370649</td>\n",
       "      <td>3</td>\n",
       "      <td>hit_speed</td>\n",
       "      <td>num_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>0.201470</td>\n",
       "      <td>0.199722</td>\n",
       "      <td>0.327051</td>\n",
       "      <td>0.324395</td>\n",
       "      <td>0.340515</td>\n",
       "      <td>0.340515</td>\n",
       "      <td>3</td>\n",
       "      <td>count</td>\n",
       "      <td>num_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>0.135034</td>\n",
       "      <td>0.227546</td>\n",
       "      <td>0.327051</td>\n",
       "      <td>0.324395</td>\n",
       "      <td>0.311973</td>\n",
       "      <td>0.375576</td>\n",
       "      <td>3</td>\n",
       "      <td>hitpoints</td>\n",
       "      <td>num_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>0.040273</td>\n",
       "      <td>0.234442</td>\n",
       "      <td>0.083232</td>\n",
       "      <td>0.317736</td>\n",
       "      <td>0.329277</td>\n",
       "      <td>0.329277</td>\n",
       "      <td>3</td>\n",
       "      <td>damage</td>\n",
       "      <td>num_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>0.320096</td>\n",
       "      <td>0.143176</td>\n",
       "      <td>0.258553</td>\n",
       "      <td>0.352738</td>\n",
       "      <td>0.355104</td>\n",
       "      <td>0.355104</td>\n",
       "      <td>3</td>\n",
       "      <td>attack_count</td>\n",
       "      <td>num_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>0.140839</td>\n",
       "      <td>0.238667</td>\n",
       "      <td>0.327051</td>\n",
       "      <td>0.324395</td>\n",
       "      <td>0.326645</td>\n",
       "      <td>0.371821</td>\n",
       "      <td>3</td>\n",
       "      <td>range</td>\n",
       "      <td>num_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>0.192269</td>\n",
       "      <td>0.199859</td>\n",
       "      <td>0.327051</td>\n",
       "      <td>0.324395</td>\n",
       "      <td>0.340515</td>\n",
       "      <td>0.340515</td>\n",
       "      <td>3</td>\n",
       "      <td>speed</td>\n",
       "      <td>num_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>0.190457</td>\n",
       "      <td>0.223575</td>\n",
       "      <td>0.318912</td>\n",
       "      <td>0.318912</td>\n",
       "      <td>0.333366</td>\n",
       "      <td>0.333366</td>\n",
       "      <td>3</td>\n",
       "      <td>damage_per_elixir</td>\n",
       "      <td>num_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>0.068356</td>\n",
       "      <td>0.237216</td>\n",
       "      <td>0.327051</td>\n",
       "      <td>0.324395</td>\n",
       "      <td>0.347825</td>\n",
       "      <td>0.347825</td>\n",
       "      <td>3</td>\n",
       "      <td>damage_per_second</td>\n",
       "      <td>num_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>0.144004</td>\n",
       "      <td>0.199908</td>\n",
       "      <td>0.089093</td>\n",
       "      <td>0.329161</td>\n",
       "      <td>0.328082</td>\n",
       "      <td>0.371025</td>\n",
       "      <td>3</td>\n",
       "      <td>damage_output</td>\n",
       "      <td>num_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>0.174210</td>\n",
       "      <td>0.230409</td>\n",
       "      <td>0.355502</td>\n",
       "      <td>0.357648</td>\n",
       "      <td>0.311749</td>\n",
       "      <td>0.377683</td>\n",
       "      <td>3</td>\n",
       "      <td>hp_per_elixir</td>\n",
       "      <td>num_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>0.100082</td>\n",
       "      <td>0.215283</td>\n",
       "      <td>0.327051</td>\n",
       "      <td>0.324395</td>\n",
       "      <td>0.333130</td>\n",
       "      <td>0.333130</td>\n",
       "      <td>3</td>\n",
       "      <td>damage_by_hitpoints</td>\n",
       "      <td>num_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>0.206269</td>\n",
       "      <td>0.198167</td>\n",
       "      <td>0.113623</td>\n",
       "      <td>0.281693</td>\n",
       "      <td>0.332748</td>\n",
       "      <td>0.332748</td>\n",
       "      <td>3</td>\n",
       "      <td>aoe_by_range</td>\n",
       "      <td>num_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>0.139154</td>\n",
       "      <td>0.216187</td>\n",
       "      <td>0.283763</td>\n",
       "      <td>0.306044</td>\n",
       "      <td>0.338196</td>\n",
       "      <td>0.338196</td>\n",
       "      <td>3</td>\n",
       "      <td>aoe_by_damage</td>\n",
       "      <td>num_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>0.092191</td>\n",
       "      <td>0.228010</td>\n",
       "      <td>0.305891</td>\n",
       "      <td>0.305891</td>\n",
       "      <td>0.335433</td>\n",
       "      <td>0.335433</td>\n",
       "      <td>3</td>\n",
       "      <td>aoe_per_elixir</td>\n",
       "      <td>num_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>-0.056923</td>\n",
       "      <td>0.154574</td>\n",
       "      <td>0.327051</td>\n",
       "      <td>0.324395</td>\n",
       "      <td>0.330773</td>\n",
       "      <td>0.349290</td>\n",
       "      <td>3</td>\n",
       "      <td>damage_output_ps</td>\n",
       "      <td>num_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>0.089186</td>\n",
       "      <td>0.148321</td>\n",
       "      <td>0.231421</td>\n",
       "      <td>0.237181</td>\n",
       "      <td>0.207324</td>\n",
       "      <td>0.357945</td>\n",
       "      <td>3</td>\n",
       "      <td>playable</td>\n",
       "      <td>bool_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>0.009642</td>\n",
       "      <td>0.150938</td>\n",
       "      <td>0.222474</td>\n",
       "      <td>0.268830</td>\n",
       "      <td>0.316538</td>\n",
       "      <td>0.368283</td>\n",
       "      <td>3</td>\n",
       "      <td>aoe_bool</td>\n",
       "      <td>bool_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>0.039663</td>\n",
       "      <td>0.147361</td>\n",
       "      <td>0.231421</td>\n",
       "      <td>0.237181</td>\n",
       "      <td>0.324458</td>\n",
       "      <td>0.373788</td>\n",
       "      <td>3</td>\n",
       "      <td>death_damage_bool</td>\n",
       "      <td>bool_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>0.131588</td>\n",
       "      <td>0.151370</td>\n",
       "      <td>0.231421</td>\n",
       "      <td>0.237181</td>\n",
       "      <td>0.215560</td>\n",
       "      <td>0.343190</td>\n",
       "      <td>3</td>\n",
       "      <td>fly_bool</td>\n",
       "      <td>bool_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>0.055999</td>\n",
       "      <td>0.147180</td>\n",
       "      <td>0.225701</td>\n",
       "      <td>0.239496</td>\n",
       "      <td>0.293055</td>\n",
       "      <td>0.340832</td>\n",
       "      <td>3</td>\n",
       "      <td>spawn_bool</td>\n",
       "      <td>bool_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>0.052304</td>\n",
       "      <td>0.146006</td>\n",
       "      <td>0.235859</td>\n",
       "      <td>0.236583</td>\n",
       "      <td>0.351844</td>\n",
       "      <td>0.351844</td>\n",
       "      <td>3</td>\n",
       "      <td>special_damage</td>\n",
       "      <td>bool_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>0.093663</td>\n",
       "      <td>0.151501</td>\n",
       "      <td>0.231421</td>\n",
       "      <td>0.237181</td>\n",
       "      <td>0.215560</td>\n",
       "      <td>0.343190</td>\n",
       "      <td>3</td>\n",
       "      <td>shield_bool</td>\n",
       "      <td>bool_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>0.093507</td>\n",
       "      <td>0.147340</td>\n",
       "      <td>0.163961</td>\n",
       "      <td>0.216218</td>\n",
       "      <td>0.233304</td>\n",
       "      <td>0.358097</td>\n",
       "      <td>3</td>\n",
       "      <td>affected_crown</td>\n",
       "      <td>bool_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>0.117973</td>\n",
       "      <td>0.148556</td>\n",
       "      <td>0.231421</td>\n",
       "      <td>0.237181</td>\n",
       "      <td>0.215560</td>\n",
       "      <td>0.343190</td>\n",
       "      <td>3</td>\n",
       "      <td>has_lifetime</td>\n",
       "      <td>bool_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>0.105447</td>\n",
       "      <td>0.151595</td>\n",
       "      <td>0.231421</td>\n",
       "      <td>0.237181</td>\n",
       "      <td>0.215560</td>\n",
       "      <td>0.343190</td>\n",
       "      <td>3</td>\n",
       "      <td>invisible</td>\n",
       "      <td>bool_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>0.142502</td>\n",
       "      <td>0.143827</td>\n",
       "      <td>0.231421</td>\n",
       "      <td>0.237181</td>\n",
       "      <td>0.215560</td>\n",
       "      <td>0.343190</td>\n",
       "      <td>3</td>\n",
       "      <td>has_ability</td>\n",
       "      <td>bool_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>0.105994</td>\n",
       "      <td>0.123592</td>\n",
       "      <td>0.231421</td>\n",
       "      <td>0.237181</td>\n",
       "      <td>0.223689</td>\n",
       "      <td>0.332534</td>\n",
       "      <td>3</td>\n",
       "      <td>any_target</td>\n",
       "      <td>bool_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>0.105994</td>\n",
       "      <td>0.123592</td>\n",
       "      <td>0.231421</td>\n",
       "      <td>0.237181</td>\n",
       "      <td>0.198989</td>\n",
       "      <td>0.321303</td>\n",
       "      <td>3</td>\n",
       "      <td>building_target</td>\n",
       "      <td>bool_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>0.074643</td>\n",
       "      <td>0.119710</td>\n",
       "      <td>0.231421</td>\n",
       "      <td>0.237181</td>\n",
       "      <td>0.198989</td>\n",
       "      <td>0.321303</td>\n",
       "      <td>3</td>\n",
       "      <td>ground_target</td>\n",
       "      <td>bool_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>0.096122</td>\n",
       "      <td>0.147997</td>\n",
       "      <td>0.236807</td>\n",
       "      <td>0.242293</td>\n",
       "      <td>0.215560</td>\n",
       "      <td>0.343190</td>\n",
       "      <td>3</td>\n",
       "      <td>has_upon_breaking_spawn</td>\n",
       "      <td>bool_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>0.043753</td>\n",
       "      <td>0.145640</td>\n",
       "      <td>0.231421</td>\n",
       "      <td>0.237181</td>\n",
       "      <td>0.293055</td>\n",
       "      <td>0.340832</td>\n",
       "      <td>3</td>\n",
       "      <td>has_upon_death_spawn</td>\n",
       "      <td>bool_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>0.142383</td>\n",
       "      <td>0.145692</td>\n",
       "      <td>0.208376</td>\n",
       "      <td>0.259145</td>\n",
       "      <td>0.323670</td>\n",
       "      <td>0.364340</td>\n",
       "      <td>3</td>\n",
       "      <td>has_periodic_spawn</td>\n",
       "      <td>bool_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>0.085859</td>\n",
       "      <td>0.145952</td>\n",
       "      <td>0.236734</td>\n",
       "      <td>0.228887</td>\n",
       "      <td>0.301942</td>\n",
       "      <td>0.336246</td>\n",
       "      <td>3</td>\n",
       "      <td>single_damage_type</td>\n",
       "      <td>bool_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>0.051620</td>\n",
       "      <td>0.142240</td>\n",
       "      <td>0.231421</td>\n",
       "      <td>0.237181</td>\n",
       "      <td>0.215560</td>\n",
       "      <td>0.343190</td>\n",
       "      <td>3</td>\n",
       "      <td>is_troop</td>\n",
       "      <td>bool_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>0.051620</td>\n",
       "      <td>0.142240</td>\n",
       "      <td>0.231421</td>\n",
       "      <td>0.237181</td>\n",
       "      <td>0.215560</td>\n",
       "      <td>0.343190</td>\n",
       "      <td>3</td>\n",
       "      <td>is_spell</td>\n",
       "      <td>bool_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>0.051620</td>\n",
       "      <td>0.142240</td>\n",
       "      <td>0.231421</td>\n",
       "      <td>0.237181</td>\n",
       "      <td>0.215560</td>\n",
       "      <td>0.343190</td>\n",
       "      <td>3</td>\n",
       "      <td>is_building</td>\n",
       "      <td>bool_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>0.051620</td>\n",
       "      <td>0.142240</td>\n",
       "      <td>0.231421</td>\n",
       "      <td>0.237181</td>\n",
       "      <td>0.215560</td>\n",
       "      <td>0.343190</td>\n",
       "      <td>3</td>\n",
       "      <td>is_tower_troop</td>\n",
       "      <td>bool_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>0.138014</td>\n",
       "      <td>0.150707</td>\n",
       "      <td>0.271257</td>\n",
       "      <td>0.251576</td>\n",
       "      <td>0.215560</td>\n",
       "      <td>0.343190</td>\n",
       "      <td>3</td>\n",
       "      <td>is_spawned</td>\n",
       "      <td>bool_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>0.129117</td>\n",
       "      <td>0.124428</td>\n",
       "      <td>0.231421</td>\n",
       "      <td>0.237181</td>\n",
       "      <td>0.339382</td>\n",
       "      <td>0.355726</td>\n",
       "      <td>3</td>\n",
       "      <td>has_ranged_attack</td>\n",
       "      <td>bool_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>0.141578</td>\n",
       "      <td>0.146018</td>\n",
       "      <td>0.212282</td>\n",
       "      <td>0.353632</td>\n",
       "      <td>0.329766</td>\n",
       "      <td>0.329766</td>\n",
       "      <td>3</td>\n",
       "      <td>special_attack_type</td>\n",
       "      <td>bool_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>0.079309</td>\n",
       "      <td>0.146570</td>\n",
       "      <td>0.268925</td>\n",
       "      <td>0.272545</td>\n",
       "      <td>0.239382</td>\n",
       "      <td>0.365088</td>\n",
       "      <td>3</td>\n",
       "      <td>has_friendly_buff</td>\n",
       "      <td>bool_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>0.089186</td>\n",
       "      <td>0.148321</td>\n",
       "      <td>0.231421</td>\n",
       "      <td>0.237181</td>\n",
       "      <td>0.207324</td>\n",
       "      <td>0.357945</td>\n",
       "      <td>3</td>\n",
       "      <td>is_free_card</td>\n",
       "      <td>bool_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>0.086111</td>\n",
       "      <td>0.145983</td>\n",
       "      <td>0.231421</td>\n",
       "      <td>0.237181</td>\n",
       "      <td>0.300587</td>\n",
       "      <td>0.330629</td>\n",
       "      <td>3</td>\n",
       "      <td>no_hit_speed</td>\n",
       "      <td>bool_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>0.139602</td>\n",
       "      <td>0.144447</td>\n",
       "      <td>0.250636</td>\n",
       "      <td>0.252505</td>\n",
       "      <td>0.306891</td>\n",
       "      <td>0.339215</td>\n",
       "      <td>3</td>\n",
       "      <td>no_attack</td>\n",
       "      <td>bool_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>0.024484</td>\n",
       "      <td>0.141500</td>\n",
       "      <td>0.231421</td>\n",
       "      <td>0.237181</td>\n",
       "      <td>0.215560</td>\n",
       "      <td>0.343190</td>\n",
       "      <td>3</td>\n",
       "      <td>no_hitpoints</td>\n",
       "      <td>bool_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>0.053710</td>\n",
       "      <td>0.148464</td>\n",
       "      <td>0.231421</td>\n",
       "      <td>0.237181</td>\n",
       "      <td>0.215560</td>\n",
       "      <td>0.343190</td>\n",
       "      <td>3</td>\n",
       "      <td>win_con</td>\n",
       "      <td>bool_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>0.090121</td>\n",
       "      <td>0.145945</td>\n",
       "      <td>0.255832</td>\n",
       "      <td>0.359731</td>\n",
       "      <td>0.351844</td>\n",
       "      <td>0.351844</td>\n",
       "      <td>3</td>\n",
       "      <td>control_special</td>\n",
       "      <td>bool_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>0.143389</td>\n",
       "      <td>0.144126</td>\n",
       "      <td>0.323183</td>\n",
       "      <td>0.349518</td>\n",
       "      <td>0.215560</td>\n",
       "      <td>0.343190</td>\n",
       "      <td>3</td>\n",
       "      <td>dps_special</td>\n",
       "      <td>bool_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.004985</td>\n",
       "      <td>0.141523</td>\n",
       "      <td>0.231421</td>\n",
       "      <td>0.237181</td>\n",
       "      <td>0.318631</td>\n",
       "      <td>0.341741</td>\n",
       "      <td>3</td>\n",
       "      <td>air_control</td>\n",
       "      <td>bool_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>0.030322</td>\n",
       "      <td>0.146976</td>\n",
       "      <td>0.231421</td>\n",
       "      <td>0.237181</td>\n",
       "      <td>0.221978</td>\n",
       "      <td>0.339160</td>\n",
       "      <td>3</td>\n",
       "      <td>ground_dps</td>\n",
       "      <td>bool_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>0.014326</td>\n",
       "      <td>0.142092</td>\n",
       "      <td>0.231421</td>\n",
       "      <td>0.237181</td>\n",
       "      <td>0.215560</td>\n",
       "      <td>0.343190</td>\n",
       "      <td>3</td>\n",
       "      <td>win_con_dmg</td>\n",
       "      <td>bool_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>0.017089</td>\n",
       "      <td>0.129288</td>\n",
       "      <td>0.257964</td>\n",
       "      <td>0.248914</td>\n",
       "      <td>0.316612</td>\n",
       "      <td>0.349014</td>\n",
       "      <td>3</td>\n",
       "      <td>high_dps</td>\n",
       "      <td>bool_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>0.078811</td>\n",
       "      <td>0.147355</td>\n",
       "      <td>0.213708</td>\n",
       "      <td>0.247953</td>\n",
       "      <td>0.306891</td>\n",
       "      <td>0.339215</td>\n",
       "      <td>3</td>\n",
       "      <td>support</td>\n",
       "      <td>bool_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>0.014090</td>\n",
       "      <td>0.148495</td>\n",
       "      <td>0.231421</td>\n",
       "      <td>0.237181</td>\n",
       "      <td>0.215560</td>\n",
       "      <td>0.343190</td>\n",
       "      <td>3</td>\n",
       "      <td>mini_tank</td>\n",
       "      <td>bool_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>0.025305</td>\n",
       "      <td>0.105113</td>\n",
       "      <td>0.167340</td>\n",
       "      <td>0.187771</td>\n",
       "      <td>0.322785</td>\n",
       "      <td>0.322785</td>\n",
       "      <td>4</td>\n",
       "      <td>playable</td>\n",
       "      <td>all_col</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>0.068766</td>\n",
       "      <td>0.102301</td>\n",
       "      <td>0.174796</td>\n",
       "      <td>0.196902</td>\n",
       "      <td>0.240473</td>\n",
       "      <td>0.312437</td>\n",
       "      <td>4</td>\n",
       "      <td>aoe_bool</td>\n",
       "      <td>all_col</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>0.101505</td>\n",
       "      <td>0.116128</td>\n",
       "      <td>0.172437</td>\n",
       "      <td>0.192254</td>\n",
       "      <td>0.241738</td>\n",
       "      <td>0.313663</td>\n",
       "      <td>4</td>\n",
       "      <td>aoe_radius</td>\n",
       "      <td>all_col</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>0.060282</td>\n",
       "      <td>0.115552</td>\n",
       "      <td>0.167340</td>\n",
       "      <td>0.187771</td>\n",
       "      <td>0.261361</td>\n",
       "      <td>0.333329</td>\n",
       "      <td>4</td>\n",
       "      <td>death_damage_bool</td>\n",
       "      <td>all_col</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>0.071996</td>\n",
       "      <td>0.114895</td>\n",
       "      <td>0.167340</td>\n",
       "      <td>0.187771</td>\n",
       "      <td>0.315098</td>\n",
       "      <td>0.315098</td>\n",
       "      <td>4</td>\n",
       "      <td>fly_bool</td>\n",
       "      <td>all_col</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>0.029864</td>\n",
       "      <td>0.109039</td>\n",
       "      <td>0.173309</td>\n",
       "      <td>0.193242</td>\n",
       "      <td>0.313806</td>\n",
       "      <td>0.313806</td>\n",
       "      <td>4</td>\n",
       "      <td>spawn_bool</td>\n",
       "      <td>all_col</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>0.065661</td>\n",
       "      <td>0.103199</td>\n",
       "      <td>0.111708</td>\n",
       "      <td>0.195961</td>\n",
       "      <td>0.326902</td>\n",
       "      <td>0.326902</td>\n",
       "      <td>4</td>\n",
       "      <td>can_evolve</td>\n",
       "      <td>all_col</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>0.066081</td>\n",
       "      <td>0.106922</td>\n",
       "      <td>0.152586</td>\n",
       "      <td>0.188113</td>\n",
       "      <td>0.317410</td>\n",
       "      <td>0.317410</td>\n",
       "      <td>4</td>\n",
       "      <td>elixircost</td>\n",
       "      <td>all_col</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>0.067165</td>\n",
       "      <td>0.114963</td>\n",
       "      <td>0.167340</td>\n",
       "      <td>0.187771</td>\n",
       "      <td>0.320137</td>\n",
       "      <td>0.320137</td>\n",
       "      <td>4</td>\n",
       "      <td>hit_speed</td>\n",
       "      <td>all_col</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>0.054197</td>\n",
       "      <td>0.114287</td>\n",
       "      <td>0.170983</td>\n",
       "      <td>0.192191</td>\n",
       "      <td>0.320609</td>\n",
       "      <td>0.320609</td>\n",
       "      <td>4</td>\n",
       "      <td>special_damage</td>\n",
       "      <td>all_col</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>-0.011696</td>\n",
       "      <td>0.108344</td>\n",
       "      <td>0.167340</td>\n",
       "      <td>0.187771</td>\n",
       "      <td>0.315098</td>\n",
       "      <td>0.315098</td>\n",
       "      <td>4</td>\n",
       "      <td>count</td>\n",
       "      <td>all_col</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>-0.044996</td>\n",
       "      <td>0.105358</td>\n",
       "      <td>0.167340</td>\n",
       "      <td>0.187771</td>\n",
       "      <td>0.308410</td>\n",
       "      <td>0.308410</td>\n",
       "      <td>4</td>\n",
       "      <td>hitpoints</td>\n",
       "      <td>all_col</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>0.060704</td>\n",
       "      <td>0.103121</td>\n",
       "      <td>0.167340</td>\n",
       "      <td>0.187771</td>\n",
       "      <td>0.315098</td>\n",
       "      <td>0.315098</td>\n",
       "      <td>4</td>\n",
       "      <td>shield_bool</td>\n",
       "      <td>all_col</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>0.065068</td>\n",
       "      <td>0.120808</td>\n",
       "      <td>0.131615</td>\n",
       "      <td>0.180097</td>\n",
       "      <td>0.309460</td>\n",
       "      <td>0.309460</td>\n",
       "      <td>4</td>\n",
       "      <td>damage</td>\n",
       "      <td>all_col</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>0.045061</td>\n",
       "      <td>0.111658</td>\n",
       "      <td>0.176191</td>\n",
       "      <td>0.203888</td>\n",
       "      <td>0.313029</td>\n",
       "      <td>0.313029</td>\n",
       "      <td>4</td>\n",
       "      <td>attack_count</td>\n",
       "      <td>all_col</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>0.051589</td>\n",
       "      <td>0.090699</td>\n",
       "      <td>0.167340</td>\n",
       "      <td>0.187771</td>\n",
       "      <td>0.320323</td>\n",
       "      <td>0.300492</td>\n",
       "      <td>4</td>\n",
       "      <td>range</td>\n",
       "      <td>all_col</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>0.033817</td>\n",
       "      <td>0.108160</td>\n",
       "      <td>0.165914</td>\n",
       "      <td>0.184836</td>\n",
       "      <td>0.323552</td>\n",
       "      <td>0.323552</td>\n",
       "      <td>4</td>\n",
       "      <td>affected_crown</td>\n",
       "      <td>all_col</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>0.049172</td>\n",
       "      <td>0.120342</td>\n",
       "      <td>0.167340</td>\n",
       "      <td>0.187771</td>\n",
       "      <td>0.315098</td>\n",
       "      <td>0.315098</td>\n",
       "      <td>4</td>\n",
       "      <td>has_lifetime</td>\n",
       "      <td>all_col</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>0.015051</td>\n",
       "      <td>0.103261</td>\n",
       "      <td>0.167340</td>\n",
       "      <td>0.187771</td>\n",
       "      <td>0.315098</td>\n",
       "      <td>0.315098</td>\n",
       "      <td>4</td>\n",
       "      <td>invisible</td>\n",
       "      <td>all_col</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>0.065440</td>\n",
       "      <td>0.107360</td>\n",
       "      <td>0.167340</td>\n",
       "      <td>0.187771</td>\n",
       "      <td>0.315098</td>\n",
       "      <td>0.315098</td>\n",
       "      <td>4</td>\n",
       "      <td>has_ability</td>\n",
       "      <td>all_col</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>0.061713</td>\n",
       "      <td>0.101304</td>\n",
       "      <td>0.167340</td>\n",
       "      <td>0.187771</td>\n",
       "      <td>0.328255</td>\n",
       "      <td>0.328255</td>\n",
       "      <td>4</td>\n",
       "      <td>any_target</td>\n",
       "      <td>all_col</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>0.061713</td>\n",
       "      <td>0.101304</td>\n",
       "      <td>0.167340</td>\n",
       "      <td>0.187771</td>\n",
       "      <td>0.317822</td>\n",
       "      <td>0.317822</td>\n",
       "      <td>4</td>\n",
       "      <td>building_target</td>\n",
       "      <td>all_col</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>0.052784</td>\n",
       "      <td>0.102419</td>\n",
       "      <td>0.167340</td>\n",
       "      <td>0.187771</td>\n",
       "      <td>0.317822</td>\n",
       "      <td>0.317822</td>\n",
       "      <td>4</td>\n",
       "      <td>ground_target</td>\n",
       "      <td>all_col</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>0.003122</td>\n",
       "      <td>0.109487</td>\n",
       "      <td>0.173640</td>\n",
       "      <td>0.197310</td>\n",
       "      <td>0.315098</td>\n",
       "      <td>0.315098</td>\n",
       "      <td>4</td>\n",
       "      <td>has_upon_breaking_spawn</td>\n",
       "      <td>all_col</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>0.035009</td>\n",
       "      <td>0.112390</td>\n",
       "      <td>0.167340</td>\n",
       "      <td>0.187771</td>\n",
       "      <td>0.313806</td>\n",
       "      <td>0.313806</td>\n",
       "      <td>4</td>\n",
       "      <td>has_upon_death_spawn</td>\n",
       "      <td>all_col</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>0.049186</td>\n",
       "      <td>0.103873</td>\n",
       "      <td>0.178692</td>\n",
       "      <td>0.201964</td>\n",
       "      <td>0.322023</td>\n",
       "      <td>0.322023</td>\n",
       "      <td>4</td>\n",
       "      <td>has_periodic_spawn</td>\n",
       "      <td>all_col</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>0.098872</td>\n",
       "      <td>0.121346</td>\n",
       "      <td>0.164284</td>\n",
       "      <td>0.196165</td>\n",
       "      <td>0.313736</td>\n",
       "      <td>0.313736</td>\n",
       "      <td>4</td>\n",
       "      <td>single_damage_type</td>\n",
       "      <td>all_col</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>0.037930</td>\n",
       "      <td>0.112239</td>\n",
       "      <td>0.167340</td>\n",
       "      <td>0.187771</td>\n",
       "      <td>0.315098</td>\n",
       "      <td>0.315098</td>\n",
       "      <td>4</td>\n",
       "      <td>is_troop</td>\n",
       "      <td>all_col</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202</th>\n",
       "      <td>0.037930</td>\n",
       "      <td>0.112239</td>\n",
       "      <td>0.167340</td>\n",
       "      <td>0.187771</td>\n",
       "      <td>0.315098</td>\n",
       "      <td>0.315098</td>\n",
       "      <td>4</td>\n",
       "      <td>is_spell</td>\n",
       "      <td>all_col</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>0.037930</td>\n",
       "      <td>0.112239</td>\n",
       "      <td>0.167340</td>\n",
       "      <td>0.187771</td>\n",
       "      <td>0.315098</td>\n",
       "      <td>0.315098</td>\n",
       "      <td>4</td>\n",
       "      <td>is_building</td>\n",
       "      <td>all_col</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>0.037930</td>\n",
       "      <td>0.112239</td>\n",
       "      <td>0.167340</td>\n",
       "      <td>0.187771</td>\n",
       "      <td>0.315098</td>\n",
       "      <td>0.315098</td>\n",
       "      <td>4</td>\n",
       "      <td>is_tower_troop</td>\n",
       "      <td>all_col</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205</th>\n",
       "      <td>0.046788</td>\n",
       "      <td>0.098383</td>\n",
       "      <td>0.174633</td>\n",
       "      <td>0.192666</td>\n",
       "      <td>0.315098</td>\n",
       "      <td>0.315098</td>\n",
       "      <td>4</td>\n",
       "      <td>is_spawned</td>\n",
       "      <td>all_col</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206</th>\n",
       "      <td>0.072609</td>\n",
       "      <td>0.112538</td>\n",
       "      <td>0.167340</td>\n",
       "      <td>0.187771</td>\n",
       "      <td>0.315098</td>\n",
       "      <td>0.315098</td>\n",
       "      <td>4</td>\n",
       "      <td>speed</td>\n",
       "      <td>all_col</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207</th>\n",
       "      <td>0.058008</td>\n",
       "      <td>0.095173</td>\n",
       "      <td>0.167340</td>\n",
       "      <td>0.187771</td>\n",
       "      <td>0.316694</td>\n",
       "      <td>0.316694</td>\n",
       "      <td>4</td>\n",
       "      <td>has_ranged_attack</td>\n",
       "      <td>all_col</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208</th>\n",
       "      <td>0.075267</td>\n",
       "      <td>0.114673</td>\n",
       "      <td>0.177837</td>\n",
       "      <td>0.204385</td>\n",
       "      <td>0.324159</td>\n",
       "      <td>0.324159</td>\n",
       "      <td>4</td>\n",
       "      <td>special_attack_type</td>\n",
       "      <td>all_col</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209</th>\n",
       "      <td>0.055220</td>\n",
       "      <td>0.102478</td>\n",
       "      <td>0.151683</td>\n",
       "      <td>0.177860</td>\n",
       "      <td>0.340280</td>\n",
       "      <td>0.340280</td>\n",
       "      <td>4</td>\n",
       "      <td>has_friendly_buff</td>\n",
       "      <td>all_col</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210</th>\n",
       "      <td>0.025305</td>\n",
       "      <td>0.105113</td>\n",
       "      <td>0.167340</td>\n",
       "      <td>0.187771</td>\n",
       "      <td>0.322785</td>\n",
       "      <td>0.322785</td>\n",
       "      <td>4</td>\n",
       "      <td>is_free_card</td>\n",
       "      <td>all_col</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211</th>\n",
       "      <td>0.058436</td>\n",
       "      <td>0.120337</td>\n",
       "      <td>0.167340</td>\n",
       "      <td>0.187771</td>\n",
       "      <td>0.319289</td>\n",
       "      <td>0.306570</td>\n",
       "      <td>4</td>\n",
       "      <td>no_hit_speed</td>\n",
       "      <td>all_col</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212</th>\n",
       "      <td>0.065305</td>\n",
       "      <td>0.114254</td>\n",
       "      <td>0.103331</td>\n",
       "      <td>0.173477</td>\n",
       "      <td>0.313029</td>\n",
       "      <td>0.313029</td>\n",
       "      <td>4</td>\n",
       "      <td>no_attack</td>\n",
       "      <td>all_col</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213</th>\n",
       "      <td>0.102407</td>\n",
       "      <td>0.115794</td>\n",
       "      <td>0.167340</td>\n",
       "      <td>0.187771</td>\n",
       "      <td>0.315098</td>\n",
       "      <td>0.315098</td>\n",
       "      <td>4</td>\n",
       "      <td>no_hitpoints</td>\n",
       "      <td>all_col</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214</th>\n",
       "      <td>0.016180</td>\n",
       "      <td>0.120794</td>\n",
       "      <td>0.162212</td>\n",
       "      <td>0.178221</td>\n",
       "      <td>0.308981</td>\n",
       "      <td>0.308981</td>\n",
       "      <td>4</td>\n",
       "      <td>damage_per_elixir</td>\n",
       "      <td>all_col</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>215</th>\n",
       "      <td>0.028916</td>\n",
       "      <td>0.109052</td>\n",
       "      <td>0.167340</td>\n",
       "      <td>0.187771</td>\n",
       "      <td>0.307174</td>\n",
       "      <td>0.307174</td>\n",
       "      <td>4</td>\n",
       "      <td>damage_per_second</td>\n",
       "      <td>all_col</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216</th>\n",
       "      <td>0.045114</td>\n",
       "      <td>0.113832</td>\n",
       "      <td>0.102004</td>\n",
       "      <td>0.186694</td>\n",
       "      <td>0.300619</td>\n",
       "      <td>0.300619</td>\n",
       "      <td>4</td>\n",
       "      <td>damage_output</td>\n",
       "      <td>all_col</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>217</th>\n",
       "      <td>0.091290</td>\n",
       "      <td>0.110946</td>\n",
       "      <td>0.082060</td>\n",
       "      <td>0.184454</td>\n",
       "      <td>0.321639</td>\n",
       "      <td>0.321639</td>\n",
       "      <td>4</td>\n",
       "      <td>hp_per_elixir</td>\n",
       "      <td>all_col</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218</th>\n",
       "      <td>0.047963</td>\n",
       "      <td>0.109110</td>\n",
       "      <td>0.167340</td>\n",
       "      <td>0.187771</td>\n",
       "      <td>0.306333</td>\n",
       "      <td>0.306333</td>\n",
       "      <td>4</td>\n",
       "      <td>damage_by_hitpoints</td>\n",
       "      <td>all_col</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>219</th>\n",
       "      <td>0.076222</td>\n",
       "      <td>0.119197</td>\n",
       "      <td>0.172437</td>\n",
       "      <td>0.192254</td>\n",
       "      <td>0.240747</td>\n",
       "      <td>0.312741</td>\n",
       "      <td>4</td>\n",
       "      <td>aoe_by_range</td>\n",
       "      <td>all_col</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220</th>\n",
       "      <td>0.017085</td>\n",
       "      <td>0.121645</td>\n",
       "      <td>0.089778</td>\n",
       "      <td>0.179454</td>\n",
       "      <td>0.311010</td>\n",
       "      <td>0.311010</td>\n",
       "      <td>4</td>\n",
       "      <td>aoe_by_damage</td>\n",
       "      <td>all_col</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221</th>\n",
       "      <td>-0.115706</td>\n",
       "      <td>0.100621</td>\n",
       "      <td>0.167340</td>\n",
       "      <td>0.187771</td>\n",
       "      <td>0.315098</td>\n",
       "      <td>0.315098</td>\n",
       "      <td>4</td>\n",
       "      <td>win_con</td>\n",
       "      <td>all_col</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222</th>\n",
       "      <td>0.114397</td>\n",
       "      <td>0.116293</td>\n",
       "      <td>0.177829</td>\n",
       "      <td>0.198396</td>\n",
       "      <td>0.241738</td>\n",
       "      <td>0.313663</td>\n",
       "      <td>4</td>\n",
       "      <td>aoe_per_elixir</td>\n",
       "      <td>all_col</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223</th>\n",
       "      <td>0.088713</td>\n",
       "      <td>0.115584</td>\n",
       "      <td>0.121874</td>\n",
       "      <td>0.205920</td>\n",
       "      <td>0.320609</td>\n",
       "      <td>0.320609</td>\n",
       "      <td>4</td>\n",
       "      <td>control_special</td>\n",
       "      <td>all_col</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>224</th>\n",
       "      <td>0.060290</td>\n",
       "      <td>0.109956</td>\n",
       "      <td>0.155376</td>\n",
       "      <td>0.188408</td>\n",
       "      <td>0.315098</td>\n",
       "      <td>0.315098</td>\n",
       "      <td>4</td>\n",
       "      <td>dps_special</td>\n",
       "      <td>all_col</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225</th>\n",
       "      <td>0.036099</td>\n",
       "      <td>0.117303</td>\n",
       "      <td>0.167340</td>\n",
       "      <td>0.187771</td>\n",
       "      <td>0.319964</td>\n",
       "      <td>0.319964</td>\n",
       "      <td>4</td>\n",
       "      <td>air_control</td>\n",
       "      <td>all_col</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>226</th>\n",
       "      <td>0.001215</td>\n",
       "      <td>0.112958</td>\n",
       "      <td>0.167340</td>\n",
       "      <td>0.187771</td>\n",
       "      <td>0.314265</td>\n",
       "      <td>0.314265</td>\n",
       "      <td>4</td>\n",
       "      <td>ground_dps</td>\n",
       "      <td>all_col</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>227</th>\n",
       "      <td>0.111139</td>\n",
       "      <td>0.100302</td>\n",
       "      <td>0.167340</td>\n",
       "      <td>0.187771</td>\n",
       "      <td>0.315098</td>\n",
       "      <td>0.315098</td>\n",
       "      <td>4</td>\n",
       "      <td>win_con_dmg</td>\n",
       "      <td>all_col</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228</th>\n",
       "      <td>0.044975</td>\n",
       "      <td>0.113763</td>\n",
       "      <td>0.156252</td>\n",
       "      <td>0.189114</td>\n",
       "      <td>0.306287</td>\n",
       "      <td>0.306287</td>\n",
       "      <td>4</td>\n",
       "      <td>high_dps</td>\n",
       "      <td>all_col</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>229</th>\n",
       "      <td>0.014627</td>\n",
       "      <td>0.112609</td>\n",
       "      <td>0.167340</td>\n",
       "      <td>0.187771</td>\n",
       "      <td>0.305143</td>\n",
       "      <td>0.305143</td>\n",
       "      <td>4</td>\n",
       "      <td>damage_output_ps</td>\n",
       "      <td>all_col</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230</th>\n",
       "      <td>0.103269</td>\n",
       "      <td>0.100473</td>\n",
       "      <td>0.161060</td>\n",
       "      <td>0.181682</td>\n",
       "      <td>0.313029</td>\n",
       "      <td>0.313029</td>\n",
       "      <td>4</td>\n",
       "      <td>support</td>\n",
       "      <td>all_col</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>231</th>\n",
       "      <td>0.025422</td>\n",
       "      <td>0.114414</td>\n",
       "      <td>0.167340</td>\n",
       "      <td>0.187771</td>\n",
       "      <td>0.315098</td>\n",
       "      <td>0.315098</td>\n",
       "      <td>4</td>\n",
       "      <td>mini_tank</td>\n",
       "      <td>all_col</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232</th>\n",
       "      <td>0.173316</td>\n",
       "      <td>0.276404</td>\n",
       "      <td>0.268685</td>\n",
       "      <td>0.433022</td>\n",
       "      <td>0.666140</td>\n",
       "      <td>0.666140</td>\n",
       "      <td>4</td>\n",
       "      <td>damage_per_elixir</td>\n",
       "      <td>engineered</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233</th>\n",
       "      <td>0.197210</td>\n",
       "      <td>0.241789</td>\n",
       "      <td>-0.014556</td>\n",
       "      <td>0.357341</td>\n",
       "      <td>0.672963</td>\n",
       "      <td>0.672963</td>\n",
       "      <td>4</td>\n",
       "      <td>damage_per_second</td>\n",
       "      <td>engineered</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>234</th>\n",
       "      <td>0.096414</td>\n",
       "      <td>0.267001</td>\n",
       "      <td>0.230581</td>\n",
       "      <td>0.376329</td>\n",
       "      <td>0.430391</td>\n",
       "      <td>0.659696</td>\n",
       "      <td>4</td>\n",
       "      <td>damage_output</td>\n",
       "      <td>engineered</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>0.198854</td>\n",
       "      <td>0.399368</td>\n",
       "      <td>0.170480</td>\n",
       "      <td>0.444480</td>\n",
       "      <td>0.781330</td>\n",
       "      <td>0.781330</td>\n",
       "      <td>4</td>\n",
       "      <td>hp_per_elixir</td>\n",
       "      <td>engineered</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236</th>\n",
       "      <td>0.216522</td>\n",
       "      <td>0.241154</td>\n",
       "      <td>-0.014556</td>\n",
       "      <td>0.357341</td>\n",
       "      <td>0.648258</td>\n",
       "      <td>0.648258</td>\n",
       "      <td>4</td>\n",
       "      <td>damage_by_hitpoints</td>\n",
       "      <td>engineered</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237</th>\n",
       "      <td>-0.089010</td>\n",
       "      <td>0.228265</td>\n",
       "      <td>0.550887</td>\n",
       "      <td>0.550887</td>\n",
       "      <td>0.641430</td>\n",
       "      <td>0.641430</td>\n",
       "      <td>4</td>\n",
       "      <td>aoe_by_range</td>\n",
       "      <td>engineered</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>0.054499</td>\n",
       "      <td>0.266273</td>\n",
       "      <td>0.358222</td>\n",
       "      <td>0.364855</td>\n",
       "      <td>0.657085</td>\n",
       "      <td>0.657085</td>\n",
       "      <td>4</td>\n",
       "      <td>aoe_by_damage</td>\n",
       "      <td>engineered</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239</th>\n",
       "      <td>0.035965</td>\n",
       "      <td>0.108436</td>\n",
       "      <td>0.168093</td>\n",
       "      <td>0.215664</td>\n",
       "      <td>0.277625</td>\n",
       "      <td>0.280980</td>\n",
       "      <td>4</td>\n",
       "      <td>playable</td>\n",
       "      <td>original</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240</th>\n",
       "      <td>0.094424</td>\n",
       "      <td>0.123865</td>\n",
       "      <td>0.192678</td>\n",
       "      <td>0.216594</td>\n",
       "      <td>0.259361</td>\n",
       "      <td>0.259361</td>\n",
       "      <td>4</td>\n",
       "      <td>aoe_bool</td>\n",
       "      <td>original</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>241</th>\n",
       "      <td>0.022701</td>\n",
       "      <td>0.130588</td>\n",
       "      <td>0.171841</td>\n",
       "      <td>0.203068</td>\n",
       "      <td>0.260910</td>\n",
       "      <td>0.260910</td>\n",
       "      <td>4</td>\n",
       "      <td>aoe_radius</td>\n",
       "      <td>original</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242</th>\n",
       "      <td>0.006743</td>\n",
       "      <td>0.126947</td>\n",
       "      <td>0.168093</td>\n",
       "      <td>0.215664</td>\n",
       "      <td>0.296378</td>\n",
       "      <td>0.283599</td>\n",
       "      <td>4</td>\n",
       "      <td>death_damage_bool</td>\n",
       "      <td>original</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>243</th>\n",
       "      <td>0.019414</td>\n",
       "      <td>0.121845</td>\n",
       "      <td>0.168093</td>\n",
       "      <td>0.215664</td>\n",
       "      <td>0.274222</td>\n",
       "      <td>0.274222</td>\n",
       "      <td>4</td>\n",
       "      <td>fly_bool</td>\n",
       "      <td>original</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244</th>\n",
       "      <td>0.014764</td>\n",
       "      <td>0.133687</td>\n",
       "      <td>0.170075</td>\n",
       "      <td>0.195704</td>\n",
       "      <td>0.272700</td>\n",
       "      <td>0.272700</td>\n",
       "      <td>4</td>\n",
       "      <td>spawn_bool</td>\n",
       "      <td>original</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245</th>\n",
       "      <td>0.079961</td>\n",
       "      <td>0.126901</td>\n",
       "      <td>0.174508</td>\n",
       "      <td>0.229665</td>\n",
       "      <td>0.287653</td>\n",
       "      <td>0.287653</td>\n",
       "      <td>4</td>\n",
       "      <td>can_evolve</td>\n",
       "      <td>original</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246</th>\n",
       "      <td>0.028182</td>\n",
       "      <td>0.118766</td>\n",
       "      <td>0.202669</td>\n",
       "      <td>0.226600</td>\n",
       "      <td>0.304143</td>\n",
       "      <td>0.304143</td>\n",
       "      <td>4</td>\n",
       "      <td>elixircost</td>\n",
       "      <td>original</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247</th>\n",
       "      <td>0.078701</td>\n",
       "      <td>0.122619</td>\n",
       "      <td>0.168093</td>\n",
       "      <td>0.215664</td>\n",
       "      <td>0.275436</td>\n",
       "      <td>0.275436</td>\n",
       "      <td>4</td>\n",
       "      <td>hit_speed</td>\n",
       "      <td>original</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>0.050420</td>\n",
       "      <td>0.133237</td>\n",
       "      <td>0.134689</td>\n",
       "      <td>0.213314</td>\n",
       "      <td>0.282350</td>\n",
       "      <td>0.282350</td>\n",
       "      <td>4</td>\n",
       "      <td>special_damage</td>\n",
       "      <td>original</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>0.033442</td>\n",
       "      <td>0.134145</td>\n",
       "      <td>0.168093</td>\n",
       "      <td>0.215664</td>\n",
       "      <td>0.274222</td>\n",
       "      <td>0.274222</td>\n",
       "      <td>4</td>\n",
       "      <td>count</td>\n",
       "      <td>original</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250</th>\n",
       "      <td>-0.021365</td>\n",
       "      <td>0.117157</td>\n",
       "      <td>0.168093</td>\n",
       "      <td>0.215664</td>\n",
       "      <td>0.280963</td>\n",
       "      <td>0.280963</td>\n",
       "      <td>4</td>\n",
       "      <td>hitpoints</td>\n",
       "      <td>original</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251</th>\n",
       "      <td>0.029035</td>\n",
       "      <td>0.121994</td>\n",
       "      <td>0.168093</td>\n",
       "      <td>0.215664</td>\n",
       "      <td>0.274222</td>\n",
       "      <td>0.274222</td>\n",
       "      <td>4</td>\n",
       "      <td>shield_bool</td>\n",
       "      <td>original</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252</th>\n",
       "      <td>0.056314</td>\n",
       "      <td>0.123431</td>\n",
       "      <td>0.174650</td>\n",
       "      <td>0.200196</td>\n",
       "      <td>0.269270</td>\n",
       "      <td>0.269270</td>\n",
       "      <td>4</td>\n",
       "      <td>damage</td>\n",
       "      <td>original</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253</th>\n",
       "      <td>0.008008</td>\n",
       "      <td>0.123461</td>\n",
       "      <td>0.162709</td>\n",
       "      <td>0.230189</td>\n",
       "      <td>0.258442</td>\n",
       "      <td>0.271519</td>\n",
       "      <td>4</td>\n",
       "      <td>attack_count</td>\n",
       "      <td>original</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>254</th>\n",
       "      <td>0.066346</td>\n",
       "      <td>0.113010</td>\n",
       "      <td>0.168093</td>\n",
       "      <td>0.215664</td>\n",
       "      <td>0.267119</td>\n",
       "      <td>0.267119</td>\n",
       "      <td>4</td>\n",
       "      <td>range</td>\n",
       "      <td>original</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>255</th>\n",
       "      <td>0.108790</td>\n",
       "      <td>0.127344</td>\n",
       "      <td>0.130819</td>\n",
       "      <td>0.185219</td>\n",
       "      <td>0.285340</td>\n",
       "      <td>0.285340</td>\n",
       "      <td>4</td>\n",
       "      <td>affected_crown</td>\n",
       "      <td>original</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>256</th>\n",
       "      <td>0.025117</td>\n",
       "      <td>0.122159</td>\n",
       "      <td>0.168093</td>\n",
       "      <td>0.215664</td>\n",
       "      <td>0.274222</td>\n",
       "      <td>0.274222</td>\n",
       "      <td>4</td>\n",
       "      <td>has_lifetime</td>\n",
       "      <td>original</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>257</th>\n",
       "      <td>0.055164</td>\n",
       "      <td>0.136273</td>\n",
       "      <td>0.168093</td>\n",
       "      <td>0.215664</td>\n",
       "      <td>0.274222</td>\n",
       "      <td>0.274222</td>\n",
       "      <td>4</td>\n",
       "      <td>invisible</td>\n",
       "      <td>original</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>258</th>\n",
       "      <td>-0.005146</td>\n",
       "      <td>0.127974</td>\n",
       "      <td>0.168093</td>\n",
       "      <td>0.215664</td>\n",
       "      <td>0.274222</td>\n",
       "      <td>0.274222</td>\n",
       "      <td>4</td>\n",
       "      <td>has_ability</td>\n",
       "      <td>original</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259</th>\n",
       "      <td>0.010207</td>\n",
       "      <td>0.115502</td>\n",
       "      <td>0.168093</td>\n",
       "      <td>0.215664</td>\n",
       "      <td>0.279474</td>\n",
       "      <td>0.279474</td>\n",
       "      <td>4</td>\n",
       "      <td>any_target</td>\n",
       "      <td>original</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260</th>\n",
       "      <td>0.010207</td>\n",
       "      <td>0.115502</td>\n",
       "      <td>0.168093</td>\n",
       "      <td>0.215664</td>\n",
       "      <td>0.277651</td>\n",
       "      <td>0.277651</td>\n",
       "      <td>4</td>\n",
       "      <td>building_target</td>\n",
       "      <td>original</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261</th>\n",
       "      <td>-0.027203</td>\n",
       "      <td>0.120545</td>\n",
       "      <td>0.168093</td>\n",
       "      <td>0.215664</td>\n",
       "      <td>0.277651</td>\n",
       "      <td>0.277651</td>\n",
       "      <td>4</td>\n",
       "      <td>ground_target</td>\n",
       "      <td>original</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>262</th>\n",
       "      <td>0.025150</td>\n",
       "      <td>0.135950</td>\n",
       "      <td>0.136863</td>\n",
       "      <td>0.192888</td>\n",
       "      <td>0.274222</td>\n",
       "      <td>0.274222</td>\n",
       "      <td>4</td>\n",
       "      <td>has_upon_breaking_spawn</td>\n",
       "      <td>original</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>263</th>\n",
       "      <td>0.038323</td>\n",
       "      <td>0.125180</td>\n",
       "      <td>0.168093</td>\n",
       "      <td>0.215664</td>\n",
       "      <td>0.272700</td>\n",
       "      <td>0.272700</td>\n",
       "      <td>4</td>\n",
       "      <td>has_upon_death_spawn</td>\n",
       "      <td>original</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>264</th>\n",
       "      <td>-0.040617</td>\n",
       "      <td>0.127364</td>\n",
       "      <td>0.218476</td>\n",
       "      <td>0.219822</td>\n",
       "      <td>0.282211</td>\n",
       "      <td>0.282211</td>\n",
       "      <td>4</td>\n",
       "      <td>has_periodic_spawn</td>\n",
       "      <td>original</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>265</th>\n",
       "      <td>0.113687</td>\n",
       "      <td>0.126912</td>\n",
       "      <td>0.128217</td>\n",
       "      <td>0.212270</td>\n",
       "      <td>0.271458</td>\n",
       "      <td>0.271458</td>\n",
       "      <td>4</td>\n",
       "      <td>single_damage_type</td>\n",
       "      <td>original</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>266</th>\n",
       "      <td>0.068868</td>\n",
       "      <td>0.124024</td>\n",
       "      <td>0.168093</td>\n",
       "      <td>0.215664</td>\n",
       "      <td>0.274222</td>\n",
       "      <td>0.274222</td>\n",
       "      <td>4</td>\n",
       "      <td>is_troop</td>\n",
       "      <td>original</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>267</th>\n",
       "      <td>0.068868</td>\n",
       "      <td>0.124024</td>\n",
       "      <td>0.168093</td>\n",
       "      <td>0.215664</td>\n",
       "      <td>0.274222</td>\n",
       "      <td>0.274222</td>\n",
       "      <td>4</td>\n",
       "      <td>is_spell</td>\n",
       "      <td>original</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>268</th>\n",
       "      <td>0.068868</td>\n",
       "      <td>0.124024</td>\n",
       "      <td>0.168093</td>\n",
       "      <td>0.215664</td>\n",
       "      <td>0.274222</td>\n",
       "      <td>0.274222</td>\n",
       "      <td>4</td>\n",
       "      <td>is_building</td>\n",
       "      <td>original</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>269</th>\n",
       "      <td>0.068868</td>\n",
       "      <td>0.124024</td>\n",
       "      <td>0.168093</td>\n",
       "      <td>0.215664</td>\n",
       "      <td>0.274222</td>\n",
       "      <td>0.274222</td>\n",
       "      <td>4</td>\n",
       "      <td>is_tower_troop</td>\n",
       "      <td>original</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>270</th>\n",
       "      <td>0.005829</td>\n",
       "      <td>0.114470</td>\n",
       "      <td>0.139412</td>\n",
       "      <td>0.208521</td>\n",
       "      <td>0.274222</td>\n",
       "      <td>0.274222</td>\n",
       "      <td>4</td>\n",
       "      <td>is_spawned</td>\n",
       "      <td>original</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>271</th>\n",
       "      <td>0.018063</td>\n",
       "      <td>0.115775</td>\n",
       "      <td>0.168093</td>\n",
       "      <td>0.215664</td>\n",
       "      <td>0.274222</td>\n",
       "      <td>0.274222</td>\n",
       "      <td>4</td>\n",
       "      <td>speed</td>\n",
       "      <td>original</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>272</th>\n",
       "      <td>0.082995</td>\n",
       "      <td>0.117077</td>\n",
       "      <td>0.168093</td>\n",
       "      <td>0.215664</td>\n",
       "      <td>0.277633</td>\n",
       "      <td>0.277633</td>\n",
       "      <td>4</td>\n",
       "      <td>has_ranged_attack</td>\n",
       "      <td>original</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>273</th>\n",
       "      <td>0.109341</td>\n",
       "      <td>0.125919</td>\n",
       "      <td>0.204120</td>\n",
       "      <td>0.231289</td>\n",
       "      <td>0.283593</td>\n",
       "      <td>0.272889</td>\n",
       "      <td>4</td>\n",
       "      <td>special_attack_type</td>\n",
       "      <td>original</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>274</th>\n",
       "      <td>-0.088864</td>\n",
       "      <td>0.132030</td>\n",
       "      <td>0.215089</td>\n",
       "      <td>0.225382</td>\n",
       "      <td>0.308411</td>\n",
       "      <td>0.292463</td>\n",
       "      <td>4</td>\n",
       "      <td>has_friendly_buff</td>\n",
       "      <td>original</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>275</th>\n",
       "      <td>0.035965</td>\n",
       "      <td>0.108436</td>\n",
       "      <td>0.168093</td>\n",
       "      <td>0.215664</td>\n",
       "      <td>0.277625</td>\n",
       "      <td>0.280980</td>\n",
       "      <td>4</td>\n",
       "      <td>is_free_card</td>\n",
       "      <td>original</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>276</th>\n",
       "      <td>0.092494</td>\n",
       "      <td>0.124172</td>\n",
       "      <td>0.168093</td>\n",
       "      <td>0.215664</td>\n",
       "      <td>0.264552</td>\n",
       "      <td>0.264552</td>\n",
       "      <td>4</td>\n",
       "      <td>no_hit_speed</td>\n",
       "      <td>original</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>277</th>\n",
       "      <td>0.127619</td>\n",
       "      <td>0.125105</td>\n",
       "      <td>0.149738</td>\n",
       "      <td>0.200282</td>\n",
       "      <td>0.258442</td>\n",
       "      <td>0.271519</td>\n",
       "      <td>4</td>\n",
       "      <td>no_attack</td>\n",
       "      <td>original</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278</th>\n",
       "      <td>0.001799</td>\n",
       "      <td>0.129707</td>\n",
       "      <td>0.168093</td>\n",
       "      <td>0.215664</td>\n",
       "      <td>0.274222</td>\n",
       "      <td>0.274222</td>\n",
       "      <td>4</td>\n",
       "      <td>no_hitpoints</td>\n",
       "      <td>original</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279</th>\n",
       "      <td>0.054810</td>\n",
       "      <td>0.116615</td>\n",
       "      <td>0.168093</td>\n",
       "      <td>0.215664</td>\n",
       "      <td>0.274222</td>\n",
       "      <td>0.274222</td>\n",
       "      <td>4</td>\n",
       "      <td>win_con</td>\n",
       "      <td>original</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280</th>\n",
       "      <td>-0.006570</td>\n",
       "      <td>0.125438</td>\n",
       "      <td>0.144441</td>\n",
       "      <td>0.196252</td>\n",
       "      <td>0.260910</td>\n",
       "      <td>0.260910</td>\n",
       "      <td>4</td>\n",
       "      <td>aoe_per_elixir</td>\n",
       "      <td>original</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281</th>\n",
       "      <td>0.056518</td>\n",
       "      <td>0.126903</td>\n",
       "      <td>0.209511</td>\n",
       "      <td>0.229153</td>\n",
       "      <td>0.282350</td>\n",
       "      <td>0.282350</td>\n",
       "      <td>4</td>\n",
       "      <td>control_special</td>\n",
       "      <td>original</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>282</th>\n",
       "      <td>-0.027912</td>\n",
       "      <td>0.136675</td>\n",
       "      <td>0.090882</td>\n",
       "      <td>0.185079</td>\n",
       "      <td>0.274222</td>\n",
       "      <td>0.274222</td>\n",
       "      <td>4</td>\n",
       "      <td>dps_special</td>\n",
       "      <td>original</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>283</th>\n",
       "      <td>0.038437</td>\n",
       "      <td>0.124440</td>\n",
       "      <td>0.168093</td>\n",
       "      <td>0.215664</td>\n",
       "      <td>0.297459</td>\n",
       "      <td>0.276797</td>\n",
       "      <td>4</td>\n",
       "      <td>air_control</td>\n",
       "      <td>original</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284</th>\n",
       "      <td>-0.069643</td>\n",
       "      <td>0.125707</td>\n",
       "      <td>0.168093</td>\n",
       "      <td>0.215664</td>\n",
       "      <td>0.292116</td>\n",
       "      <td>0.275380</td>\n",
       "      <td>4</td>\n",
       "      <td>ground_dps</td>\n",
       "      <td>original</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>285</th>\n",
       "      <td>0.027477</td>\n",
       "      <td>0.128951</td>\n",
       "      <td>0.168093</td>\n",
       "      <td>0.215664</td>\n",
       "      <td>0.274222</td>\n",
       "      <td>0.274222</td>\n",
       "      <td>4</td>\n",
       "      <td>win_con_dmg</td>\n",
       "      <td>original</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>286</th>\n",
       "      <td>-0.023001</td>\n",
       "      <td>0.124543</td>\n",
       "      <td>0.164396</td>\n",
       "      <td>0.171460</td>\n",
       "      <td>0.270010</td>\n",
       "      <td>0.270010</td>\n",
       "      <td>4</td>\n",
       "      <td>high_dps</td>\n",
       "      <td>original</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287</th>\n",
       "      <td>0.029891</td>\n",
       "      <td>0.127705</td>\n",
       "      <td>0.168093</td>\n",
       "      <td>0.215664</td>\n",
       "      <td>0.261614</td>\n",
       "      <td>0.261614</td>\n",
       "      <td>4</td>\n",
       "      <td>damage_output_ps</td>\n",
       "      <td>original</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288</th>\n",
       "      <td>0.068224</td>\n",
       "      <td>0.126527</td>\n",
       "      <td>0.194752</td>\n",
       "      <td>0.214788</td>\n",
       "      <td>0.258442</td>\n",
       "      <td>0.271519</td>\n",
       "      <td>4</td>\n",
       "      <td>support</td>\n",
       "      <td>original</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289</th>\n",
       "      <td>0.057031</td>\n",
       "      <td>0.120254</td>\n",
       "      <td>0.168093</td>\n",
       "      <td>0.215664</td>\n",
       "      <td>0.274222</td>\n",
       "      <td>0.274222</td>\n",
       "      <td>4</td>\n",
       "      <td>mini_tank</td>\n",
       "      <td>original</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>290</th>\n",
       "      <td>0.153248</td>\n",
       "      <td>0.141424</td>\n",
       "      <td>0.299404</td>\n",
       "      <td>0.357598</td>\n",
       "      <td>0.440365</td>\n",
       "      <td>0.440365</td>\n",
       "      <td>4</td>\n",
       "      <td>aoe_radius</td>\n",
       "      <td>num_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>291</th>\n",
       "      <td>0.137762</td>\n",
       "      <td>0.224171</td>\n",
       "      <td>0.036177</td>\n",
       "      <td>0.311827</td>\n",
       "      <td>0.501335</td>\n",
       "      <td>0.501335</td>\n",
       "      <td>4</td>\n",
       "      <td>can_evolve</td>\n",
       "      <td>num_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>292</th>\n",
       "      <td>0.151481</td>\n",
       "      <td>0.242657</td>\n",
       "      <td>0.339720</td>\n",
       "      <td>0.399204</td>\n",
       "      <td>0.483812</td>\n",
       "      <td>0.483812</td>\n",
       "      <td>4</td>\n",
       "      <td>elixircost</td>\n",
       "      <td>num_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>293</th>\n",
       "      <td>0.194079</td>\n",
       "      <td>0.137573</td>\n",
       "      <td>0.287850</td>\n",
       "      <td>0.369134</td>\n",
       "      <td>0.462545</td>\n",
       "      <td>0.462545</td>\n",
       "      <td>4</td>\n",
       "      <td>hit_speed</td>\n",
       "      <td>num_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>294</th>\n",
       "      <td>0.071431</td>\n",
       "      <td>0.153480</td>\n",
       "      <td>0.287850</td>\n",
       "      <td>0.369134</td>\n",
       "      <td>0.445564</td>\n",
       "      <td>0.445564</td>\n",
       "      <td>4</td>\n",
       "      <td>count</td>\n",
       "      <td>num_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>0.047577</td>\n",
       "      <td>0.225302</td>\n",
       "      <td>0.287850</td>\n",
       "      <td>0.369134</td>\n",
       "      <td>0.454658</td>\n",
       "      <td>0.454658</td>\n",
       "      <td>4</td>\n",
       "      <td>hitpoints</td>\n",
       "      <td>num_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>0.195497</td>\n",
       "      <td>0.144523</td>\n",
       "      <td>0.287300</td>\n",
       "      <td>0.367461</td>\n",
       "      <td>0.428302</td>\n",
       "      <td>0.428302</td>\n",
       "      <td>4</td>\n",
       "      <td>damage</td>\n",
       "      <td>num_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>0.184525</td>\n",
       "      <td>0.154531</td>\n",
       "      <td>0.278668</td>\n",
       "      <td>0.422844</td>\n",
       "      <td>0.409217</td>\n",
       "      <td>0.409217</td>\n",
       "      <td>4</td>\n",
       "      <td>attack_count</td>\n",
       "      <td>num_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>0.008270</td>\n",
       "      <td>0.234161</td>\n",
       "      <td>0.287850</td>\n",
       "      <td>0.369134</td>\n",
       "      <td>0.452090</td>\n",
       "      <td>0.452090</td>\n",
       "      <td>4</td>\n",
       "      <td>range</td>\n",
       "      <td>num_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>0.252432</td>\n",
       "      <td>0.151986</td>\n",
       "      <td>0.287850</td>\n",
       "      <td>0.369134</td>\n",
       "      <td>0.445564</td>\n",
       "      <td>0.445564</td>\n",
       "      <td>4</td>\n",
       "      <td>speed</td>\n",
       "      <td>num_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <td>0.069583</td>\n",
       "      <td>0.239322</td>\n",
       "      <td>0.321536</td>\n",
       "      <td>0.383210</td>\n",
       "      <td>0.432426</td>\n",
       "      <td>0.432426</td>\n",
       "      <td>4</td>\n",
       "      <td>damage_per_elixir</td>\n",
       "      <td>num_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301</th>\n",
       "      <td>-0.051760</td>\n",
       "      <td>0.227794</td>\n",
       "      <td>0.287850</td>\n",
       "      <td>0.369134</td>\n",
       "      <td>0.431260</td>\n",
       "      <td>0.431260</td>\n",
       "      <td>4</td>\n",
       "      <td>damage_per_second</td>\n",
       "      <td>num_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>302</th>\n",
       "      <td>0.122149</td>\n",
       "      <td>0.129964</td>\n",
       "      <td>0.132781</td>\n",
       "      <td>0.378132</td>\n",
       "      <td>0.392889</td>\n",
       "      <td>0.392889</td>\n",
       "      <td>4</td>\n",
       "      <td>damage_output</td>\n",
       "      <td>num_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>303</th>\n",
       "      <td>0.182395</td>\n",
       "      <td>0.224839</td>\n",
       "      <td>0.401957</td>\n",
       "      <td>0.401458</td>\n",
       "      <td>0.454709</td>\n",
       "      <td>0.454709</td>\n",
       "      <td>4</td>\n",
       "      <td>hp_per_elixir</td>\n",
       "      <td>num_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>304</th>\n",
       "      <td>0.176885</td>\n",
       "      <td>0.220143</td>\n",
       "      <td>0.287850</td>\n",
       "      <td>0.369134</td>\n",
       "      <td>0.425694</td>\n",
       "      <td>0.425694</td>\n",
       "      <td>4</td>\n",
       "      <td>damage_by_hitpoints</td>\n",
       "      <td>num_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>305</th>\n",
       "      <td>0.181013</td>\n",
       "      <td>0.135590</td>\n",
       "      <td>0.299404</td>\n",
       "      <td>0.357598</td>\n",
       "      <td>0.437608</td>\n",
       "      <td>0.437608</td>\n",
       "      <td>4</td>\n",
       "      <td>aoe_by_range</td>\n",
       "      <td>num_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>306</th>\n",
       "      <td>0.119049</td>\n",
       "      <td>0.135174</td>\n",
       "      <td>0.311106</td>\n",
       "      <td>0.368675</td>\n",
       "      <td>0.443157</td>\n",
       "      <td>0.443157</td>\n",
       "      <td>4</td>\n",
       "      <td>aoe_by_damage</td>\n",
       "      <td>num_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307</th>\n",
       "      <td>0.112535</td>\n",
       "      <td>0.132789</td>\n",
       "      <td>0.261834</td>\n",
       "      <td>0.374880</td>\n",
       "      <td>0.440365</td>\n",
       "      <td>0.440365</td>\n",
       "      <td>4</td>\n",
       "      <td>aoe_per_elixir</td>\n",
       "      <td>num_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>308</th>\n",
       "      <td>-0.022086</td>\n",
       "      <td>0.165853</td>\n",
       "      <td>0.287850</td>\n",
       "      <td>0.369134</td>\n",
       "      <td>0.445874</td>\n",
       "      <td>0.445874</td>\n",
       "      <td>4</td>\n",
       "      <td>damage_output_ps</td>\n",
       "      <td>num_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>309</th>\n",
       "      <td>0.017218</td>\n",
       "      <td>0.150718</td>\n",
       "      <td>0.173861</td>\n",
       "      <td>0.319230</td>\n",
       "      <td>0.233098</td>\n",
       "      <td>0.325465</td>\n",
       "      <td>4</td>\n",
       "      <td>playable</td>\n",
       "      <td>bool_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>310</th>\n",
       "      <td>0.058598</td>\n",
       "      <td>0.150575</td>\n",
       "      <td>0.313749</td>\n",
       "      <td>0.344809</td>\n",
       "      <td>0.363711</td>\n",
       "      <td>0.354658</td>\n",
       "      <td>4</td>\n",
       "      <td>aoe_bool</td>\n",
       "      <td>bool_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>311</th>\n",
       "      <td>0.030212</td>\n",
       "      <td>0.166836</td>\n",
       "      <td>0.173861</td>\n",
       "      <td>0.319230</td>\n",
       "      <td>0.359645</td>\n",
       "      <td>0.359645</td>\n",
       "      <td>4</td>\n",
       "      <td>death_damage_bool</td>\n",
       "      <td>bool_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>312</th>\n",
       "      <td>0.050230</td>\n",
       "      <td>0.166437</td>\n",
       "      <td>0.173861</td>\n",
       "      <td>0.319230</td>\n",
       "      <td>0.306930</td>\n",
       "      <td>0.306930</td>\n",
       "      <td>4</td>\n",
       "      <td>fly_bool</td>\n",
       "      <td>bool_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>313</th>\n",
       "      <td>0.026038</td>\n",
       "      <td>0.170098</td>\n",
       "      <td>0.338399</td>\n",
       "      <td>0.336732</td>\n",
       "      <td>0.226190</td>\n",
       "      <td>0.306836</td>\n",
       "      <td>4</td>\n",
       "      <td>spawn_bool</td>\n",
       "      <td>bool_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>314</th>\n",
       "      <td>0.032884</td>\n",
       "      <td>0.165966</td>\n",
       "      <td>0.337680</td>\n",
       "      <td>0.338193</td>\n",
       "      <td>0.234903</td>\n",
       "      <td>0.318345</td>\n",
       "      <td>4</td>\n",
       "      <td>special_damage</td>\n",
       "      <td>bool_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>315</th>\n",
       "      <td>0.049923</td>\n",
       "      <td>0.164731</td>\n",
       "      <td>0.173861</td>\n",
       "      <td>0.319230</td>\n",
       "      <td>0.306930</td>\n",
       "      <td>0.306930</td>\n",
       "      <td>4</td>\n",
       "      <td>shield_bool</td>\n",
       "      <td>bool_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>316</th>\n",
       "      <td>0.065061</td>\n",
       "      <td>0.164108</td>\n",
       "      <td>0.269515</td>\n",
       "      <td>0.310786</td>\n",
       "      <td>0.242113</td>\n",
       "      <td>0.322178</td>\n",
       "      <td>4</td>\n",
       "      <td>affected_crown</td>\n",
       "      <td>bool_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>317</th>\n",
       "      <td>0.085905</td>\n",
       "      <td>0.152272</td>\n",
       "      <td>0.173861</td>\n",
       "      <td>0.319230</td>\n",
       "      <td>0.306930</td>\n",
       "      <td>0.306930</td>\n",
       "      <td>4</td>\n",
       "      <td>has_lifetime</td>\n",
       "      <td>bool_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>318</th>\n",
       "      <td>0.074770</td>\n",
       "      <td>0.138711</td>\n",
       "      <td>0.173861</td>\n",
       "      <td>0.319230</td>\n",
       "      <td>0.306930</td>\n",
       "      <td>0.306930</td>\n",
       "      <td>4</td>\n",
       "      <td>invisible</td>\n",
       "      <td>bool_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>319</th>\n",
       "      <td>0.067504</td>\n",
       "      <td>0.164538</td>\n",
       "      <td>0.173861</td>\n",
       "      <td>0.319230</td>\n",
       "      <td>0.306930</td>\n",
       "      <td>0.306930</td>\n",
       "      <td>4</td>\n",
       "      <td>has_ability</td>\n",
       "      <td>bool_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>320</th>\n",
       "      <td>0.029772</td>\n",
       "      <td>0.137492</td>\n",
       "      <td>0.173861</td>\n",
       "      <td>0.319230</td>\n",
       "      <td>0.224739</td>\n",
       "      <td>0.282312</td>\n",
       "      <td>4</td>\n",
       "      <td>any_target</td>\n",
       "      <td>bool_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>321</th>\n",
       "      <td>0.029772</td>\n",
       "      <td>0.137492</td>\n",
       "      <td>0.173861</td>\n",
       "      <td>0.319230</td>\n",
       "      <td>0.223959</td>\n",
       "      <td>0.276676</td>\n",
       "      <td>4</td>\n",
       "      <td>building_target</td>\n",
       "      <td>bool_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>322</th>\n",
       "      <td>0.058994</td>\n",
       "      <td>0.140374</td>\n",
       "      <td>0.173861</td>\n",
       "      <td>0.319230</td>\n",
       "      <td>0.223959</td>\n",
       "      <td>0.276676</td>\n",
       "      <td>4</td>\n",
       "      <td>ground_target</td>\n",
       "      <td>bool_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>323</th>\n",
       "      <td>0.132042</td>\n",
       "      <td>0.165609</td>\n",
       "      <td>0.206570</td>\n",
       "      <td>0.271159</td>\n",
       "      <td>0.306930</td>\n",
       "      <td>0.306930</td>\n",
       "      <td>4</td>\n",
       "      <td>has_upon_breaking_spawn</td>\n",
       "      <td>bool_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>324</th>\n",
       "      <td>0.002351</td>\n",
       "      <td>0.167935</td>\n",
       "      <td>0.173861</td>\n",
       "      <td>0.319230</td>\n",
       "      <td>0.226190</td>\n",
       "      <td>0.306836</td>\n",
       "      <td>4</td>\n",
       "      <td>has_upon_death_spawn</td>\n",
       "      <td>bool_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>325</th>\n",
       "      <td>0.106046</td>\n",
       "      <td>0.165364</td>\n",
       "      <td>0.323185</td>\n",
       "      <td>0.353816</td>\n",
       "      <td>0.249821</td>\n",
       "      <td>0.329853</td>\n",
       "      <td>4</td>\n",
       "      <td>has_periodic_spawn</td>\n",
       "      <td>bool_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>326</th>\n",
       "      <td>0.056902</td>\n",
       "      <td>0.169146</td>\n",
       "      <td>0.295917</td>\n",
       "      <td>0.295990</td>\n",
       "      <td>0.297124</td>\n",
       "      <td>0.297124</td>\n",
       "      <td>4</td>\n",
       "      <td>single_damage_type</td>\n",
       "      <td>bool_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>327</th>\n",
       "      <td>0.030340</td>\n",
       "      <td>0.164295</td>\n",
       "      <td>0.173861</td>\n",
       "      <td>0.319230</td>\n",
       "      <td>0.306930</td>\n",
       "      <td>0.306930</td>\n",
       "      <td>4</td>\n",
       "      <td>is_troop</td>\n",
       "      <td>bool_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>328</th>\n",
       "      <td>0.030340</td>\n",
       "      <td>0.164295</td>\n",
       "      <td>0.173861</td>\n",
       "      <td>0.319230</td>\n",
       "      <td>0.306930</td>\n",
       "      <td>0.306930</td>\n",
       "      <td>4</td>\n",
       "      <td>is_spell</td>\n",
       "      <td>bool_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>329</th>\n",
       "      <td>0.030340</td>\n",
       "      <td>0.164295</td>\n",
       "      <td>0.173861</td>\n",
       "      <td>0.319230</td>\n",
       "      <td>0.306930</td>\n",
       "      <td>0.306930</td>\n",
       "      <td>4</td>\n",
       "      <td>is_building</td>\n",
       "      <td>bool_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>330</th>\n",
       "      <td>0.030340</td>\n",
       "      <td>0.164295</td>\n",
       "      <td>0.173861</td>\n",
       "      <td>0.319230</td>\n",
       "      <td>0.306930</td>\n",
       "      <td>0.306930</td>\n",
       "      <td>4</td>\n",
       "      <td>is_tower_troop</td>\n",
       "      <td>bool_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>331</th>\n",
       "      <td>0.145004</td>\n",
       "      <td>0.169162</td>\n",
       "      <td>0.322669</td>\n",
       "      <td>0.347844</td>\n",
       "      <td>0.306930</td>\n",
       "      <td>0.306930</td>\n",
       "      <td>4</td>\n",
       "      <td>is_spawned</td>\n",
       "      <td>bool_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>332</th>\n",
       "      <td>0.032807</td>\n",
       "      <td>0.152619</td>\n",
       "      <td>0.173861</td>\n",
       "      <td>0.319230</td>\n",
       "      <td>0.321725</td>\n",
       "      <td>0.321725</td>\n",
       "      <td>4</td>\n",
       "      <td>has_ranged_attack</td>\n",
       "      <td>bool_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>333</th>\n",
       "      <td>0.166453</td>\n",
       "      <td>0.153263</td>\n",
       "      <td>0.319424</td>\n",
       "      <td>0.362207</td>\n",
       "      <td>0.247781</td>\n",
       "      <td>0.332203</td>\n",
       "      <td>4</td>\n",
       "      <td>special_attack_type</td>\n",
       "      <td>bool_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>334</th>\n",
       "      <td>0.057354</td>\n",
       "      <td>0.168251</td>\n",
       "      <td>0.272776</td>\n",
       "      <td>0.355125</td>\n",
       "      <td>0.250245</td>\n",
       "      <td>0.330546</td>\n",
       "      <td>4</td>\n",
       "      <td>has_friendly_buff</td>\n",
       "      <td>bool_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>335</th>\n",
       "      <td>0.017218</td>\n",
       "      <td>0.150718</td>\n",
       "      <td>0.173861</td>\n",
       "      <td>0.319230</td>\n",
       "      <td>0.233098</td>\n",
       "      <td>0.325465</td>\n",
       "      <td>4</td>\n",
       "      <td>is_free_card</td>\n",
       "      <td>bool_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>336</th>\n",
       "      <td>0.038291</td>\n",
       "      <td>0.169463</td>\n",
       "      <td>0.173861</td>\n",
       "      <td>0.319230</td>\n",
       "      <td>0.297228</td>\n",
       "      <td>0.297228</td>\n",
       "      <td>4</td>\n",
       "      <td>no_hit_speed</td>\n",
       "      <td>bool_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>337</th>\n",
       "      <td>0.076702</td>\n",
       "      <td>0.144614</td>\n",
       "      <td>0.234766</td>\n",
       "      <td>0.275195</td>\n",
       "      <td>0.225237</td>\n",
       "      <td>0.306137</td>\n",
       "      <td>4</td>\n",
       "      <td>no_attack</td>\n",
       "      <td>bool_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>338</th>\n",
       "      <td>0.089819</td>\n",
       "      <td>0.151407</td>\n",
       "      <td>0.173861</td>\n",
       "      <td>0.319230</td>\n",
       "      <td>0.306930</td>\n",
       "      <td>0.306930</td>\n",
       "      <td>4</td>\n",
       "      <td>no_hitpoints</td>\n",
       "      <td>bool_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>339</th>\n",
       "      <td>0.008247</td>\n",
       "      <td>0.151455</td>\n",
       "      <td>0.173861</td>\n",
       "      <td>0.319230</td>\n",
       "      <td>0.306930</td>\n",
       "      <td>0.306930</td>\n",
       "      <td>4</td>\n",
       "      <td>win_con</td>\n",
       "      <td>bool_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>340</th>\n",
       "      <td>0.078462</td>\n",
       "      <td>0.154076</td>\n",
       "      <td>0.313524</td>\n",
       "      <td>0.304720</td>\n",
       "      <td>0.234903</td>\n",
       "      <td>0.318345</td>\n",
       "      <td>4</td>\n",
       "      <td>control_special</td>\n",
       "      <td>bool_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341</th>\n",
       "      <td>0.144094</td>\n",
       "      <td>0.153850</td>\n",
       "      <td>0.350885</td>\n",
       "      <td>0.352348</td>\n",
       "      <td>0.306930</td>\n",
       "      <td>0.306930</td>\n",
       "      <td>4</td>\n",
       "      <td>dps_special</td>\n",
       "      <td>bool_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>342</th>\n",
       "      <td>-0.025146</td>\n",
       "      <td>0.159653</td>\n",
       "      <td>0.173861</td>\n",
       "      <td>0.319230</td>\n",
       "      <td>0.322630</td>\n",
       "      <td>0.341854</td>\n",
       "      <td>4</td>\n",
       "      <td>air_control</td>\n",
       "      <td>bool_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>343</th>\n",
       "      <td>-0.002001</td>\n",
       "      <td>0.157414</td>\n",
       "      <td>0.173861</td>\n",
       "      <td>0.319230</td>\n",
       "      <td>0.212142</td>\n",
       "      <td>0.304797</td>\n",
       "      <td>4</td>\n",
       "      <td>ground_dps</td>\n",
       "      <td>bool_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>344</th>\n",
       "      <td>0.028814</td>\n",
       "      <td>0.154730</td>\n",
       "      <td>0.173861</td>\n",
       "      <td>0.319230</td>\n",
       "      <td>0.306930</td>\n",
       "      <td>0.306930</td>\n",
       "      <td>4</td>\n",
       "      <td>win_con_dmg</td>\n",
       "      <td>bool_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>345</th>\n",
       "      <td>0.038162</td>\n",
       "      <td>0.168242</td>\n",
       "      <td>0.289822</td>\n",
       "      <td>0.306019</td>\n",
       "      <td>0.311404</td>\n",
       "      <td>0.311404</td>\n",
       "      <td>4</td>\n",
       "      <td>high_dps</td>\n",
       "      <td>bool_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>346</th>\n",
       "      <td>0.091454</td>\n",
       "      <td>0.121762</td>\n",
       "      <td>0.228638</td>\n",
       "      <td>0.279167</td>\n",
       "      <td>0.225237</td>\n",
       "      <td>0.306137</td>\n",
       "      <td>4</td>\n",
       "      <td>support</td>\n",
       "      <td>bool_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>347</th>\n",
       "      <td>0.091729</td>\n",
       "      <td>0.155585</td>\n",
       "      <td>0.173861</td>\n",
       "      <td>0.319230</td>\n",
       "      <td>0.306930</td>\n",
       "      <td>0.306930</td>\n",
       "      <td>4</td>\n",
       "      <td>mini_tank</td>\n",
       "      <td>bool_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>348</th>\n",
       "      <td>0.019937</td>\n",
       "      <td>0.105846</td>\n",
       "      <td>0.190475</td>\n",
       "      <td>0.190475</td>\n",
       "      <td>0.316115</td>\n",
       "      <td>0.316115</td>\n",
       "      <td>5</td>\n",
       "      <td>playable</td>\n",
       "      <td>all_col</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>349</th>\n",
       "      <td>-0.077081</td>\n",
       "      <td>0.123750</td>\n",
       "      <td>0.122963</td>\n",
       "      <td>0.201543</td>\n",
       "      <td>0.300120</td>\n",
       "      <td>0.300120</td>\n",
       "      <td>5</td>\n",
       "      <td>aoe_bool</td>\n",
       "      <td>all_col</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>350</th>\n",
       "      <td>0.024071</td>\n",
       "      <td>0.123589</td>\n",
       "      <td>0.174387</td>\n",
       "      <td>0.198648</td>\n",
       "      <td>0.301346</td>\n",
       "      <td>0.301346</td>\n",
       "      <td>5</td>\n",
       "      <td>aoe_radius</td>\n",
       "      <td>all_col</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>351</th>\n",
       "      <td>0.054188</td>\n",
       "      <td>0.121049</td>\n",
       "      <td>0.190475</td>\n",
       "      <td>0.190475</td>\n",
       "      <td>0.321012</td>\n",
       "      <td>0.321012</td>\n",
       "      <td>5</td>\n",
       "      <td>death_damage_bool</td>\n",
       "      <td>all_col</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>352</th>\n",
       "      <td>-0.091573</td>\n",
       "      <td>0.123309</td>\n",
       "      <td>0.190475</td>\n",
       "      <td>0.190475</td>\n",
       "      <td>0.306917</td>\n",
       "      <td>0.306917</td>\n",
       "      <td>5</td>\n",
       "      <td>fly_bool</td>\n",
       "      <td>all_col</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>353</th>\n",
       "      <td>0.016221</td>\n",
       "      <td>0.123527</td>\n",
       "      <td>0.177661</td>\n",
       "      <td>0.200465</td>\n",
       "      <td>0.311477</td>\n",
       "      <td>0.311477</td>\n",
       "      <td>5</td>\n",
       "      <td>spawn_bool</td>\n",
       "      <td>all_col</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>354</th>\n",
       "      <td>0.049465</td>\n",
       "      <td>0.120723</td>\n",
       "      <td>0.179240</td>\n",
       "      <td>0.233239</td>\n",
       "      <td>0.315817</td>\n",
       "      <td>0.315817</td>\n",
       "      <td>5</td>\n",
       "      <td>can_evolve</td>\n",
       "      <td>all_col</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>355</th>\n",
       "      <td>0.098124</td>\n",
       "      <td>0.105830</td>\n",
       "      <td>0.176272</td>\n",
       "      <td>0.199138</td>\n",
       "      <td>0.312681</td>\n",
       "      <td>0.312681</td>\n",
       "      <td>5</td>\n",
       "      <td>elixircost</td>\n",
       "      <td>all_col</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>356</th>\n",
       "      <td>0.025277</td>\n",
       "      <td>0.101845</td>\n",
       "      <td>0.190475</td>\n",
       "      <td>0.190475</td>\n",
       "      <td>0.312924</td>\n",
       "      <td>0.312924</td>\n",
       "      <td>5</td>\n",
       "      <td>hit_speed</td>\n",
       "      <td>all_col</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>357</th>\n",
       "      <td>0.008742</td>\n",
       "      <td>0.122679</td>\n",
       "      <td>0.177394</td>\n",
       "      <td>0.201960</td>\n",
       "      <td>0.300235</td>\n",
       "      <td>0.300235</td>\n",
       "      <td>5</td>\n",
       "      <td>special_damage</td>\n",
       "      <td>all_col</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>358</th>\n",
       "      <td>0.114077</td>\n",
       "      <td>0.115661</td>\n",
       "      <td>0.190475</td>\n",
       "      <td>0.190475</td>\n",
       "      <td>0.306917</td>\n",
       "      <td>0.306917</td>\n",
       "      <td>5</td>\n",
       "      <td>count</td>\n",
       "      <td>all_col</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>359</th>\n",
       "      <td>0.053455</td>\n",
       "      <td>0.119257</td>\n",
       "      <td>0.190475</td>\n",
       "      <td>0.190475</td>\n",
       "      <td>0.306247</td>\n",
       "      <td>0.306247</td>\n",
       "      <td>5</td>\n",
       "      <td>hitpoints</td>\n",
       "      <td>all_col</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>360</th>\n",
       "      <td>0.100891</td>\n",
       "      <td>0.118330</td>\n",
       "      <td>0.190475</td>\n",
       "      <td>0.190475</td>\n",
       "      <td>0.306917</td>\n",
       "      <td>0.306917</td>\n",
       "      <td>5</td>\n",
       "      <td>shield_bool</td>\n",
       "      <td>all_col</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>361</th>\n",
       "      <td>0.062145</td>\n",
       "      <td>0.111660</td>\n",
       "      <td>0.168299</td>\n",
       "      <td>0.189842</td>\n",
       "      <td>0.301359</td>\n",
       "      <td>0.301359</td>\n",
       "      <td>5</td>\n",
       "      <td>damage</td>\n",
       "      <td>all_col</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>362</th>\n",
       "      <td>0.014880</td>\n",
       "      <td>0.096676</td>\n",
       "      <td>0.172816</td>\n",
       "      <td>0.190221</td>\n",
       "      <td>0.299833</td>\n",
       "      <td>0.299833</td>\n",
       "      <td>5</td>\n",
       "      <td>attack_count</td>\n",
       "      <td>all_col</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>363</th>\n",
       "      <td>0.062610</td>\n",
       "      <td>0.115057</td>\n",
       "      <td>0.190475</td>\n",
       "      <td>0.190475</td>\n",
       "      <td>0.303695</td>\n",
       "      <td>0.303695</td>\n",
       "      <td>5</td>\n",
       "      <td>range</td>\n",
       "      <td>all_col</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>364</th>\n",
       "      <td>-0.010168</td>\n",
       "      <td>0.126202</td>\n",
       "      <td>0.175054</td>\n",
       "      <td>0.196418</td>\n",
       "      <td>0.270514</td>\n",
       "      <td>0.270514</td>\n",
       "      <td>5</td>\n",
       "      <td>affected_crown</td>\n",
       "      <td>all_col</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>365</th>\n",
       "      <td>0.007030</td>\n",
       "      <td>0.110354</td>\n",
       "      <td>0.190475</td>\n",
       "      <td>0.190475</td>\n",
       "      <td>0.306917</td>\n",
       "      <td>0.306917</td>\n",
       "      <td>5</td>\n",
       "      <td>has_lifetime</td>\n",
       "      <td>all_col</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>366</th>\n",
       "      <td>0.042119</td>\n",
       "      <td>0.127480</td>\n",
       "      <td>0.190475</td>\n",
       "      <td>0.190475</td>\n",
       "      <td>0.306917</td>\n",
       "      <td>0.306917</td>\n",
       "      <td>5</td>\n",
       "      <td>invisible</td>\n",
       "      <td>all_col</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>367</th>\n",
       "      <td>0.052008</td>\n",
       "      <td>0.123381</td>\n",
       "      <td>0.190475</td>\n",
       "      <td>0.190475</td>\n",
       "      <td>0.306917</td>\n",
       "      <td>0.306917</td>\n",
       "      <td>5</td>\n",
       "      <td>has_ability</td>\n",
       "      <td>all_col</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>368</th>\n",
       "      <td>0.047749</td>\n",
       "      <td>0.116389</td>\n",
       "      <td>0.190475</td>\n",
       "      <td>0.190475</td>\n",
       "      <td>0.315011</td>\n",
       "      <td>0.315011</td>\n",
       "      <td>5</td>\n",
       "      <td>any_target</td>\n",
       "      <td>all_col</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>369</th>\n",
       "      <td>0.047749</td>\n",
       "      <td>0.116389</td>\n",
       "      <td>0.190475</td>\n",
       "      <td>0.190475</td>\n",
       "      <td>0.313165</td>\n",
       "      <td>0.313165</td>\n",
       "      <td>5</td>\n",
       "      <td>building_target</td>\n",
       "      <td>all_col</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>370</th>\n",
       "      <td>0.052612</td>\n",
       "      <td>0.114188</td>\n",
       "      <td>0.190475</td>\n",
       "      <td>0.190475</td>\n",
       "      <td>0.313165</td>\n",
       "      <td>0.313165</td>\n",
       "      <td>5</td>\n",
       "      <td>ground_target</td>\n",
       "      <td>all_col</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>371</th>\n",
       "      <td>0.046590</td>\n",
       "      <td>0.113037</td>\n",
       "      <td>0.148028</td>\n",
       "      <td>0.209356</td>\n",
       "      <td>0.306917</td>\n",
       "      <td>0.306917</td>\n",
       "      <td>5</td>\n",
       "      <td>has_upon_breaking_spawn</td>\n",
       "      <td>all_col</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>372</th>\n",
       "      <td>0.017124</td>\n",
       "      <td>0.121850</td>\n",
       "      <td>0.190475</td>\n",
       "      <td>0.190475</td>\n",
       "      <td>0.311477</td>\n",
       "      <td>0.311477</td>\n",
       "      <td>5</td>\n",
       "      <td>has_upon_death_spawn</td>\n",
       "      <td>all_col</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>373</th>\n",
       "      <td>0.076124</td>\n",
       "      <td>0.121676</td>\n",
       "      <td>0.206717</td>\n",
       "      <td>0.206717</td>\n",
       "      <td>0.319361</td>\n",
       "      <td>0.319361</td>\n",
       "      <td>5</td>\n",
       "      <td>has_periodic_spawn</td>\n",
       "      <td>all_col</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>374</th>\n",
       "      <td>0.032241</td>\n",
       "      <td>0.122780</td>\n",
       "      <td>0.167942</td>\n",
       "      <td>0.195495</td>\n",
       "      <td>0.309363</td>\n",
       "      <td>0.309363</td>\n",
       "      <td>5</td>\n",
       "      <td>single_damage_type</td>\n",
       "      <td>all_col</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>375</th>\n",
       "      <td>0.049656</td>\n",
       "      <td>0.108423</td>\n",
       "      <td>0.190475</td>\n",
       "      <td>0.190475</td>\n",
       "      <td>0.306917</td>\n",
       "      <td>0.306917</td>\n",
       "      <td>5</td>\n",
       "      <td>is_troop</td>\n",
       "      <td>all_col</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>376</th>\n",
       "      <td>0.049656</td>\n",
       "      <td>0.108423</td>\n",
       "      <td>0.190475</td>\n",
       "      <td>0.190475</td>\n",
       "      <td>0.306917</td>\n",
       "      <td>0.306917</td>\n",
       "      <td>5</td>\n",
       "      <td>is_spell</td>\n",
       "      <td>all_col</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>377</th>\n",
       "      <td>0.049656</td>\n",
       "      <td>0.108423</td>\n",
       "      <td>0.190475</td>\n",
       "      <td>0.190475</td>\n",
       "      <td>0.306917</td>\n",
       "      <td>0.306917</td>\n",
       "      <td>5</td>\n",
       "      <td>is_building</td>\n",
       "      <td>all_col</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>378</th>\n",
       "      <td>0.049656</td>\n",
       "      <td>0.108423</td>\n",
       "      <td>0.190475</td>\n",
       "      <td>0.190475</td>\n",
       "      <td>0.306917</td>\n",
       "      <td>0.306917</td>\n",
       "      <td>5</td>\n",
       "      <td>is_tower_troop</td>\n",
       "      <td>all_col</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>379</th>\n",
       "      <td>0.033882</td>\n",
       "      <td>0.106490</td>\n",
       "      <td>0.169726</td>\n",
       "      <td>0.203535</td>\n",
       "      <td>0.306917</td>\n",
       "      <td>0.306917</td>\n",
       "      <td>5</td>\n",
       "      <td>is_spawned</td>\n",
       "      <td>all_col</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>380</th>\n",
       "      <td>0.046107</td>\n",
       "      <td>0.121986</td>\n",
       "      <td>0.190475</td>\n",
       "      <td>0.190475</td>\n",
       "      <td>0.306917</td>\n",
       "      <td>0.306917</td>\n",
       "      <td>5</td>\n",
       "      <td>speed</td>\n",
       "      <td>all_col</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>381</th>\n",
       "      <td>0.064699</td>\n",
       "      <td>0.113735</td>\n",
       "      <td>0.190475</td>\n",
       "      <td>0.190475</td>\n",
       "      <td>0.313508</td>\n",
       "      <td>0.313508</td>\n",
       "      <td>5</td>\n",
       "      <td>has_ranged_attack</td>\n",
       "      <td>all_col</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>382</th>\n",
       "      <td>-0.043712</td>\n",
       "      <td>0.117863</td>\n",
       "      <td>0.197948</td>\n",
       "      <td>0.216689</td>\n",
       "      <td>0.309147</td>\n",
       "      <td>0.309147</td>\n",
       "      <td>5</td>\n",
       "      <td>special_attack_type</td>\n",
       "      <td>all_col</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>383</th>\n",
       "      <td>0.087133</td>\n",
       "      <td>0.122329</td>\n",
       "      <td>0.191887</td>\n",
       "      <td>0.191887</td>\n",
       "      <td>0.329861</td>\n",
       "      <td>0.329861</td>\n",
       "      <td>5</td>\n",
       "      <td>has_friendly_buff</td>\n",
       "      <td>all_col</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>384</th>\n",
       "      <td>0.019937</td>\n",
       "      <td>0.105846</td>\n",
       "      <td>0.190475</td>\n",
       "      <td>0.190475</td>\n",
       "      <td>0.316115</td>\n",
       "      <td>0.316115</td>\n",
       "      <td>5</td>\n",
       "      <td>is_free_card</td>\n",
       "      <td>all_col</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>385</th>\n",
       "      <td>0.045268</td>\n",
       "      <td>0.121007</td>\n",
       "      <td>0.190475</td>\n",
       "      <td>0.190475</td>\n",
       "      <td>0.303707</td>\n",
       "      <td>0.303707</td>\n",
       "      <td>5</td>\n",
       "      <td>no_hit_speed</td>\n",
       "      <td>all_col</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>386</th>\n",
       "      <td>0.023420</td>\n",
       "      <td>0.119868</td>\n",
       "      <td>0.118642</td>\n",
       "      <td>0.180773</td>\n",
       "      <td>0.299833</td>\n",
       "      <td>0.299833</td>\n",
       "      <td>5</td>\n",
       "      <td>no_attack</td>\n",
       "      <td>all_col</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>387</th>\n",
       "      <td>-0.054601</td>\n",
       "      <td>0.121860</td>\n",
       "      <td>0.190475</td>\n",
       "      <td>0.190475</td>\n",
       "      <td>0.306917</td>\n",
       "      <td>0.306917</td>\n",
       "      <td>5</td>\n",
       "      <td>no_hitpoints</td>\n",
       "      <td>all_col</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>388</th>\n",
       "      <td>0.044770</td>\n",
       "      <td>0.114371</td>\n",
       "      <td>0.133067</td>\n",
       "      <td>0.189649</td>\n",
       "      <td>0.301080</td>\n",
       "      <td>0.301080</td>\n",
       "      <td>5</td>\n",
       "      <td>damage_per_elixir</td>\n",
       "      <td>all_col</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>389</th>\n",
       "      <td>0.075524</td>\n",
       "      <td>0.107476</td>\n",
       "      <td>0.190475</td>\n",
       "      <td>0.190475</td>\n",
       "      <td>0.300189</td>\n",
       "      <td>0.300189</td>\n",
       "      <td>5</td>\n",
       "      <td>damage_per_second</td>\n",
       "      <td>all_col</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>390</th>\n",
       "      <td>-0.024919</td>\n",
       "      <td>0.132375</td>\n",
       "      <td>0.172707</td>\n",
       "      <td>0.196561</td>\n",
       "      <td>0.271133</td>\n",
       "      <td>0.271133</td>\n",
       "      <td>5</td>\n",
       "      <td>damage_output</td>\n",
       "      <td>all_col</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>391</th>\n",
       "      <td>0.060041</td>\n",
       "      <td>0.117008</td>\n",
       "      <td>0.188704</td>\n",
       "      <td>0.188066</td>\n",
       "      <td>0.311989</td>\n",
       "      <td>0.311989</td>\n",
       "      <td>5</td>\n",
       "      <td>hp_per_elixir</td>\n",
       "      <td>all_col</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>392</th>\n",
       "      <td>0.059894</td>\n",
       "      <td>0.114528</td>\n",
       "      <td>0.190475</td>\n",
       "      <td>0.190475</td>\n",
       "      <td>0.299296</td>\n",
       "      <td>0.299296</td>\n",
       "      <td>5</td>\n",
       "      <td>damage_by_hitpoints</td>\n",
       "      <td>all_col</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>393</th>\n",
       "      <td>0.004787</td>\n",
       "      <td>0.123558</td>\n",
       "      <td>0.174387</td>\n",
       "      <td>0.198648</td>\n",
       "      <td>0.300424</td>\n",
       "      <td>0.300424</td>\n",
       "      <td>5</td>\n",
       "      <td>aoe_by_range</td>\n",
       "      <td>all_col</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>394</th>\n",
       "      <td>0.046049</td>\n",
       "      <td>0.122523</td>\n",
       "      <td>0.171124</td>\n",
       "      <td>0.189457</td>\n",
       "      <td>0.302829</td>\n",
       "      <td>0.302829</td>\n",
       "      <td>5</td>\n",
       "      <td>aoe_by_damage</td>\n",
       "      <td>all_col</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>0.053428</td>\n",
       "      <td>0.117318</td>\n",
       "      <td>0.190475</td>\n",
       "      <td>0.190475</td>\n",
       "      <td>0.306917</td>\n",
       "      <td>0.306917</td>\n",
       "      <td>5</td>\n",
       "      <td>win_con</td>\n",
       "      <td>all_col</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>0.037061</td>\n",
       "      <td>0.122076</td>\n",
       "      <td>0.174005</td>\n",
       "      <td>0.202656</td>\n",
       "      <td>0.301346</td>\n",
       "      <td>0.301346</td>\n",
       "      <td>5</td>\n",
       "      <td>aoe_per_elixir</td>\n",
       "      <td>all_col</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>0.037472</td>\n",
       "      <td>0.122897</td>\n",
       "      <td>0.199898</td>\n",
       "      <td>0.217794</td>\n",
       "      <td>0.300235</td>\n",
       "      <td>0.300235</td>\n",
       "      <td>5</td>\n",
       "      <td>control_special</td>\n",
       "      <td>all_col</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>0.028952</td>\n",
       "      <td>0.121175</td>\n",
       "      <td>0.151679</td>\n",
       "      <td>0.191665</td>\n",
       "      <td>0.306917</td>\n",
       "      <td>0.306917</td>\n",
       "      <td>5</td>\n",
       "      <td>dps_special</td>\n",
       "      <td>all_col</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>0.021605</td>\n",
       "      <td>0.119781</td>\n",
       "      <td>0.190475</td>\n",
       "      <td>0.190475</td>\n",
       "      <td>0.313608</td>\n",
       "      <td>0.313608</td>\n",
       "      <td>5</td>\n",
       "      <td>air_control</td>\n",
       "      <td>all_col</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>400</th>\n",
       "      <td>-0.045294</td>\n",
       "      <td>0.111679</td>\n",
       "      <td>0.190475</td>\n",
       "      <td>0.190475</td>\n",
       "      <td>0.307052</td>\n",
       "      <td>0.307052</td>\n",
       "      <td>5</td>\n",
       "      <td>ground_dps</td>\n",
       "      <td>all_col</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>401</th>\n",
       "      <td>0.073530</td>\n",
       "      <td>0.121048</td>\n",
       "      <td>0.190475</td>\n",
       "      <td>0.190475</td>\n",
       "      <td>0.306917</td>\n",
       "      <td>0.306917</td>\n",
       "      <td>5</td>\n",
       "      <td>win_con_dmg</td>\n",
       "      <td>all_col</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>402</th>\n",
       "      <td>0.026831</td>\n",
       "      <td>0.118916</td>\n",
       "      <td>0.154941</td>\n",
       "      <td>0.187643</td>\n",
       "      <td>0.299578</td>\n",
       "      <td>0.299578</td>\n",
       "      <td>5</td>\n",
       "      <td>high_dps</td>\n",
       "      <td>all_col</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>403</th>\n",
       "      <td>0.055158</td>\n",
       "      <td>0.107066</td>\n",
       "      <td>0.190475</td>\n",
       "      <td>0.190475</td>\n",
       "      <td>0.299209</td>\n",
       "      <td>0.299209</td>\n",
       "      <td>5</td>\n",
       "      <td>damage_output_ps</td>\n",
       "      <td>all_col</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404</th>\n",
       "      <td>0.023358</td>\n",
       "      <td>0.114779</td>\n",
       "      <td>0.191578</td>\n",
       "      <td>0.191578</td>\n",
       "      <td>0.299833</td>\n",
       "      <td>0.299833</td>\n",
       "      <td>5</td>\n",
       "      <td>support</td>\n",
       "      <td>all_col</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>405</th>\n",
       "      <td>0.022123</td>\n",
       "      <td>0.121062</td>\n",
       "      <td>0.190475</td>\n",
       "      <td>0.190475</td>\n",
       "      <td>0.306917</td>\n",
       "      <td>0.306917</td>\n",
       "      <td>5</td>\n",
       "      <td>mini_tank</td>\n",
       "      <td>all_col</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>406</th>\n",
       "      <td>0.126108</td>\n",
       "      <td>0.232277</td>\n",
       "      <td>0.424232</td>\n",
       "      <td>0.491928</td>\n",
       "      <td>0.644220</td>\n",
       "      <td>0.644220</td>\n",
       "      <td>5</td>\n",
       "      <td>damage_per_elixir</td>\n",
       "      <td>engineered</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>407</th>\n",
       "      <td>0.199591</td>\n",
       "      <td>0.263016</td>\n",
       "      <td>0.064068</td>\n",
       "      <td>0.429905</td>\n",
       "      <td>0.662429</td>\n",
       "      <td>0.662429</td>\n",
       "      <td>5</td>\n",
       "      <td>damage_per_second</td>\n",
       "      <td>engineered</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>408</th>\n",
       "      <td>0.109811</td>\n",
       "      <td>0.271057</td>\n",
       "      <td>0.311268</td>\n",
       "      <td>0.445470</td>\n",
       "      <td>0.435506</td>\n",
       "      <td>0.575621</td>\n",
       "      <td>5</td>\n",
       "      <td>damage_output</td>\n",
       "      <td>engineered</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>409</th>\n",
       "      <td>-0.079962</td>\n",
       "      <td>0.335940</td>\n",
       "      <td>0.520646</td>\n",
       "      <td>0.404968</td>\n",
       "      <td>0.698454</td>\n",
       "      <td>0.698454</td>\n",
       "      <td>5</td>\n",
       "      <td>hp_per_elixir</td>\n",
       "      <td>engineered</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>410</th>\n",
       "      <td>0.066778</td>\n",
       "      <td>0.276691</td>\n",
       "      <td>0.064068</td>\n",
       "      <td>0.429905</td>\n",
       "      <td>0.631296</td>\n",
       "      <td>0.631296</td>\n",
       "      <td>5</td>\n",
       "      <td>damage_by_hitpoints</td>\n",
       "      <td>engineered</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>411</th>\n",
       "      <td>0.079014</td>\n",
       "      <td>0.241365</td>\n",
       "      <td>0.519276</td>\n",
       "      <td>0.519276</td>\n",
       "      <td>0.624940</td>\n",
       "      <td>0.624940</td>\n",
       "      <td>5</td>\n",
       "      <td>aoe_by_range</td>\n",
       "      <td>engineered</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>412</th>\n",
       "      <td>-0.016976</td>\n",
       "      <td>0.236397</td>\n",
       "      <td>0.040824</td>\n",
       "      <td>0.434213</td>\n",
       "      <td>0.640167</td>\n",
       "      <td>0.640167</td>\n",
       "      <td>5</td>\n",
       "      <td>aoe_by_damage</td>\n",
       "      <td>engineered</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>413</th>\n",
       "      <td>-0.020598</td>\n",
       "      <td>0.119020</td>\n",
       "      <td>0.159886</td>\n",
       "      <td>0.193872</td>\n",
       "      <td>0.232555</td>\n",
       "      <td>0.274827</td>\n",
       "      <td>5</td>\n",
       "      <td>playable</td>\n",
       "      <td>original</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>414</th>\n",
       "      <td>0.059842</td>\n",
       "      <td>0.140260</td>\n",
       "      <td>0.226299</td>\n",
       "      <td>0.226299</td>\n",
       "      <td>0.248450</td>\n",
       "      <td>0.248450</td>\n",
       "      <td>5</td>\n",
       "      <td>aoe_bool</td>\n",
       "      <td>original</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415</th>\n",
       "      <td>0.004605</td>\n",
       "      <td>0.133306</td>\n",
       "      <td>0.204456</td>\n",
       "      <td>0.223564</td>\n",
       "      <td>0.250099</td>\n",
       "      <td>0.250099</td>\n",
       "      <td>5</td>\n",
       "      <td>aoe_radius</td>\n",
       "      <td>original</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416</th>\n",
       "      <td>0.055351</td>\n",
       "      <td>0.133153</td>\n",
       "      <td>0.159886</td>\n",
       "      <td>0.193872</td>\n",
       "      <td>0.210550</td>\n",
       "      <td>0.275946</td>\n",
       "      <td>5</td>\n",
       "      <td>death_damage_bool</td>\n",
       "      <td>original</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>417</th>\n",
       "      <td>0.122181</td>\n",
       "      <td>0.139363</td>\n",
       "      <td>0.159886</td>\n",
       "      <td>0.193872</td>\n",
       "      <td>0.263601</td>\n",
       "      <td>0.263601</td>\n",
       "      <td>5</td>\n",
       "      <td>fly_bool</td>\n",
       "      <td>original</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>418</th>\n",
       "      <td>0.046477</td>\n",
       "      <td>0.133187</td>\n",
       "      <td>0.217738</td>\n",
       "      <td>0.217738</td>\n",
       "      <td>0.270042</td>\n",
       "      <td>0.270042</td>\n",
       "      <td>5</td>\n",
       "      <td>spawn_bool</td>\n",
       "      <td>original</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>419</th>\n",
       "      <td>0.124848</td>\n",
       "      <td>0.116387</td>\n",
       "      <td>0.164338</td>\n",
       "      <td>0.201152</td>\n",
       "      <td>0.280080</td>\n",
       "      <td>0.280080</td>\n",
       "      <td>5</td>\n",
       "      <td>can_evolve</td>\n",
       "      <td>original</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>420</th>\n",
       "      <td>-0.023761</td>\n",
       "      <td>0.109484</td>\n",
       "      <td>0.187128</td>\n",
       "      <td>0.222544</td>\n",
       "      <td>0.283015</td>\n",
       "      <td>0.283015</td>\n",
       "      <td>5</td>\n",
       "      <td>elixircost</td>\n",
       "      <td>original</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>421</th>\n",
       "      <td>0.121156</td>\n",
       "      <td>0.141733</td>\n",
       "      <td>0.159886</td>\n",
       "      <td>0.193872</td>\n",
       "      <td>0.266726</td>\n",
       "      <td>0.266726</td>\n",
       "      <td>5</td>\n",
       "      <td>hit_speed</td>\n",
       "      <td>original</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>422</th>\n",
       "      <td>0.039111</td>\n",
       "      <td>0.130516</td>\n",
       "      <td>0.234060</td>\n",
       "      <td>0.234060</td>\n",
       "      <td>0.237164</td>\n",
       "      <td>0.237164</td>\n",
       "      <td>5</td>\n",
       "      <td>special_damage</td>\n",
       "      <td>original</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>423</th>\n",
       "      <td>0.080384</td>\n",
       "      <td>0.141382</td>\n",
       "      <td>0.159886</td>\n",
       "      <td>0.193872</td>\n",
       "      <td>0.263601</td>\n",
       "      <td>0.263601</td>\n",
       "      <td>5</td>\n",
       "      <td>count</td>\n",
       "      <td>original</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>424</th>\n",
       "      <td>0.034771</td>\n",
       "      <td>0.127886</td>\n",
       "      <td>0.159886</td>\n",
       "      <td>0.193872</td>\n",
       "      <td>0.275373</td>\n",
       "      <td>0.275373</td>\n",
       "      <td>5</td>\n",
       "      <td>hitpoints</td>\n",
       "      <td>original</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>425</th>\n",
       "      <td>-0.016498</td>\n",
       "      <td>0.118410</td>\n",
       "      <td>0.159886</td>\n",
       "      <td>0.193872</td>\n",
       "      <td>0.263601</td>\n",
       "      <td>0.263601</td>\n",
       "      <td>5</td>\n",
       "      <td>shield_bool</td>\n",
       "      <td>original</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>426</th>\n",
       "      <td>-0.009426</td>\n",
       "      <td>0.130034</td>\n",
       "      <td>0.199313</td>\n",
       "      <td>0.208923</td>\n",
       "      <td>0.264261</td>\n",
       "      <td>0.264261</td>\n",
       "      <td>5</td>\n",
       "      <td>damage</td>\n",
       "      <td>original</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>427</th>\n",
       "      <td>0.063956</td>\n",
       "      <td>0.139225</td>\n",
       "      <td>0.210506</td>\n",
       "      <td>0.223029</td>\n",
       "      <td>0.255061</td>\n",
       "      <td>0.255061</td>\n",
       "      <td>5</td>\n",
       "      <td>attack_count</td>\n",
       "      <td>original</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>428</th>\n",
       "      <td>0.119504</td>\n",
       "      <td>0.134013</td>\n",
       "      <td>0.159886</td>\n",
       "      <td>0.193872</td>\n",
       "      <td>0.266897</td>\n",
       "      <td>0.266897</td>\n",
       "      <td>5</td>\n",
       "      <td>range</td>\n",
       "      <td>original</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>429</th>\n",
       "      <td>0.055759</td>\n",
       "      <td>0.136534</td>\n",
       "      <td>0.201281</td>\n",
       "      <td>0.174637</td>\n",
       "      <td>0.257463</td>\n",
       "      <td>0.257463</td>\n",
       "      <td>5</td>\n",
       "      <td>affected_crown</td>\n",
       "      <td>original</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>430</th>\n",
       "      <td>-0.088925</td>\n",
       "      <td>0.134910</td>\n",
       "      <td>0.159886</td>\n",
       "      <td>0.193872</td>\n",
       "      <td>0.263601</td>\n",
       "      <td>0.263601</td>\n",
       "      <td>5</td>\n",
       "      <td>has_lifetime</td>\n",
       "      <td>original</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>431</th>\n",
       "      <td>0.021312</td>\n",
       "      <td>0.130892</td>\n",
       "      <td>0.159886</td>\n",
       "      <td>0.193872</td>\n",
       "      <td>0.263601</td>\n",
       "      <td>0.263601</td>\n",
       "      <td>5</td>\n",
       "      <td>invisible</td>\n",
       "      <td>original</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>432</th>\n",
       "      <td>0.078186</td>\n",
       "      <td>0.135386</td>\n",
       "      <td>0.159886</td>\n",
       "      <td>0.193872</td>\n",
       "      <td>0.263601</td>\n",
       "      <td>0.263601</td>\n",
       "      <td>5</td>\n",
       "      <td>has_ability</td>\n",
       "      <td>original</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>433</th>\n",
       "      <td>0.085798</td>\n",
       "      <td>0.116486</td>\n",
       "      <td>0.159886</td>\n",
       "      <td>0.193872</td>\n",
       "      <td>0.272254</td>\n",
       "      <td>0.272254</td>\n",
       "      <td>5</td>\n",
       "      <td>any_target</td>\n",
       "      <td>original</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>434</th>\n",
       "      <td>0.085798</td>\n",
       "      <td>0.116486</td>\n",
       "      <td>0.159886</td>\n",
       "      <td>0.193872</td>\n",
       "      <td>0.269310</td>\n",
       "      <td>0.269310</td>\n",
       "      <td>5</td>\n",
       "      <td>building_target</td>\n",
       "      <td>original</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>435</th>\n",
       "      <td>0.049314</td>\n",
       "      <td>0.119164</td>\n",
       "      <td>0.159886</td>\n",
       "      <td>0.193872</td>\n",
       "      <td>0.269310</td>\n",
       "      <td>0.269310</td>\n",
       "      <td>5</td>\n",
       "      <td>ground_target</td>\n",
       "      <td>original</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>436</th>\n",
       "      <td>0.031850</td>\n",
       "      <td>0.131308</td>\n",
       "      <td>0.217878</td>\n",
       "      <td>0.217878</td>\n",
       "      <td>0.263601</td>\n",
       "      <td>0.263601</td>\n",
       "      <td>5</td>\n",
       "      <td>has_upon_breaking_spawn</td>\n",
       "      <td>original</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>437</th>\n",
       "      <td>0.026256</td>\n",
       "      <td>0.132249</td>\n",
       "      <td>0.159886</td>\n",
       "      <td>0.193872</td>\n",
       "      <td>0.270042</td>\n",
       "      <td>0.270042</td>\n",
       "      <td>5</td>\n",
       "      <td>has_upon_death_spawn</td>\n",
       "      <td>original</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>438</th>\n",
       "      <td>0.061440</td>\n",
       "      <td>0.141977</td>\n",
       "      <td>0.227388</td>\n",
       "      <td>0.230629</td>\n",
       "      <td>0.279065</td>\n",
       "      <td>0.279065</td>\n",
       "      <td>5</td>\n",
       "      <td>has_periodic_spawn</td>\n",
       "      <td>original</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>439</th>\n",
       "      <td>0.027689</td>\n",
       "      <td>0.132984</td>\n",
       "      <td>0.225902</td>\n",
       "      <td>0.235404</td>\n",
       "      <td>0.265293</td>\n",
       "      <td>0.265293</td>\n",
       "      <td>5</td>\n",
       "      <td>single_damage_type</td>\n",
       "      <td>original</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>440</th>\n",
       "      <td>0.048582</td>\n",
       "      <td>0.127368</td>\n",
       "      <td>0.159886</td>\n",
       "      <td>0.193872</td>\n",
       "      <td>0.263601</td>\n",
       "      <td>0.263601</td>\n",
       "      <td>5</td>\n",
       "      <td>is_troop</td>\n",
       "      <td>original</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>441</th>\n",
       "      <td>0.048582</td>\n",
       "      <td>0.127368</td>\n",
       "      <td>0.159886</td>\n",
       "      <td>0.193872</td>\n",
       "      <td>0.263601</td>\n",
       "      <td>0.263601</td>\n",
       "      <td>5</td>\n",
       "      <td>is_spell</td>\n",
       "      <td>original</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>442</th>\n",
       "      <td>0.048582</td>\n",
       "      <td>0.127368</td>\n",
       "      <td>0.159886</td>\n",
       "      <td>0.193872</td>\n",
       "      <td>0.263601</td>\n",
       "      <td>0.263601</td>\n",
       "      <td>5</td>\n",
       "      <td>is_building</td>\n",
       "      <td>original</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>443</th>\n",
       "      <td>0.048582</td>\n",
       "      <td>0.127368</td>\n",
       "      <td>0.159886</td>\n",
       "      <td>0.193872</td>\n",
       "      <td>0.263601</td>\n",
       "      <td>0.263601</td>\n",
       "      <td>5</td>\n",
       "      <td>is_tower_troop</td>\n",
       "      <td>original</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>444</th>\n",
       "      <td>0.034091</td>\n",
       "      <td>0.116847</td>\n",
       "      <td>0.212286</td>\n",
       "      <td>0.191077</td>\n",
       "      <td>0.263601</td>\n",
       "      <td>0.263601</td>\n",
       "      <td>5</td>\n",
       "      <td>is_spawned</td>\n",
       "      <td>original</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>445</th>\n",
       "      <td>0.054267</td>\n",
       "      <td>0.140983</td>\n",
       "      <td>0.159886</td>\n",
       "      <td>0.193872</td>\n",
       "      <td>0.263601</td>\n",
       "      <td>0.263601</td>\n",
       "      <td>5</td>\n",
       "      <td>speed</td>\n",
       "      <td>original</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>446</th>\n",
       "      <td>0.039315</td>\n",
       "      <td>0.125627</td>\n",
       "      <td>0.159886</td>\n",
       "      <td>0.193872</td>\n",
       "      <td>0.277176</td>\n",
       "      <td>0.277176</td>\n",
       "      <td>5</td>\n",
       "      <td>has_ranged_attack</td>\n",
       "      <td>original</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>447</th>\n",
       "      <td>0.065172</td>\n",
       "      <td>0.137202</td>\n",
       "      <td>0.210831</td>\n",
       "      <td>0.242028</td>\n",
       "      <td>0.265690</td>\n",
       "      <td>0.265690</td>\n",
       "      <td>5</td>\n",
       "      <td>special_attack_type</td>\n",
       "      <td>original</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>448</th>\n",
       "      <td>0.033865</td>\n",
       "      <td>0.132388</td>\n",
       "      <td>0.255605</td>\n",
       "      <td>0.252566</td>\n",
       "      <td>0.288495</td>\n",
       "      <td>0.288495</td>\n",
       "      <td>5</td>\n",
       "      <td>has_friendly_buff</td>\n",
       "      <td>original</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>449</th>\n",
       "      <td>-0.020598</td>\n",
       "      <td>0.119020</td>\n",
       "      <td>0.159886</td>\n",
       "      <td>0.193872</td>\n",
       "      <td>0.232555</td>\n",
       "      <td>0.274827</td>\n",
       "      <td>5</td>\n",
       "      <td>is_free_card</td>\n",
       "      <td>original</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>450</th>\n",
       "      <td>0.039151</td>\n",
       "      <td>0.131194</td>\n",
       "      <td>0.159886</td>\n",
       "      <td>0.193872</td>\n",
       "      <td>0.263202</td>\n",
       "      <td>0.263202</td>\n",
       "      <td>5</td>\n",
       "      <td>no_hit_speed</td>\n",
       "      <td>original</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>451</th>\n",
       "      <td>0.009930</td>\n",
       "      <td>0.108618</td>\n",
       "      <td>0.222025</td>\n",
       "      <td>0.220154</td>\n",
       "      <td>0.255061</td>\n",
       "      <td>0.255061</td>\n",
       "      <td>5</td>\n",
       "      <td>no_attack</td>\n",
       "      <td>original</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>452</th>\n",
       "      <td>0.005192</td>\n",
       "      <td>0.135488</td>\n",
       "      <td>0.159886</td>\n",
       "      <td>0.193872</td>\n",
       "      <td>0.263601</td>\n",
       "      <td>0.263601</td>\n",
       "      <td>5</td>\n",
       "      <td>no_hitpoints</td>\n",
       "      <td>original</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>453</th>\n",
       "      <td>0.042779</td>\n",
       "      <td>0.125953</td>\n",
       "      <td>0.159886</td>\n",
       "      <td>0.193872</td>\n",
       "      <td>0.263601</td>\n",
       "      <td>0.263601</td>\n",
       "      <td>5</td>\n",
       "      <td>win_con</td>\n",
       "      <td>original</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>454</th>\n",
       "      <td>-0.047879</td>\n",
       "      <td>0.137441</td>\n",
       "      <td>0.188014</td>\n",
       "      <td>0.215859</td>\n",
       "      <td>0.250099</td>\n",
       "      <td>0.250099</td>\n",
       "      <td>5</td>\n",
       "      <td>aoe_per_elixir</td>\n",
       "      <td>original</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>455</th>\n",
       "      <td>0.066124</td>\n",
       "      <td>0.137407</td>\n",
       "      <td>0.218838</td>\n",
       "      <td>0.240243</td>\n",
       "      <td>0.237164</td>\n",
       "      <td>0.237164</td>\n",
       "      <td>5</td>\n",
       "      <td>control_special</td>\n",
       "      <td>original</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>456</th>\n",
       "      <td>0.035762</td>\n",
       "      <td>0.130778</td>\n",
       "      <td>0.120951</td>\n",
       "      <td>0.197679</td>\n",
       "      <td>0.263601</td>\n",
       "      <td>0.263601</td>\n",
       "      <td>5</td>\n",
       "      <td>dps_special</td>\n",
       "      <td>original</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>457</th>\n",
       "      <td>-0.034247</td>\n",
       "      <td>0.132096</td>\n",
       "      <td>0.159886</td>\n",
       "      <td>0.193872</td>\n",
       "      <td>0.274199</td>\n",
       "      <td>0.274199</td>\n",
       "      <td>5</td>\n",
       "      <td>air_control</td>\n",
       "      <td>original</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>458</th>\n",
       "      <td>0.001577</td>\n",
       "      <td>0.124374</td>\n",
       "      <td>0.159886</td>\n",
       "      <td>0.193872</td>\n",
       "      <td>0.270983</td>\n",
       "      <td>0.270983</td>\n",
       "      <td>5</td>\n",
       "      <td>ground_dps</td>\n",
       "      <td>original</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>459</th>\n",
       "      <td>0.009906</td>\n",
       "      <td>0.123822</td>\n",
       "      <td>0.159886</td>\n",
       "      <td>0.193872</td>\n",
       "      <td>0.263601</td>\n",
       "      <td>0.263601</td>\n",
       "      <td>5</td>\n",
       "      <td>win_con_dmg</td>\n",
       "      <td>original</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>460</th>\n",
       "      <td>0.052525</td>\n",
       "      <td>0.141109</td>\n",
       "      <td>0.198647</td>\n",
       "      <td>0.220314</td>\n",
       "      <td>0.266749</td>\n",
       "      <td>0.266749</td>\n",
       "      <td>5</td>\n",
       "      <td>high_dps</td>\n",
       "      <td>original</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>461</th>\n",
       "      <td>0.116119</td>\n",
       "      <td>0.140443</td>\n",
       "      <td>0.159886</td>\n",
       "      <td>0.193872</td>\n",
       "      <td>0.254981</td>\n",
       "      <td>0.254981</td>\n",
       "      <td>5</td>\n",
       "      <td>damage_output_ps</td>\n",
       "      <td>original</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>462</th>\n",
       "      <td>0.045213</td>\n",
       "      <td>0.121251</td>\n",
       "      <td>0.148776</td>\n",
       "      <td>0.234327</td>\n",
       "      <td>0.255061</td>\n",
       "      <td>0.255061</td>\n",
       "      <td>5</td>\n",
       "      <td>support</td>\n",
       "      <td>original</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>463</th>\n",
       "      <td>0.113081</td>\n",
       "      <td>0.140675</td>\n",
       "      <td>0.159886</td>\n",
       "      <td>0.193872</td>\n",
       "      <td>0.263601</td>\n",
       "      <td>0.263601</td>\n",
       "      <td>5</td>\n",
       "      <td>mini_tank</td>\n",
       "      <td>original</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>464</th>\n",
       "      <td>0.092713</td>\n",
       "      <td>0.169730</td>\n",
       "      <td>0.254193</td>\n",
       "      <td>0.351541</td>\n",
       "      <td>0.363459</td>\n",
       "      <td>0.363459</td>\n",
       "      <td>5</td>\n",
       "      <td>aoe_radius</td>\n",
       "      <td>num_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>465</th>\n",
       "      <td>0.153543</td>\n",
       "      <td>0.137870</td>\n",
       "      <td>0.177285</td>\n",
       "      <td>0.274877</td>\n",
       "      <td>0.435061</td>\n",
       "      <td>0.435061</td>\n",
       "      <td>5</td>\n",
       "      <td>can_evolve</td>\n",
       "      <td>num_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>466</th>\n",
       "      <td>0.117764</td>\n",
       "      <td>0.201754</td>\n",
       "      <td>0.389297</td>\n",
       "      <td>0.389297</td>\n",
       "      <td>0.427145</td>\n",
       "      <td>0.427145</td>\n",
       "      <td>5</td>\n",
       "      <td>elixircost</td>\n",
       "      <td>num_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>467</th>\n",
       "      <td>0.072674</td>\n",
       "      <td>0.147081</td>\n",
       "      <td>0.276429</td>\n",
       "      <td>0.350547</td>\n",
       "      <td>0.385092</td>\n",
       "      <td>0.385092</td>\n",
       "      <td>5</td>\n",
       "      <td>hit_speed</td>\n",
       "      <td>num_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>468</th>\n",
       "      <td>0.072861</td>\n",
       "      <td>0.129108</td>\n",
       "      <td>0.276429</td>\n",
       "      <td>0.350547</td>\n",
       "      <td>0.386803</td>\n",
       "      <td>0.386803</td>\n",
       "      <td>5</td>\n",
       "      <td>count</td>\n",
       "      <td>num_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>469</th>\n",
       "      <td>0.168056</td>\n",
       "      <td>0.140759</td>\n",
       "      <td>0.276429</td>\n",
       "      <td>0.350547</td>\n",
       "      <td>0.397581</td>\n",
       "      <td>0.397581</td>\n",
       "      <td>5</td>\n",
       "      <td>hitpoints</td>\n",
       "      <td>num_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>470</th>\n",
       "      <td>0.129522</td>\n",
       "      <td>0.150179</td>\n",
       "      <td>0.277385</td>\n",
       "      <td>0.355320</td>\n",
       "      <td>0.370806</td>\n",
       "      <td>0.370806</td>\n",
       "      <td>5</td>\n",
       "      <td>damage</td>\n",
       "      <td>num_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>471</th>\n",
       "      <td>0.108243</td>\n",
       "      <td>0.142353</td>\n",
       "      <td>0.293945</td>\n",
       "      <td>0.363255</td>\n",
       "      <td>0.350457</td>\n",
       "      <td>0.350457</td>\n",
       "      <td>5</td>\n",
       "      <td>attack_count</td>\n",
       "      <td>num_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>472</th>\n",
       "      <td>-0.044428</td>\n",
       "      <td>0.141116</td>\n",
       "      <td>0.276429</td>\n",
       "      <td>0.350547</td>\n",
       "      <td>0.392591</td>\n",
       "      <td>0.392591</td>\n",
       "      <td>5</td>\n",
       "      <td>range</td>\n",
       "      <td>num_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>473</th>\n",
       "      <td>0.069220</td>\n",
       "      <td>0.149635</td>\n",
       "      <td>0.276429</td>\n",
       "      <td>0.350547</td>\n",
       "      <td>0.386803</td>\n",
       "      <td>0.386803</td>\n",
       "      <td>5</td>\n",
       "      <td>speed</td>\n",
       "      <td>num_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>474</th>\n",
       "      <td>-0.016587</td>\n",
       "      <td>0.153734</td>\n",
       "      <td>0.271824</td>\n",
       "      <td>0.373891</td>\n",
       "      <td>0.374910</td>\n",
       "      <td>0.374910</td>\n",
       "      <td>5</td>\n",
       "      <td>damage_per_elixir</td>\n",
       "      <td>num_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>475</th>\n",
       "      <td>0.171036</td>\n",
       "      <td>0.154512</td>\n",
       "      <td>0.276429</td>\n",
       "      <td>0.350547</td>\n",
       "      <td>0.365530</td>\n",
       "      <td>0.365530</td>\n",
       "      <td>5</td>\n",
       "      <td>damage_per_second</td>\n",
       "      <td>num_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>476</th>\n",
       "      <td>0.015937</td>\n",
       "      <td>0.141383</td>\n",
       "      <td>0.084126</td>\n",
       "      <td>0.358651</td>\n",
       "      <td>0.337198</td>\n",
       "      <td>0.337198</td>\n",
       "      <td>5</td>\n",
       "      <td>damage_output</td>\n",
       "      <td>num_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>477</th>\n",
       "      <td>0.149896</td>\n",
       "      <td>0.121266</td>\n",
       "      <td>0.345510</td>\n",
       "      <td>0.398781</td>\n",
       "      <td>0.396858</td>\n",
       "      <td>0.396858</td>\n",
       "      <td>5</td>\n",
       "      <td>hp_per_elixir</td>\n",
       "      <td>num_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>478</th>\n",
       "      <td>-0.031848</td>\n",
       "      <td>0.137396</td>\n",
       "      <td>0.276429</td>\n",
       "      <td>0.350547</td>\n",
       "      <td>0.367318</td>\n",
       "      <td>0.367318</td>\n",
       "      <td>5</td>\n",
       "      <td>damage_by_hitpoints</td>\n",
       "      <td>num_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>479</th>\n",
       "      <td>0.136843</td>\n",
       "      <td>0.159652</td>\n",
       "      <td>0.254193</td>\n",
       "      <td>0.351541</td>\n",
       "      <td>0.386377</td>\n",
       "      <td>0.386377</td>\n",
       "      <td>5</td>\n",
       "      <td>aoe_by_range</td>\n",
       "      <td>num_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>480</th>\n",
       "      <td>0.211469</td>\n",
       "      <td>0.171731</td>\n",
       "      <td>0.288067</td>\n",
       "      <td>0.351742</td>\n",
       "      <td>0.366306</td>\n",
       "      <td>0.366306</td>\n",
       "      <td>5</td>\n",
       "      <td>aoe_by_damage</td>\n",
       "      <td>num_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>481</th>\n",
       "      <td>0.072061</td>\n",
       "      <td>0.127985</td>\n",
       "      <td>0.071334</td>\n",
       "      <td>0.368005</td>\n",
       "      <td>0.363459</td>\n",
       "      <td>0.363459</td>\n",
       "      <td>5</td>\n",
       "      <td>aoe_per_elixir</td>\n",
       "      <td>num_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>482</th>\n",
       "      <td>0.138729</td>\n",
       "      <td>0.138702</td>\n",
       "      <td>0.276429</td>\n",
       "      <td>0.350547</td>\n",
       "      <td>0.387830</td>\n",
       "      <td>0.387830</td>\n",
       "      <td>5</td>\n",
       "      <td>damage_output_ps</td>\n",
       "      <td>num_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>483</th>\n",
       "      <td>0.060864</td>\n",
       "      <td>0.153622</td>\n",
       "      <td>0.330093</td>\n",
       "      <td>0.339213</td>\n",
       "      <td>0.332985</td>\n",
       "      <td>0.332985</td>\n",
       "      <td>5</td>\n",
       "      <td>playable</td>\n",
       "      <td>bool_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>484</th>\n",
       "      <td>0.067365</td>\n",
       "      <td>0.162824</td>\n",
       "      <td>0.390904</td>\n",
       "      <td>0.390904</td>\n",
       "      <td>0.343104</td>\n",
       "      <td>0.343104</td>\n",
       "      <td>5</td>\n",
       "      <td>aoe_bool</td>\n",
       "      <td>bool_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>485</th>\n",
       "      <td>0.070453</td>\n",
       "      <td>0.174998</td>\n",
       "      <td>0.330093</td>\n",
       "      <td>0.339213</td>\n",
       "      <td>0.351055</td>\n",
       "      <td>0.351055</td>\n",
       "      <td>5</td>\n",
       "      <td>death_damage_bool</td>\n",
       "      <td>bool_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>486</th>\n",
       "      <td>0.039336</td>\n",
       "      <td>0.155718</td>\n",
       "      <td>0.330093</td>\n",
       "      <td>0.339213</td>\n",
       "      <td>0.311537</td>\n",
       "      <td>0.311537</td>\n",
       "      <td>5</td>\n",
       "      <td>fly_bool</td>\n",
       "      <td>bool_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>487</th>\n",
       "      <td>0.064510</td>\n",
       "      <td>0.149837</td>\n",
       "      <td>0.361144</td>\n",
       "      <td>0.361144</td>\n",
       "      <td>0.320906</td>\n",
       "      <td>0.320906</td>\n",
       "      <td>5</td>\n",
       "      <td>spawn_bool</td>\n",
       "      <td>bool_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>488</th>\n",
       "      <td>0.139950</td>\n",
       "      <td>0.150257</td>\n",
       "      <td>0.340254</td>\n",
       "      <td>0.349724</td>\n",
       "      <td>0.295282</td>\n",
       "      <td>0.295282</td>\n",
       "      <td>5</td>\n",
       "      <td>special_damage</td>\n",
       "      <td>bool_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>489</th>\n",
       "      <td>0.108116</td>\n",
       "      <td>0.162514</td>\n",
       "      <td>0.330093</td>\n",
       "      <td>0.339213</td>\n",
       "      <td>0.311537</td>\n",
       "      <td>0.311537</td>\n",
       "      <td>5</td>\n",
       "      <td>shield_bool</td>\n",
       "      <td>bool_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>490</th>\n",
       "      <td>0.046786</td>\n",
       "      <td>0.159596</td>\n",
       "      <td>0.358266</td>\n",
       "      <td>0.347219</td>\n",
       "      <td>0.304409</td>\n",
       "      <td>0.311218</td>\n",
       "      <td>5</td>\n",
       "      <td>affected_crown</td>\n",
       "      <td>bool_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>491</th>\n",
       "      <td>0.080241</td>\n",
       "      <td>0.157390</td>\n",
       "      <td>0.330093</td>\n",
       "      <td>0.339213</td>\n",
       "      <td>0.311537</td>\n",
       "      <td>0.311537</td>\n",
       "      <td>5</td>\n",
       "      <td>has_lifetime</td>\n",
       "      <td>bool_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>492</th>\n",
       "      <td>0.126221</td>\n",
       "      <td>0.166911</td>\n",
       "      <td>0.330093</td>\n",
       "      <td>0.339213</td>\n",
       "      <td>0.311537</td>\n",
       "      <td>0.311537</td>\n",
       "      <td>5</td>\n",
       "      <td>invisible</td>\n",
       "      <td>bool_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>493</th>\n",
       "      <td>0.110314</td>\n",
       "      <td>0.160405</td>\n",
       "      <td>0.330093</td>\n",
       "      <td>0.339213</td>\n",
       "      <td>0.311537</td>\n",
       "      <td>0.311537</td>\n",
       "      <td>5</td>\n",
       "      <td>has_ability</td>\n",
       "      <td>bool_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>494</th>\n",
       "      <td>0.061682</td>\n",
       "      <td>0.144609</td>\n",
       "      <td>0.330093</td>\n",
       "      <td>0.339213</td>\n",
       "      <td>0.240351</td>\n",
       "      <td>0.297752</td>\n",
       "      <td>5</td>\n",
       "      <td>any_target</td>\n",
       "      <td>bool_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>0.061682</td>\n",
       "      <td>0.144609</td>\n",
       "      <td>0.330093</td>\n",
       "      <td>0.339213</td>\n",
       "      <td>0.236462</td>\n",
       "      <td>0.295411</td>\n",
       "      <td>5</td>\n",
       "      <td>building_target</td>\n",
       "      <td>bool_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>0.056610</td>\n",
       "      <td>0.121950</td>\n",
       "      <td>0.330093</td>\n",
       "      <td>0.339213</td>\n",
       "      <td>0.236462</td>\n",
       "      <td>0.295411</td>\n",
       "      <td>5</td>\n",
       "      <td>ground_target</td>\n",
       "      <td>bool_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>0.063180</td>\n",
       "      <td>0.170334</td>\n",
       "      <td>0.271742</td>\n",
       "      <td>0.294794</td>\n",
       "      <td>0.311537</td>\n",
       "      <td>0.311537</td>\n",
       "      <td>5</td>\n",
       "      <td>has_upon_breaking_spawn</td>\n",
       "      <td>bool_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>0.106294</td>\n",
       "      <td>0.155334</td>\n",
       "      <td>0.330093</td>\n",
       "      <td>0.339213</td>\n",
       "      <td>0.320906</td>\n",
       "      <td>0.320906</td>\n",
       "      <td>5</td>\n",
       "      <td>has_upon_death_spawn</td>\n",
       "      <td>bool_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>0.006772</td>\n",
       "      <td>0.156595</td>\n",
       "      <td>0.364892</td>\n",
       "      <td>0.374380</td>\n",
       "      <td>0.349626</td>\n",
       "      <td>0.349626</td>\n",
       "      <td>5</td>\n",
       "      <td>has_periodic_spawn</td>\n",
       "      <td>bool_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500</th>\n",
       "      <td>0.172237</td>\n",
       "      <td>0.169392</td>\n",
       "      <td>0.343251</td>\n",
       "      <td>0.354560</td>\n",
       "      <td>0.309750</td>\n",
       "      <td>0.309750</td>\n",
       "      <td>5</td>\n",
       "      <td>single_damage_type</td>\n",
       "      <td>bool_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501</th>\n",
       "      <td>0.094856</td>\n",
       "      <td>0.156382</td>\n",
       "      <td>0.330093</td>\n",
       "      <td>0.339213</td>\n",
       "      <td>0.311537</td>\n",
       "      <td>0.311537</td>\n",
       "      <td>5</td>\n",
       "      <td>is_troop</td>\n",
       "      <td>bool_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>502</th>\n",
       "      <td>0.094856</td>\n",
       "      <td>0.156382</td>\n",
       "      <td>0.330093</td>\n",
       "      <td>0.339213</td>\n",
       "      <td>0.311537</td>\n",
       "      <td>0.311537</td>\n",
       "      <td>5</td>\n",
       "      <td>is_spell</td>\n",
       "      <td>bool_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503</th>\n",
       "      <td>0.094856</td>\n",
       "      <td>0.156382</td>\n",
       "      <td>0.330093</td>\n",
       "      <td>0.339213</td>\n",
       "      <td>0.311537</td>\n",
       "      <td>0.311537</td>\n",
       "      <td>5</td>\n",
       "      <td>is_building</td>\n",
       "      <td>bool_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>504</th>\n",
       "      <td>0.094856</td>\n",
       "      <td>0.156382</td>\n",
       "      <td>0.330093</td>\n",
       "      <td>0.339213</td>\n",
       "      <td>0.311537</td>\n",
       "      <td>0.311537</td>\n",
       "      <td>5</td>\n",
       "      <td>is_tower_troop</td>\n",
       "      <td>bool_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>505</th>\n",
       "      <td>0.075756</td>\n",
       "      <td>0.157046</td>\n",
       "      <td>0.296429</td>\n",
       "      <td>0.361211</td>\n",
       "      <td>0.311537</td>\n",
       "      <td>0.311537</td>\n",
       "      <td>5</td>\n",
       "      <td>is_spawned</td>\n",
       "      <td>bool_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>506</th>\n",
       "      <td>0.090128</td>\n",
       "      <td>0.147893</td>\n",
       "      <td>0.330093</td>\n",
       "      <td>0.339213</td>\n",
       "      <td>0.263281</td>\n",
       "      <td>0.340491</td>\n",
       "      <td>5</td>\n",
       "      <td>has_ranged_attack</td>\n",
       "      <td>bool_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>507</th>\n",
       "      <td>0.112166</td>\n",
       "      <td>0.169524</td>\n",
       "      <td>0.342406</td>\n",
       "      <td>0.373107</td>\n",
       "      <td>0.308318</td>\n",
       "      <td>0.308318</td>\n",
       "      <td>5</td>\n",
       "      <td>special_attack_type</td>\n",
       "      <td>bool_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>508</th>\n",
       "      <td>0.050206</td>\n",
       "      <td>0.163046</td>\n",
       "      <td>0.391588</td>\n",
       "      <td>0.432696</td>\n",
       "      <td>0.342148</td>\n",
       "      <td>0.342148</td>\n",
       "      <td>5</td>\n",
       "      <td>has_friendly_buff</td>\n",
       "      <td>bool_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>509</th>\n",
       "      <td>0.060864</td>\n",
       "      <td>0.153622</td>\n",
       "      <td>0.330093</td>\n",
       "      <td>0.339213</td>\n",
       "      <td>0.332985</td>\n",
       "      <td>0.332985</td>\n",
       "      <td>5</td>\n",
       "      <td>is_free_card</td>\n",
       "      <td>bool_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>510</th>\n",
       "      <td>0.001666</td>\n",
       "      <td>0.161417</td>\n",
       "      <td>0.330093</td>\n",
       "      <td>0.339213</td>\n",
       "      <td>0.309750</td>\n",
       "      <td>0.309750</td>\n",
       "      <td>5</td>\n",
       "      <td>no_hit_speed</td>\n",
       "      <td>bool_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>511</th>\n",
       "      <td>-0.037347</td>\n",
       "      <td>0.148170</td>\n",
       "      <td>0.318916</td>\n",
       "      <td>0.318916</td>\n",
       "      <td>0.302115</td>\n",
       "      <td>0.302115</td>\n",
       "      <td>5</td>\n",
       "      <td>no_attack</td>\n",
       "      <td>bool_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>512</th>\n",
       "      <td>0.061025</td>\n",
       "      <td>0.163565</td>\n",
       "      <td>0.330093</td>\n",
       "      <td>0.339213</td>\n",
       "      <td>0.311537</td>\n",
       "      <td>0.311537</td>\n",
       "      <td>5</td>\n",
       "      <td>no_hitpoints</td>\n",
       "      <td>bool_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>513</th>\n",
       "      <td>0.077050</td>\n",
       "      <td>0.156981</td>\n",
       "      <td>0.330093</td>\n",
       "      <td>0.339213</td>\n",
       "      <td>0.311537</td>\n",
       "      <td>0.311537</td>\n",
       "      <td>5</td>\n",
       "      <td>win_con</td>\n",
       "      <td>bool_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>514</th>\n",
       "      <td>0.146842</td>\n",
       "      <td>0.162256</td>\n",
       "      <td>0.343393</td>\n",
       "      <td>0.373837</td>\n",
       "      <td>0.295282</td>\n",
       "      <td>0.295282</td>\n",
       "      <td>5</td>\n",
       "      <td>control_special</td>\n",
       "      <td>bool_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>515</th>\n",
       "      <td>0.112279</td>\n",
       "      <td>0.170520</td>\n",
       "      <td>0.360382</td>\n",
       "      <td>0.365106</td>\n",
       "      <td>0.311537</td>\n",
       "      <td>0.311537</td>\n",
       "      <td>5</td>\n",
       "      <td>dps_special</td>\n",
       "      <td>bool_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>516</th>\n",
       "      <td>0.059870</td>\n",
       "      <td>0.119097</td>\n",
       "      <td>0.330093</td>\n",
       "      <td>0.339213</td>\n",
       "      <td>0.246536</td>\n",
       "      <td>0.246536</td>\n",
       "      <td>5</td>\n",
       "      <td>air_control</td>\n",
       "      <td>bool_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>517</th>\n",
       "      <td>0.042818</td>\n",
       "      <td>0.152494</td>\n",
       "      <td>0.330093</td>\n",
       "      <td>0.339213</td>\n",
       "      <td>0.313840</td>\n",
       "      <td>0.313840</td>\n",
       "      <td>5</td>\n",
       "      <td>ground_dps</td>\n",
       "      <td>bool_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>518</th>\n",
       "      <td>-0.019160</td>\n",
       "      <td>0.165140</td>\n",
       "      <td>0.330093</td>\n",
       "      <td>0.339213</td>\n",
       "      <td>0.311537</td>\n",
       "      <td>0.311537</td>\n",
       "      <td>5</td>\n",
       "      <td>win_con_dmg</td>\n",
       "      <td>bool_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>519</th>\n",
       "      <td>0.003438</td>\n",
       "      <td>0.168484</td>\n",
       "      <td>0.315524</td>\n",
       "      <td>0.315524</td>\n",
       "      <td>0.319391</td>\n",
       "      <td>0.319391</td>\n",
       "      <td>5</td>\n",
       "      <td>high_dps</td>\n",
       "      <td>bool_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>520</th>\n",
       "      <td>0.076141</td>\n",
       "      <td>0.154155</td>\n",
       "      <td>0.276683</td>\n",
       "      <td>0.335843</td>\n",
       "      <td>0.302115</td>\n",
       "      <td>0.302115</td>\n",
       "      <td>5</td>\n",
       "      <td>support</td>\n",
       "      <td>bool_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>521</th>\n",
       "      <td>0.083192</td>\n",
       "      <td>0.164867</td>\n",
       "      <td>0.330093</td>\n",
       "      <td>0.339213</td>\n",
       "      <td>0.311537</td>\n",
       "      <td>0.311537</td>\n",
       "      <td>5</td>\n",
       "      <td>mini_tank</td>\n",
       "      <td>bool_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>522</th>\n",
       "      <td>0.092415</td>\n",
       "      <td>0.108209</td>\n",
       "      <td>0.207409</td>\n",
       "      <td>0.203593</td>\n",
       "      <td>0.278201</td>\n",
       "      <td>0.278201</td>\n",
       "      <td>6</td>\n",
       "      <td>playable</td>\n",
       "      <td>all_col</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>523</th>\n",
       "      <td>0.030577</td>\n",
       "      <td>0.124768</td>\n",
       "      <td>0.183901</td>\n",
       "      <td>0.183910</td>\n",
       "      <td>0.260968</td>\n",
       "      <td>0.260968</td>\n",
       "      <td>6</td>\n",
       "      <td>aoe_bool</td>\n",
       "      <td>all_col</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>524</th>\n",
       "      <td>0.066137</td>\n",
       "      <td>0.129663</td>\n",
       "      <td>0.211258</td>\n",
       "      <td>0.219338</td>\n",
       "      <td>0.262127</td>\n",
       "      <td>0.262127</td>\n",
       "      <td>6</td>\n",
       "      <td>aoe_radius</td>\n",
       "      <td>all_col</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>525</th>\n",
       "      <td>0.026713</td>\n",
       "      <td>0.118359</td>\n",
       "      <td>0.207409</td>\n",
       "      <td>0.203593</td>\n",
       "      <td>0.282985</td>\n",
       "      <td>0.282985</td>\n",
       "      <td>6</td>\n",
       "      <td>death_damage_bool</td>\n",
       "      <td>all_col</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>526</th>\n",
       "      <td>0.043035</td>\n",
       "      <td>0.129696</td>\n",
       "      <td>0.207409</td>\n",
       "      <td>0.203593</td>\n",
       "      <td>0.265692</td>\n",
       "      <td>0.265692</td>\n",
       "      <td>6</td>\n",
       "      <td>fly_bool</td>\n",
       "      <td>all_col</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>527</th>\n",
       "      <td>0.054439</td>\n",
       "      <td>0.109120</td>\n",
       "      <td>0.201549</td>\n",
       "      <td>0.217234</td>\n",
       "      <td>0.270252</td>\n",
       "      <td>0.270252</td>\n",
       "      <td>6</td>\n",
       "      <td>spawn_bool</td>\n",
       "      <td>all_col</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>528</th>\n",
       "      <td>0.043394</td>\n",
       "      <td>0.127532</td>\n",
       "      <td>0.204417</td>\n",
       "      <td>0.204417</td>\n",
       "      <td>0.277512</td>\n",
       "      <td>0.277512</td>\n",
       "      <td>6</td>\n",
       "      <td>can_evolve</td>\n",
       "      <td>all_col</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>529</th>\n",
       "      <td>-0.030416</td>\n",
       "      <td>0.102473</td>\n",
       "      <td>0.153505</td>\n",
       "      <td>0.209035</td>\n",
       "      <td>0.281054</td>\n",
       "      <td>0.281054</td>\n",
       "      <td>6</td>\n",
       "      <td>elixircost</td>\n",
       "      <td>all_col</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>530</th>\n",
       "      <td>-0.013314</td>\n",
       "      <td>0.115786</td>\n",
       "      <td>0.207409</td>\n",
       "      <td>0.203593</td>\n",
       "      <td>0.273871</td>\n",
       "      <td>0.273871</td>\n",
       "      <td>6</td>\n",
       "      <td>hit_speed</td>\n",
       "      <td>all_col</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>531</th>\n",
       "      <td>0.004773</td>\n",
       "      <td>0.133934</td>\n",
       "      <td>0.208311</td>\n",
       "      <td>0.186604</td>\n",
       "      <td>0.261859</td>\n",
       "      <td>0.261859</td>\n",
       "      <td>6</td>\n",
       "      <td>special_damage</td>\n",
       "      <td>all_col</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>532</th>\n",
       "      <td>0.059555</td>\n",
       "      <td>0.094987</td>\n",
       "      <td>0.207409</td>\n",
       "      <td>0.203593</td>\n",
       "      <td>0.265692</td>\n",
       "      <td>0.265692</td>\n",
       "      <td>6</td>\n",
       "      <td>count</td>\n",
       "      <td>all_col</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>533</th>\n",
       "      <td>0.081726</td>\n",
       "      <td>0.128172</td>\n",
       "      <td>0.207409</td>\n",
       "      <td>0.203593</td>\n",
       "      <td>0.270103</td>\n",
       "      <td>0.270103</td>\n",
       "      <td>6</td>\n",
       "      <td>hitpoints</td>\n",
       "      <td>all_col</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>534</th>\n",
       "      <td>0.091520</td>\n",
       "      <td>0.097222</td>\n",
       "      <td>0.207409</td>\n",
       "      <td>0.203593</td>\n",
       "      <td>0.265692</td>\n",
       "      <td>0.265692</td>\n",
       "      <td>6</td>\n",
       "      <td>shield_bool</td>\n",
       "      <td>all_col</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>535</th>\n",
       "      <td>0.041937</td>\n",
       "      <td>0.129442</td>\n",
       "      <td>0.101750</td>\n",
       "      <td>0.199974</td>\n",
       "      <td>0.261819</td>\n",
       "      <td>0.261819</td>\n",
       "      <td>6</td>\n",
       "      <td>damage</td>\n",
       "      <td>all_col</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>536</th>\n",
       "      <td>0.025878</td>\n",
       "      <td>0.117753</td>\n",
       "      <td>0.163722</td>\n",
       "      <td>0.208042</td>\n",
       "      <td>0.258607</td>\n",
       "      <td>0.258607</td>\n",
       "      <td>6</td>\n",
       "      <td>attack_count</td>\n",
       "      <td>all_col</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>537</th>\n",
       "      <td>0.051882</td>\n",
       "      <td>0.117608</td>\n",
       "      <td>0.207409</td>\n",
       "      <td>0.203593</td>\n",
       "      <td>0.263995</td>\n",
       "      <td>0.263995</td>\n",
       "      <td>6</td>\n",
       "      <td>range</td>\n",
       "      <td>all_col</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>538</th>\n",
       "      <td>0.020621</td>\n",
       "      <td>0.135287</td>\n",
       "      <td>0.196992</td>\n",
       "      <td>0.213148</td>\n",
       "      <td>0.256772</td>\n",
       "      <td>0.256772</td>\n",
       "      <td>6</td>\n",
       "      <td>affected_crown</td>\n",
       "      <td>all_col</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>539</th>\n",
       "      <td>-0.026500</td>\n",
       "      <td>0.109176</td>\n",
       "      <td>0.207409</td>\n",
       "      <td>0.203593</td>\n",
       "      <td>0.265692</td>\n",
       "      <td>0.265692</td>\n",
       "      <td>6</td>\n",
       "      <td>has_lifetime</td>\n",
       "      <td>all_col</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>540</th>\n",
       "      <td>0.071044</td>\n",
       "      <td>0.111078</td>\n",
       "      <td>0.207409</td>\n",
       "      <td>0.203593</td>\n",
       "      <td>0.265692</td>\n",
       "      <td>0.265692</td>\n",
       "      <td>6</td>\n",
       "      <td>invisible</td>\n",
       "      <td>all_col</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>541</th>\n",
       "      <td>0.078522</td>\n",
       "      <td>0.099301</td>\n",
       "      <td>0.207409</td>\n",
       "      <td>0.203593</td>\n",
       "      <td>0.265692</td>\n",
       "      <td>0.265692</td>\n",
       "      <td>6</td>\n",
       "      <td>has_ability</td>\n",
       "      <td>all_col</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>542</th>\n",
       "      <td>0.060227</td>\n",
       "      <td>0.110946</td>\n",
       "      <td>0.207409</td>\n",
       "      <td>0.203593</td>\n",
       "      <td>0.279389</td>\n",
       "      <td>0.279389</td>\n",
       "      <td>6</td>\n",
       "      <td>any_target</td>\n",
       "      <td>all_col</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>543</th>\n",
       "      <td>0.060227</td>\n",
       "      <td>0.110946</td>\n",
       "      <td>0.207409</td>\n",
       "      <td>0.203593</td>\n",
       "      <td>0.274926</td>\n",
       "      <td>0.274926</td>\n",
       "      <td>6</td>\n",
       "      <td>building_target</td>\n",
       "      <td>all_col</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>544</th>\n",
       "      <td>0.051358</td>\n",
       "      <td>0.102651</td>\n",
       "      <td>0.207409</td>\n",
       "      <td>0.203593</td>\n",
       "      <td>0.274926</td>\n",
       "      <td>0.274926</td>\n",
       "      <td>6</td>\n",
       "      <td>ground_target</td>\n",
       "      <td>all_col</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>545</th>\n",
       "      <td>0.042195</td>\n",
       "      <td>0.129197</td>\n",
       "      <td>0.226141</td>\n",
       "      <td>0.226141</td>\n",
       "      <td>0.265692</td>\n",
       "      <td>0.265692</td>\n",
       "      <td>6</td>\n",
       "      <td>has_upon_breaking_spawn</td>\n",
       "      <td>all_col</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>546</th>\n",
       "      <td>0.041674</td>\n",
       "      <td>0.120306</td>\n",
       "      <td>0.207409</td>\n",
       "      <td>0.203593</td>\n",
       "      <td>0.270252</td>\n",
       "      <td>0.270252</td>\n",
       "      <td>6</td>\n",
       "      <td>has_upon_death_spawn</td>\n",
       "      <td>all_col</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>547</th>\n",
       "      <td>0.058861</td>\n",
       "      <td>0.116792</td>\n",
       "      <td>0.190657</td>\n",
       "      <td>0.224398</td>\n",
       "      <td>0.278135</td>\n",
       "      <td>0.278135</td>\n",
       "      <td>6</td>\n",
       "      <td>has_periodic_spawn</td>\n",
       "      <td>all_col</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>548</th>\n",
       "      <td>0.012194</td>\n",
       "      <td>0.122371</td>\n",
       "      <td>0.126147</td>\n",
       "      <td>0.192683</td>\n",
       "      <td>0.269602</td>\n",
       "      <td>0.269602</td>\n",
       "      <td>6</td>\n",
       "      <td>single_damage_type</td>\n",
       "      <td>all_col</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>549</th>\n",
       "      <td>0.062020</td>\n",
       "      <td>0.117054</td>\n",
       "      <td>0.207409</td>\n",
       "      <td>0.203593</td>\n",
       "      <td>0.265692</td>\n",
       "      <td>0.265692</td>\n",
       "      <td>6</td>\n",
       "      <td>is_troop</td>\n",
       "      <td>all_col</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>550</th>\n",
       "      <td>0.062020</td>\n",
       "      <td>0.117054</td>\n",
       "      <td>0.207409</td>\n",
       "      <td>0.203593</td>\n",
       "      <td>0.265692</td>\n",
       "      <td>0.265692</td>\n",
       "      <td>6</td>\n",
       "      <td>is_spell</td>\n",
       "      <td>all_col</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>551</th>\n",
       "      <td>0.062020</td>\n",
       "      <td>0.117054</td>\n",
       "      <td>0.207409</td>\n",
       "      <td>0.203593</td>\n",
       "      <td>0.265692</td>\n",
       "      <td>0.265692</td>\n",
       "      <td>6</td>\n",
       "      <td>is_building</td>\n",
       "      <td>all_col</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>552</th>\n",
       "      <td>0.062020</td>\n",
       "      <td>0.117054</td>\n",
       "      <td>0.207409</td>\n",
       "      <td>0.203593</td>\n",
       "      <td>0.265692</td>\n",
       "      <td>0.265692</td>\n",
       "      <td>6</td>\n",
       "      <td>is_tower_troop</td>\n",
       "      <td>all_col</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>553</th>\n",
       "      <td>-0.138748</td>\n",
       "      <td>0.110276</td>\n",
       "      <td>0.173570</td>\n",
       "      <td>0.193385</td>\n",
       "      <td>0.265692</td>\n",
       "      <td>0.265692</td>\n",
       "      <td>6</td>\n",
       "      <td>is_spawned</td>\n",
       "      <td>all_col</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>554</th>\n",
       "      <td>0.020397</td>\n",
       "      <td>0.123837</td>\n",
       "      <td>0.207409</td>\n",
       "      <td>0.203593</td>\n",
       "      <td>0.265692</td>\n",
       "      <td>0.265692</td>\n",
       "      <td>6</td>\n",
       "      <td>speed</td>\n",
       "      <td>all_col</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>555</th>\n",
       "      <td>0.048003</td>\n",
       "      <td>0.120696</td>\n",
       "      <td>0.207409</td>\n",
       "      <td>0.203593</td>\n",
       "      <td>0.272282</td>\n",
       "      <td>0.272282</td>\n",
       "      <td>6</td>\n",
       "      <td>has_ranged_attack</td>\n",
       "      <td>all_col</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>556</th>\n",
       "      <td>0.022520</td>\n",
       "      <td>0.094966</td>\n",
       "      <td>0.159639</td>\n",
       "      <td>0.187227</td>\n",
       "      <td>0.273327</td>\n",
       "      <td>0.273327</td>\n",
       "      <td>6</td>\n",
       "      <td>special_attack_type</td>\n",
       "      <td>all_col</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>557</th>\n",
       "      <td>0.036818</td>\n",
       "      <td>0.116378</td>\n",
       "      <td>0.197835</td>\n",
       "      <td>0.239227</td>\n",
       "      <td>0.288635</td>\n",
       "      <td>0.288635</td>\n",
       "      <td>6</td>\n",
       "      <td>has_friendly_buff</td>\n",
       "      <td>all_col</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>558</th>\n",
       "      <td>0.092415</td>\n",
       "      <td>0.108209</td>\n",
       "      <td>0.207409</td>\n",
       "      <td>0.203593</td>\n",
       "      <td>0.278201</td>\n",
       "      <td>0.278201</td>\n",
       "      <td>6</td>\n",
       "      <td>is_free_card</td>\n",
       "      <td>all_col</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>559</th>\n",
       "      <td>0.014213</td>\n",
       "      <td>0.102577</td>\n",
       "      <td>0.207409</td>\n",
       "      <td>0.203593</td>\n",
       "      <td>0.262482</td>\n",
       "      <td>0.262482</td>\n",
       "      <td>6</td>\n",
       "      <td>no_hit_speed</td>\n",
       "      <td>all_col</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>560</th>\n",
       "      <td>0.059238</td>\n",
       "      <td>0.135021</td>\n",
       "      <td>0.174570</td>\n",
       "      <td>0.194280</td>\n",
       "      <td>0.258607</td>\n",
       "      <td>0.258607</td>\n",
       "      <td>6</td>\n",
       "      <td>no_attack</td>\n",
       "      <td>all_col</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>561</th>\n",
       "      <td>-0.008812</td>\n",
       "      <td>0.120076</td>\n",
       "      <td>0.207409</td>\n",
       "      <td>0.203593</td>\n",
       "      <td>0.265692</td>\n",
       "      <td>0.265692</td>\n",
       "      <td>6</td>\n",
       "      <td>no_hitpoints</td>\n",
       "      <td>all_col</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>562</th>\n",
       "      <td>0.059634</td>\n",
       "      <td>0.123432</td>\n",
       "      <td>0.177956</td>\n",
       "      <td>0.182440</td>\n",
       "      <td>0.272099</td>\n",
       "      <td>0.272099</td>\n",
       "      <td>6</td>\n",
       "      <td>damage_per_elixir</td>\n",
       "      <td>all_col</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>563</th>\n",
       "      <td>-0.009911</td>\n",
       "      <td>0.113166</td>\n",
       "      <td>0.207409</td>\n",
       "      <td>0.203593</td>\n",
       "      <td>0.263002</td>\n",
       "      <td>0.263002</td>\n",
       "      <td>6</td>\n",
       "      <td>damage_per_second</td>\n",
       "      <td>all_col</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>564</th>\n",
       "      <td>0.033912</td>\n",
       "      <td>0.095265</td>\n",
       "      <td>0.192802</td>\n",
       "      <td>0.231553</td>\n",
       "      <td>0.252306</td>\n",
       "      <td>0.252306</td>\n",
       "      <td>6</td>\n",
       "      <td>damage_output</td>\n",
       "      <td>all_col</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>565</th>\n",
       "      <td>-0.011167</td>\n",
       "      <td>0.086857</td>\n",
       "      <td>0.205091</td>\n",
       "      <td>0.205091</td>\n",
       "      <td>0.271280</td>\n",
       "      <td>0.271280</td>\n",
       "      <td>6</td>\n",
       "      <td>hp_per_elixir</td>\n",
       "      <td>all_col</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566</th>\n",
       "      <td>-0.005227</td>\n",
       "      <td>0.093350</td>\n",
       "      <td>0.207409</td>\n",
       "      <td>0.203593</td>\n",
       "      <td>0.261899</td>\n",
       "      <td>0.261899</td>\n",
       "      <td>6</td>\n",
       "      <td>damage_by_hitpoints</td>\n",
       "      <td>all_col</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>567</th>\n",
       "      <td>0.066005</td>\n",
       "      <td>0.095368</td>\n",
       "      <td>0.211258</td>\n",
       "      <td>0.219338</td>\n",
       "      <td>0.261383</td>\n",
       "      <td>0.261383</td>\n",
       "      <td>6</td>\n",
       "      <td>aoe_by_range</td>\n",
       "      <td>all_col</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568</th>\n",
       "      <td>-0.015855</td>\n",
       "      <td>0.129001</td>\n",
       "      <td>0.101770</td>\n",
       "      <td>0.201102</td>\n",
       "      <td>0.263602</td>\n",
       "      <td>0.263602</td>\n",
       "      <td>6</td>\n",
       "      <td>aoe_by_damage</td>\n",
       "      <td>all_col</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>569</th>\n",
       "      <td>0.063996</td>\n",
       "      <td>0.117134</td>\n",
       "      <td>0.207409</td>\n",
       "      <td>0.203593</td>\n",
       "      <td>0.265692</td>\n",
       "      <td>0.265692</td>\n",
       "      <td>6</td>\n",
       "      <td>win_con</td>\n",
       "      <td>all_col</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>570</th>\n",
       "      <td>0.027669</td>\n",
       "      <td>0.124851</td>\n",
       "      <td>0.221166</td>\n",
       "      <td>0.224416</td>\n",
       "      <td>0.262127</td>\n",
       "      <td>0.262127</td>\n",
       "      <td>6</td>\n",
       "      <td>aoe_per_elixir</td>\n",
       "      <td>all_col</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>571</th>\n",
       "      <td>0.070918</td>\n",
       "      <td>0.120819</td>\n",
       "      <td>0.206900</td>\n",
       "      <td>0.206900</td>\n",
       "      <td>0.261859</td>\n",
       "      <td>0.261859</td>\n",
       "      <td>6</td>\n",
       "      <td>control_special</td>\n",
       "      <td>all_col</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>572</th>\n",
       "      <td>0.028616</td>\n",
       "      <td>0.133892</td>\n",
       "      <td>0.156650</td>\n",
       "      <td>0.203774</td>\n",
       "      <td>0.265692</td>\n",
       "      <td>0.265692</td>\n",
       "      <td>6</td>\n",
       "      <td>dps_special</td>\n",
       "      <td>all_col</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>573</th>\n",
       "      <td>0.018360</td>\n",
       "      <td>0.120005</td>\n",
       "      <td>0.207409</td>\n",
       "      <td>0.203593</td>\n",
       "      <td>0.279199</td>\n",
       "      <td>0.279199</td>\n",
       "      <td>6</td>\n",
       "      <td>air_control</td>\n",
       "      <td>all_col</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>574</th>\n",
       "      <td>0.016424</td>\n",
       "      <td>0.126147</td>\n",
       "      <td>0.207409</td>\n",
       "      <td>0.203593</td>\n",
       "      <td>0.270966</td>\n",
       "      <td>0.270966</td>\n",
       "      <td>6</td>\n",
       "      <td>ground_dps</td>\n",
       "      <td>all_col</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>575</th>\n",
       "      <td>0.087924</td>\n",
       "      <td>0.128066</td>\n",
       "      <td>0.207409</td>\n",
       "      <td>0.203593</td>\n",
       "      <td>0.265692</td>\n",
       "      <td>0.265692</td>\n",
       "      <td>6</td>\n",
       "      <td>win_con_dmg</td>\n",
       "      <td>all_col</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>576</th>\n",
       "      <td>0.117448</td>\n",
       "      <td>0.118199</td>\n",
       "      <td>0.157139</td>\n",
       "      <td>0.195688</td>\n",
       "      <td>0.261090</td>\n",
       "      <td>0.261090</td>\n",
       "      <td>6</td>\n",
       "      <td>high_dps</td>\n",
       "      <td>all_col</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>577</th>\n",
       "      <td>0.012604</td>\n",
       "      <td>0.093334</td>\n",
       "      <td>0.207409</td>\n",
       "      <td>0.203593</td>\n",
       "      <td>0.261565</td>\n",
       "      <td>0.261565</td>\n",
       "      <td>6</td>\n",
       "      <td>damage_output_ps</td>\n",
       "      <td>all_col</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>578</th>\n",
       "      <td>0.024615</td>\n",
       "      <td>0.107744</td>\n",
       "      <td>0.157473</td>\n",
       "      <td>0.207249</td>\n",
       "      <td>0.258607</td>\n",
       "      <td>0.258607</td>\n",
       "      <td>6</td>\n",
       "      <td>support</td>\n",
       "      <td>all_col</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>579</th>\n",
       "      <td>0.014063</td>\n",
       "      <td>0.122689</td>\n",
       "      <td>0.207409</td>\n",
       "      <td>0.203593</td>\n",
       "      <td>0.265692</td>\n",
       "      <td>0.265692</td>\n",
       "      <td>6</td>\n",
       "      <td>mini_tank</td>\n",
       "      <td>all_col</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>580</th>\n",
       "      <td>0.129871</td>\n",
       "      <td>0.273063</td>\n",
       "      <td>0.169976</td>\n",
       "      <td>0.470936</td>\n",
       "      <td>0.565772</td>\n",
       "      <td>0.565772</td>\n",
       "      <td>6</td>\n",
       "      <td>damage_per_elixir</td>\n",
       "      <td>engineered</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>581</th>\n",
       "      <td>0.213485</td>\n",
       "      <td>0.277090</td>\n",
       "      <td>0.165137</td>\n",
       "      <td>0.495681</td>\n",
       "      <td>0.568255</td>\n",
       "      <td>0.568255</td>\n",
       "      <td>6</td>\n",
       "      <td>damage_per_second</td>\n",
       "      <td>engineered</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>582</th>\n",
       "      <td>0.155438</td>\n",
       "      <td>0.293943</td>\n",
       "      <td>0.299816</td>\n",
       "      <td>0.493309</td>\n",
       "      <td>0.514241</td>\n",
       "      <td>0.514241</td>\n",
       "      <td>6</td>\n",
       "      <td>damage_output</td>\n",
       "      <td>engineered</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>583</th>\n",
       "      <td>0.192755</td>\n",
       "      <td>0.317003</td>\n",
       "      <td>0.092793</td>\n",
       "      <td>0.401288</td>\n",
       "      <td>0.565909</td>\n",
       "      <td>0.565909</td>\n",
       "      <td>6</td>\n",
       "      <td>hp_per_elixir</td>\n",
       "      <td>engineered</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>584</th>\n",
       "      <td>0.150591</td>\n",
       "      <td>0.279608</td>\n",
       "      <td>0.165137</td>\n",
       "      <td>0.495681</td>\n",
       "      <td>0.550193</td>\n",
       "      <td>0.550193</td>\n",
       "      <td>6</td>\n",
       "      <td>damage_by_hitpoints</td>\n",
       "      <td>engineered</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>585</th>\n",
       "      <td>-0.169894</td>\n",
       "      <td>0.256951</td>\n",
       "      <td>0.332727</td>\n",
       "      <td>0.504181</td>\n",
       "      <td>0.545525</td>\n",
       "      <td>0.545525</td>\n",
       "      <td>6</td>\n",
       "      <td>aoe_by_range</td>\n",
       "      <td>engineered</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>586</th>\n",
       "      <td>-0.100141</td>\n",
       "      <td>0.248947</td>\n",
       "      <td>0.343976</td>\n",
       "      <td>0.469337</td>\n",
       "      <td>0.554646</td>\n",
       "      <td>0.554646</td>\n",
       "      <td>6</td>\n",
       "      <td>aoe_by_damage</td>\n",
       "      <td>engineered</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>587</th>\n",
       "      <td>-0.115937</td>\n",
       "      <td>0.123265</td>\n",
       "      <td>0.246536</td>\n",
       "      <td>0.246536</td>\n",
       "      <td>0.234724</td>\n",
       "      <td>0.234724</td>\n",
       "      <td>6</td>\n",
       "      <td>playable</td>\n",
       "      <td>original</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>588</th>\n",
       "      <td>-0.096004</td>\n",
       "      <td>0.131804</td>\n",
       "      <td>0.248604</td>\n",
       "      <td>0.248604</td>\n",
       "      <td>0.228556</td>\n",
       "      <td>0.228556</td>\n",
       "      <td>6</td>\n",
       "      <td>aoe_bool</td>\n",
       "      <td>original</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>589</th>\n",
       "      <td>0.080004</td>\n",
       "      <td>0.148884</td>\n",
       "      <td>0.259574</td>\n",
       "      <td>0.259574</td>\n",
       "      <td>0.229989</td>\n",
       "      <td>0.229989</td>\n",
       "      <td>6</td>\n",
       "      <td>aoe_radius</td>\n",
       "      <td>original</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>590</th>\n",
       "      <td>0.036666</td>\n",
       "      <td>0.131878</td>\n",
       "      <td>0.246536</td>\n",
       "      <td>0.246536</td>\n",
       "      <td>0.268314</td>\n",
       "      <td>0.268314</td>\n",
       "      <td>6</td>\n",
       "      <td>death_damage_bool</td>\n",
       "      <td>original</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>591</th>\n",
       "      <td>0.038068</td>\n",
       "      <td>0.141108</td>\n",
       "      <td>0.246536</td>\n",
       "      <td>0.246536</td>\n",
       "      <td>0.235857</td>\n",
       "      <td>0.235857</td>\n",
       "      <td>6</td>\n",
       "      <td>fly_bool</td>\n",
       "      <td>original</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>592</th>\n",
       "      <td>-0.071475</td>\n",
       "      <td>0.132967</td>\n",
       "      <td>0.236678</td>\n",
       "      <td>0.236678</td>\n",
       "      <td>0.241251</td>\n",
       "      <td>0.241251</td>\n",
       "      <td>6</td>\n",
       "      <td>spawn_bool</td>\n",
       "      <td>original</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>593</th>\n",
       "      <td>0.002263</td>\n",
       "      <td>0.140651</td>\n",
       "      <td>0.254227</td>\n",
       "      <td>0.254227</td>\n",
       "      <td>0.235819</td>\n",
       "      <td>0.235819</td>\n",
       "      <td>6</td>\n",
       "      <td>can_evolve</td>\n",
       "      <td>original</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>594</th>\n",
       "      <td>-0.029269</td>\n",
       "      <td>0.127101</td>\n",
       "      <td>0.237280</td>\n",
       "      <td>0.245568</td>\n",
       "      <td>0.261562</td>\n",
       "      <td>0.261562</td>\n",
       "      <td>6</td>\n",
       "      <td>elixircost</td>\n",
       "      <td>original</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>595</th>\n",
       "      <td>-0.089385</td>\n",
       "      <td>0.132615</td>\n",
       "      <td>0.246536</td>\n",
       "      <td>0.246536</td>\n",
       "      <td>0.245315</td>\n",
       "      <td>0.245315</td>\n",
       "      <td>6</td>\n",
       "      <td>hit_speed</td>\n",
       "      <td>original</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>596</th>\n",
       "      <td>0.037141</td>\n",
       "      <td>0.126065</td>\n",
       "      <td>0.247653</td>\n",
       "      <td>0.245421</td>\n",
       "      <td>0.226948</td>\n",
       "      <td>0.226948</td>\n",
       "      <td>6</td>\n",
       "      <td>special_damage</td>\n",
       "      <td>original</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>597</th>\n",
       "      <td>0.061333</td>\n",
       "      <td>0.119749</td>\n",
       "      <td>0.246536</td>\n",
       "      <td>0.246536</td>\n",
       "      <td>0.235857</td>\n",
       "      <td>0.235857</td>\n",
       "      <td>6</td>\n",
       "      <td>count</td>\n",
       "      <td>original</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>598</th>\n",
       "      <td>-0.023216</td>\n",
       "      <td>0.124011</td>\n",
       "      <td>0.246536</td>\n",
       "      <td>0.246536</td>\n",
       "      <td>0.256027</td>\n",
       "      <td>0.256027</td>\n",
       "      <td>6</td>\n",
       "      <td>hitpoints</td>\n",
       "      <td>original</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>599</th>\n",
       "      <td>0.089407</td>\n",
       "      <td>0.122401</td>\n",
       "      <td>0.246536</td>\n",
       "      <td>0.246536</td>\n",
       "      <td>0.235857</td>\n",
       "      <td>0.235857</td>\n",
       "      <td>6</td>\n",
       "      <td>shield_bool</td>\n",
       "      <td>original</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>600</th>\n",
       "      <td>0.072346</td>\n",
       "      <td>0.133548</td>\n",
       "      <td>0.235801</td>\n",
       "      <td>0.235801</td>\n",
       "      <td>0.229969</td>\n",
       "      <td>0.229969</td>\n",
       "      <td>6</td>\n",
       "      <td>damage</td>\n",
       "      <td>original</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>601</th>\n",
       "      <td>0.012163</td>\n",
       "      <td>0.113836</td>\n",
       "      <td>0.207836</td>\n",
       "      <td>0.221171</td>\n",
       "      <td>0.227208</td>\n",
       "      <td>0.227208</td>\n",
       "      <td>6</td>\n",
       "      <td>attack_count</td>\n",
       "      <td>original</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>602</th>\n",
       "      <td>0.028911</td>\n",
       "      <td>0.115182</td>\n",
       "      <td>0.246536</td>\n",
       "      <td>0.246536</td>\n",
       "      <td>0.232588</td>\n",
       "      <td>0.232588</td>\n",
       "      <td>6</td>\n",
       "      <td>range</td>\n",
       "      <td>original</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>603</th>\n",
       "      <td>0.020811</td>\n",
       "      <td>0.136276</td>\n",
       "      <td>0.229206</td>\n",
       "      <td>0.229206</td>\n",
       "      <td>0.239476</td>\n",
       "      <td>0.239476</td>\n",
       "      <td>6</td>\n",
       "      <td>affected_crown</td>\n",
       "      <td>original</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>604</th>\n",
       "      <td>0.016866</td>\n",
       "      <td>0.137675</td>\n",
       "      <td>0.246536</td>\n",
       "      <td>0.246536</td>\n",
       "      <td>0.235857</td>\n",
       "      <td>0.235857</td>\n",
       "      <td>6</td>\n",
       "      <td>has_lifetime</td>\n",
       "      <td>original</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>605</th>\n",
       "      <td>0.015234</td>\n",
       "      <td>0.142694</td>\n",
       "      <td>0.246536</td>\n",
       "      <td>0.246536</td>\n",
       "      <td>0.235857</td>\n",
       "      <td>0.235857</td>\n",
       "      <td>6</td>\n",
       "      <td>invisible</td>\n",
       "      <td>original</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>606</th>\n",
       "      <td>0.059498</td>\n",
       "      <td>0.124905</td>\n",
       "      <td>0.246536</td>\n",
       "      <td>0.246536</td>\n",
       "      <td>0.235857</td>\n",
       "      <td>0.235857</td>\n",
       "      <td>6</td>\n",
       "      <td>has_ability</td>\n",
       "      <td>original</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>607</th>\n",
       "      <td>-0.042333</td>\n",
       "      <td>0.128107</td>\n",
       "      <td>0.246536</td>\n",
       "      <td>0.246536</td>\n",
       "      <td>0.251683</td>\n",
       "      <td>0.251683</td>\n",
       "      <td>6</td>\n",
       "      <td>any_target</td>\n",
       "      <td>original</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>608</th>\n",
       "      <td>-0.042333</td>\n",
       "      <td>0.128107</td>\n",
       "      <td>0.246536</td>\n",
       "      <td>0.246536</td>\n",
       "      <td>0.249014</td>\n",
       "      <td>0.249014</td>\n",
       "      <td>6</td>\n",
       "      <td>building_target</td>\n",
       "      <td>original</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>609</th>\n",
       "      <td>-0.043399</td>\n",
       "      <td>0.120614</td>\n",
       "      <td>0.246536</td>\n",
       "      <td>0.246536</td>\n",
       "      <td>0.249014</td>\n",
       "      <td>0.249014</td>\n",
       "      <td>6</td>\n",
       "      <td>ground_target</td>\n",
       "      <td>original</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>610</th>\n",
       "      <td>0.017438</td>\n",
       "      <td>0.129544</td>\n",
       "      <td>0.223411</td>\n",
       "      <td>0.223411</td>\n",
       "      <td>0.235857</td>\n",
       "      <td>0.235857</td>\n",
       "      <td>6</td>\n",
       "      <td>has_upon_breaking_spawn</td>\n",
       "      <td>original</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>611</th>\n",
       "      <td>0.004725</td>\n",
       "      <td>0.130293</td>\n",
       "      <td>0.246536</td>\n",
       "      <td>0.246536</td>\n",
       "      <td>0.241251</td>\n",
       "      <td>0.241251</td>\n",
       "      <td>6</td>\n",
       "      <td>has_upon_death_spawn</td>\n",
       "      <td>original</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>612</th>\n",
       "      <td>0.052777</td>\n",
       "      <td>0.133564</td>\n",
       "      <td>0.271169</td>\n",
       "      <td>0.271169</td>\n",
       "      <td>0.250020</td>\n",
       "      <td>0.250020</td>\n",
       "      <td>6</td>\n",
       "      <td>has_periodic_spawn</td>\n",
       "      <td>original</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>613</th>\n",
       "      <td>0.027834</td>\n",
       "      <td>0.140460</td>\n",
       "      <td>0.200007</td>\n",
       "      <td>0.208782</td>\n",
       "      <td>0.238899</td>\n",
       "      <td>0.238899</td>\n",
       "      <td>6</td>\n",
       "      <td>single_damage_type</td>\n",
       "      <td>original</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>614</th>\n",
       "      <td>-0.005989</td>\n",
       "      <td>0.128067</td>\n",
       "      <td>0.246536</td>\n",
       "      <td>0.246536</td>\n",
       "      <td>0.235857</td>\n",
       "      <td>0.235857</td>\n",
       "      <td>6</td>\n",
       "      <td>is_troop</td>\n",
       "      <td>original</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>615</th>\n",
       "      <td>-0.005989</td>\n",
       "      <td>0.128067</td>\n",
       "      <td>0.246536</td>\n",
       "      <td>0.246536</td>\n",
       "      <td>0.235857</td>\n",
       "      <td>0.235857</td>\n",
       "      <td>6</td>\n",
       "      <td>is_spell</td>\n",
       "      <td>original</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>616</th>\n",
       "      <td>-0.005989</td>\n",
       "      <td>0.128067</td>\n",
       "      <td>0.246536</td>\n",
       "      <td>0.246536</td>\n",
       "      <td>0.235857</td>\n",
       "      <td>0.235857</td>\n",
       "      <td>6</td>\n",
       "      <td>is_building</td>\n",
       "      <td>original</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>617</th>\n",
       "      <td>-0.005989</td>\n",
       "      <td>0.128067</td>\n",
       "      <td>0.246536</td>\n",
       "      <td>0.246536</td>\n",
       "      <td>0.235857</td>\n",
       "      <td>0.235857</td>\n",
       "      <td>6</td>\n",
       "      <td>is_tower_troop</td>\n",
       "      <td>original</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>618</th>\n",
       "      <td>0.023598</td>\n",
       "      <td>0.129678</td>\n",
       "      <td>0.227995</td>\n",
       "      <td>0.251214</td>\n",
       "      <td>0.235857</td>\n",
       "      <td>0.235857</td>\n",
       "      <td>6</td>\n",
       "      <td>is_spawned</td>\n",
       "      <td>original</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>619</th>\n",
       "      <td>0.068818</td>\n",
       "      <td>0.128721</td>\n",
       "      <td>0.246536</td>\n",
       "      <td>0.246536</td>\n",
       "      <td>0.235857</td>\n",
       "      <td>0.235857</td>\n",
       "      <td>6</td>\n",
       "      <td>speed</td>\n",
       "      <td>original</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>620</th>\n",
       "      <td>0.002154</td>\n",
       "      <td>0.122259</td>\n",
       "      <td>0.246536</td>\n",
       "      <td>0.246536</td>\n",
       "      <td>0.246255</td>\n",
       "      <td>0.246255</td>\n",
       "      <td>6</td>\n",
       "      <td>has_ranged_attack</td>\n",
       "      <td>original</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>621</th>\n",
       "      <td>0.002561</td>\n",
       "      <td>0.127176</td>\n",
       "      <td>0.233420</td>\n",
       "      <td>0.233411</td>\n",
       "      <td>0.242758</td>\n",
       "      <td>0.242758</td>\n",
       "      <td>6</td>\n",
       "      <td>special_attack_type</td>\n",
       "      <td>original</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>622</th>\n",
       "      <td>0.004207</td>\n",
       "      <td>0.130430</td>\n",
       "      <td>0.244571</td>\n",
       "      <td>0.244571</td>\n",
       "      <td>0.260718</td>\n",
       "      <td>0.260718</td>\n",
       "      <td>6</td>\n",
       "      <td>has_friendly_buff</td>\n",
       "      <td>original</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>623</th>\n",
       "      <td>-0.115937</td>\n",
       "      <td>0.123265</td>\n",
       "      <td>0.246536</td>\n",
       "      <td>0.246536</td>\n",
       "      <td>0.234724</td>\n",
       "      <td>0.234724</td>\n",
       "      <td>6</td>\n",
       "      <td>is_free_card</td>\n",
       "      <td>original</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>624</th>\n",
       "      <td>-0.067397</td>\n",
       "      <td>0.130679</td>\n",
       "      <td>0.246536</td>\n",
       "      <td>0.246536</td>\n",
       "      <td>0.232360</td>\n",
       "      <td>0.232360</td>\n",
       "      <td>6</td>\n",
       "      <td>no_hit_speed</td>\n",
       "      <td>original</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>625</th>\n",
       "      <td>-0.004231</td>\n",
       "      <td>0.127811</td>\n",
       "      <td>0.235503</td>\n",
       "      <td>0.235503</td>\n",
       "      <td>0.227208</td>\n",
       "      <td>0.227208</td>\n",
       "      <td>6</td>\n",
       "      <td>no_attack</td>\n",
       "      <td>original</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>626</th>\n",
       "      <td>0.029534</td>\n",
       "      <td>0.135051</td>\n",
       "      <td>0.246536</td>\n",
       "      <td>0.246536</td>\n",
       "      <td>0.235857</td>\n",
       "      <td>0.235857</td>\n",
       "      <td>6</td>\n",
       "      <td>no_hitpoints</td>\n",
       "      <td>original</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>627</th>\n",
       "      <td>0.046899</td>\n",
       "      <td>0.133108</td>\n",
       "      <td>0.246536</td>\n",
       "      <td>0.246536</td>\n",
       "      <td>0.235857</td>\n",
       "      <td>0.235857</td>\n",
       "      <td>6</td>\n",
       "      <td>win_con</td>\n",
       "      <td>original</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>628</th>\n",
       "      <td>0.045851</td>\n",
       "      <td>0.152098</td>\n",
       "      <td>0.246038</td>\n",
       "      <td>0.246038</td>\n",
       "      <td>0.229989</td>\n",
       "      <td>0.229989</td>\n",
       "      <td>6</td>\n",
       "      <td>aoe_per_elixir</td>\n",
       "      <td>original</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>629</th>\n",
       "      <td>0.017627</td>\n",
       "      <td>0.140138</td>\n",
       "      <td>0.266143</td>\n",
       "      <td>0.266143</td>\n",
       "      <td>0.226948</td>\n",
       "      <td>0.226948</td>\n",
       "      <td>6</td>\n",
       "      <td>control_special</td>\n",
       "      <td>original</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>630</th>\n",
       "      <td>0.023797</td>\n",
       "      <td>0.127765</td>\n",
       "      <td>0.172095</td>\n",
       "      <td>0.185345</td>\n",
       "      <td>0.235857</td>\n",
       "      <td>0.235857</td>\n",
       "      <td>6</td>\n",
       "      <td>dps_special</td>\n",
       "      <td>original</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>631</th>\n",
       "      <td>-0.022954</td>\n",
       "      <td>0.127946</td>\n",
       "      <td>0.246536</td>\n",
       "      <td>0.246536</td>\n",
       "      <td>0.259875</td>\n",
       "      <td>0.259875</td>\n",
       "      <td>6</td>\n",
       "      <td>air_control</td>\n",
       "      <td>original</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>632</th>\n",
       "      <td>-0.075736</td>\n",
       "      <td>0.131458</td>\n",
       "      <td>0.246536</td>\n",
       "      <td>0.246536</td>\n",
       "      <td>0.240571</td>\n",
       "      <td>0.240571</td>\n",
       "      <td>6</td>\n",
       "      <td>ground_dps</td>\n",
       "      <td>original</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>633</th>\n",
       "      <td>0.024891</td>\n",
       "      <td>0.118983</td>\n",
       "      <td>0.246536</td>\n",
       "      <td>0.246536</td>\n",
       "      <td>0.235857</td>\n",
       "      <td>0.235857</td>\n",
       "      <td>6</td>\n",
       "      <td>win_con_dmg</td>\n",
       "      <td>original</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>634</th>\n",
       "      <td>0.124345</td>\n",
       "      <td>0.139666</td>\n",
       "      <td>0.186387</td>\n",
       "      <td>0.170466</td>\n",
       "      <td>0.250060</td>\n",
       "      <td>0.250060</td>\n",
       "      <td>6</td>\n",
       "      <td>high_dps</td>\n",
       "      <td>original</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>635</th>\n",
       "      <td>-0.029535</td>\n",
       "      <td>0.138772</td>\n",
       "      <td>0.246536</td>\n",
       "      <td>0.246536</td>\n",
       "      <td>0.229545</td>\n",
       "      <td>0.229545</td>\n",
       "      <td>6</td>\n",
       "      <td>damage_output_ps</td>\n",
       "      <td>original</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>636</th>\n",
       "      <td>0.020494</td>\n",
       "      <td>0.137560</td>\n",
       "      <td>0.240747</td>\n",
       "      <td>0.240747</td>\n",
       "      <td>0.227208</td>\n",
       "      <td>0.227208</td>\n",
       "      <td>6</td>\n",
       "      <td>support</td>\n",
       "      <td>original</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>637</th>\n",
       "      <td>0.040618</td>\n",
       "      <td>0.141981</td>\n",
       "      <td>0.246536</td>\n",
       "      <td>0.246536</td>\n",
       "      <td>0.235857</td>\n",
       "      <td>0.235857</td>\n",
       "      <td>6</td>\n",
       "      <td>mini_tank</td>\n",
       "      <td>original</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>638</th>\n",
       "      <td>-0.174803</td>\n",
       "      <td>0.151961</td>\n",
       "      <td>0.278532</td>\n",
       "      <td>0.289313</td>\n",
       "      <td>0.314152</td>\n",
       "      <td>0.314152</td>\n",
       "      <td>6</td>\n",
       "      <td>aoe_radius</td>\n",
       "      <td>num_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>639</th>\n",
       "      <td>-0.061029</td>\n",
       "      <td>0.164195</td>\n",
       "      <td>0.135529</td>\n",
       "      <td>0.280682</td>\n",
       "      <td>0.334164</td>\n",
       "      <td>0.334164</td>\n",
       "      <td>6</td>\n",
       "      <td>can_evolve</td>\n",
       "      <td>num_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>640</th>\n",
       "      <td>0.152184</td>\n",
       "      <td>0.148118</td>\n",
       "      <td>0.318005</td>\n",
       "      <td>0.373240</td>\n",
       "      <td>0.367111</td>\n",
       "      <td>0.367111</td>\n",
       "      <td>6</td>\n",
       "      <td>elixircost</td>\n",
       "      <td>num_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>641</th>\n",
       "      <td>0.117664</td>\n",
       "      <td>0.157533</td>\n",
       "      <td>0.308252</td>\n",
       "      <td>0.308252</td>\n",
       "      <td>0.380623</td>\n",
       "      <td>0.380623</td>\n",
       "      <td>6</td>\n",
       "      <td>hit_speed</td>\n",
       "      <td>num_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>642</th>\n",
       "      <td>0.185738</td>\n",
       "      <td>0.153484</td>\n",
       "      <td>0.308252</td>\n",
       "      <td>0.308252</td>\n",
       "      <td>0.314152</td>\n",
       "      <td>0.314152</td>\n",
       "      <td>6</td>\n",
       "      <td>count</td>\n",
       "      <td>num_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>643</th>\n",
       "      <td>0.029894</td>\n",
       "      <td>0.134010</td>\n",
       "      <td>0.308252</td>\n",
       "      <td>0.308252</td>\n",
       "      <td>0.276927</td>\n",
       "      <td>0.335033</td>\n",
       "      <td>6</td>\n",
       "      <td>hitpoints</td>\n",
       "      <td>num_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>644</th>\n",
       "      <td>0.056687</td>\n",
       "      <td>0.144664</td>\n",
       "      <td>0.206188</td>\n",
       "      <td>0.313422</td>\n",
       "      <td>0.302604</td>\n",
       "      <td>0.302604</td>\n",
       "      <td>6</td>\n",
       "      <td>damage</td>\n",
       "      <td>num_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>645</th>\n",
       "      <td>0.176521</td>\n",
       "      <td>0.147586</td>\n",
       "      <td>0.367936</td>\n",
       "      <td>0.367936</td>\n",
       "      <td>0.285824</td>\n",
       "      <td>0.285824</td>\n",
       "      <td>6</td>\n",
       "      <td>attack_count</td>\n",
       "      <td>num_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>646</th>\n",
       "      <td>0.175068</td>\n",
       "      <td>0.149788</td>\n",
       "      <td>0.308252</td>\n",
       "      <td>0.308252</td>\n",
       "      <td>0.355316</td>\n",
       "      <td>0.355316</td>\n",
       "      <td>6</td>\n",
       "      <td>range</td>\n",
       "      <td>num_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>647</th>\n",
       "      <td>-0.054193</td>\n",
       "      <td>0.167426</td>\n",
       "      <td>0.308252</td>\n",
       "      <td>0.308252</td>\n",
       "      <td>0.314152</td>\n",
       "      <td>0.314152</td>\n",
       "      <td>6</td>\n",
       "      <td>speed</td>\n",
       "      <td>num_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>648</th>\n",
       "      <td>0.165812</td>\n",
       "      <td>0.153460</td>\n",
       "      <td>0.126904</td>\n",
       "      <td>0.291047</td>\n",
       "      <td>0.307583</td>\n",
       "      <td>0.307583</td>\n",
       "      <td>6</td>\n",
       "      <td>damage_per_elixir</td>\n",
       "      <td>num_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>649</th>\n",
       "      <td>0.181360</td>\n",
       "      <td>0.154789</td>\n",
       "      <td>0.308252</td>\n",
       "      <td>0.308252</td>\n",
       "      <td>0.307754</td>\n",
       "      <td>0.307754</td>\n",
       "      <td>6</td>\n",
       "      <td>damage_per_second</td>\n",
       "      <td>num_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>650</th>\n",
       "      <td>0.083913</td>\n",
       "      <td>0.136147</td>\n",
       "      <td>0.250954</td>\n",
       "      <td>0.291333</td>\n",
       "      <td>0.300742</td>\n",
       "      <td>0.269633</td>\n",
       "      <td>6</td>\n",
       "      <td>damage_output</td>\n",
       "      <td>num_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>651</th>\n",
       "      <td>0.116668</td>\n",
       "      <td>0.152297</td>\n",
       "      <td>0.358724</td>\n",
       "      <td>0.357063</td>\n",
       "      <td>0.336034</td>\n",
       "      <td>0.336034</td>\n",
       "      <td>6</td>\n",
       "      <td>hp_per_elixir</td>\n",
       "      <td>num_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>652</th>\n",
       "      <td>-0.114938</td>\n",
       "      <td>0.137822</td>\n",
       "      <td>0.308252</td>\n",
       "      <td>0.308252</td>\n",
       "      <td>0.304067</td>\n",
       "      <td>0.304067</td>\n",
       "      <td>6</td>\n",
       "      <td>damage_by_hitpoints</td>\n",
       "      <td>num_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>653</th>\n",
       "      <td>-0.025327</td>\n",
       "      <td>0.145113</td>\n",
       "      <td>0.278532</td>\n",
       "      <td>0.289313</td>\n",
       "      <td>0.314152</td>\n",
       "      <td>0.314152</td>\n",
       "      <td>6</td>\n",
       "      <td>aoe_by_range</td>\n",
       "      <td>num_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>654</th>\n",
       "      <td>-0.023694</td>\n",
       "      <td>0.149150</td>\n",
       "      <td>0.078142</td>\n",
       "      <td>0.312810</td>\n",
       "      <td>0.314152</td>\n",
       "      <td>0.314152</td>\n",
       "      <td>6</td>\n",
       "      <td>aoe_by_damage</td>\n",
       "      <td>num_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>655</th>\n",
       "      <td>0.055903</td>\n",
       "      <td>0.149615</td>\n",
       "      <td>0.263099</td>\n",
       "      <td>0.330161</td>\n",
       "      <td>0.314152</td>\n",
       "      <td>0.314152</td>\n",
       "      <td>6</td>\n",
       "      <td>aoe_per_elixir</td>\n",
       "      <td>num_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>656</th>\n",
       "      <td>0.056747</td>\n",
       "      <td>0.136857</td>\n",
       "      <td>0.308252</td>\n",
       "      <td>0.308252</td>\n",
       "      <td>0.311665</td>\n",
       "      <td>0.311665</td>\n",
       "      <td>6</td>\n",
       "      <td>damage_output_ps</td>\n",
       "      <td>num_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>657</th>\n",
       "      <td>0.090995</td>\n",
       "      <td>0.166401</td>\n",
       "      <td>0.382929</td>\n",
       "      <td>0.363934</td>\n",
       "      <td>0.326994</td>\n",
       "      <td>0.326994</td>\n",
       "      <td>6</td>\n",
       "      <td>playable</td>\n",
       "      <td>bool_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>658</th>\n",
       "      <td>0.096003</td>\n",
       "      <td>0.182951</td>\n",
       "      <td>0.363272</td>\n",
       "      <td>0.411884</td>\n",
       "      <td>0.344582</td>\n",
       "      <td>0.344582</td>\n",
       "      <td>6</td>\n",
       "      <td>aoe_bool</td>\n",
       "      <td>bool_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>659</th>\n",
       "      <td>0.123061</td>\n",
       "      <td>0.181043</td>\n",
       "      <td>0.382929</td>\n",
       "      <td>0.363934</td>\n",
       "      <td>0.356988</td>\n",
       "      <td>0.356988</td>\n",
       "      <td>6</td>\n",
       "      <td>death_damage_bool</td>\n",
       "      <td>bool_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>660</th>\n",
       "      <td>0.081416</td>\n",
       "      <td>0.163232</td>\n",
       "      <td>0.382929</td>\n",
       "      <td>0.363934</td>\n",
       "      <td>0.304594</td>\n",
       "      <td>0.304594</td>\n",
       "      <td>6</td>\n",
       "      <td>fly_bool</td>\n",
       "      <td>bool_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>661</th>\n",
       "      <td>0.031068</td>\n",
       "      <td>0.180132</td>\n",
       "      <td>0.405065</td>\n",
       "      <td>0.405065</td>\n",
       "      <td>0.251558</td>\n",
       "      <td>0.315118</td>\n",
       "      <td>6</td>\n",
       "      <td>spawn_bool</td>\n",
       "      <td>bool_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>662</th>\n",
       "      <td>0.078434</td>\n",
       "      <td>0.172074</td>\n",
       "      <td>0.405548</td>\n",
       "      <td>0.403666</td>\n",
       "      <td>0.263291</td>\n",
       "      <td>0.263291</td>\n",
       "      <td>6</td>\n",
       "      <td>special_damage</td>\n",
       "      <td>bool_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>663</th>\n",
       "      <td>0.051836</td>\n",
       "      <td>0.158103</td>\n",
       "      <td>0.382929</td>\n",
       "      <td>0.363934</td>\n",
       "      <td>0.305602</td>\n",
       "      <td>0.305602</td>\n",
       "      <td>6</td>\n",
       "      <td>shield_bool</td>\n",
       "      <td>bool_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>664</th>\n",
       "      <td>0.050777</td>\n",
       "      <td>0.167731</td>\n",
       "      <td>0.384668</td>\n",
       "      <td>0.384668</td>\n",
       "      <td>0.270288</td>\n",
       "      <td>0.270288</td>\n",
       "      <td>6</td>\n",
       "      <td>affected_crown</td>\n",
       "      <td>bool_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>665</th>\n",
       "      <td>0.096654</td>\n",
       "      <td>0.174245</td>\n",
       "      <td>0.382929</td>\n",
       "      <td>0.363934</td>\n",
       "      <td>0.305602</td>\n",
       "      <td>0.305602</td>\n",
       "      <td>6</td>\n",
       "      <td>has_lifetime</td>\n",
       "      <td>bool_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>666</th>\n",
       "      <td>0.093419</td>\n",
       "      <td>0.175032</td>\n",
       "      <td>0.382929</td>\n",
       "      <td>0.363934</td>\n",
       "      <td>0.305602</td>\n",
       "      <td>0.305602</td>\n",
       "      <td>6</td>\n",
       "      <td>invisible</td>\n",
       "      <td>bool_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>667</th>\n",
       "      <td>0.041629</td>\n",
       "      <td>0.162674</td>\n",
       "      <td>0.382929</td>\n",
       "      <td>0.363934</td>\n",
       "      <td>0.305602</td>\n",
       "      <td>0.305602</td>\n",
       "      <td>6</td>\n",
       "      <td>has_ability</td>\n",
       "      <td>bool_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>668</th>\n",
       "      <td>0.057691</td>\n",
       "      <td>0.150695</td>\n",
       "      <td>0.382929</td>\n",
       "      <td>0.363934</td>\n",
       "      <td>0.292553</td>\n",
       "      <td>0.292553</td>\n",
       "      <td>6</td>\n",
       "      <td>any_target</td>\n",
       "      <td>bool_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>669</th>\n",
       "      <td>0.057691</td>\n",
       "      <td>0.150695</td>\n",
       "      <td>0.382929</td>\n",
       "      <td>0.363934</td>\n",
       "      <td>0.251555</td>\n",
       "      <td>0.251555</td>\n",
       "      <td>6</td>\n",
       "      <td>building_target</td>\n",
       "      <td>bool_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>670</th>\n",
       "      <td>0.052907</td>\n",
       "      <td>0.163246</td>\n",
       "      <td>0.382929</td>\n",
       "      <td>0.363934</td>\n",
       "      <td>0.251555</td>\n",
       "      <td>0.251555</td>\n",
       "      <td>6</td>\n",
       "      <td>ground_target</td>\n",
       "      <td>bool_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>671</th>\n",
       "      <td>0.100432</td>\n",
       "      <td>0.165260</td>\n",
       "      <td>0.322922</td>\n",
       "      <td>0.316366</td>\n",
       "      <td>0.305602</td>\n",
       "      <td>0.305602</td>\n",
       "      <td>6</td>\n",
       "      <td>has_upon_breaking_spawn</td>\n",
       "      <td>bool_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>672</th>\n",
       "      <td>0.119450</td>\n",
       "      <td>0.148281</td>\n",
       "      <td>0.382929</td>\n",
       "      <td>0.363934</td>\n",
       "      <td>0.251558</td>\n",
       "      <td>0.315118</td>\n",
       "      <td>6</td>\n",
       "      <td>has_upon_death_spawn</td>\n",
       "      <td>bool_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>673</th>\n",
       "      <td>0.164025</td>\n",
       "      <td>0.176225</td>\n",
       "      <td>0.385311</td>\n",
       "      <td>0.399253</td>\n",
       "      <td>0.280400</td>\n",
       "      <td>0.280400</td>\n",
       "      <td>6</td>\n",
       "      <td>has_periodic_spawn</td>\n",
       "      <td>bool_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>674</th>\n",
       "      <td>0.096667</td>\n",
       "      <td>0.120211</td>\n",
       "      <td>0.366523</td>\n",
       "      <td>0.382258</td>\n",
       "      <td>0.303593</td>\n",
       "      <td>0.303593</td>\n",
       "      <td>6</td>\n",
       "      <td>single_damage_type</td>\n",
       "      <td>bool_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>675</th>\n",
       "      <td>0.076202</td>\n",
       "      <td>0.173323</td>\n",
       "      <td>0.382929</td>\n",
       "      <td>0.363934</td>\n",
       "      <td>0.305602</td>\n",
       "      <td>0.305602</td>\n",
       "      <td>6</td>\n",
       "      <td>is_troop</td>\n",
       "      <td>bool_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>676</th>\n",
       "      <td>0.076202</td>\n",
       "      <td>0.173323</td>\n",
       "      <td>0.382929</td>\n",
       "      <td>0.363934</td>\n",
       "      <td>0.305602</td>\n",
       "      <td>0.305602</td>\n",
       "      <td>6</td>\n",
       "      <td>is_spell</td>\n",
       "      <td>bool_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>677</th>\n",
       "      <td>0.076202</td>\n",
       "      <td>0.173323</td>\n",
       "      <td>0.382929</td>\n",
       "      <td>0.363934</td>\n",
       "      <td>0.305602</td>\n",
       "      <td>0.305602</td>\n",
       "      <td>6</td>\n",
       "      <td>is_building</td>\n",
       "      <td>bool_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>678</th>\n",
       "      <td>0.076202</td>\n",
       "      <td>0.173323</td>\n",
       "      <td>0.382929</td>\n",
       "      <td>0.363934</td>\n",
       "      <td>0.305602</td>\n",
       "      <td>0.305602</td>\n",
       "      <td>6</td>\n",
       "      <td>is_tower_troop</td>\n",
       "      <td>bool_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>679</th>\n",
       "      <td>0.062801</td>\n",
       "      <td>0.171814</td>\n",
       "      <td>0.400643</td>\n",
       "      <td>0.400643</td>\n",
       "      <td>0.305602</td>\n",
       "      <td>0.305602</td>\n",
       "      <td>6</td>\n",
       "      <td>is_spawned</td>\n",
       "      <td>bool_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>680</th>\n",
       "      <td>0.093545</td>\n",
       "      <td>0.124098</td>\n",
       "      <td>0.382929</td>\n",
       "      <td>0.363934</td>\n",
       "      <td>0.334359</td>\n",
       "      <td>0.334359</td>\n",
       "      <td>6</td>\n",
       "      <td>has_ranged_attack</td>\n",
       "      <td>bool_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>681</th>\n",
       "      <td>-0.022864</td>\n",
       "      <td>0.148632</td>\n",
       "      <td>0.404644</td>\n",
       "      <td>0.402241</td>\n",
       "      <td>0.273077</td>\n",
       "      <td>0.309699</td>\n",
       "      <td>6</td>\n",
       "      <td>special_attack_type</td>\n",
       "      <td>bool_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>682</th>\n",
       "      <td>0.034551</td>\n",
       "      <td>0.175883</td>\n",
       "      <td>0.449460</td>\n",
       "      <td>0.449460</td>\n",
       "      <td>0.336052</td>\n",
       "      <td>0.336052</td>\n",
       "      <td>6</td>\n",
       "      <td>has_friendly_buff</td>\n",
       "      <td>bool_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>683</th>\n",
       "      <td>0.090995</td>\n",
       "      <td>0.166401</td>\n",
       "      <td>0.382929</td>\n",
       "      <td>0.363934</td>\n",
       "      <td>0.326994</td>\n",
       "      <td>0.326994</td>\n",
       "      <td>6</td>\n",
       "      <td>is_free_card</td>\n",
       "      <td>bool_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>684</th>\n",
       "      <td>0.068735</td>\n",
       "      <td>0.177779</td>\n",
       "      <td>0.382929</td>\n",
       "      <td>0.363934</td>\n",
       "      <td>0.303593</td>\n",
       "      <td>0.303593</td>\n",
       "      <td>6</td>\n",
       "      <td>no_hit_speed</td>\n",
       "      <td>bool_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>685</th>\n",
       "      <td>0.069566</td>\n",
       "      <td>0.168662</td>\n",
       "      <td>0.371841</td>\n",
       "      <td>0.371841</td>\n",
       "      <td>0.295945</td>\n",
       "      <td>0.295945</td>\n",
       "      <td>6</td>\n",
       "      <td>no_attack</td>\n",
       "      <td>bool_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>686</th>\n",
       "      <td>0.126155</td>\n",
       "      <td>0.160605</td>\n",
       "      <td>0.382929</td>\n",
       "      <td>0.363934</td>\n",
       "      <td>0.305602</td>\n",
       "      <td>0.305602</td>\n",
       "      <td>6</td>\n",
       "      <td>no_hitpoints</td>\n",
       "      <td>bool_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>687</th>\n",
       "      <td>0.063345</td>\n",
       "      <td>0.148209</td>\n",
       "      <td>0.382929</td>\n",
       "      <td>0.363934</td>\n",
       "      <td>0.305602</td>\n",
       "      <td>0.305602</td>\n",
       "      <td>6</td>\n",
       "      <td>win_con</td>\n",
       "      <td>bool_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>688</th>\n",
       "      <td>0.048456</td>\n",
       "      <td>0.155894</td>\n",
       "      <td>0.460809</td>\n",
       "      <td>0.410261</td>\n",
       "      <td>0.263291</td>\n",
       "      <td>0.263291</td>\n",
       "      <td>6</td>\n",
       "      <td>control_special</td>\n",
       "      <td>bool_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>689</th>\n",
       "      <td>0.054227</td>\n",
       "      <td>0.167725</td>\n",
       "      <td>0.390405</td>\n",
       "      <td>0.390405</td>\n",
       "      <td>0.305602</td>\n",
       "      <td>0.305602</td>\n",
       "      <td>6</td>\n",
       "      <td>dps_special</td>\n",
       "      <td>bool_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>690</th>\n",
       "      <td>0.100992</td>\n",
       "      <td>0.165467</td>\n",
       "      <td>0.382929</td>\n",
       "      <td>0.363934</td>\n",
       "      <td>0.302750</td>\n",
       "      <td>0.297951</td>\n",
       "      <td>6</td>\n",
       "      <td>air_control</td>\n",
       "      <td>bool_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>691</th>\n",
       "      <td>0.036445</td>\n",
       "      <td>0.176312</td>\n",
       "      <td>0.382929</td>\n",
       "      <td>0.363934</td>\n",
       "      <td>0.319982</td>\n",
       "      <td>0.319982</td>\n",
       "      <td>6</td>\n",
       "      <td>ground_dps</td>\n",
       "      <td>bool_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>692</th>\n",
       "      <td>0.106511</td>\n",
       "      <td>0.150712</td>\n",
       "      <td>0.382929</td>\n",
       "      <td>0.363934</td>\n",
       "      <td>0.305602</td>\n",
       "      <td>0.305602</td>\n",
       "      <td>6</td>\n",
       "      <td>win_con_dmg</td>\n",
       "      <td>bool_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>693</th>\n",
       "      <td>0.097158</td>\n",
       "      <td>0.170562</td>\n",
       "      <td>0.375922</td>\n",
       "      <td>0.375922</td>\n",
       "      <td>0.316427</td>\n",
       "      <td>0.316427</td>\n",
       "      <td>6</td>\n",
       "      <td>high_dps</td>\n",
       "      <td>bool_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>694</th>\n",
       "      <td>0.047326</td>\n",
       "      <td>0.153810</td>\n",
       "      <td>0.347251</td>\n",
       "      <td>0.397019</td>\n",
       "      <td>0.295945</td>\n",
       "      <td>0.295945</td>\n",
       "      <td>6</td>\n",
       "      <td>support</td>\n",
       "      <td>bool_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>695</th>\n",
       "      <td>0.087845</td>\n",
       "      <td>0.156619</td>\n",
       "      <td>0.382929</td>\n",
       "      <td>0.363934</td>\n",
       "      <td>0.305602</td>\n",
       "      <td>0.305602</td>\n",
       "      <td>6</td>\n",
       "      <td>mini_tank</td>\n",
       "      <td>bool_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>696</th>\n",
       "      <td>0.021064</td>\n",
       "      <td>0.112621</td>\n",
       "      <td>0.184854</td>\n",
       "      <td>0.207206</td>\n",
       "      <td>0.276543</td>\n",
       "      <td>0.276543</td>\n",
       "      <td>7</td>\n",
       "      <td>playable</td>\n",
       "      <td>all_col</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>697</th>\n",
       "      <td>0.013804</td>\n",
       "      <td>0.139102</td>\n",
       "      <td>0.177495</td>\n",
       "      <td>0.177495</td>\n",
       "      <td>0.245808</td>\n",
       "      <td>0.245808</td>\n",
       "      <td>7</td>\n",
       "      <td>aoe_bool</td>\n",
       "      <td>all_col</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>698</th>\n",
       "      <td>0.070967</td>\n",
       "      <td>0.095352</td>\n",
       "      <td>0.165237</td>\n",
       "      <td>0.200397</td>\n",
       "      <td>0.246967</td>\n",
       "      <td>0.246967</td>\n",
       "      <td>7</td>\n",
       "      <td>aoe_radius</td>\n",
       "      <td>all_col</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>699</th>\n",
       "      <td>0.037924</td>\n",
       "      <td>0.123586</td>\n",
       "      <td>0.184854</td>\n",
       "      <td>0.207206</td>\n",
       "      <td>0.267825</td>\n",
       "      <td>0.267825</td>\n",
       "      <td>7</td>\n",
       "      <td>death_damage_bool</td>\n",
       "      <td>all_col</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>700</th>\n",
       "      <td>-0.040982</td>\n",
       "      <td>0.131216</td>\n",
       "      <td>0.184854</td>\n",
       "      <td>0.207206</td>\n",
       "      <td>0.250532</td>\n",
       "      <td>0.250532</td>\n",
       "      <td>7</td>\n",
       "      <td>fly_bool</td>\n",
       "      <td>all_col</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>701</th>\n",
       "      <td>-0.010972</td>\n",
       "      <td>0.122489</td>\n",
       "      <td>0.164138</td>\n",
       "      <td>0.200675</td>\n",
       "      <td>0.257899</td>\n",
       "      <td>0.257899</td>\n",
       "      <td>7</td>\n",
       "      <td>spawn_bool</td>\n",
       "      <td>all_col</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>702</th>\n",
       "      <td>0.012361</td>\n",
       "      <td>0.128900</td>\n",
       "      <td>0.211844</td>\n",
       "      <td>0.211844</td>\n",
       "      <td>0.275566</td>\n",
       "      <td>0.275566</td>\n",
       "      <td>7</td>\n",
       "      <td>can_evolve</td>\n",
       "      <td>all_col</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>703</th>\n",
       "      <td>0.039939</td>\n",
       "      <td>0.119575</td>\n",
       "      <td>0.214215</td>\n",
       "      <td>0.210199</td>\n",
       "      <td>0.268628</td>\n",
       "      <td>0.268628</td>\n",
       "      <td>7</td>\n",
       "      <td>elixircost</td>\n",
       "      <td>all_col</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>704</th>\n",
       "      <td>0.021676</td>\n",
       "      <td>0.128839</td>\n",
       "      <td>0.184854</td>\n",
       "      <td>0.207206</td>\n",
       "      <td>0.258923</td>\n",
       "      <td>0.258923</td>\n",
       "      <td>7</td>\n",
       "      <td>hit_speed</td>\n",
       "      <td>all_col</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>705</th>\n",
       "      <td>-0.006685</td>\n",
       "      <td>0.120179</td>\n",
       "      <td>0.179971</td>\n",
       "      <td>0.206010</td>\n",
       "      <td>0.245384</td>\n",
       "      <td>0.245384</td>\n",
       "      <td>7</td>\n",
       "      <td>special_damage</td>\n",
       "      <td>all_col</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>706</th>\n",
       "      <td>0.029928</td>\n",
       "      <td>0.118429</td>\n",
       "      <td>0.184854</td>\n",
       "      <td>0.207206</td>\n",
       "      <td>0.250532</td>\n",
       "      <td>0.250532</td>\n",
       "      <td>7</td>\n",
       "      <td>count</td>\n",
       "      <td>all_col</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>707</th>\n",
       "      <td>0.066106</td>\n",
       "      <td>0.120794</td>\n",
       "      <td>0.184854</td>\n",
       "      <td>0.207206</td>\n",
       "      <td>0.258427</td>\n",
       "      <td>0.258427</td>\n",
       "      <td>7</td>\n",
       "      <td>hitpoints</td>\n",
       "      <td>all_col</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>708</th>\n",
       "      <td>0.054831</td>\n",
       "      <td>0.128956</td>\n",
       "      <td>0.184854</td>\n",
       "      <td>0.207206</td>\n",
       "      <td>0.250532</td>\n",
       "      <td>0.250532</td>\n",
       "      <td>7</td>\n",
       "      <td>shield_bool</td>\n",
       "      <td>all_col</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>709</th>\n",
       "      <td>0.015478</td>\n",
       "      <td>0.136713</td>\n",
       "      <td>0.183868</td>\n",
       "      <td>0.203319</td>\n",
       "      <td>0.247527</td>\n",
       "      <td>0.247527</td>\n",
       "      <td>7</td>\n",
       "      <td>damage</td>\n",
       "      <td>all_col</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>710</th>\n",
       "      <td>0.056502</td>\n",
       "      <td>0.122254</td>\n",
       "      <td>0.184813</td>\n",
       "      <td>0.214135</td>\n",
       "      <td>0.243134</td>\n",
       "      <td>0.243134</td>\n",
       "      <td>7</td>\n",
       "      <td>attack_count</td>\n",
       "      <td>all_col</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>711</th>\n",
       "      <td>0.090623</td>\n",
       "      <td>0.116815</td>\n",
       "      <td>0.184854</td>\n",
       "      <td>0.207206</td>\n",
       "      <td>0.242398</td>\n",
       "      <td>0.242398</td>\n",
       "      <td>7</td>\n",
       "      <td>range</td>\n",
       "      <td>all_col</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>712</th>\n",
       "      <td>0.047661</td>\n",
       "      <td>0.136467</td>\n",
       "      <td>0.147790</td>\n",
       "      <td>0.176359</td>\n",
       "      <td>0.233984</td>\n",
       "      <td>0.233984</td>\n",
       "      <td>7</td>\n",
       "      <td>affected_crown</td>\n",
       "      <td>all_col</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>713</th>\n",
       "      <td>-0.001867</td>\n",
       "      <td>0.126857</td>\n",
       "      <td>0.184854</td>\n",
       "      <td>0.207206</td>\n",
       "      <td>0.250532</td>\n",
       "      <td>0.250532</td>\n",
       "      <td>7</td>\n",
       "      <td>has_lifetime</td>\n",
       "      <td>all_col</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>714</th>\n",
       "      <td>-0.093923</td>\n",
       "      <td>0.126374</td>\n",
       "      <td>0.184854</td>\n",
       "      <td>0.207206</td>\n",
       "      <td>0.250532</td>\n",
       "      <td>0.250532</td>\n",
       "      <td>7</td>\n",
       "      <td>invisible</td>\n",
       "      <td>all_col</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>715</th>\n",
       "      <td>0.047008</td>\n",
       "      <td>0.091309</td>\n",
       "      <td>0.184854</td>\n",
       "      <td>0.207206</td>\n",
       "      <td>0.250532</td>\n",
       "      <td>0.250532</td>\n",
       "      <td>7</td>\n",
       "      <td>has_ability</td>\n",
       "      <td>all_col</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>716</th>\n",
       "      <td>-0.010436</td>\n",
       "      <td>0.079530</td>\n",
       "      <td>0.184854</td>\n",
       "      <td>0.207206</td>\n",
       "      <td>0.259701</td>\n",
       "      <td>0.259701</td>\n",
       "      <td>7</td>\n",
       "      <td>any_target</td>\n",
       "      <td>all_col</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>717</th>\n",
       "      <td>-0.010436</td>\n",
       "      <td>0.079530</td>\n",
       "      <td>0.184854</td>\n",
       "      <td>0.207206</td>\n",
       "      <td>0.253829</td>\n",
       "      <td>0.253829</td>\n",
       "      <td>7</td>\n",
       "      <td>building_target</td>\n",
       "      <td>all_col</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>718</th>\n",
       "      <td>-0.057592</td>\n",
       "      <td>0.119244</td>\n",
       "      <td>0.184854</td>\n",
       "      <td>0.207206</td>\n",
       "      <td>0.253829</td>\n",
       "      <td>0.253829</td>\n",
       "      <td>7</td>\n",
       "      <td>ground_target</td>\n",
       "      <td>all_col</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>719</th>\n",
       "      <td>-0.004174</td>\n",
       "      <td>0.104800</td>\n",
       "      <td>0.177672</td>\n",
       "      <td>0.200559</td>\n",
       "      <td>0.250532</td>\n",
       "      <td>0.250532</td>\n",
       "      <td>7</td>\n",
       "      <td>has_upon_breaking_spawn</td>\n",
       "      <td>all_col</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>720</th>\n",
       "      <td>0.010570</td>\n",
       "      <td>0.123468</td>\n",
       "      <td>0.184854</td>\n",
       "      <td>0.207206</td>\n",
       "      <td>0.257899</td>\n",
       "      <td>0.257899</td>\n",
       "      <td>7</td>\n",
       "      <td>has_upon_death_spawn</td>\n",
       "      <td>all_col</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>721</th>\n",
       "      <td>0.086148</td>\n",
       "      <td>0.117724</td>\n",
       "      <td>0.212726</td>\n",
       "      <td>0.229249</td>\n",
       "      <td>0.266121</td>\n",
       "      <td>0.266121</td>\n",
       "      <td>7</td>\n",
       "      <td>has_periodic_spawn</td>\n",
       "      <td>all_col</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>722</th>\n",
       "      <td>0.059292</td>\n",
       "      <td>0.130205</td>\n",
       "      <td>0.149380</td>\n",
       "      <td>0.171108</td>\n",
       "      <td>0.249072</td>\n",
       "      <td>0.249072</td>\n",
       "      <td>7</td>\n",
       "      <td>single_damage_type</td>\n",
       "      <td>all_col</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>723</th>\n",
       "      <td>0.029961</td>\n",
       "      <td>0.122014</td>\n",
       "      <td>0.184854</td>\n",
       "      <td>0.207206</td>\n",
       "      <td>0.250532</td>\n",
       "      <td>0.250532</td>\n",
       "      <td>7</td>\n",
       "      <td>is_troop</td>\n",
       "      <td>all_col</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>724</th>\n",
       "      <td>0.029961</td>\n",
       "      <td>0.122014</td>\n",
       "      <td>0.184854</td>\n",
       "      <td>0.207206</td>\n",
       "      <td>0.250532</td>\n",
       "      <td>0.250532</td>\n",
       "      <td>7</td>\n",
       "      <td>is_spell</td>\n",
       "      <td>all_col</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>725</th>\n",
       "      <td>0.029961</td>\n",
       "      <td>0.122014</td>\n",
       "      <td>0.184854</td>\n",
       "      <td>0.207206</td>\n",
       "      <td>0.250532</td>\n",
       "      <td>0.250532</td>\n",
       "      <td>7</td>\n",
       "      <td>is_building</td>\n",
       "      <td>all_col</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>726</th>\n",
       "      <td>0.029961</td>\n",
       "      <td>0.122014</td>\n",
       "      <td>0.184854</td>\n",
       "      <td>0.207206</td>\n",
       "      <td>0.250532</td>\n",
       "      <td>0.250532</td>\n",
       "      <td>7</td>\n",
       "      <td>is_tower_troop</td>\n",
       "      <td>all_col</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>727</th>\n",
       "      <td>0.019919</td>\n",
       "      <td>0.128182</td>\n",
       "      <td>0.202608</td>\n",
       "      <td>0.202608</td>\n",
       "      <td>0.250532</td>\n",
       "      <td>0.250532</td>\n",
       "      <td>7</td>\n",
       "      <td>is_spawned</td>\n",
       "      <td>all_col</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>728</th>\n",
       "      <td>0.043264</td>\n",
       "      <td>0.126415</td>\n",
       "      <td>0.184854</td>\n",
       "      <td>0.207206</td>\n",
       "      <td>0.250532</td>\n",
       "      <td>0.250532</td>\n",
       "      <td>7</td>\n",
       "      <td>speed</td>\n",
       "      <td>all_col</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>729</th>\n",
       "      <td>0.012474</td>\n",
       "      <td>0.120589</td>\n",
       "      <td>0.184854</td>\n",
       "      <td>0.207206</td>\n",
       "      <td>0.259027</td>\n",
       "      <td>0.259027</td>\n",
       "      <td>7</td>\n",
       "      <td>has_ranged_attack</td>\n",
       "      <td>all_col</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>730</th>\n",
       "      <td>-0.049964</td>\n",
       "      <td>0.130310</td>\n",
       "      <td>0.160620</td>\n",
       "      <td>0.174349</td>\n",
       "      <td>0.217479</td>\n",
       "      <td>0.217479</td>\n",
       "      <td>7</td>\n",
       "      <td>special_attack_type</td>\n",
       "      <td>all_col</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>731</th>\n",
       "      <td>0.047872</td>\n",
       "      <td>0.129626</td>\n",
       "      <td>0.204417</td>\n",
       "      <td>0.227585</td>\n",
       "      <td>0.273493</td>\n",
       "      <td>0.273493</td>\n",
       "      <td>7</td>\n",
       "      <td>has_friendly_buff</td>\n",
       "      <td>all_col</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>732</th>\n",
       "      <td>0.021064</td>\n",
       "      <td>0.112621</td>\n",
       "      <td>0.184854</td>\n",
       "      <td>0.207206</td>\n",
       "      <td>0.276543</td>\n",
       "      <td>0.276543</td>\n",
       "      <td>7</td>\n",
       "      <td>is_free_card</td>\n",
       "      <td>all_col</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>733</th>\n",
       "      <td>0.009995</td>\n",
       "      <td>0.136670</td>\n",
       "      <td>0.184854</td>\n",
       "      <td>0.207206</td>\n",
       "      <td>0.249072</td>\n",
       "      <td>0.249072</td>\n",
       "      <td>7</td>\n",
       "      <td>no_hit_speed</td>\n",
       "      <td>all_col</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>734</th>\n",
       "      <td>0.025280</td>\n",
       "      <td>0.114601</td>\n",
       "      <td>0.198122</td>\n",
       "      <td>0.198122</td>\n",
       "      <td>0.243134</td>\n",
       "      <td>0.243134</td>\n",
       "      <td>7</td>\n",
       "      <td>no_attack</td>\n",
       "      <td>all_col</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>735</th>\n",
       "      <td>0.025037</td>\n",
       "      <td>0.123322</td>\n",
       "      <td>0.184854</td>\n",
       "      <td>0.207206</td>\n",
       "      <td>0.250532</td>\n",
       "      <td>0.250532</td>\n",
       "      <td>7</td>\n",
       "      <td>no_hitpoints</td>\n",
       "      <td>all_col</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>736</th>\n",
       "      <td>0.000484</td>\n",
       "      <td>0.130287</td>\n",
       "      <td>0.202479</td>\n",
       "      <td>0.202479</td>\n",
       "      <td>0.256265</td>\n",
       "      <td>0.256265</td>\n",
       "      <td>7</td>\n",
       "      <td>damage_per_elixir</td>\n",
       "      <td>all_col</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>737</th>\n",
       "      <td>0.015631</td>\n",
       "      <td>0.134562</td>\n",
       "      <td>0.184854</td>\n",
       "      <td>0.207206</td>\n",
       "      <td>0.248989</td>\n",
       "      <td>0.248989</td>\n",
       "      <td>7</td>\n",
       "      <td>damage_per_second</td>\n",
       "      <td>all_col</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>738</th>\n",
       "      <td>0.055841</td>\n",
       "      <td>0.110430</td>\n",
       "      <td>0.195370</td>\n",
       "      <td>0.195370</td>\n",
       "      <td>0.237991</td>\n",
       "      <td>0.237991</td>\n",
       "      <td>7</td>\n",
       "      <td>damage_output</td>\n",
       "      <td>all_col</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>739</th>\n",
       "      <td>0.046698</td>\n",
       "      <td>0.114634</td>\n",
       "      <td>0.198983</td>\n",
       "      <td>0.198441</td>\n",
       "      <td>0.254733</td>\n",
       "      <td>0.254733</td>\n",
       "      <td>7</td>\n",
       "      <td>hp_per_elixir</td>\n",
       "      <td>all_col</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>740</th>\n",
       "      <td>0.052112</td>\n",
       "      <td>0.136333</td>\n",
       "      <td>0.184854</td>\n",
       "      <td>0.207206</td>\n",
       "      <td>0.249118</td>\n",
       "      <td>0.249118</td>\n",
       "      <td>7</td>\n",
       "      <td>damage_by_hitpoints</td>\n",
       "      <td>all_col</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>741</th>\n",
       "      <td>0.033257</td>\n",
       "      <td>0.126218</td>\n",
       "      <td>0.165237</td>\n",
       "      <td>0.200397</td>\n",
       "      <td>0.246223</td>\n",
       "      <td>0.246223</td>\n",
       "      <td>7</td>\n",
       "      <td>aoe_by_range</td>\n",
       "      <td>all_col</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>742</th>\n",
       "      <td>0.080396</td>\n",
       "      <td>0.131500</td>\n",
       "      <td>0.180865</td>\n",
       "      <td>0.203140</td>\n",
       "      <td>0.248442</td>\n",
       "      <td>0.248442</td>\n",
       "      <td>7</td>\n",
       "      <td>aoe_by_damage</td>\n",
       "      <td>all_col</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>743</th>\n",
       "      <td>-0.008397</td>\n",
       "      <td>0.129700</td>\n",
       "      <td>0.184854</td>\n",
       "      <td>0.207206</td>\n",
       "      <td>0.250532</td>\n",
       "      <td>0.250532</td>\n",
       "      <td>7</td>\n",
       "      <td>win_con</td>\n",
       "      <td>all_col</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>744</th>\n",
       "      <td>-0.010885</td>\n",
       "      <td>0.120585</td>\n",
       "      <td>0.208904</td>\n",
       "      <td>0.214297</td>\n",
       "      <td>0.246967</td>\n",
       "      <td>0.246967</td>\n",
       "      <td>7</td>\n",
       "      <td>aoe_per_elixir</td>\n",
       "      <td>all_col</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>745</th>\n",
       "      <td>-0.037661</td>\n",
       "      <td>0.125608</td>\n",
       "      <td>0.186495</td>\n",
       "      <td>0.206997</td>\n",
       "      <td>0.245384</td>\n",
       "      <td>0.245384</td>\n",
       "      <td>7</td>\n",
       "      <td>control_special</td>\n",
       "      <td>all_col</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>746</th>\n",
       "      <td>0.075707</td>\n",
       "      <td>0.132924</td>\n",
       "      <td>0.194135</td>\n",
       "      <td>0.194135</td>\n",
       "      <td>0.250532</td>\n",
       "      <td>0.250532</td>\n",
       "      <td>7</td>\n",
       "      <td>dps_special</td>\n",
       "      <td>all_col</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>747</th>\n",
       "      <td>-0.066038</td>\n",
       "      <td>0.136622</td>\n",
       "      <td>0.184854</td>\n",
       "      <td>0.207206</td>\n",
       "      <td>0.268947</td>\n",
       "      <td>0.268947</td>\n",
       "      <td>7</td>\n",
       "      <td>air_control</td>\n",
       "      <td>all_col</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>748</th>\n",
       "      <td>0.063295</td>\n",
       "      <td>0.105753</td>\n",
       "      <td>0.184854</td>\n",
       "      <td>0.207206</td>\n",
       "      <td>0.257320</td>\n",
       "      <td>0.257320</td>\n",
       "      <td>7</td>\n",
       "      <td>ground_dps</td>\n",
       "      <td>all_col</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>749</th>\n",
       "      <td>-0.002214</td>\n",
       "      <td>0.123703</td>\n",
       "      <td>0.184854</td>\n",
       "      <td>0.207206</td>\n",
       "      <td>0.250532</td>\n",
       "      <td>0.250532</td>\n",
       "      <td>7</td>\n",
       "      <td>win_con_dmg</td>\n",
       "      <td>all_col</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>750</th>\n",
       "      <td>-0.004546</td>\n",
       "      <td>0.136588</td>\n",
       "      <td>0.182994</td>\n",
       "      <td>0.182994</td>\n",
       "      <td>0.247175</td>\n",
       "      <td>0.247175</td>\n",
       "      <td>7</td>\n",
       "      <td>high_dps</td>\n",
       "      <td>all_col</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>751</th>\n",
       "      <td>0.010371</td>\n",
       "      <td>0.109394</td>\n",
       "      <td>0.184854</td>\n",
       "      <td>0.207206</td>\n",
       "      <td>0.248849</td>\n",
       "      <td>0.248849</td>\n",
       "      <td>7</td>\n",
       "      <td>damage_output_ps</td>\n",
       "      <td>all_col</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>752</th>\n",
       "      <td>0.023381</td>\n",
       "      <td>0.132654</td>\n",
       "      <td>0.197715</td>\n",
       "      <td>0.205461</td>\n",
       "      <td>0.243134</td>\n",
       "      <td>0.243134</td>\n",
       "      <td>7</td>\n",
       "      <td>support</td>\n",
       "      <td>all_col</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>753</th>\n",
       "      <td>0.006365</td>\n",
       "      <td>0.122394</td>\n",
       "      <td>0.184854</td>\n",
       "      <td>0.207206</td>\n",
       "      <td>0.250532</td>\n",
       "      <td>0.250532</td>\n",
       "      <td>7</td>\n",
       "      <td>mini_tank</td>\n",
       "      <td>all_col</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>754</th>\n",
       "      <td>0.015196</td>\n",
       "      <td>0.279752</td>\n",
       "      <td>-0.112759</td>\n",
       "      <td>0.422395</td>\n",
       "      <td>0.296983</td>\n",
       "      <td>0.488964</td>\n",
       "      <td>7</td>\n",
       "      <td>damage_per_elixir</td>\n",
       "      <td>engineered</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>755</th>\n",
       "      <td>-0.033987</td>\n",
       "      <td>0.281805</td>\n",
       "      <td>0.253522</td>\n",
       "      <td>0.465129</td>\n",
       "      <td>0.266975</td>\n",
       "      <td>0.492265</td>\n",
       "      <td>7</td>\n",
       "      <td>damage_per_second</td>\n",
       "      <td>engineered</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>756</th>\n",
       "      <td>0.062800</td>\n",
       "      <td>0.301533</td>\n",
       "      <td>0.157268</td>\n",
       "      <td>0.490916</td>\n",
       "      <td>0.387891</td>\n",
       "      <td>0.387891</td>\n",
       "      <td>7</td>\n",
       "      <td>damage_output</td>\n",
       "      <td>engineered</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>757</th>\n",
       "      <td>0.115600</td>\n",
       "      <td>0.243450</td>\n",
       "      <td>0.316345</td>\n",
       "      <td>0.374594</td>\n",
       "      <td>0.434397</td>\n",
       "      <td>0.434397</td>\n",
       "      <td>7</td>\n",
       "      <td>hp_per_elixir</td>\n",
       "      <td>engineered</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>758</th>\n",
       "      <td>0.125645</td>\n",
       "      <td>0.290796</td>\n",
       "      <td>0.253522</td>\n",
       "      <td>0.465129</td>\n",
       "      <td>0.474517</td>\n",
       "      <td>0.474517</td>\n",
       "      <td>7</td>\n",
       "      <td>damage_by_hitpoints</td>\n",
       "      <td>engineered</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>759</th>\n",
       "      <td>-0.021732</td>\n",
       "      <td>0.248136</td>\n",
       "      <td>0.353331</td>\n",
       "      <td>0.431133</td>\n",
       "      <td>0.466487</td>\n",
       "      <td>0.466487</td>\n",
       "      <td>7</td>\n",
       "      <td>aoe_by_range</td>\n",
       "      <td>engineered</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>760</th>\n",
       "      <td>-0.150439</td>\n",
       "      <td>0.223694</td>\n",
       "      <td>0.238360</td>\n",
       "      <td>0.445319</td>\n",
       "      <td>0.475608</td>\n",
       "      <td>0.475608</td>\n",
       "      <td>7</td>\n",
       "      <td>aoe_by_damage</td>\n",
       "      <td>engineered</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>761</th>\n",
       "      <td>0.035091</td>\n",
       "      <td>0.119344</td>\n",
       "      <td>0.247386</td>\n",
       "      <td>0.247386</td>\n",
       "      <td>0.254302</td>\n",
       "      <td>0.254302</td>\n",
       "      <td>7</td>\n",
       "      <td>playable</td>\n",
       "      <td>original</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>762</th>\n",
       "      <td>0.072122</td>\n",
       "      <td>0.141598</td>\n",
       "      <td>0.210123</td>\n",
       "      <td>0.201421</td>\n",
       "      <td>0.223338</td>\n",
       "      <td>0.223338</td>\n",
       "      <td>7</td>\n",
       "      <td>aoe_bool</td>\n",
       "      <td>original</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>763</th>\n",
       "      <td>0.023593</td>\n",
       "      <td>0.141471</td>\n",
       "      <td>0.226335</td>\n",
       "      <td>0.257990</td>\n",
       "      <td>0.225226</td>\n",
       "      <td>0.225226</td>\n",
       "      <td>7</td>\n",
       "      <td>aoe_radius</td>\n",
       "      <td>original</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>764</th>\n",
       "      <td>-0.009874</td>\n",
       "      <td>0.127004</td>\n",
       "      <td>0.247386</td>\n",
       "      <td>0.247386</td>\n",
       "      <td>0.253620</td>\n",
       "      <td>0.253620</td>\n",
       "      <td>7</td>\n",
       "      <td>death_damage_bool</td>\n",
       "      <td>original</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>765</th>\n",
       "      <td>-0.021978</td>\n",
       "      <td>0.144837</td>\n",
       "      <td>0.247386</td>\n",
       "      <td>0.247386</td>\n",
       "      <td>0.232356</td>\n",
       "      <td>0.232356</td>\n",
       "      <td>7</td>\n",
       "      <td>fly_bool</td>\n",
       "      <td>original</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>766</th>\n",
       "      <td>0.056406</td>\n",
       "      <td>0.130513</td>\n",
       "      <td>0.227486</td>\n",
       "      <td>0.244974</td>\n",
       "      <td>0.240326</td>\n",
       "      <td>0.240326</td>\n",
       "      <td>7</td>\n",
       "      <td>spawn_bool</td>\n",
       "      <td>original</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>767</th>\n",
       "      <td>0.050057</td>\n",
       "      <td>0.140974</td>\n",
       "      <td>0.231599</td>\n",
       "      <td>0.249029</td>\n",
       "      <td>0.247968</td>\n",
       "      <td>0.247968</td>\n",
       "      <td>7</td>\n",
       "      <td>can_evolve</td>\n",
       "      <td>original</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>768</th>\n",
       "      <td>0.015962</td>\n",
       "      <td>0.111680</td>\n",
       "      <td>0.271665</td>\n",
       "      <td>0.271665</td>\n",
       "      <td>0.244935</td>\n",
       "      <td>0.244935</td>\n",
       "      <td>7</td>\n",
       "      <td>elixircost</td>\n",
       "      <td>original</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>769</th>\n",
       "      <td>0.001856</td>\n",
       "      <td>0.142497</td>\n",
       "      <td>0.247386</td>\n",
       "      <td>0.247386</td>\n",
       "      <td>0.242226</td>\n",
       "      <td>0.242226</td>\n",
       "      <td>7</td>\n",
       "      <td>hit_speed</td>\n",
       "      <td>original</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>770</th>\n",
       "      <td>0.026657</td>\n",
       "      <td>0.120737</td>\n",
       "      <td>0.224926</td>\n",
       "      <td>0.224926</td>\n",
       "      <td>0.215683</td>\n",
       "      <td>0.215683</td>\n",
       "      <td>7</td>\n",
       "      <td>special_damage</td>\n",
       "      <td>original</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>771</th>\n",
       "      <td>0.017695</td>\n",
       "      <td>0.113345</td>\n",
       "      <td>0.247386</td>\n",
       "      <td>0.247386</td>\n",
       "      <td>0.232356</td>\n",
       "      <td>0.232356</td>\n",
       "      <td>7</td>\n",
       "      <td>count</td>\n",
       "      <td>original</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>772</th>\n",
       "      <td>0.007231</td>\n",
       "      <td>0.125449</td>\n",
       "      <td>0.247386</td>\n",
       "      <td>0.247386</td>\n",
       "      <td>0.250309</td>\n",
       "      <td>0.250309</td>\n",
       "      <td>7</td>\n",
       "      <td>hitpoints</td>\n",
       "      <td>original</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>773</th>\n",
       "      <td>0.028528</td>\n",
       "      <td>0.117187</td>\n",
       "      <td>0.247386</td>\n",
       "      <td>0.247386</td>\n",
       "      <td>0.232356</td>\n",
       "      <td>0.232356</td>\n",
       "      <td>7</td>\n",
       "      <td>shield_bool</td>\n",
       "      <td>original</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>774</th>\n",
       "      <td>0.048387</td>\n",
       "      <td>0.132785</td>\n",
       "      <td>0.239047</td>\n",
       "      <td>0.239047</td>\n",
       "      <td>0.232823</td>\n",
       "      <td>0.232823</td>\n",
       "      <td>7</td>\n",
       "      <td>damage</td>\n",
       "      <td>original</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>775</th>\n",
       "      <td>0.007049</td>\n",
       "      <td>0.118687</td>\n",
       "      <td>0.207870</td>\n",
       "      <td>0.243410</td>\n",
       "      <td>0.223521</td>\n",
       "      <td>0.223521</td>\n",
       "      <td>7</td>\n",
       "      <td>attack_count</td>\n",
       "      <td>original</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>776</th>\n",
       "      <td>0.018586</td>\n",
       "      <td>0.112522</td>\n",
       "      <td>0.247386</td>\n",
       "      <td>0.247386</td>\n",
       "      <td>0.234876</td>\n",
       "      <td>0.234876</td>\n",
       "      <td>7</td>\n",
       "      <td>range</td>\n",
       "      <td>original</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>777</th>\n",
       "      <td>-0.000318</td>\n",
       "      <td>0.132209</td>\n",
       "      <td>0.216063</td>\n",
       "      <td>0.240924</td>\n",
       "      <td>0.201879</td>\n",
       "      <td>0.201879</td>\n",
       "      <td>7</td>\n",
       "      <td>affected_crown</td>\n",
       "      <td>original</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>778</th>\n",
       "      <td>-0.006272</td>\n",
       "      <td>0.117934</td>\n",
       "      <td>0.247386</td>\n",
       "      <td>0.247386</td>\n",
       "      <td>0.232356</td>\n",
       "      <td>0.232356</td>\n",
       "      <td>7</td>\n",
       "      <td>has_lifetime</td>\n",
       "      <td>original</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>779</th>\n",
       "      <td>0.018708</td>\n",
       "      <td>0.121340</td>\n",
       "      <td>0.247386</td>\n",
       "      <td>0.247386</td>\n",
       "      <td>0.232356</td>\n",
       "      <td>0.232356</td>\n",
       "      <td>7</td>\n",
       "      <td>invisible</td>\n",
       "      <td>original</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>780</th>\n",
       "      <td>0.021762</td>\n",
       "      <td>0.125641</td>\n",
       "      <td>0.247386</td>\n",
       "      <td>0.247386</td>\n",
       "      <td>0.232356</td>\n",
       "      <td>0.232356</td>\n",
       "      <td>7</td>\n",
       "      <td>has_ability</td>\n",
       "      <td>original</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>781</th>\n",
       "      <td>0.028631</td>\n",
       "      <td>0.107635</td>\n",
       "      <td>0.247386</td>\n",
       "      <td>0.247386</td>\n",
       "      <td>0.231401</td>\n",
       "      <td>0.231401</td>\n",
       "      <td>7</td>\n",
       "      <td>any_target</td>\n",
       "      <td>original</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>782</th>\n",
       "      <td>0.028631</td>\n",
       "      <td>0.107635</td>\n",
       "      <td>0.247386</td>\n",
       "      <td>0.247386</td>\n",
       "      <td>0.211797</td>\n",
       "      <td>0.211797</td>\n",
       "      <td>7</td>\n",
       "      <td>building_target</td>\n",
       "      <td>original</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>783</th>\n",
       "      <td>0.014146</td>\n",
       "      <td>0.103661</td>\n",
       "      <td>0.247386</td>\n",
       "      <td>0.247386</td>\n",
       "      <td>0.211797</td>\n",
       "      <td>0.211797</td>\n",
       "      <td>7</td>\n",
       "      <td>ground_target</td>\n",
       "      <td>original</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>784</th>\n",
       "      <td>0.073369</td>\n",
       "      <td>0.132721</td>\n",
       "      <td>0.209680</td>\n",
       "      <td>0.240842</td>\n",
       "      <td>0.232356</td>\n",
       "      <td>0.232356</td>\n",
       "      <td>7</td>\n",
       "      <td>has_upon_breaking_spawn</td>\n",
       "      <td>original</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>785</th>\n",
       "      <td>0.064170</td>\n",
       "      <td>0.145074</td>\n",
       "      <td>0.247386</td>\n",
       "      <td>0.247386</td>\n",
       "      <td>0.240326</td>\n",
       "      <td>0.240326</td>\n",
       "      <td>7</td>\n",
       "      <td>has_upon_death_spawn</td>\n",
       "      <td>original</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>786</th>\n",
       "      <td>0.023089</td>\n",
       "      <td>0.134047</td>\n",
       "      <td>0.254833</td>\n",
       "      <td>0.272412</td>\n",
       "      <td>0.249483</td>\n",
       "      <td>0.249483</td>\n",
       "      <td>7</td>\n",
       "      <td>has_periodic_spawn</td>\n",
       "      <td>original</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>787</th>\n",
       "      <td>0.021335</td>\n",
       "      <td>0.131113</td>\n",
       "      <td>0.191547</td>\n",
       "      <td>0.219127</td>\n",
       "      <td>0.230142</td>\n",
       "      <td>0.230142</td>\n",
       "      <td>7</td>\n",
       "      <td>single_damage_type</td>\n",
       "      <td>original</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>788</th>\n",
       "      <td>0.037686</td>\n",
       "      <td>0.131765</td>\n",
       "      <td>0.247386</td>\n",
       "      <td>0.247386</td>\n",
       "      <td>0.232356</td>\n",
       "      <td>0.232356</td>\n",
       "      <td>7</td>\n",
       "      <td>is_troop</td>\n",
       "      <td>original</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>789</th>\n",
       "      <td>0.037686</td>\n",
       "      <td>0.131765</td>\n",
       "      <td>0.247386</td>\n",
       "      <td>0.247386</td>\n",
       "      <td>0.232356</td>\n",
       "      <td>0.232356</td>\n",
       "      <td>7</td>\n",
       "      <td>is_spell</td>\n",
       "      <td>original</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>790</th>\n",
       "      <td>0.037686</td>\n",
       "      <td>0.131765</td>\n",
       "      <td>0.247386</td>\n",
       "      <td>0.247386</td>\n",
       "      <td>0.232356</td>\n",
       "      <td>0.232356</td>\n",
       "      <td>7</td>\n",
       "      <td>is_building</td>\n",
       "      <td>original</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>791</th>\n",
       "      <td>0.037686</td>\n",
       "      <td>0.131765</td>\n",
       "      <td>0.247386</td>\n",
       "      <td>0.247386</td>\n",
       "      <td>0.232356</td>\n",
       "      <td>0.232356</td>\n",
       "      <td>7</td>\n",
       "      <td>is_tower_troop</td>\n",
       "      <td>original</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>792</th>\n",
       "      <td>-0.105782</td>\n",
       "      <td>0.123079</td>\n",
       "      <td>0.265997</td>\n",
       "      <td>0.241797</td>\n",
       "      <td>0.232356</td>\n",
       "      <td>0.232356</td>\n",
       "      <td>7</td>\n",
       "      <td>is_spawned</td>\n",
       "      <td>original</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>793</th>\n",
       "      <td>0.010695</td>\n",
       "      <td>0.143981</td>\n",
       "      <td>0.247386</td>\n",
       "      <td>0.247386</td>\n",
       "      <td>0.232356</td>\n",
       "      <td>0.232356</td>\n",
       "      <td>7</td>\n",
       "      <td>speed</td>\n",
       "      <td>original</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>794</th>\n",
       "      <td>0.028821</td>\n",
       "      <td>0.119588</td>\n",
       "      <td>0.247386</td>\n",
       "      <td>0.247386</td>\n",
       "      <td>0.244767</td>\n",
       "      <td>0.244767</td>\n",
       "      <td>7</td>\n",
       "      <td>has_ranged_attack</td>\n",
       "      <td>original</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>795</th>\n",
       "      <td>-0.008521</td>\n",
       "      <td>0.135832</td>\n",
       "      <td>0.213855</td>\n",
       "      <td>0.239039</td>\n",
       "      <td>0.224565</td>\n",
       "      <td>0.224565</td>\n",
       "      <td>7</td>\n",
       "      <td>special_attack_type</td>\n",
       "      <td>original</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>796</th>\n",
       "      <td>-0.015565</td>\n",
       "      <td>0.132115</td>\n",
       "      <td>0.249243</td>\n",
       "      <td>0.267906</td>\n",
       "      <td>0.257180</td>\n",
       "      <td>0.257180</td>\n",
       "      <td>7</td>\n",
       "      <td>has_friendly_buff</td>\n",
       "      <td>original</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>797</th>\n",
       "      <td>0.035091</td>\n",
       "      <td>0.119344</td>\n",
       "      <td>0.247386</td>\n",
       "      <td>0.247386</td>\n",
       "      <td>0.254302</td>\n",
       "      <td>0.254302</td>\n",
       "      <td>7</td>\n",
       "      <td>is_free_card</td>\n",
       "      <td>original</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>798</th>\n",
       "      <td>-0.030302</td>\n",
       "      <td>0.142494</td>\n",
       "      <td>0.247386</td>\n",
       "      <td>0.247386</td>\n",
       "      <td>0.230737</td>\n",
       "      <td>0.230737</td>\n",
       "      <td>7</td>\n",
       "      <td>no_hit_speed</td>\n",
       "      <td>original</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>799</th>\n",
       "      <td>0.012906</td>\n",
       "      <td>0.117088</td>\n",
       "      <td>0.219208</td>\n",
       "      <td>0.236745</td>\n",
       "      <td>0.223521</td>\n",
       "      <td>0.223521</td>\n",
       "      <td>7</td>\n",
       "      <td>no_attack</td>\n",
       "      <td>original</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>800</th>\n",
       "      <td>-0.004751</td>\n",
       "      <td>0.136102</td>\n",
       "      <td>0.247386</td>\n",
       "      <td>0.247386</td>\n",
       "      <td>0.232356</td>\n",
       "      <td>0.232356</td>\n",
       "      <td>7</td>\n",
       "      <td>no_hitpoints</td>\n",
       "      <td>original</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>801</th>\n",
       "      <td>0.050390</td>\n",
       "      <td>0.121410</td>\n",
       "      <td>0.247386</td>\n",
       "      <td>0.247386</td>\n",
       "      <td>0.232356</td>\n",
       "      <td>0.232356</td>\n",
       "      <td>7</td>\n",
       "      <td>win_con</td>\n",
       "      <td>original</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>802</th>\n",
       "      <td>0.043528</td>\n",
       "      <td>0.114799</td>\n",
       "      <td>0.256292</td>\n",
       "      <td>0.256292</td>\n",
       "      <td>0.225226</td>\n",
       "      <td>0.225226</td>\n",
       "      <td>7</td>\n",
       "      <td>aoe_per_elixir</td>\n",
       "      <td>original</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>803</th>\n",
       "      <td>-0.014811</td>\n",
       "      <td>0.131992</td>\n",
       "      <td>0.268194</td>\n",
       "      <td>0.268194</td>\n",
       "      <td>0.215683</td>\n",
       "      <td>0.215683</td>\n",
       "      <td>7</td>\n",
       "      <td>control_special</td>\n",
       "      <td>original</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>804</th>\n",
       "      <td>-0.025961</td>\n",
       "      <td>0.147719</td>\n",
       "      <td>0.184739</td>\n",
       "      <td>0.184739</td>\n",
       "      <td>0.232356</td>\n",
       "      <td>0.232356</td>\n",
       "      <td>7</td>\n",
       "      <td>dps_special</td>\n",
       "      <td>original</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>805</th>\n",
       "      <td>0.019010</td>\n",
       "      <td>0.121224</td>\n",
       "      <td>0.247386</td>\n",
       "      <td>0.247386</td>\n",
       "      <td>0.223332</td>\n",
       "      <td>0.223332</td>\n",
       "      <td>7</td>\n",
       "      <td>air_control</td>\n",
       "      <td>original</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>806</th>\n",
       "      <td>0.051154</td>\n",
       "      <td>0.125187</td>\n",
       "      <td>0.247386</td>\n",
       "      <td>0.247386</td>\n",
       "      <td>0.234396</td>\n",
       "      <td>0.234396</td>\n",
       "      <td>7</td>\n",
       "      <td>ground_dps</td>\n",
       "      <td>original</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>807</th>\n",
       "      <td>0.026308</td>\n",
       "      <td>0.125693</td>\n",
       "      <td>0.247386</td>\n",
       "      <td>0.247386</td>\n",
       "      <td>0.232356</td>\n",
       "      <td>0.232356</td>\n",
       "      <td>7</td>\n",
       "      <td>win_con_dmg</td>\n",
       "      <td>original</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>808</th>\n",
       "      <td>0.005607</td>\n",
       "      <td>0.125447</td>\n",
       "      <td>0.190041</td>\n",
       "      <td>0.192159</td>\n",
       "      <td>0.235984</td>\n",
       "      <td>0.235984</td>\n",
       "      <td>7</td>\n",
       "      <td>high_dps</td>\n",
       "      <td>original</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>809</th>\n",
       "      <td>0.038387</td>\n",
       "      <td>0.112207</td>\n",
       "      <td>0.247386</td>\n",
       "      <td>0.247386</td>\n",
       "      <td>0.235043</td>\n",
       "      <td>0.235043</td>\n",
       "      <td>7</td>\n",
       "      <td>damage_output_ps</td>\n",
       "      <td>original</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>810</th>\n",
       "      <td>0.093528</td>\n",
       "      <td>0.123259</td>\n",
       "      <td>0.225713</td>\n",
       "      <td>0.243105</td>\n",
       "      <td>0.223521</td>\n",
       "      <td>0.223521</td>\n",
       "      <td>7</td>\n",
       "      <td>support</td>\n",
       "      <td>original</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>811</th>\n",
       "      <td>0.041136</td>\n",
       "      <td>0.134074</td>\n",
       "      <td>0.247386</td>\n",
       "      <td>0.247386</td>\n",
       "      <td>0.232356</td>\n",
       "      <td>0.232356</td>\n",
       "      <td>7</td>\n",
       "      <td>mini_tank</td>\n",
       "      <td>original</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>812</th>\n",
       "      <td>0.142749</td>\n",
       "      <td>0.140545</td>\n",
       "      <td>0.288911</td>\n",
       "      <td>0.288911</td>\n",
       "      <td>0.310745</td>\n",
       "      <td>0.310745</td>\n",
       "      <td>7</td>\n",
       "      <td>aoe_radius</td>\n",
       "      <td>num_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>813</th>\n",
       "      <td>0.052479</td>\n",
       "      <td>0.159303</td>\n",
       "      <td>0.213059</td>\n",
       "      <td>0.275755</td>\n",
       "      <td>0.364000</td>\n",
       "      <td>0.287954</td>\n",
       "      <td>7</td>\n",
       "      <td>can_evolve</td>\n",
       "      <td>num_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>814</th>\n",
       "      <td>0.118535</td>\n",
       "      <td>0.154687</td>\n",
       "      <td>0.347082</td>\n",
       "      <td>0.347082</td>\n",
       "      <td>0.266618</td>\n",
       "      <td>0.266618</td>\n",
       "      <td>7</td>\n",
       "      <td>elixircost</td>\n",
       "      <td>num_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>815</th>\n",
       "      <td>0.149993</td>\n",
       "      <td>0.161741</td>\n",
       "      <td>0.175109</td>\n",
       "      <td>0.289698</td>\n",
       "      <td>0.308595</td>\n",
       "      <td>0.308595</td>\n",
       "      <td>7</td>\n",
       "      <td>hit_speed</td>\n",
       "      <td>num_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>816</th>\n",
       "      <td>0.090298</td>\n",
       "      <td>0.158051</td>\n",
       "      <td>0.175109</td>\n",
       "      <td>0.289698</td>\n",
       "      <td>0.310745</td>\n",
       "      <td>0.310745</td>\n",
       "      <td>7</td>\n",
       "      <td>count</td>\n",
       "      <td>num_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>817</th>\n",
       "      <td>0.134902</td>\n",
       "      <td>0.171022</td>\n",
       "      <td>0.175109</td>\n",
       "      <td>0.289698</td>\n",
       "      <td>0.343274</td>\n",
       "      <td>0.343274</td>\n",
       "      <td>7</td>\n",
       "      <td>hitpoints</td>\n",
       "      <td>num_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>818</th>\n",
       "      <td>0.068877</td>\n",
       "      <td>0.152631</td>\n",
       "      <td>0.260675</td>\n",
       "      <td>0.269125</td>\n",
       "      <td>0.304013</td>\n",
       "      <td>0.304013</td>\n",
       "      <td>7</td>\n",
       "      <td>damage</td>\n",
       "      <td>num_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>819</th>\n",
       "      <td>0.167004</td>\n",
       "      <td>0.152011</td>\n",
       "      <td>0.209623</td>\n",
       "      <td>0.363168</td>\n",
       "      <td>0.253482</td>\n",
       "      <td>0.282417</td>\n",
       "      <td>7</td>\n",
       "      <td>attack_count</td>\n",
       "      <td>num_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>820</th>\n",
       "      <td>0.142134</td>\n",
       "      <td>0.163329</td>\n",
       "      <td>0.175109</td>\n",
       "      <td>0.289698</td>\n",
       "      <td>0.318400</td>\n",
       "      <td>0.318400</td>\n",
       "      <td>7</td>\n",
       "      <td>range</td>\n",
       "      <td>num_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>821</th>\n",
       "      <td>-0.108669</td>\n",
       "      <td>0.151345</td>\n",
       "      <td>0.175109</td>\n",
       "      <td>0.289698</td>\n",
       "      <td>0.310745</td>\n",
       "      <td>0.310745</td>\n",
       "      <td>7</td>\n",
       "      <td>speed</td>\n",
       "      <td>num_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>822</th>\n",
       "      <td>0.134901</td>\n",
       "      <td>0.137939</td>\n",
       "      <td>0.297332</td>\n",
       "      <td>0.320166</td>\n",
       "      <td>0.307636</td>\n",
       "      <td>0.307636</td>\n",
       "      <td>7</td>\n",
       "      <td>damage_per_elixir</td>\n",
       "      <td>num_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>823</th>\n",
       "      <td>-0.087060</td>\n",
       "      <td>0.174961</td>\n",
       "      <td>0.175109</td>\n",
       "      <td>0.289698</td>\n",
       "      <td>0.311838</td>\n",
       "      <td>0.311838</td>\n",
       "      <td>7</td>\n",
       "      <td>damage_per_second</td>\n",
       "      <td>num_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>824</th>\n",
       "      <td>-0.095126</td>\n",
       "      <td>0.149512</td>\n",
       "      <td>0.284828</td>\n",
       "      <td>0.325294</td>\n",
       "      <td>0.243491</td>\n",
       "      <td>0.275018</td>\n",
       "      <td>7</td>\n",
       "      <td>damage_output</td>\n",
       "      <td>num_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>825</th>\n",
       "      <td>0.101260</td>\n",
       "      <td>0.136335</td>\n",
       "      <td>0.271879</td>\n",
       "      <td>0.339375</td>\n",
       "      <td>0.334719</td>\n",
       "      <td>0.334719</td>\n",
       "      <td>7</td>\n",
       "      <td>hp_per_elixir</td>\n",
       "      <td>num_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>826</th>\n",
       "      <td>0.149056</td>\n",
       "      <td>0.169342</td>\n",
       "      <td>0.175109</td>\n",
       "      <td>0.289698</td>\n",
       "      <td>0.312569</td>\n",
       "      <td>0.312569</td>\n",
       "      <td>7</td>\n",
       "      <td>damage_by_hitpoints</td>\n",
       "      <td>num_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>827</th>\n",
       "      <td>0.098247</td>\n",
       "      <td>0.161244</td>\n",
       "      <td>0.288911</td>\n",
       "      <td>0.288911</td>\n",
       "      <td>0.310745</td>\n",
       "      <td>0.310745</td>\n",
       "      <td>7</td>\n",
       "      <td>aoe_by_range</td>\n",
       "      <td>num_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>828</th>\n",
       "      <td>0.088131</td>\n",
       "      <td>0.142910</td>\n",
       "      <td>0.232501</td>\n",
       "      <td>0.268966</td>\n",
       "      <td>0.310745</td>\n",
       "      <td>0.310745</td>\n",
       "      <td>7</td>\n",
       "      <td>aoe_by_damage</td>\n",
       "      <td>num_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>829</th>\n",
       "      <td>0.163758</td>\n",
       "      <td>0.143204</td>\n",
       "      <td>0.262484</td>\n",
       "      <td>0.308784</td>\n",
       "      <td>0.310745</td>\n",
       "      <td>0.310745</td>\n",
       "      <td>7</td>\n",
       "      <td>aoe_per_elixir</td>\n",
       "      <td>num_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>830</th>\n",
       "      <td>-0.094322</td>\n",
       "      <td>0.166126</td>\n",
       "      <td>0.175109</td>\n",
       "      <td>0.289698</td>\n",
       "      <td>0.307491</td>\n",
       "      <td>0.307491</td>\n",
       "      <td>7</td>\n",
       "      <td>damage_output_ps</td>\n",
       "      <td>num_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>831</th>\n",
       "      <td>0.075543</td>\n",
       "      <td>0.135299</td>\n",
       "      <td>0.408323</td>\n",
       "      <td>0.408323</td>\n",
       "      <td>0.256397</td>\n",
       "      <td>0.256397</td>\n",
       "      <td>7</td>\n",
       "      <td>playable</td>\n",
       "      <td>bool_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>832</th>\n",
       "      <td>0.077903</td>\n",
       "      <td>0.168291</td>\n",
       "      <td>0.382726</td>\n",
       "      <td>0.412986</td>\n",
       "      <td>0.341201</td>\n",
       "      <td>0.341201</td>\n",
       "      <td>7</td>\n",
       "      <td>aoe_bool</td>\n",
       "      <td>bool_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>833</th>\n",
       "      <td>0.074335</td>\n",
       "      <td>0.176383</td>\n",
       "      <td>0.408323</td>\n",
       "      <td>0.408323</td>\n",
       "      <td>0.353401</td>\n",
       "      <td>0.353401</td>\n",
       "      <td>7</td>\n",
       "      <td>death_damage_bool</td>\n",
       "      <td>bool_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>834</th>\n",
       "      <td>0.067465</td>\n",
       "      <td>0.172628</td>\n",
       "      <td>0.408323</td>\n",
       "      <td>0.408323</td>\n",
       "      <td>0.250980</td>\n",
       "      <td>0.300451</td>\n",
       "      <td>7</td>\n",
       "      <td>fly_bool</td>\n",
       "      <td>bool_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>835</th>\n",
       "      <td>0.057658</td>\n",
       "      <td>0.154074</td>\n",
       "      <td>0.411299</td>\n",
       "      <td>0.411299</td>\n",
       "      <td>0.290049</td>\n",
       "      <td>0.290049</td>\n",
       "      <td>7</td>\n",
       "      <td>spawn_bool</td>\n",
       "      <td>bool_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>836</th>\n",
       "      <td>0.118325</td>\n",
       "      <td>0.179360</td>\n",
       "      <td>0.426272</td>\n",
       "      <td>0.426272</td>\n",
       "      <td>0.250840</td>\n",
       "      <td>0.300451</td>\n",
       "      <td>7</td>\n",
       "      <td>special_damage</td>\n",
       "      <td>bool_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>837</th>\n",
       "      <td>0.095832</td>\n",
       "      <td>0.174999</td>\n",
       "      <td>0.408323</td>\n",
       "      <td>0.408323</td>\n",
       "      <td>0.250980</td>\n",
       "      <td>0.300451</td>\n",
       "      <td>7</td>\n",
       "      <td>shield_bool</td>\n",
       "      <td>bool_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>838</th>\n",
       "      <td>0.082230</td>\n",
       "      <td>0.179555</td>\n",
       "      <td>0.406837</td>\n",
       "      <td>0.406837</td>\n",
       "      <td>0.246187</td>\n",
       "      <td>0.295657</td>\n",
       "      <td>7</td>\n",
       "      <td>affected_crown</td>\n",
       "      <td>bool_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>839</th>\n",
       "      <td>-0.018937</td>\n",
       "      <td>0.174302</td>\n",
       "      <td>0.408323</td>\n",
       "      <td>0.408323</td>\n",
       "      <td>0.250980</td>\n",
       "      <td>0.300451</td>\n",
       "      <td>7</td>\n",
       "      <td>has_lifetime</td>\n",
       "      <td>bool_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>840</th>\n",
       "      <td>0.130740</td>\n",
       "      <td>0.179921</td>\n",
       "      <td>0.408323</td>\n",
       "      <td>0.408323</td>\n",
       "      <td>0.250980</td>\n",
       "      <td>0.300451</td>\n",
       "      <td>7</td>\n",
       "      <td>invisible</td>\n",
       "      <td>bool_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>841</th>\n",
       "      <td>0.163496</td>\n",
       "      <td>0.185737</td>\n",
       "      <td>0.408323</td>\n",
       "      <td>0.408323</td>\n",
       "      <td>0.250980</td>\n",
       "      <td>0.300451</td>\n",
       "      <td>7</td>\n",
       "      <td>has_ability</td>\n",
       "      <td>bool_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>842</th>\n",
       "      <td>0.094865</td>\n",
       "      <td>0.154150</td>\n",
       "      <td>0.408323</td>\n",
       "      <td>0.408323</td>\n",
       "      <td>0.291097</td>\n",
       "      <td>0.291097</td>\n",
       "      <td>7</td>\n",
       "      <td>any_target</td>\n",
       "      <td>bool_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>843</th>\n",
       "      <td>0.094865</td>\n",
       "      <td>0.154150</td>\n",
       "      <td>0.408323</td>\n",
       "      <td>0.408323</td>\n",
       "      <td>0.296728</td>\n",
       "      <td>0.296728</td>\n",
       "      <td>7</td>\n",
       "      <td>building_target</td>\n",
       "      <td>bool_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>844</th>\n",
       "      <td>0.053474</td>\n",
       "      <td>0.165453</td>\n",
       "      <td>0.408323</td>\n",
       "      <td>0.408323</td>\n",
       "      <td>0.296728</td>\n",
       "      <td>0.296728</td>\n",
       "      <td>7</td>\n",
       "      <td>ground_target</td>\n",
       "      <td>bool_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>845</th>\n",
       "      <td>0.064815</td>\n",
       "      <td>0.177957</td>\n",
       "      <td>0.421017</td>\n",
       "      <td>0.421017</td>\n",
       "      <td>0.250980</td>\n",
       "      <td>0.300451</td>\n",
       "      <td>7</td>\n",
       "      <td>has_upon_breaking_spawn</td>\n",
       "      <td>bool_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>846</th>\n",
       "      <td>0.069478</td>\n",
       "      <td>0.180090</td>\n",
       "      <td>0.408323</td>\n",
       "      <td>0.408323</td>\n",
       "      <td>0.290049</td>\n",
       "      <td>0.290049</td>\n",
       "      <td>7</td>\n",
       "      <td>has_upon_death_spawn</td>\n",
       "      <td>bool_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>847</th>\n",
       "      <td>0.118619</td>\n",
       "      <td>0.179680</td>\n",
       "      <td>0.446708</td>\n",
       "      <td>0.446708</td>\n",
       "      <td>0.350060</td>\n",
       "      <td>0.350060</td>\n",
       "      <td>7</td>\n",
       "      <td>has_periodic_spawn</td>\n",
       "      <td>bool_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>848</th>\n",
       "      <td>0.106628</td>\n",
       "      <td>0.137891</td>\n",
       "      <td>0.409778</td>\n",
       "      <td>0.409778</td>\n",
       "      <td>0.250980</td>\n",
       "      <td>0.300451</td>\n",
       "      <td>7</td>\n",
       "      <td>single_damage_type</td>\n",
       "      <td>bool_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>849</th>\n",
       "      <td>0.028059</td>\n",
       "      <td>0.174214</td>\n",
       "      <td>0.408323</td>\n",
       "      <td>0.408323</td>\n",
       "      <td>0.250980</td>\n",
       "      <td>0.300451</td>\n",
       "      <td>7</td>\n",
       "      <td>is_troop</td>\n",
       "      <td>bool_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>850</th>\n",
       "      <td>0.028059</td>\n",
       "      <td>0.174214</td>\n",
       "      <td>0.408323</td>\n",
       "      <td>0.408323</td>\n",
       "      <td>0.250980</td>\n",
       "      <td>0.300451</td>\n",
       "      <td>7</td>\n",
       "      <td>is_spell</td>\n",
       "      <td>bool_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>851</th>\n",
       "      <td>0.028059</td>\n",
       "      <td>0.174214</td>\n",
       "      <td>0.408323</td>\n",
       "      <td>0.408323</td>\n",
       "      <td>0.250980</td>\n",
       "      <td>0.300451</td>\n",
       "      <td>7</td>\n",
       "      <td>is_building</td>\n",
       "      <td>bool_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>852</th>\n",
       "      <td>0.028059</td>\n",
       "      <td>0.174214</td>\n",
       "      <td>0.408323</td>\n",
       "      <td>0.408323</td>\n",
       "      <td>0.250980</td>\n",
       "      <td>0.300451</td>\n",
       "      <td>7</td>\n",
       "      <td>is_tower_troop</td>\n",
       "      <td>bool_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>853</th>\n",
       "      <td>0.070489</td>\n",
       "      <td>0.176746</td>\n",
       "      <td>0.401255</td>\n",
       "      <td>0.401255</td>\n",
       "      <td>0.250980</td>\n",
       "      <td>0.300451</td>\n",
       "      <td>7</td>\n",
       "      <td>is_spawned</td>\n",
       "      <td>bool_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>854</th>\n",
       "      <td>0.094730</td>\n",
       "      <td>0.174290</td>\n",
       "      <td>0.408323</td>\n",
       "      <td>0.408323</td>\n",
       "      <td>0.346884</td>\n",
       "      <td>0.346884</td>\n",
       "      <td>7</td>\n",
       "      <td>has_ranged_attack</td>\n",
       "      <td>bool_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>855</th>\n",
       "      <td>0.046421</td>\n",
       "      <td>0.123496</td>\n",
       "      <td>0.434640</td>\n",
       "      <td>0.434640</td>\n",
       "      <td>0.245294</td>\n",
       "      <td>0.300451</td>\n",
       "      <td>7</td>\n",
       "      <td>special_attack_type</td>\n",
       "      <td>bool_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>856</th>\n",
       "      <td>0.122611</td>\n",
       "      <td>0.164464</td>\n",
       "      <td>0.475001</td>\n",
       "      <td>0.488764</td>\n",
       "      <td>0.291110</td>\n",
       "      <td>0.291110</td>\n",
       "      <td>7</td>\n",
       "      <td>has_friendly_buff</td>\n",
       "      <td>bool_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>857</th>\n",
       "      <td>0.075543</td>\n",
       "      <td>0.135299</td>\n",
       "      <td>0.408323</td>\n",
       "      <td>0.408323</td>\n",
       "      <td>0.256397</td>\n",
       "      <td>0.256397</td>\n",
       "      <td>7</td>\n",
       "      <td>is_free_card</td>\n",
       "      <td>bool_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>858</th>\n",
       "      <td>0.114077</td>\n",
       "      <td>0.180661</td>\n",
       "      <td>0.408323</td>\n",
       "      <td>0.408323</td>\n",
       "      <td>0.250980</td>\n",
       "      <td>0.300451</td>\n",
       "      <td>7</td>\n",
       "      <td>no_hit_speed</td>\n",
       "      <td>bool_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>859</th>\n",
       "      <td>0.080884</td>\n",
       "      <td>0.179499</td>\n",
       "      <td>0.394834</td>\n",
       "      <td>0.394834</td>\n",
       "      <td>0.300451</td>\n",
       "      <td>0.300451</td>\n",
       "      <td>7</td>\n",
       "      <td>no_attack</td>\n",
       "      <td>bool_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>860</th>\n",
       "      <td>0.106734</td>\n",
       "      <td>0.178964</td>\n",
       "      <td>0.408323</td>\n",
       "      <td>0.408323</td>\n",
       "      <td>0.250980</td>\n",
       "      <td>0.300451</td>\n",
       "      <td>7</td>\n",
       "      <td>no_hitpoints</td>\n",
       "      <td>bool_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>861</th>\n",
       "      <td>0.049794</td>\n",
       "      <td>0.172112</td>\n",
       "      <td>0.408323</td>\n",
       "      <td>0.408323</td>\n",
       "      <td>0.250980</td>\n",
       "      <td>0.300451</td>\n",
       "      <td>7</td>\n",
       "      <td>win_con</td>\n",
       "      <td>bool_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>862</th>\n",
       "      <td>0.050160</td>\n",
       "      <td>0.164405</td>\n",
       "      <td>0.457786</td>\n",
       "      <td>0.513556</td>\n",
       "      <td>0.250840</td>\n",
       "      <td>0.300451</td>\n",
       "      <td>7</td>\n",
       "      <td>control_special</td>\n",
       "      <td>bool_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>863</th>\n",
       "      <td>0.081245</td>\n",
       "      <td>0.182716</td>\n",
       "      <td>0.386328</td>\n",
       "      <td>0.386328</td>\n",
       "      <td>0.250980</td>\n",
       "      <td>0.300451</td>\n",
       "      <td>7</td>\n",
       "      <td>dps_special</td>\n",
       "      <td>bool_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>864</th>\n",
       "      <td>0.014980</td>\n",
       "      <td>0.174280</td>\n",
       "      <td>0.408323</td>\n",
       "      <td>0.408323</td>\n",
       "      <td>0.250460</td>\n",
       "      <td>0.259083</td>\n",
       "      <td>7</td>\n",
       "      <td>air_control</td>\n",
       "      <td>bool_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>865</th>\n",
       "      <td>0.016303</td>\n",
       "      <td>0.172712</td>\n",
       "      <td>0.408323</td>\n",
       "      <td>0.408323</td>\n",
       "      <td>0.316502</td>\n",
       "      <td>0.316502</td>\n",
       "      <td>7</td>\n",
       "      <td>ground_dps</td>\n",
       "      <td>bool_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>866</th>\n",
       "      <td>0.053871</td>\n",
       "      <td>0.146358</td>\n",
       "      <td>0.408323</td>\n",
       "      <td>0.408323</td>\n",
       "      <td>0.250980</td>\n",
       "      <td>0.300451</td>\n",
       "      <td>7</td>\n",
       "      <td>win_con_dmg</td>\n",
       "      <td>bool_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>867</th>\n",
       "      <td>0.091179</td>\n",
       "      <td>0.176519</td>\n",
       "      <td>0.371868</td>\n",
       "      <td>0.371868</td>\n",
       "      <td>0.312772</td>\n",
       "      <td>0.312772</td>\n",
       "      <td>7</td>\n",
       "      <td>high_dps</td>\n",
       "      <td>bool_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>868</th>\n",
       "      <td>0.056143</td>\n",
       "      <td>0.174845</td>\n",
       "      <td>0.402568</td>\n",
       "      <td>0.402568</td>\n",
       "      <td>0.300451</td>\n",
       "      <td>0.300451</td>\n",
       "      <td>7</td>\n",
       "      <td>support</td>\n",
       "      <td>bool_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>869</th>\n",
       "      <td>0.087376</td>\n",
       "      <td>0.180661</td>\n",
       "      <td>0.408323</td>\n",
       "      <td>0.408323</td>\n",
       "      <td>0.250980</td>\n",
       "      <td>0.300451</td>\n",
       "      <td>7</td>\n",
       "      <td>mini_tank</td>\n",
       "      <td>bool_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>870</th>\n",
       "      <td>0.020306</td>\n",
       "      <td>0.112655</td>\n",
       "      <td>0.192727</td>\n",
       "      <td>0.196270</td>\n",
       "      <td>0.222439</td>\n",
       "      <td>0.222439</td>\n",
       "      <td>8</td>\n",
       "      <td>playable</td>\n",
       "      <td>all_col</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>871</th>\n",
       "      <td>-0.005442</td>\n",
       "      <td>0.117219</td>\n",
       "      <td>0.206256</td>\n",
       "      <td>0.227806</td>\n",
       "      <td>0.191705</td>\n",
       "      <td>0.191705</td>\n",
       "      <td>8</td>\n",
       "      <td>aoe_bool</td>\n",
       "      <td>all_col</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>872</th>\n",
       "      <td>0.045023</td>\n",
       "      <td>0.113308</td>\n",
       "      <td>0.209540</td>\n",
       "      <td>0.208512</td>\n",
       "      <td>0.192863</td>\n",
       "      <td>0.192863</td>\n",
       "      <td>8</td>\n",
       "      <td>aoe_radius</td>\n",
       "      <td>all_col</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>873</th>\n",
       "      <td>0.055734</td>\n",
       "      <td>0.133665</td>\n",
       "      <td>0.192727</td>\n",
       "      <td>0.196270</td>\n",
       "      <td>0.213721</td>\n",
       "      <td>0.213721</td>\n",
       "      <td>8</td>\n",
       "      <td>death_damage_bool</td>\n",
       "      <td>all_col</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>874</th>\n",
       "      <td>-0.003159</td>\n",
       "      <td>0.107305</td>\n",
       "      <td>0.192727</td>\n",
       "      <td>0.196270</td>\n",
       "      <td>0.196428</td>\n",
       "      <td>0.196428</td>\n",
       "      <td>8</td>\n",
       "      <td>fly_bool</td>\n",
       "      <td>all_col</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>875</th>\n",
       "      <td>0.034676</td>\n",
       "      <td>0.121112</td>\n",
       "      <td>0.183250</td>\n",
       "      <td>0.180390</td>\n",
       "      <td>0.182532</td>\n",
       "      <td>0.182532</td>\n",
       "      <td>8</td>\n",
       "      <td>spawn_bool</td>\n",
       "      <td>all_col</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>876</th>\n",
       "      <td>0.049713</td>\n",
       "      <td>0.120358</td>\n",
       "      <td>0.189324</td>\n",
       "      <td>0.189324</td>\n",
       "      <td>0.228752</td>\n",
       "      <td>0.228752</td>\n",
       "      <td>8</td>\n",
       "      <td>can_evolve</td>\n",
       "      <td>all_col</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>877</th>\n",
       "      <td>-0.036662</td>\n",
       "      <td>0.102037</td>\n",
       "      <td>0.217566</td>\n",
       "      <td>0.186915</td>\n",
       "      <td>0.213676</td>\n",
       "      <td>0.213676</td>\n",
       "      <td>8</td>\n",
       "      <td>elixircost</td>\n",
       "      <td>all_col</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>878</th>\n",
       "      <td>0.032060</td>\n",
       "      <td>0.143889</td>\n",
       "      <td>0.192727</td>\n",
       "      <td>0.196270</td>\n",
       "      <td>0.205106</td>\n",
       "      <td>0.205106</td>\n",
       "      <td>8</td>\n",
       "      <td>hit_speed</td>\n",
       "      <td>all_col</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>879</th>\n",
       "      <td>-0.003803</td>\n",
       "      <td>0.127321</td>\n",
       "      <td>0.169920</td>\n",
       "      <td>0.180478</td>\n",
       "      <td>0.196428</td>\n",
       "      <td>0.196428</td>\n",
       "      <td>8</td>\n",
       "      <td>special_damage</td>\n",
       "      <td>all_col</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>880</th>\n",
       "      <td>0.002689</td>\n",
       "      <td>0.131475</td>\n",
       "      <td>0.192727</td>\n",
       "      <td>0.196270</td>\n",
       "      <td>0.196428</td>\n",
       "      <td>0.196428</td>\n",
       "      <td>8</td>\n",
       "      <td>count</td>\n",
       "      <td>all_col</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>881</th>\n",
       "      <td>0.030015</td>\n",
       "      <td>0.137480</td>\n",
       "      <td>0.192727</td>\n",
       "      <td>0.196270</td>\n",
       "      <td>0.211886</td>\n",
       "      <td>0.211886</td>\n",
       "      <td>8</td>\n",
       "      <td>hitpoints</td>\n",
       "      <td>all_col</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>882</th>\n",
       "      <td>0.009878</td>\n",
       "      <td>0.100007</td>\n",
       "      <td>0.192727</td>\n",
       "      <td>0.196270</td>\n",
       "      <td>0.196428</td>\n",
       "      <td>0.196428</td>\n",
       "      <td>8</td>\n",
       "      <td>shield_bool</td>\n",
       "      <td>all_col</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>883</th>\n",
       "      <td>0.001371</td>\n",
       "      <td>0.102576</td>\n",
       "      <td>0.197291</td>\n",
       "      <td>0.197291</td>\n",
       "      <td>0.194360</td>\n",
       "      <td>0.194360</td>\n",
       "      <td>8</td>\n",
       "      <td>damage</td>\n",
       "      <td>all_col</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>884</th>\n",
       "      <td>0.010554</td>\n",
       "      <td>0.140543</td>\n",
       "      <td>0.187728</td>\n",
       "      <td>0.189755</td>\n",
       "      <td>0.196428</td>\n",
       "      <td>0.196428</td>\n",
       "      <td>8</td>\n",
       "      <td>attack_count</td>\n",
       "      <td>all_col</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>885</th>\n",
       "      <td>0.022288</td>\n",
       "      <td>0.089904</td>\n",
       "      <td>0.192727</td>\n",
       "      <td>0.196270</td>\n",
       "      <td>0.194106</td>\n",
       "      <td>0.194106</td>\n",
       "      <td>8</td>\n",
       "      <td>range</td>\n",
       "      <td>all_col</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>0.001192</td>\n",
       "      <td>0.103816</td>\n",
       "      <td>0.178136</td>\n",
       "      <td>0.175611</td>\n",
       "      <td>0.196428</td>\n",
       "      <td>0.196428</td>\n",
       "      <td>8</td>\n",
       "      <td>affected_crown</td>\n",
       "      <td>all_col</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>0.046227</td>\n",
       "      <td>0.116088</td>\n",
       "      <td>0.192727</td>\n",
       "      <td>0.196270</td>\n",
       "      <td>0.196428</td>\n",
       "      <td>0.196428</td>\n",
       "      <td>8</td>\n",
       "      <td>has_lifetime</td>\n",
       "      <td>all_col</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>-0.029356</td>\n",
       "      <td>0.118584</td>\n",
       "      <td>0.192727</td>\n",
       "      <td>0.196270</td>\n",
       "      <td>0.196428</td>\n",
       "      <td>0.196428</td>\n",
       "      <td>8</td>\n",
       "      <td>invisible</td>\n",
       "      <td>all_col</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>-0.061860</td>\n",
       "      <td>0.125166</td>\n",
       "      <td>0.192727</td>\n",
       "      <td>0.196270</td>\n",
       "      <td>0.196428</td>\n",
       "      <td>0.196428</td>\n",
       "      <td>8</td>\n",
       "      <td>has_ability</td>\n",
       "      <td>all_col</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>-0.073450</td>\n",
       "      <td>0.110937</td>\n",
       "      <td>0.192727</td>\n",
       "      <td>0.196270</td>\n",
       "      <td>0.205597</td>\n",
       "      <td>0.205597</td>\n",
       "      <td>8</td>\n",
       "      <td>any_target</td>\n",
       "      <td>all_col</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>891</th>\n",
       "      <td>-0.073450</td>\n",
       "      <td>0.110937</td>\n",
       "      <td>0.192727</td>\n",
       "      <td>0.196270</td>\n",
       "      <td>0.201261</td>\n",
       "      <td>0.201261</td>\n",
       "      <td>8</td>\n",
       "      <td>building_target</td>\n",
       "      <td>all_col</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>892</th>\n",
       "      <td>0.047345</td>\n",
       "      <td>0.110166</td>\n",
       "      <td>0.192727</td>\n",
       "      <td>0.196270</td>\n",
       "      <td>0.201261</td>\n",
       "      <td>0.201261</td>\n",
       "      <td>8</td>\n",
       "      <td>ground_target</td>\n",
       "      <td>all_col</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>893</th>\n",
       "      <td>0.058045</td>\n",
       "      <td>0.116338</td>\n",
       "      <td>0.191554</td>\n",
       "      <td>0.191554</td>\n",
       "      <td>0.196428</td>\n",
       "      <td>0.196428</td>\n",
       "      <td>8</td>\n",
       "      <td>has_upon_breaking_spawn</td>\n",
       "      <td>all_col</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>894</th>\n",
       "      <td>-0.049267</td>\n",
       "      <td>0.104078</td>\n",
       "      <td>0.192727</td>\n",
       "      <td>0.196270</td>\n",
       "      <td>0.182532</td>\n",
       "      <td>0.182532</td>\n",
       "      <td>8</td>\n",
       "      <td>has_upon_death_spawn</td>\n",
       "      <td>all_col</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>895</th>\n",
       "      <td>0.014313</td>\n",
       "      <td>0.116810</td>\n",
       "      <td>0.218471</td>\n",
       "      <td>0.255519</td>\n",
       "      <td>0.206816</td>\n",
       "      <td>0.206816</td>\n",
       "      <td>8</td>\n",
       "      <td>has_periodic_spawn</td>\n",
       "      <td>all_col</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>896</th>\n",
       "      <td>0.093257</td>\n",
       "      <td>0.088454</td>\n",
       "      <td>0.177472</td>\n",
       "      <td>0.221584</td>\n",
       "      <td>0.196428</td>\n",
       "      <td>0.196428</td>\n",
       "      <td>8</td>\n",
       "      <td>single_damage_type</td>\n",
       "      <td>all_col</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>897</th>\n",
       "      <td>0.016285</td>\n",
       "      <td>0.115972</td>\n",
       "      <td>0.192727</td>\n",
       "      <td>0.196270</td>\n",
       "      <td>0.196428</td>\n",
       "      <td>0.196428</td>\n",
       "      <td>8</td>\n",
       "      <td>is_troop</td>\n",
       "      <td>all_col</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>898</th>\n",
       "      <td>0.016285</td>\n",
       "      <td>0.115972</td>\n",
       "      <td>0.192727</td>\n",
       "      <td>0.196270</td>\n",
       "      <td>0.196428</td>\n",
       "      <td>0.196428</td>\n",
       "      <td>8</td>\n",
       "      <td>is_spell</td>\n",
       "      <td>all_col</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>899</th>\n",
       "      <td>0.016285</td>\n",
       "      <td>0.115972</td>\n",
       "      <td>0.192727</td>\n",
       "      <td>0.196270</td>\n",
       "      <td>0.196428</td>\n",
       "      <td>0.196428</td>\n",
       "      <td>8</td>\n",
       "      <td>is_building</td>\n",
       "      <td>all_col</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>900</th>\n",
       "      <td>0.016285</td>\n",
       "      <td>0.115972</td>\n",
       "      <td>0.192727</td>\n",
       "      <td>0.196270</td>\n",
       "      <td>0.196428</td>\n",
       "      <td>0.196428</td>\n",
       "      <td>8</td>\n",
       "      <td>is_tower_troop</td>\n",
       "      <td>all_col</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>901</th>\n",
       "      <td>-0.090225</td>\n",
       "      <td>0.118332</td>\n",
       "      <td>0.184814</td>\n",
       "      <td>0.184562</td>\n",
       "      <td>0.196428</td>\n",
       "      <td>0.196428</td>\n",
       "      <td>8</td>\n",
       "      <td>is_spawned</td>\n",
       "      <td>all_col</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>902</th>\n",
       "      <td>0.011509</td>\n",
       "      <td>0.139378</td>\n",
       "      <td>0.192727</td>\n",
       "      <td>0.196270</td>\n",
       "      <td>0.196428</td>\n",
       "      <td>0.196428</td>\n",
       "      <td>8</td>\n",
       "      <td>speed</td>\n",
       "      <td>all_col</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>903</th>\n",
       "      <td>0.035354</td>\n",
       "      <td>0.108277</td>\n",
       "      <td>0.192727</td>\n",
       "      <td>0.196270</td>\n",
       "      <td>0.211463</td>\n",
       "      <td>0.211463</td>\n",
       "      <td>8</td>\n",
       "      <td>has_ranged_attack</td>\n",
       "      <td>all_col</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>904</th>\n",
       "      <td>0.077096</td>\n",
       "      <td>0.130349</td>\n",
       "      <td>0.171849</td>\n",
       "      <td>0.180773</td>\n",
       "      <td>0.196428</td>\n",
       "      <td>0.196428</td>\n",
       "      <td>8</td>\n",
       "      <td>special_attack_type</td>\n",
       "      <td>all_col</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>905</th>\n",
       "      <td>0.063727</td>\n",
       "      <td>0.145929</td>\n",
       "      <td>0.255945</td>\n",
       "      <td>0.255945</td>\n",
       "      <td>0.246066</td>\n",
       "      <td>0.246066</td>\n",
       "      <td>8</td>\n",
       "      <td>has_friendly_buff</td>\n",
       "      <td>all_col</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>906</th>\n",
       "      <td>0.020306</td>\n",
       "      <td>0.112655</td>\n",
       "      <td>0.192727</td>\n",
       "      <td>0.196270</td>\n",
       "      <td>0.222439</td>\n",
       "      <td>0.222439</td>\n",
       "      <td>8</td>\n",
       "      <td>is_free_card</td>\n",
       "      <td>all_col</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>907</th>\n",
       "      <td>0.045614</td>\n",
       "      <td>0.131239</td>\n",
       "      <td>0.192727</td>\n",
       "      <td>0.196270</td>\n",
       "      <td>0.196428</td>\n",
       "      <td>0.196428</td>\n",
       "      <td>8</td>\n",
       "      <td>no_hit_speed</td>\n",
       "      <td>all_col</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>908</th>\n",
       "      <td>0.018206</td>\n",
       "      <td>0.121443</td>\n",
       "      <td>0.172805</td>\n",
       "      <td>0.176456</td>\n",
       "      <td>0.196428</td>\n",
       "      <td>0.196428</td>\n",
       "      <td>8</td>\n",
       "      <td>no_attack</td>\n",
       "      <td>all_col</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>909</th>\n",
       "      <td>0.032016</td>\n",
       "      <td>0.120755</td>\n",
       "      <td>0.192727</td>\n",
       "      <td>0.196270</td>\n",
       "      <td>0.196428</td>\n",
       "      <td>0.196428</td>\n",
       "      <td>8</td>\n",
       "      <td>no_hitpoints</td>\n",
       "      <td>all_col</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>910</th>\n",
       "      <td>0.006985</td>\n",
       "      <td>0.134788</td>\n",
       "      <td>0.196933</td>\n",
       "      <td>0.185379</td>\n",
       "      <td>0.202969</td>\n",
       "      <td>0.202969</td>\n",
       "      <td>8</td>\n",
       "      <td>damage_per_elixir</td>\n",
       "      <td>all_col</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>911</th>\n",
       "      <td>0.048970</td>\n",
       "      <td>0.141463</td>\n",
       "      <td>0.192727</td>\n",
       "      <td>0.196270</td>\n",
       "      <td>0.194895</td>\n",
       "      <td>0.194895</td>\n",
       "      <td>8</td>\n",
       "      <td>damage_per_second</td>\n",
       "      <td>all_col</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>912</th>\n",
       "      <td>-0.005645</td>\n",
       "      <td>0.099813</td>\n",
       "      <td>0.205334</td>\n",
       "      <td>0.205334</td>\n",
       "      <td>0.192660</td>\n",
       "      <td>0.192660</td>\n",
       "      <td>8</td>\n",
       "      <td>damage_output</td>\n",
       "      <td>all_col</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>913</th>\n",
       "      <td>0.010006</td>\n",
       "      <td>0.126340</td>\n",
       "      <td>0.209225</td>\n",
       "      <td>0.210952</td>\n",
       "      <td>0.208406</td>\n",
       "      <td>0.208406</td>\n",
       "      <td>8</td>\n",
       "      <td>hp_per_elixir</td>\n",
       "      <td>all_col</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>914</th>\n",
       "      <td>0.051915</td>\n",
       "      <td>0.102652</td>\n",
       "      <td>0.192727</td>\n",
       "      <td>0.196270</td>\n",
       "      <td>0.195571</td>\n",
       "      <td>0.195571</td>\n",
       "      <td>8</td>\n",
       "      <td>damage_by_hitpoints</td>\n",
       "      <td>all_col</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>915</th>\n",
       "      <td>0.073396</td>\n",
       "      <td>0.136838</td>\n",
       "      <td>0.209540</td>\n",
       "      <td>0.208512</td>\n",
       "      <td>0.192119</td>\n",
       "      <td>0.192119</td>\n",
       "      <td>8</td>\n",
       "      <td>aoe_by_range</td>\n",
       "      <td>all_col</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>916</th>\n",
       "      <td>0.025010</td>\n",
       "      <td>0.110274</td>\n",
       "      <td>0.198255</td>\n",
       "      <td>0.185113</td>\n",
       "      <td>0.194339</td>\n",
       "      <td>0.194339</td>\n",
       "      <td>8</td>\n",
       "      <td>aoe_by_damage</td>\n",
       "      <td>all_col</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>917</th>\n",
       "      <td>0.066149</td>\n",
       "      <td>0.117962</td>\n",
       "      <td>0.192727</td>\n",
       "      <td>0.196270</td>\n",
       "      <td>0.196428</td>\n",
       "      <td>0.196428</td>\n",
       "      <td>8</td>\n",
       "      <td>win_con</td>\n",
       "      <td>all_col</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>918</th>\n",
       "      <td>0.067596</td>\n",
       "      <td>0.123943</td>\n",
       "      <td>0.202863</td>\n",
       "      <td>0.204912</td>\n",
       "      <td>0.192863</td>\n",
       "      <td>0.192863</td>\n",
       "      <td>8</td>\n",
       "      <td>aoe_per_elixir</td>\n",
       "      <td>all_col</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>919</th>\n",
       "      <td>0.015419</td>\n",
       "      <td>0.120922</td>\n",
       "      <td>0.202303</td>\n",
       "      <td>0.202303</td>\n",
       "      <td>0.196428</td>\n",
       "      <td>0.196428</td>\n",
       "      <td>8</td>\n",
       "      <td>control_special</td>\n",
       "      <td>all_col</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>920</th>\n",
       "      <td>0.056505</td>\n",
       "      <td>0.143383</td>\n",
       "      <td>0.212255</td>\n",
       "      <td>0.234388</td>\n",
       "      <td>0.196428</td>\n",
       "      <td>0.196428</td>\n",
       "      <td>8</td>\n",
       "      <td>dps_special</td>\n",
       "      <td>all_col</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>921</th>\n",
       "      <td>0.069697</td>\n",
       "      <td>0.133275</td>\n",
       "      <td>0.192727</td>\n",
       "      <td>0.196270</td>\n",
       "      <td>0.214843</td>\n",
       "      <td>0.214843</td>\n",
       "      <td>8</td>\n",
       "      <td>air_control</td>\n",
       "      <td>all_col</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>922</th>\n",
       "      <td>0.007055</td>\n",
       "      <td>0.113576</td>\n",
       "      <td>0.192727</td>\n",
       "      <td>0.196270</td>\n",
       "      <td>0.203217</td>\n",
       "      <td>0.203217</td>\n",
       "      <td>8</td>\n",
       "      <td>ground_dps</td>\n",
       "      <td>all_col</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>923</th>\n",
       "      <td>0.015122</td>\n",
       "      <td>0.109554</td>\n",
       "      <td>0.192727</td>\n",
       "      <td>0.196270</td>\n",
       "      <td>0.196428</td>\n",
       "      <td>0.196428</td>\n",
       "      <td>8</td>\n",
       "      <td>win_con_dmg</td>\n",
       "      <td>all_col</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>924</th>\n",
       "      <td>-0.008865</td>\n",
       "      <td>0.119087</td>\n",
       "      <td>0.161598</td>\n",
       "      <td>0.173334</td>\n",
       "      <td>0.193071</td>\n",
       "      <td>0.193071</td>\n",
       "      <td>8</td>\n",
       "      <td>high_dps</td>\n",
       "      <td>all_col</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>925</th>\n",
       "      <td>-0.027971</td>\n",
       "      <td>0.124319</td>\n",
       "      <td>0.192727</td>\n",
       "      <td>0.196270</td>\n",
       "      <td>0.195049</td>\n",
       "      <td>0.195049</td>\n",
       "      <td>8</td>\n",
       "      <td>damage_output_ps</td>\n",
       "      <td>all_col</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>926</th>\n",
       "      <td>0.037058</td>\n",
       "      <td>0.139155</td>\n",
       "      <td>0.179801</td>\n",
       "      <td>0.184777</td>\n",
       "      <td>0.196428</td>\n",
       "      <td>0.196428</td>\n",
       "      <td>8</td>\n",
       "      <td>support</td>\n",
       "      <td>all_col</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>927</th>\n",
       "      <td>-0.028164</td>\n",
       "      <td>0.108531</td>\n",
       "      <td>0.192727</td>\n",
       "      <td>0.196270</td>\n",
       "      <td>0.196428</td>\n",
       "      <td>0.196428</td>\n",
       "      <td>8</td>\n",
       "      <td>mini_tank</td>\n",
       "      <td>all_col</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>928</th>\n",
       "      <td>0.046309</td>\n",
       "      <td>0.237214</td>\n",
       "      <td>0.073265</td>\n",
       "      <td>0.412195</td>\n",
       "      <td>0.382443</td>\n",
       "      <td>0.382443</td>\n",
       "      <td>8</td>\n",
       "      <td>damage_per_elixir</td>\n",
       "      <td>engineered</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>929</th>\n",
       "      <td>0.127380</td>\n",
       "      <td>0.284490</td>\n",
       "      <td>0.138073</td>\n",
       "      <td>0.451978</td>\n",
       "      <td>0.347117</td>\n",
       "      <td>0.347117</td>\n",
       "      <td>8</td>\n",
       "      <td>damage_per_second</td>\n",
       "      <td>engineered</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>930</th>\n",
       "      <td>0.046998</td>\n",
       "      <td>0.287480</td>\n",
       "      <td>0.207953</td>\n",
       "      <td>0.472280</td>\n",
       "      <td>0.358819</td>\n",
       "      <td>0.358819</td>\n",
       "      <td>8</td>\n",
       "      <td>damage_output</td>\n",
       "      <td>engineered</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>931</th>\n",
       "      <td>0.174557</td>\n",
       "      <td>0.253933</td>\n",
       "      <td>0.340272</td>\n",
       "      <td>0.371867</td>\n",
       "      <td>0.404456</td>\n",
       "      <td>0.404456</td>\n",
       "      <td>8</td>\n",
       "      <td>hp_per_elixir</td>\n",
       "      <td>engineered</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>932</th>\n",
       "      <td>0.024326</td>\n",
       "      <td>0.272840</td>\n",
       "      <td>0.138073</td>\n",
       "      <td>0.451978</td>\n",
       "      <td>0.374480</td>\n",
       "      <td>0.374480</td>\n",
       "      <td>8</td>\n",
       "      <td>damage_by_hitpoints</td>\n",
       "      <td>engineered</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>933</th>\n",
       "      <td>-0.071788</td>\n",
       "      <td>0.263205</td>\n",
       "      <td>0.230192</td>\n",
       "      <td>0.397084</td>\n",
       "      <td>0.343044</td>\n",
       "      <td>0.343044</td>\n",
       "      <td>8</td>\n",
       "      <td>aoe_by_range</td>\n",
       "      <td>engineered</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>934</th>\n",
       "      <td>0.034300</td>\n",
       "      <td>0.248685</td>\n",
       "      <td>0.092870</td>\n",
       "      <td>0.444215</td>\n",
       "      <td>0.343044</td>\n",
       "      <td>0.343044</td>\n",
       "      <td>8</td>\n",
       "      <td>aoe_by_damage</td>\n",
       "      <td>engineered</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>935</th>\n",
       "      <td>0.008715</td>\n",
       "      <td>0.100801</td>\n",
       "      <td>0.192266</td>\n",
       "      <td>0.227173</td>\n",
       "      <td>0.218674</td>\n",
       "      <td>0.218674</td>\n",
       "      <td>8</td>\n",
       "      <td>playable</td>\n",
       "      <td>original</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>936</th>\n",
       "      <td>0.034970</td>\n",
       "      <td>0.131021</td>\n",
       "      <td>0.237326</td>\n",
       "      <td>0.237326</td>\n",
       "      <td>0.186243</td>\n",
       "      <td>0.186243</td>\n",
       "      <td>8</td>\n",
       "      <td>aoe_bool</td>\n",
       "      <td>original</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>937</th>\n",
       "      <td>0.037661</td>\n",
       "      <td>0.135668</td>\n",
       "      <td>0.263202</td>\n",
       "      <td>0.263202</td>\n",
       "      <td>0.188131</td>\n",
       "      <td>0.188131</td>\n",
       "      <td>8</td>\n",
       "      <td>aoe_radius</td>\n",
       "      <td>original</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>938</th>\n",
       "      <td>0.081751</td>\n",
       "      <td>0.141276</td>\n",
       "      <td>0.192266</td>\n",
       "      <td>0.227173</td>\n",
       "      <td>0.216525</td>\n",
       "      <td>0.216525</td>\n",
       "      <td>8</td>\n",
       "      <td>death_damage_bool</td>\n",
       "      <td>original</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>939</th>\n",
       "      <td>0.060127</td>\n",
       "      <td>0.142096</td>\n",
       "      <td>0.192266</td>\n",
       "      <td>0.227173</td>\n",
       "      <td>0.195261</td>\n",
       "      <td>0.195261</td>\n",
       "      <td>8</td>\n",
       "      <td>fly_bool</td>\n",
       "      <td>original</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>940</th>\n",
       "      <td>0.064655</td>\n",
       "      <td>0.142268</td>\n",
       "      <td>0.240192</td>\n",
       "      <td>0.240192</td>\n",
       "      <td>0.181888</td>\n",
       "      <td>0.181888</td>\n",
       "      <td>8</td>\n",
       "      <td>spawn_bool</td>\n",
       "      <td>original</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>941</th>\n",
       "      <td>0.016130</td>\n",
       "      <td>0.127470</td>\n",
       "      <td>0.228159</td>\n",
       "      <td>0.245239</td>\n",
       "      <td>0.219283</td>\n",
       "      <td>0.219283</td>\n",
       "      <td>8</td>\n",
       "      <td>can_evolve</td>\n",
       "      <td>original</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>942</th>\n",
       "      <td>0.035142</td>\n",
       "      <td>0.132218</td>\n",
       "      <td>0.261615</td>\n",
       "      <td>0.261615</td>\n",
       "      <td>0.207664</td>\n",
       "      <td>0.207664</td>\n",
       "      <td>8</td>\n",
       "      <td>elixircost</td>\n",
       "      <td>original</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>943</th>\n",
       "      <td>0.043252</td>\n",
       "      <td>0.140992</td>\n",
       "      <td>0.192266</td>\n",
       "      <td>0.227173</td>\n",
       "      <td>0.205308</td>\n",
       "      <td>0.205308</td>\n",
       "      <td>8</td>\n",
       "      <td>hit_speed</td>\n",
       "      <td>original</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>944</th>\n",
       "      <td>0.036880</td>\n",
       "      <td>0.139379</td>\n",
       "      <td>0.241445</td>\n",
       "      <td>0.241445</td>\n",
       "      <td>0.192320</td>\n",
       "      <td>0.192320</td>\n",
       "      <td>8</td>\n",
       "      <td>special_damage</td>\n",
       "      <td>original</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>945</th>\n",
       "      <td>0.027929</td>\n",
       "      <td>0.118362</td>\n",
       "      <td>0.192266</td>\n",
       "      <td>0.227173</td>\n",
       "      <td>0.195261</td>\n",
       "      <td>0.195261</td>\n",
       "      <td>8</td>\n",
       "      <td>count</td>\n",
       "      <td>original</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>946</th>\n",
       "      <td>0.019142</td>\n",
       "      <td>0.097108</td>\n",
       "      <td>0.192266</td>\n",
       "      <td>0.227173</td>\n",
       "      <td>0.221441</td>\n",
       "      <td>0.221441</td>\n",
       "      <td>8</td>\n",
       "      <td>hitpoints</td>\n",
       "      <td>original</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>947</th>\n",
       "      <td>0.006141</td>\n",
       "      <td>0.140507</td>\n",
       "      <td>0.192266</td>\n",
       "      <td>0.227173</td>\n",
       "      <td>0.195261</td>\n",
       "      <td>0.195261</td>\n",
       "      <td>8</td>\n",
       "      <td>shield_bool</td>\n",
       "      <td>original</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>948</th>\n",
       "      <td>0.009869</td>\n",
       "      <td>0.130233</td>\n",
       "      <td>0.207752</td>\n",
       "      <td>0.233592</td>\n",
       "      <td>0.197632</td>\n",
       "      <td>0.197632</td>\n",
       "      <td>8</td>\n",
       "      <td>damage</td>\n",
       "      <td>original</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>949</th>\n",
       "      <td>0.021247</td>\n",
       "      <td>0.136029</td>\n",
       "      <td>0.221206</td>\n",
       "      <td>0.237391</td>\n",
       "      <td>0.195261</td>\n",
       "      <td>0.195261</td>\n",
       "      <td>8</td>\n",
       "      <td>attack_count</td>\n",
       "      <td>original</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>950</th>\n",
       "      <td>0.053291</td>\n",
       "      <td>0.131053</td>\n",
       "      <td>0.192266</td>\n",
       "      <td>0.227173</td>\n",
       "      <td>0.200803</td>\n",
       "      <td>0.200803</td>\n",
       "      <td>8</td>\n",
       "      <td>range</td>\n",
       "      <td>original</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>951</th>\n",
       "      <td>0.031115</td>\n",
       "      <td>0.118646</td>\n",
       "      <td>0.235526</td>\n",
       "      <td>0.235526</td>\n",
       "      <td>0.195261</td>\n",
       "      <td>0.195261</td>\n",
       "      <td>8</td>\n",
       "      <td>affected_crown</td>\n",
       "      <td>original</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>952</th>\n",
       "      <td>0.005311</td>\n",
       "      <td>0.137436</td>\n",
       "      <td>0.192266</td>\n",
       "      <td>0.227173</td>\n",
       "      <td>0.195261</td>\n",
       "      <td>0.195261</td>\n",
       "      <td>8</td>\n",
       "      <td>has_lifetime</td>\n",
       "      <td>original</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>953</th>\n",
       "      <td>-0.019593</td>\n",
       "      <td>0.126695</td>\n",
       "      <td>0.192266</td>\n",
       "      <td>0.227173</td>\n",
       "      <td>0.195261</td>\n",
       "      <td>0.195261</td>\n",
       "      <td>8</td>\n",
       "      <td>invisible</td>\n",
       "      <td>original</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>954</th>\n",
       "      <td>0.076816</td>\n",
       "      <td>0.150118</td>\n",
       "      <td>0.192266</td>\n",
       "      <td>0.227173</td>\n",
       "      <td>0.195261</td>\n",
       "      <td>0.195261</td>\n",
       "      <td>8</td>\n",
       "      <td>has_ability</td>\n",
       "      <td>original</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>955</th>\n",
       "      <td>-0.018462</td>\n",
       "      <td>0.126593</td>\n",
       "      <td>0.192266</td>\n",
       "      <td>0.227173</td>\n",
       "      <td>0.195773</td>\n",
       "      <td>0.195773</td>\n",
       "      <td>8</td>\n",
       "      <td>any_target</td>\n",
       "      <td>original</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>956</th>\n",
       "      <td>-0.018462</td>\n",
       "      <td>0.126593</td>\n",
       "      <td>0.192266</td>\n",
       "      <td>0.227173</td>\n",
       "      <td>0.188015</td>\n",
       "      <td>0.188015</td>\n",
       "      <td>8</td>\n",
       "      <td>building_target</td>\n",
       "      <td>original</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>957</th>\n",
       "      <td>0.038685</td>\n",
       "      <td>0.118337</td>\n",
       "      <td>0.192266</td>\n",
       "      <td>0.227173</td>\n",
       "      <td>0.188015</td>\n",
       "      <td>0.188015</td>\n",
       "      <td>8</td>\n",
       "      <td>ground_target</td>\n",
       "      <td>original</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>958</th>\n",
       "      <td>0.066489</td>\n",
       "      <td>0.143141</td>\n",
       "      <td>0.244875</td>\n",
       "      <td>0.244875</td>\n",
       "      <td>0.195261</td>\n",
       "      <td>0.195261</td>\n",
       "      <td>8</td>\n",
       "      <td>has_upon_breaking_spawn</td>\n",
       "      <td>original</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>959</th>\n",
       "      <td>0.034932</td>\n",
       "      <td>0.127901</td>\n",
       "      <td>0.192266</td>\n",
       "      <td>0.227173</td>\n",
       "      <td>0.181888</td>\n",
       "      <td>0.181888</td>\n",
       "      <td>8</td>\n",
       "      <td>has_upon_death_spawn</td>\n",
       "      <td>original</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>960</th>\n",
       "      <td>0.062541</td>\n",
       "      <td>0.142482</td>\n",
       "      <td>0.261043</td>\n",
       "      <td>0.261043</td>\n",
       "      <td>0.207027</td>\n",
       "      <td>0.207027</td>\n",
       "      <td>8</td>\n",
       "      <td>has_periodic_spawn</td>\n",
       "      <td>original</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>961</th>\n",
       "      <td>-0.009548</td>\n",
       "      <td>0.148124</td>\n",
       "      <td>0.270719</td>\n",
       "      <td>0.270719</td>\n",
       "      <td>0.194667</td>\n",
       "      <td>0.194667</td>\n",
       "      <td>8</td>\n",
       "      <td>single_damage_type</td>\n",
       "      <td>original</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>962</th>\n",
       "      <td>0.012908</td>\n",
       "      <td>0.129339</td>\n",
       "      <td>0.192266</td>\n",
       "      <td>0.227173</td>\n",
       "      <td>0.195261</td>\n",
       "      <td>0.195261</td>\n",
       "      <td>8</td>\n",
       "      <td>is_troop</td>\n",
       "      <td>original</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>963</th>\n",
       "      <td>0.012908</td>\n",
       "      <td>0.129339</td>\n",
       "      <td>0.192266</td>\n",
       "      <td>0.227173</td>\n",
       "      <td>0.195261</td>\n",
       "      <td>0.195261</td>\n",
       "      <td>8</td>\n",
       "      <td>is_spell</td>\n",
       "      <td>original</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>964</th>\n",
       "      <td>0.012908</td>\n",
       "      <td>0.129339</td>\n",
       "      <td>0.192266</td>\n",
       "      <td>0.227173</td>\n",
       "      <td>0.195261</td>\n",
       "      <td>0.195261</td>\n",
       "      <td>8</td>\n",
       "      <td>is_building</td>\n",
       "      <td>original</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>965</th>\n",
       "      <td>0.012908</td>\n",
       "      <td>0.129339</td>\n",
       "      <td>0.192266</td>\n",
       "      <td>0.227173</td>\n",
       "      <td>0.195261</td>\n",
       "      <td>0.195261</td>\n",
       "      <td>8</td>\n",
       "      <td>is_tower_troop</td>\n",
       "      <td>original</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>966</th>\n",
       "      <td>-0.029594</td>\n",
       "      <td>0.112028</td>\n",
       "      <td>0.211729</td>\n",
       "      <td>0.211729</td>\n",
       "      <td>0.195261</td>\n",
       "      <td>0.195261</td>\n",
       "      <td>8</td>\n",
       "      <td>is_spawned</td>\n",
       "      <td>original</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>967</th>\n",
       "      <td>0.008680</td>\n",
       "      <td>0.147473</td>\n",
       "      <td>0.192266</td>\n",
       "      <td>0.227173</td>\n",
       "      <td>0.195261</td>\n",
       "      <td>0.195261</td>\n",
       "      <td>8</td>\n",
       "      <td>speed</td>\n",
       "      <td>original</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>968</th>\n",
       "      <td>-0.008186</td>\n",
       "      <td>0.129936</td>\n",
       "      <td>0.192266</td>\n",
       "      <td>0.227173</td>\n",
       "      <td>0.216268</td>\n",
       "      <td>0.216268</td>\n",
       "      <td>8</td>\n",
       "      <td>has_ranged_attack</td>\n",
       "      <td>original</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>969</th>\n",
       "      <td>0.083951</td>\n",
       "      <td>0.148129</td>\n",
       "      <td>0.217061</td>\n",
       "      <td>0.217061</td>\n",
       "      <td>0.187470</td>\n",
       "      <td>0.187470</td>\n",
       "      <td>8</td>\n",
       "      <td>special_attack_type</td>\n",
       "      <td>original</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>970</th>\n",
       "      <td>0.076787</td>\n",
       "      <td>0.139216</td>\n",
       "      <td>0.241609</td>\n",
       "      <td>0.259586</td>\n",
       "      <td>0.227069</td>\n",
       "      <td>0.227069</td>\n",
       "      <td>8</td>\n",
       "      <td>has_friendly_buff</td>\n",
       "      <td>original</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>971</th>\n",
       "      <td>0.008715</td>\n",
       "      <td>0.100801</td>\n",
       "      <td>0.192266</td>\n",
       "      <td>0.227173</td>\n",
       "      <td>0.218674</td>\n",
       "      <td>0.218674</td>\n",
       "      <td>8</td>\n",
       "      <td>is_free_card</td>\n",
       "      <td>original</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>972</th>\n",
       "      <td>0.055081</td>\n",
       "      <td>0.122705</td>\n",
       "      <td>0.192266</td>\n",
       "      <td>0.227173</td>\n",
       "      <td>0.195261</td>\n",
       "      <td>0.195261</td>\n",
       "      <td>8</td>\n",
       "      <td>no_hit_speed</td>\n",
       "      <td>original</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>973</th>\n",
       "      <td>0.026182</td>\n",
       "      <td>0.131354</td>\n",
       "      <td>0.230220</td>\n",
       "      <td>0.230220</td>\n",
       "      <td>0.195261</td>\n",
       "      <td>0.195261</td>\n",
       "      <td>8</td>\n",
       "      <td>no_attack</td>\n",
       "      <td>original</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>974</th>\n",
       "      <td>-0.029774</td>\n",
       "      <td>0.135546</td>\n",
       "      <td>0.192266</td>\n",
       "      <td>0.227173</td>\n",
       "      <td>0.195261</td>\n",
       "      <td>0.195261</td>\n",
       "      <td>8</td>\n",
       "      <td>no_hitpoints</td>\n",
       "      <td>original</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>975</th>\n",
       "      <td>0.043430</td>\n",
       "      <td>0.110546</td>\n",
       "      <td>0.192266</td>\n",
       "      <td>0.227173</td>\n",
       "      <td>0.195261</td>\n",
       "      <td>0.195261</td>\n",
       "      <td>8</td>\n",
       "      <td>win_con</td>\n",
       "      <td>original</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>976</th>\n",
       "      <td>0.077282</td>\n",
       "      <td>0.135624</td>\n",
       "      <td>0.232785</td>\n",
       "      <td>0.250990</td>\n",
       "      <td>0.188131</td>\n",
       "      <td>0.188131</td>\n",
       "      <td>8</td>\n",
       "      <td>aoe_per_elixir</td>\n",
       "      <td>original</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>977</th>\n",
       "      <td>0.057986</td>\n",
       "      <td>0.136856</td>\n",
       "      <td>0.241933</td>\n",
       "      <td>0.261007</td>\n",
       "      <td>0.192320</td>\n",
       "      <td>0.192320</td>\n",
       "      <td>8</td>\n",
       "      <td>control_special</td>\n",
       "      <td>original</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>978</th>\n",
       "      <td>0.025703</td>\n",
       "      <td>0.139526</td>\n",
       "      <td>0.225433</td>\n",
       "      <td>0.225433</td>\n",
       "      <td>0.195261</td>\n",
       "      <td>0.195261</td>\n",
       "      <td>8</td>\n",
       "      <td>dps_special</td>\n",
       "      <td>original</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>979</th>\n",
       "      <td>0.004002</td>\n",
       "      <td>0.132833</td>\n",
       "      <td>0.192266</td>\n",
       "      <td>0.227173</td>\n",
       "      <td>0.205842</td>\n",
       "      <td>0.205842</td>\n",
       "      <td>8</td>\n",
       "      <td>air_control</td>\n",
       "      <td>original</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>980</th>\n",
       "      <td>0.070776</td>\n",
       "      <td>0.119561</td>\n",
       "      <td>0.192266</td>\n",
       "      <td>0.227173</td>\n",
       "      <td>0.198209</td>\n",
       "      <td>0.198209</td>\n",
       "      <td>8</td>\n",
       "      <td>ground_dps</td>\n",
       "      <td>original</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>981</th>\n",
       "      <td>0.078256</td>\n",
       "      <td>0.132668</td>\n",
       "      <td>0.192266</td>\n",
       "      <td>0.227173</td>\n",
       "      <td>0.195261</td>\n",
       "      <td>0.195261</td>\n",
       "      <td>8</td>\n",
       "      <td>win_con_dmg</td>\n",
       "      <td>original</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>982</th>\n",
       "      <td>0.038094</td>\n",
       "      <td>0.121151</td>\n",
       "      <td>0.199191</td>\n",
       "      <td>0.221655</td>\n",
       "      <td>0.199704</td>\n",
       "      <td>0.199704</td>\n",
       "      <td>8</td>\n",
       "      <td>high_dps</td>\n",
       "      <td>original</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>983</th>\n",
       "      <td>0.035254</td>\n",
       "      <td>0.129824</td>\n",
       "      <td>0.192266</td>\n",
       "      <td>0.227173</td>\n",
       "      <td>0.198171</td>\n",
       "      <td>0.198171</td>\n",
       "      <td>8</td>\n",
       "      <td>damage_output_ps</td>\n",
       "      <td>original</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>984</th>\n",
       "      <td>0.096349</td>\n",
       "      <td>0.135951</td>\n",
       "      <td>0.227453</td>\n",
       "      <td>0.227453</td>\n",
       "      <td>0.195261</td>\n",
       "      <td>0.195261</td>\n",
       "      <td>8</td>\n",
       "      <td>support</td>\n",
       "      <td>original</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>985</th>\n",
       "      <td>0.035548</td>\n",
       "      <td>0.135382</td>\n",
       "      <td>0.192266</td>\n",
       "      <td>0.227173</td>\n",
       "      <td>0.195261</td>\n",
       "      <td>0.195261</td>\n",
       "      <td>8</td>\n",
       "      <td>mini_tank</td>\n",
       "      <td>original</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>986</th>\n",
       "      <td>0.120805</td>\n",
       "      <td>0.137043</td>\n",
       "      <td>0.187889</td>\n",
       "      <td>0.317455</td>\n",
       "      <td>0.252473</td>\n",
       "      <td>0.252473</td>\n",
       "      <td>8</td>\n",
       "      <td>aoe_radius</td>\n",
       "      <td>num_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>987</th>\n",
       "      <td>0.087812</td>\n",
       "      <td>0.170517</td>\n",
       "      <td>0.256111</td>\n",
       "      <td>0.319095</td>\n",
       "      <td>0.246758</td>\n",
       "      <td>0.246758</td>\n",
       "      <td>8</td>\n",
       "      <td>can_evolve</td>\n",
       "      <td>num_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>988</th>\n",
       "      <td>0.068282</td>\n",
       "      <td>0.159604</td>\n",
       "      <td>0.133100</td>\n",
       "      <td>0.344380</td>\n",
       "      <td>0.223007</td>\n",
       "      <td>0.223007</td>\n",
       "      <td>8</td>\n",
       "      <td>elixircost</td>\n",
       "      <td>num_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>989</th>\n",
       "      <td>-0.126392</td>\n",
       "      <td>0.165567</td>\n",
       "      <td>0.215876</td>\n",
       "      <td>0.292149</td>\n",
       "      <td>0.250323</td>\n",
       "      <td>0.250323</td>\n",
       "      <td>8</td>\n",
       "      <td>hit_speed</td>\n",
       "      <td>num_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>990</th>\n",
       "      <td>0.112911</td>\n",
       "      <td>0.137208</td>\n",
       "      <td>0.215876</td>\n",
       "      <td>0.292149</td>\n",
       "      <td>0.252473</td>\n",
       "      <td>0.252473</td>\n",
       "      <td>8</td>\n",
       "      <td>count</td>\n",
       "      <td>num_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>991</th>\n",
       "      <td>0.159031</td>\n",
       "      <td>0.160650</td>\n",
       "      <td>0.215876</td>\n",
       "      <td>0.292149</td>\n",
       "      <td>0.223853</td>\n",
       "      <td>0.223853</td>\n",
       "      <td>8</td>\n",
       "      <td>hitpoints</td>\n",
       "      <td>num_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>992</th>\n",
       "      <td>0.062770</td>\n",
       "      <td>0.158731</td>\n",
       "      <td>0.156638</td>\n",
       "      <td>0.286236</td>\n",
       "      <td>0.249481</td>\n",
       "      <td>0.249481</td>\n",
       "      <td>8</td>\n",
       "      <td>damage</td>\n",
       "      <td>num_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>993</th>\n",
       "      <td>0.126939</td>\n",
       "      <td>0.152870</td>\n",
       "      <td>0.265766</td>\n",
       "      <td>0.384913</td>\n",
       "      <td>0.252473</td>\n",
       "      <td>0.252473</td>\n",
       "      <td>8</td>\n",
       "      <td>attack_count</td>\n",
       "      <td>num_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>994</th>\n",
       "      <td>0.010317</td>\n",
       "      <td>0.190741</td>\n",
       "      <td>0.215876</td>\n",
       "      <td>0.292149</td>\n",
       "      <td>0.260788</td>\n",
       "      <td>0.260788</td>\n",
       "      <td>8</td>\n",
       "      <td>range</td>\n",
       "      <td>num_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>0.080438</td>\n",
       "      <td>0.168776</td>\n",
       "      <td>0.215876</td>\n",
       "      <td>0.292149</td>\n",
       "      <td>0.252473</td>\n",
       "      <td>0.252473</td>\n",
       "      <td>8</td>\n",
       "      <td>speed</td>\n",
       "      <td>num_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>0.131887</td>\n",
       "      <td>0.145658</td>\n",
       "      <td>0.183654</td>\n",
       "      <td>0.285181</td>\n",
       "      <td>0.252705</td>\n",
       "      <td>0.252705</td>\n",
       "      <td>8</td>\n",
       "      <td>damage_per_elixir</td>\n",
       "      <td>num_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>0.173604</td>\n",
       "      <td>0.158903</td>\n",
       "      <td>0.215876</td>\n",
       "      <td>0.292149</td>\n",
       "      <td>0.253566</td>\n",
       "      <td>0.253566</td>\n",
       "      <td>8</td>\n",
       "      <td>damage_per_second</td>\n",
       "      <td>num_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>0.114776</td>\n",
       "      <td>0.150607</td>\n",
       "      <td>0.250677</td>\n",
       "      <td>0.323409</td>\n",
       "      <td>0.246901</td>\n",
       "      <td>0.246901</td>\n",
       "      <td>8</td>\n",
       "      <td>damage_output</td>\n",
       "      <td>num_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>-0.023204</td>\n",
       "      <td>0.139046</td>\n",
       "      <td>0.296367</td>\n",
       "      <td>0.334677</td>\n",
       "      <td>0.301342</td>\n",
       "      <td>0.301342</td>\n",
       "      <td>8</td>\n",
       "      <td>hp_per_elixir</td>\n",
       "      <td>num_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000</th>\n",
       "      <td>0.065270</td>\n",
       "      <td>0.159956</td>\n",
       "      <td>0.215876</td>\n",
       "      <td>0.292149</td>\n",
       "      <td>0.256775</td>\n",
       "      <td>0.256775</td>\n",
       "      <td>8</td>\n",
       "      <td>damage_by_hitpoints</td>\n",
       "      <td>num_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1001</th>\n",
       "      <td>0.108806</td>\n",
       "      <td>0.142730</td>\n",
       "      <td>0.187889</td>\n",
       "      <td>0.317455</td>\n",
       "      <td>0.252473</td>\n",
       "      <td>0.252473</td>\n",
       "      <td>8</td>\n",
       "      <td>aoe_by_range</td>\n",
       "      <td>num_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1002</th>\n",
       "      <td>0.037090</td>\n",
       "      <td>0.150994</td>\n",
       "      <td>0.141212</td>\n",
       "      <td>0.298064</td>\n",
       "      <td>0.252473</td>\n",
       "      <td>0.252473</td>\n",
       "      <td>8</td>\n",
       "      <td>aoe_by_damage</td>\n",
       "      <td>num_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1003</th>\n",
       "      <td>0.104517</td>\n",
       "      <td>0.152114</td>\n",
       "      <td>0.285335</td>\n",
       "      <td>0.285335</td>\n",
       "      <td>0.252473</td>\n",
       "      <td>0.252473</td>\n",
       "      <td>8</td>\n",
       "      <td>aoe_per_elixir</td>\n",
       "      <td>num_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1004</th>\n",
       "      <td>-0.205450</td>\n",
       "      <td>0.167269</td>\n",
       "      <td>0.215876</td>\n",
       "      <td>0.292149</td>\n",
       "      <td>0.249219</td>\n",
       "      <td>0.249219</td>\n",
       "      <td>8</td>\n",
       "      <td>damage_output_ps</td>\n",
       "      <td>num_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1005</th>\n",
       "      <td>0.006411</td>\n",
       "      <td>0.152235</td>\n",
       "      <td>0.408935</td>\n",
       "      <td>0.408935</td>\n",
       "      <td>0.251960</td>\n",
       "      <td>0.239175</td>\n",
       "      <td>8</td>\n",
       "      <td>playable</td>\n",
       "      <td>bool_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1006</th>\n",
       "      <td>0.107188</td>\n",
       "      <td>0.171999</td>\n",
       "      <td>0.436862</td>\n",
       "      <td>0.436862</td>\n",
       "      <td>0.315861</td>\n",
       "      <td>0.315861</td>\n",
       "      <td>8</td>\n",
       "      <td>aoe_bool</td>\n",
       "      <td>bool_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1007</th>\n",
       "      <td>0.082154</td>\n",
       "      <td>0.182247</td>\n",
       "      <td>0.408935</td>\n",
       "      <td>0.408935</td>\n",
       "      <td>0.363058</td>\n",
       "      <td>0.363058</td>\n",
       "      <td>8</td>\n",
       "      <td>death_damage_bool</td>\n",
       "      <td>bool_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1008</th>\n",
       "      <td>0.093875</td>\n",
       "      <td>0.166726</td>\n",
       "      <td>0.408935</td>\n",
       "      <td>0.408935</td>\n",
       "      <td>0.258316</td>\n",
       "      <td>0.258316</td>\n",
       "      <td>8</td>\n",
       "      <td>fly_bool</td>\n",
       "      <td>bool_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1009</th>\n",
       "      <td>0.071305</td>\n",
       "      <td>0.172592</td>\n",
       "      <td>0.415403</td>\n",
       "      <td>0.415403</td>\n",
       "      <td>0.247913</td>\n",
       "      <td>0.247913</td>\n",
       "      <td>8</td>\n",
       "      <td>spawn_bool</td>\n",
       "      <td>bool_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1010</th>\n",
       "      <td>0.134314</td>\n",
       "      <td>0.160032</td>\n",
       "      <td>0.426524</td>\n",
       "      <td>0.426524</td>\n",
       "      <td>0.258316</td>\n",
       "      <td>0.258316</td>\n",
       "      <td>8</td>\n",
       "      <td>special_damage</td>\n",
       "      <td>bool_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1011</th>\n",
       "      <td>0.075702</td>\n",
       "      <td>0.166847</td>\n",
       "      <td>0.408935</td>\n",
       "      <td>0.408935</td>\n",
       "      <td>0.258316</td>\n",
       "      <td>0.258316</td>\n",
       "      <td>8</td>\n",
       "      <td>shield_bool</td>\n",
       "      <td>bool_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1012</th>\n",
       "      <td>0.104254</td>\n",
       "      <td>0.171504</td>\n",
       "      <td>0.407868</td>\n",
       "      <td>0.407868</td>\n",
       "      <td>0.253522</td>\n",
       "      <td>0.253522</td>\n",
       "      <td>8</td>\n",
       "      <td>affected_crown</td>\n",
       "      <td>bool_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1013</th>\n",
       "      <td>0.102818</td>\n",
       "      <td>0.173773</td>\n",
       "      <td>0.408935</td>\n",
       "      <td>0.408935</td>\n",
       "      <td>0.258316</td>\n",
       "      <td>0.258316</td>\n",
       "      <td>8</td>\n",
       "      <td>has_lifetime</td>\n",
       "      <td>bool_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1014</th>\n",
       "      <td>0.115990</td>\n",
       "      <td>0.173406</td>\n",
       "      <td>0.408935</td>\n",
       "      <td>0.408935</td>\n",
       "      <td>0.258316</td>\n",
       "      <td>0.258316</td>\n",
       "      <td>8</td>\n",
       "      <td>invisible</td>\n",
       "      <td>bool_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1015</th>\n",
       "      <td>0.135031</td>\n",
       "      <td>0.180794</td>\n",
       "      <td>0.408935</td>\n",
       "      <td>0.408935</td>\n",
       "      <td>0.258316</td>\n",
       "      <td>0.258316</td>\n",
       "      <td>8</td>\n",
       "      <td>has_ability</td>\n",
       "      <td>bool_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1016</th>\n",
       "      <td>0.001413</td>\n",
       "      <td>0.162499</td>\n",
       "      <td>0.408935</td>\n",
       "      <td>0.408935</td>\n",
       "      <td>0.254842</td>\n",
       "      <td>0.254842</td>\n",
       "      <td>8</td>\n",
       "      <td>any_target</td>\n",
       "      <td>bool_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1017</th>\n",
       "      <td>0.001413</td>\n",
       "      <td>0.162499</td>\n",
       "      <td>0.408935</td>\n",
       "      <td>0.408935</td>\n",
       "      <td>0.257937</td>\n",
       "      <td>0.257937</td>\n",
       "      <td>8</td>\n",
       "      <td>building_target</td>\n",
       "      <td>bool_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1018</th>\n",
       "      <td>0.046913</td>\n",
       "      <td>0.154824</td>\n",
       "      <td>0.408935</td>\n",
       "      <td>0.408935</td>\n",
       "      <td>0.257937</td>\n",
       "      <td>0.257937</td>\n",
       "      <td>8</td>\n",
       "      <td>ground_target</td>\n",
       "      <td>bool_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1019</th>\n",
       "      <td>0.092810</td>\n",
       "      <td>0.163228</td>\n",
       "      <td>0.444893</td>\n",
       "      <td>0.432024</td>\n",
       "      <td>0.258316</td>\n",
       "      <td>0.258316</td>\n",
       "      <td>8</td>\n",
       "      <td>has_upon_breaking_spawn</td>\n",
       "      <td>bool_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1020</th>\n",
       "      <td>0.109187</td>\n",
       "      <td>0.144058</td>\n",
       "      <td>0.408935</td>\n",
       "      <td>0.408935</td>\n",
       "      <td>0.247913</td>\n",
       "      <td>0.247913</td>\n",
       "      <td>8</td>\n",
       "      <td>has_upon_death_spawn</td>\n",
       "      <td>bool_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1021</th>\n",
       "      <td>0.085201</td>\n",
       "      <td>0.181925</td>\n",
       "      <td>0.468887</td>\n",
       "      <td>0.468887</td>\n",
       "      <td>0.307925</td>\n",
       "      <td>0.307925</td>\n",
       "      <td>8</td>\n",
       "      <td>has_periodic_spawn</td>\n",
       "      <td>bool_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1022</th>\n",
       "      <td>0.142844</td>\n",
       "      <td>0.175440</td>\n",
       "      <td>0.399734</td>\n",
       "      <td>0.399734</td>\n",
       "      <td>0.258316</td>\n",
       "      <td>0.258316</td>\n",
       "      <td>8</td>\n",
       "      <td>single_damage_type</td>\n",
       "      <td>bool_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1023</th>\n",
       "      <td>0.045868</td>\n",
       "      <td>0.158413</td>\n",
       "      <td>0.408935</td>\n",
       "      <td>0.408935</td>\n",
       "      <td>0.258316</td>\n",
       "      <td>0.258316</td>\n",
       "      <td>8</td>\n",
       "      <td>is_troop</td>\n",
       "      <td>bool_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1024</th>\n",
       "      <td>0.045868</td>\n",
       "      <td>0.158413</td>\n",
       "      <td>0.408935</td>\n",
       "      <td>0.408935</td>\n",
       "      <td>0.258316</td>\n",
       "      <td>0.258316</td>\n",
       "      <td>8</td>\n",
       "      <td>is_spell</td>\n",
       "      <td>bool_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1025</th>\n",
       "      <td>0.045868</td>\n",
       "      <td>0.158413</td>\n",
       "      <td>0.408935</td>\n",
       "      <td>0.408935</td>\n",
       "      <td>0.258316</td>\n",
       "      <td>0.258316</td>\n",
       "      <td>8</td>\n",
       "      <td>is_building</td>\n",
       "      <td>bool_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1026</th>\n",
       "      <td>0.045868</td>\n",
       "      <td>0.158413</td>\n",
       "      <td>0.408935</td>\n",
       "      <td>0.408935</td>\n",
       "      <td>0.258316</td>\n",
       "      <td>0.258316</td>\n",
       "      <td>8</td>\n",
       "      <td>is_tower_troop</td>\n",
       "      <td>bool_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1027</th>\n",
       "      <td>0.078825</td>\n",
       "      <td>0.167963</td>\n",
       "      <td>0.419030</td>\n",
       "      <td>0.419030</td>\n",
       "      <td>0.258316</td>\n",
       "      <td>0.258316</td>\n",
       "      <td>8</td>\n",
       "      <td>is_spawned</td>\n",
       "      <td>bool_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1028</th>\n",
       "      <td>0.156082</td>\n",
       "      <td>0.173182</td>\n",
       "      <td>0.408935</td>\n",
       "      <td>0.408935</td>\n",
       "      <td>0.304749</td>\n",
       "      <td>0.304749</td>\n",
       "      <td>8</td>\n",
       "      <td>has_ranged_attack</td>\n",
       "      <td>bool_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1029</th>\n",
       "      <td>0.097325</td>\n",
       "      <td>0.168566</td>\n",
       "      <td>0.435570</td>\n",
       "      <td>0.435570</td>\n",
       "      <td>0.258316</td>\n",
       "      <td>0.258316</td>\n",
       "      <td>8</td>\n",
       "      <td>special_attack_type</td>\n",
       "      <td>bool_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1030</th>\n",
       "      <td>0.111542</td>\n",
       "      <td>0.170025</td>\n",
       "      <td>0.478967</td>\n",
       "      <td>0.478967</td>\n",
       "      <td>0.201899</td>\n",
       "      <td>0.202590</td>\n",
       "      <td>8</td>\n",
       "      <td>has_friendly_buff</td>\n",
       "      <td>bool_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1031</th>\n",
       "      <td>0.006411</td>\n",
       "      <td>0.152235</td>\n",
       "      <td>0.408935</td>\n",
       "      <td>0.408935</td>\n",
       "      <td>0.251960</td>\n",
       "      <td>0.239175</td>\n",
       "      <td>8</td>\n",
       "      <td>is_free_card</td>\n",
       "      <td>bool_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1032</th>\n",
       "      <td>0.096239</td>\n",
       "      <td>0.157541</td>\n",
       "      <td>0.408935</td>\n",
       "      <td>0.408935</td>\n",
       "      <td>0.258316</td>\n",
       "      <td>0.258316</td>\n",
       "      <td>8</td>\n",
       "      <td>no_hit_speed</td>\n",
       "      <td>bool_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1033</th>\n",
       "      <td>0.057466</td>\n",
       "      <td>0.154561</td>\n",
       "      <td>0.399144</td>\n",
       "      <td>0.399144</td>\n",
       "      <td>0.258316</td>\n",
       "      <td>0.258316</td>\n",
       "      <td>8</td>\n",
       "      <td>no_attack</td>\n",
       "      <td>bool_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1034</th>\n",
       "      <td>0.092866</td>\n",
       "      <td>0.170270</td>\n",
       "      <td>0.408935</td>\n",
       "      <td>0.408935</td>\n",
       "      <td>0.258316</td>\n",
       "      <td>0.258316</td>\n",
       "      <td>8</td>\n",
       "      <td>no_hitpoints</td>\n",
       "      <td>bool_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1035</th>\n",
       "      <td>0.120113</td>\n",
       "      <td>0.165393</td>\n",
       "      <td>0.408935</td>\n",
       "      <td>0.408935</td>\n",
       "      <td>0.258316</td>\n",
       "      <td>0.258316</td>\n",
       "      <td>8</td>\n",
       "      <td>win_con</td>\n",
       "      <td>bool_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1036</th>\n",
       "      <td>0.023063</td>\n",
       "      <td>0.159879</td>\n",
       "      <td>0.501942</td>\n",
       "      <td>0.501942</td>\n",
       "      <td>0.258316</td>\n",
       "      <td>0.258316</td>\n",
       "      <td>8</td>\n",
       "      <td>control_special</td>\n",
       "      <td>bool_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1037</th>\n",
       "      <td>0.067362</td>\n",
       "      <td>0.150081</td>\n",
       "      <td>0.389451</td>\n",
       "      <td>0.389451</td>\n",
       "      <td>0.258316</td>\n",
       "      <td>0.258316</td>\n",
       "      <td>8</td>\n",
       "      <td>dps_special</td>\n",
       "      <td>bool_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1038</th>\n",
       "      <td>0.032497</td>\n",
       "      <td>0.173641</td>\n",
       "      <td>0.408935</td>\n",
       "      <td>0.408935</td>\n",
       "      <td>0.246093</td>\n",
       "      <td>0.246093</td>\n",
       "      <td>8</td>\n",
       "      <td>air_control</td>\n",
       "      <td>bool_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1039</th>\n",
       "      <td>0.124549</td>\n",
       "      <td>0.165833</td>\n",
       "      <td>0.408935</td>\n",
       "      <td>0.408935</td>\n",
       "      <td>0.279872</td>\n",
       "      <td>0.279872</td>\n",
       "      <td>8</td>\n",
       "      <td>ground_dps</td>\n",
       "      <td>bool_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1040</th>\n",
       "      <td>0.028975</td>\n",
       "      <td>0.172320</td>\n",
       "      <td>0.408935</td>\n",
       "      <td>0.408935</td>\n",
       "      <td>0.258316</td>\n",
       "      <td>0.258316</td>\n",
       "      <td>8</td>\n",
       "      <td>win_con_dmg</td>\n",
       "      <td>bool_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1041</th>\n",
       "      <td>0.126363</td>\n",
       "      <td>0.170702</td>\n",
       "      <td>0.309196</td>\n",
       "      <td>0.377096</td>\n",
       "      <td>0.277300</td>\n",
       "      <td>0.277300</td>\n",
       "      <td>8</td>\n",
       "      <td>high_dps</td>\n",
       "      <td>bool_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1042</th>\n",
       "      <td>0.120372</td>\n",
       "      <td>0.187217</td>\n",
       "      <td>0.409813</td>\n",
       "      <td>0.409813</td>\n",
       "      <td>0.258316</td>\n",
       "      <td>0.258316</td>\n",
       "      <td>8</td>\n",
       "      <td>support</td>\n",
       "      <td>bool_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1043</th>\n",
       "      <td>0.181814</td>\n",
       "      <td>0.186997</td>\n",
       "      <td>0.408935</td>\n",
       "      <td>0.408935</td>\n",
       "      <td>0.258316</td>\n",
       "      <td>0.258316</td>\n",
       "      <td>8</td>\n",
       "      <td>mini_tank</td>\n",
       "      <td>bool_features</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      gmm_troop  km_troop  gmm_spell  km_spell  gmm_building  km_building  K  \\\n",
       "0      0.100037  0.101809   0.062831  0.196593      0.303626     0.303626  3   \n",
       "1      0.062340  0.110193   0.211933  0.211933      0.289034     0.289034  3   \n",
       "2      0.056719  0.110700   0.075182  0.205529      0.290237     0.290237  3   \n",
       "3      0.035059  0.114044   0.062831  0.196593      0.309203     0.309203  3   \n",
       "4      0.040841  0.111170   0.062831  0.196593      0.298635     0.298635  3   \n",
       "5      0.054749  0.114876   0.168812  0.196606      0.294232     0.294232  3   \n",
       "6      0.084860  0.110139   0.141692  0.212579      0.314256     0.314256  3   \n",
       "7      0.097165  0.101387   0.142337  0.206865      0.308941     0.308941  3   \n",
       "8      0.092766  0.115080   0.062831  0.196593      0.301437     0.301437  3   \n",
       "9      0.034007  0.106351   0.195995  0.183295      0.305407     0.305407  3   \n",
       "10     0.044282  0.104321   0.062831  0.196593      0.298635     0.298635  3   \n",
       "11     0.048145  0.112099   0.062831  0.196593      0.305311     0.305311  3   \n",
       "12     0.027239  0.113499   0.062831  0.196593      0.298635     0.298635  3   \n",
       "13     0.064645  0.105246   0.191919  0.191919      0.297216     0.297216  3   \n",
       "14     0.052031  0.117405   0.119865  0.206207      0.293146     0.293146  3   \n",
       "15     0.038947  0.099117   0.062831  0.196593      0.289131     0.289131  3   \n",
       "16     0.086173  0.108281   0.164229  0.170569      0.305534     0.305534  3   \n",
       "17     0.081734  0.106841   0.062831  0.196593      0.298635     0.298635  3   \n",
       "18     0.073947  0.115919   0.062831  0.196593      0.298635     0.298635  3   \n",
       "19     0.047314  0.112191   0.062831  0.196593      0.298635     0.298635  3   \n",
       "20     0.060326  0.100080   0.062831  0.196593      0.298061     0.298061  3   \n",
       "21     0.060326  0.100080   0.062831  0.196593      0.297973     0.297973  3   \n",
       "22     0.101762  0.105216   0.062831  0.196593      0.297973     0.297973  3   \n",
       "23     0.049734  0.113567   0.078776  0.188895      0.298635     0.298635  3   \n",
       "24     0.034046  0.110214   0.062831  0.196593      0.294232     0.294232  3   \n",
       "25     0.114821  0.118159   0.213373  0.213373      0.302838     0.302838  3   \n",
       "26     0.055701  0.095201   0.164355  0.211537      0.293041     0.293041  3   \n",
       "27     0.045117  0.111977   0.062831  0.196593      0.298635     0.298635  3   \n",
       "28     0.045117  0.111977   0.062831  0.196593      0.298635     0.298635  3   \n",
       "29     0.045117  0.111977   0.062831  0.196593      0.298635     0.298635  3   \n",
       "30     0.045117  0.111977   0.062831  0.196593      0.298635     0.298635  3   \n",
       "31     0.029134  0.116375   0.168548  0.208661      0.298635     0.298635  3   \n",
       "32     0.104153  0.114854   0.062831  0.196593      0.298635     0.298635  3   \n",
       "33     0.065812  0.099128   0.062831  0.196593      0.297040     0.297040  3   \n",
       "34     0.090829  0.109798   0.163398  0.207380      0.299783     0.299783  3   \n",
       "35     0.049132  0.114477   0.139334  0.213835      0.313071     0.313071  3   \n",
       "36     0.100037  0.101809   0.062831  0.196593      0.303626     0.303626  3   \n",
       "37     0.043611  0.113980   0.062831  0.196593      0.286797     0.286797  3   \n",
       "38     0.079762  0.112477   0.112732  0.200056      0.293146     0.293146  3   \n",
       "39     0.055088  0.112943   0.062831  0.196593      0.298635     0.298635  3   \n",
       "40     0.051997  0.107561   0.147079  0.192018      0.298946     0.298946  3   \n",
       "41     0.029025  0.106955   0.062831  0.196593      0.294527     0.294527  3   \n",
       "42     0.045049  0.114034   0.166616  0.197958      0.299470     0.299470  3   \n",
       "43     0.042387  0.103179   0.141541  0.207821      0.303454     0.303454  3   \n",
       "44     0.055057  0.106570   0.062831  0.196593      0.298016     0.298016  3   \n",
       "45     0.113998  0.096147   0.075182  0.205529      0.289315     0.289315  3   \n",
       "46     0.036152  0.117122   0.195294  0.195294      0.291683     0.291683  3   \n",
       "47     0.092391  0.112364   0.062831  0.196593      0.298635     0.298635  3   \n",
       "48     0.112357  0.108330   0.167061  0.188712      0.290237     0.290237  3   \n",
       "49     0.036747  0.107812   0.171329  0.189742      0.305407     0.305407  3   \n",
       "50     0.077235  0.115209   0.079474  0.186587      0.298635     0.298635  3   \n",
       "51     0.047161  0.109228   0.062831  0.196593      0.303539     0.303539  3   \n",
       "52     0.081228  0.112854   0.062831  0.196593      0.301109     0.301109  3   \n",
       "53     0.030494  0.109627   0.062831  0.196593      0.298635     0.298635  3   \n",
       "54     0.060032  0.109786   0.084474  0.189142      0.298007     0.298007  3   \n",
       "55     0.047135  0.105350   0.062831  0.196593      0.295283     0.295283  3   \n",
       "56     0.045123  0.102547   0.140592  0.209416      0.293146     0.293146  3   \n",
       "57     0.051795  0.107345   0.062831  0.196593      0.298635     0.298635  3   \n",
       "58     0.203116  0.200817  -0.118462  0.376307      0.365330     0.483052  3   \n",
       "59     0.238237  0.227292   0.349300  0.349300      0.496696     0.496696  3   \n",
       "60     0.137030  0.256585   0.367224  0.367224      0.607867     0.607867  3   \n",
       "61    -0.218974  0.324801   0.302610  0.476886      0.454261     0.618569  3   \n",
       "62     0.225847  0.240614   0.349300  0.349300      0.454409     0.454409  3   \n",
       "63     0.176890  0.224405   0.496813  0.496813      0.404310     0.505912  3   \n",
       "64     0.124872  0.207028   0.358222  0.358222      0.354810     0.521772  3   \n",
       "65     0.072872  0.116738   0.167337  0.189348      0.283977     0.283977  3   \n",
       "66     0.121182  0.121625   0.119199  0.201773      0.265478     0.255912  3   \n",
       "67     0.027491  0.120760   0.198583  0.185648      0.265403     0.255856  3   \n",
       "68     0.051542  0.120779   0.167337  0.189348      0.240949     0.284104  3   \n",
       "69     0.068196  0.120036   0.167337  0.189348      0.279214     0.279214  3   \n",
       "70     0.107533  0.122857   0.104524  0.185357      0.276239     0.276239  3   \n",
       "71     0.046575  0.122889   0.178781  0.204377      0.297026     0.297026  3   \n",
       "72     0.090041  0.104541   0.168079  0.198395      0.290833     0.290833  3   \n",
       "73     0.074318  0.109901   0.167337  0.189348      0.225523     0.285088  3   \n",
       "74     0.089871  0.123058   0.099888  0.183428      0.288105     0.288105  3   \n",
       "75     0.065422  0.125942   0.167337  0.189348      0.279214     0.279214  3   \n",
       "76     0.068319  0.117190   0.167337  0.189348      0.289000     0.289000  3   \n",
       "77     0.097603  0.119704   0.167337  0.189348      0.279214     0.279214  3   \n",
       "78     0.040057  0.118153   0.170277  0.171650      0.276056     0.276056  3   \n",
       "79     0.028625  0.125393   0.171973  0.198453      0.274979     0.274979  3   \n",
       "80     0.045184  0.112558   0.167337  0.189348      0.271222     0.271222  3   \n",
       "81     0.102699  0.118776   0.087869  0.175591      0.289352     0.289352  3   \n",
       "82     0.046404  0.116495   0.167337  0.189348      0.279214     0.279214  3   \n",
       "83     0.096984  0.115751   0.167337  0.189348      0.279214     0.279214  3   \n",
       "84     0.105142  0.122176   0.167337  0.189348      0.279214     0.279214  3   \n",
       "85     0.074764  0.104661   0.167337  0.189348      0.278589     0.278589  3   \n",
       "86     0.074764  0.104661   0.167337  0.189348      0.281220     0.281220  3   \n",
       "87     0.084551  0.115426   0.167337  0.189348      0.281220     0.281220  3   \n",
       "88     0.094505  0.125212   0.113141  0.175544      0.279214     0.279214  3   \n",
       "89     0.056602  0.120200   0.167337  0.189348      0.276239     0.276239  3   \n",
       "90     0.099591  0.114642   0.123969  0.205100      0.285812     0.285812  3   \n",
       "91     0.081793  0.121287   0.111922  0.201875      0.275449     0.275449  3   \n",
       "92     0.065651  0.120897   0.167337  0.189348      0.279214     0.279214  3   \n",
       "93     0.065651  0.120897   0.167337  0.189348      0.279214     0.279214  3   \n",
       "94     0.065651  0.120897   0.167337  0.189348      0.279214     0.279214  3   \n",
       "95     0.065651  0.120897   0.167337  0.189348      0.279214     0.279214  3   \n",
       "96     0.028489  0.100220   0.129067  0.199322      0.279214     0.279214  3   \n",
       "97     0.083493  0.121804   0.167337  0.189348      0.279214     0.279214  3   \n",
       "98     0.044072  0.112747   0.167337  0.189348      0.281101     0.281101  3   \n",
       "99     0.102556  0.114016   0.151637  0.199671      0.281121     0.281121  3   \n",
       "100    0.028942  0.122802   0.190514  0.206585      0.295956     0.295956  3   \n",
       "101    0.072872  0.116738   0.167337  0.189348      0.283977     0.283977  3   \n",
       "102    0.107737  0.122180   0.167337  0.189348      0.268246     0.268246  3   \n",
       "103    0.111382  0.112258   0.111952  0.190356      0.274979     0.274979  3   \n",
       "104    0.066611  0.115442   0.167337  0.189348      0.279214     0.279214  3   \n",
       "105    0.068600  0.111817   0.167337  0.189348      0.279214     0.279214  3   \n",
       "106    0.051913  0.116296   0.154005  0.183808      0.265403     0.255856  3   \n",
       "107    0.085090  0.117841   0.171551  0.198072      0.288105     0.288105  3   \n",
       "108    0.038378  0.123295   0.070564  0.160120      0.279214     0.279214  3   \n",
       "109    0.094384  0.111277   0.167337  0.189348      0.284787     0.284787  3   \n",
       "110    0.067411  0.115689   0.167337  0.189348      0.280329     0.280329  3   \n",
       "111    0.041809  0.124493   0.167337  0.189348      0.279214     0.279214  3   \n",
       "112    0.067284  0.122343   0.073406  0.176645      0.277153     0.277153  3   \n",
       "113    0.107552  0.122408   0.167337  0.189348      0.247894     0.247894  3   \n",
       "114    0.111163  0.107395   0.108052  0.198949      0.274979     0.274979  3   \n",
       "115    0.045536  0.124075   0.167337  0.189348      0.279214     0.279214  3   \n",
       "116    0.153018  0.216140   0.113623  0.281693      0.335433     0.335433  3   \n",
       "117    0.200291  0.247407   0.063930  0.359095      0.342103     0.379770  3   \n",
       "118    0.105191  0.248185   0.329103  0.329103      0.372733     0.372733  3   \n",
       "119    0.193856  0.239770   0.327051  0.324395      0.303170     0.370649  3   \n",
       "120    0.201470  0.199722   0.327051  0.324395      0.340515     0.340515  3   \n",
       "121    0.135034  0.227546   0.327051  0.324395      0.311973     0.375576  3   \n",
       "122    0.040273  0.234442   0.083232  0.317736      0.329277     0.329277  3   \n",
       "123    0.320096  0.143176   0.258553  0.352738      0.355104     0.355104  3   \n",
       "124    0.140839  0.238667   0.327051  0.324395      0.326645     0.371821  3   \n",
       "125    0.192269  0.199859   0.327051  0.324395      0.340515     0.340515  3   \n",
       "126    0.190457  0.223575   0.318912  0.318912      0.333366     0.333366  3   \n",
       "127    0.068356  0.237216   0.327051  0.324395      0.347825     0.347825  3   \n",
       "128    0.144004  0.199908   0.089093  0.329161      0.328082     0.371025  3   \n",
       "129    0.174210  0.230409   0.355502  0.357648      0.311749     0.377683  3   \n",
       "130    0.100082  0.215283   0.327051  0.324395      0.333130     0.333130  3   \n",
       "131    0.206269  0.198167   0.113623  0.281693      0.332748     0.332748  3   \n",
       "132    0.139154  0.216187   0.283763  0.306044      0.338196     0.338196  3   \n",
       "133    0.092191  0.228010   0.305891  0.305891      0.335433     0.335433  3   \n",
       "134   -0.056923  0.154574   0.327051  0.324395      0.330773     0.349290  3   \n",
       "135    0.089186  0.148321   0.231421  0.237181      0.207324     0.357945  3   \n",
       "136    0.009642  0.150938   0.222474  0.268830      0.316538     0.368283  3   \n",
       "137    0.039663  0.147361   0.231421  0.237181      0.324458     0.373788  3   \n",
       "138    0.131588  0.151370   0.231421  0.237181      0.215560     0.343190  3   \n",
       "139    0.055999  0.147180   0.225701  0.239496      0.293055     0.340832  3   \n",
       "140    0.052304  0.146006   0.235859  0.236583      0.351844     0.351844  3   \n",
       "141    0.093663  0.151501   0.231421  0.237181      0.215560     0.343190  3   \n",
       "142    0.093507  0.147340   0.163961  0.216218      0.233304     0.358097  3   \n",
       "143    0.117973  0.148556   0.231421  0.237181      0.215560     0.343190  3   \n",
       "144    0.105447  0.151595   0.231421  0.237181      0.215560     0.343190  3   \n",
       "145    0.142502  0.143827   0.231421  0.237181      0.215560     0.343190  3   \n",
       "146    0.105994  0.123592   0.231421  0.237181      0.223689     0.332534  3   \n",
       "147    0.105994  0.123592   0.231421  0.237181      0.198989     0.321303  3   \n",
       "148    0.074643  0.119710   0.231421  0.237181      0.198989     0.321303  3   \n",
       "149    0.096122  0.147997   0.236807  0.242293      0.215560     0.343190  3   \n",
       "150    0.043753  0.145640   0.231421  0.237181      0.293055     0.340832  3   \n",
       "151    0.142383  0.145692   0.208376  0.259145      0.323670     0.364340  3   \n",
       "152    0.085859  0.145952   0.236734  0.228887      0.301942     0.336246  3   \n",
       "153    0.051620  0.142240   0.231421  0.237181      0.215560     0.343190  3   \n",
       "154    0.051620  0.142240   0.231421  0.237181      0.215560     0.343190  3   \n",
       "155    0.051620  0.142240   0.231421  0.237181      0.215560     0.343190  3   \n",
       "156    0.051620  0.142240   0.231421  0.237181      0.215560     0.343190  3   \n",
       "157    0.138014  0.150707   0.271257  0.251576      0.215560     0.343190  3   \n",
       "158    0.129117  0.124428   0.231421  0.237181      0.339382     0.355726  3   \n",
       "159    0.141578  0.146018   0.212282  0.353632      0.329766     0.329766  3   \n",
       "160    0.079309  0.146570   0.268925  0.272545      0.239382     0.365088  3   \n",
       "161    0.089186  0.148321   0.231421  0.237181      0.207324     0.357945  3   \n",
       "162    0.086111  0.145983   0.231421  0.237181      0.300587     0.330629  3   \n",
       "163    0.139602  0.144447   0.250636  0.252505      0.306891     0.339215  3   \n",
       "164    0.024484  0.141500   0.231421  0.237181      0.215560     0.343190  3   \n",
       "165    0.053710  0.148464   0.231421  0.237181      0.215560     0.343190  3   \n",
       "166    0.090121  0.145945   0.255832  0.359731      0.351844     0.351844  3   \n",
       "167    0.143389  0.144126   0.323183  0.349518      0.215560     0.343190  3   \n",
       "168    0.004985  0.141523   0.231421  0.237181      0.318631     0.341741  3   \n",
       "169    0.030322  0.146976   0.231421  0.237181      0.221978     0.339160  3   \n",
       "170    0.014326  0.142092   0.231421  0.237181      0.215560     0.343190  3   \n",
       "171    0.017089  0.129288   0.257964  0.248914      0.316612     0.349014  3   \n",
       "172    0.078811  0.147355   0.213708  0.247953      0.306891     0.339215  3   \n",
       "173    0.014090  0.148495   0.231421  0.237181      0.215560     0.343190  3   \n",
       "174    0.025305  0.105113   0.167340  0.187771      0.322785     0.322785  4   \n",
       "175    0.068766  0.102301   0.174796  0.196902      0.240473     0.312437  4   \n",
       "176    0.101505  0.116128   0.172437  0.192254      0.241738     0.313663  4   \n",
       "177    0.060282  0.115552   0.167340  0.187771      0.261361     0.333329  4   \n",
       "178    0.071996  0.114895   0.167340  0.187771      0.315098     0.315098  4   \n",
       "179    0.029864  0.109039   0.173309  0.193242      0.313806     0.313806  4   \n",
       "180    0.065661  0.103199   0.111708  0.195961      0.326902     0.326902  4   \n",
       "181    0.066081  0.106922   0.152586  0.188113      0.317410     0.317410  4   \n",
       "182    0.067165  0.114963   0.167340  0.187771      0.320137     0.320137  4   \n",
       "183    0.054197  0.114287   0.170983  0.192191      0.320609     0.320609  4   \n",
       "184   -0.011696  0.108344   0.167340  0.187771      0.315098     0.315098  4   \n",
       "185   -0.044996  0.105358   0.167340  0.187771      0.308410     0.308410  4   \n",
       "186    0.060704  0.103121   0.167340  0.187771      0.315098     0.315098  4   \n",
       "187    0.065068  0.120808   0.131615  0.180097      0.309460     0.309460  4   \n",
       "188    0.045061  0.111658   0.176191  0.203888      0.313029     0.313029  4   \n",
       "189    0.051589  0.090699   0.167340  0.187771      0.320323     0.300492  4   \n",
       "190    0.033817  0.108160   0.165914  0.184836      0.323552     0.323552  4   \n",
       "191    0.049172  0.120342   0.167340  0.187771      0.315098     0.315098  4   \n",
       "192    0.015051  0.103261   0.167340  0.187771      0.315098     0.315098  4   \n",
       "193    0.065440  0.107360   0.167340  0.187771      0.315098     0.315098  4   \n",
       "194    0.061713  0.101304   0.167340  0.187771      0.328255     0.328255  4   \n",
       "195    0.061713  0.101304   0.167340  0.187771      0.317822     0.317822  4   \n",
       "196    0.052784  0.102419   0.167340  0.187771      0.317822     0.317822  4   \n",
       "197    0.003122  0.109487   0.173640  0.197310      0.315098     0.315098  4   \n",
       "198    0.035009  0.112390   0.167340  0.187771      0.313806     0.313806  4   \n",
       "199    0.049186  0.103873   0.178692  0.201964      0.322023     0.322023  4   \n",
       "200    0.098872  0.121346   0.164284  0.196165      0.313736     0.313736  4   \n",
       "201    0.037930  0.112239   0.167340  0.187771      0.315098     0.315098  4   \n",
       "202    0.037930  0.112239   0.167340  0.187771      0.315098     0.315098  4   \n",
       "203    0.037930  0.112239   0.167340  0.187771      0.315098     0.315098  4   \n",
       "204    0.037930  0.112239   0.167340  0.187771      0.315098     0.315098  4   \n",
       "205    0.046788  0.098383   0.174633  0.192666      0.315098     0.315098  4   \n",
       "206    0.072609  0.112538   0.167340  0.187771      0.315098     0.315098  4   \n",
       "207    0.058008  0.095173   0.167340  0.187771      0.316694     0.316694  4   \n",
       "208    0.075267  0.114673   0.177837  0.204385      0.324159     0.324159  4   \n",
       "209    0.055220  0.102478   0.151683  0.177860      0.340280     0.340280  4   \n",
       "210    0.025305  0.105113   0.167340  0.187771      0.322785     0.322785  4   \n",
       "211    0.058436  0.120337   0.167340  0.187771      0.319289     0.306570  4   \n",
       "212    0.065305  0.114254   0.103331  0.173477      0.313029     0.313029  4   \n",
       "213    0.102407  0.115794   0.167340  0.187771      0.315098     0.315098  4   \n",
       "214    0.016180  0.120794   0.162212  0.178221      0.308981     0.308981  4   \n",
       "215    0.028916  0.109052   0.167340  0.187771      0.307174     0.307174  4   \n",
       "216    0.045114  0.113832   0.102004  0.186694      0.300619     0.300619  4   \n",
       "217    0.091290  0.110946   0.082060  0.184454      0.321639     0.321639  4   \n",
       "218    0.047963  0.109110   0.167340  0.187771      0.306333     0.306333  4   \n",
       "219    0.076222  0.119197   0.172437  0.192254      0.240747     0.312741  4   \n",
       "220    0.017085  0.121645   0.089778  0.179454      0.311010     0.311010  4   \n",
       "221   -0.115706  0.100621   0.167340  0.187771      0.315098     0.315098  4   \n",
       "222    0.114397  0.116293   0.177829  0.198396      0.241738     0.313663  4   \n",
       "223    0.088713  0.115584   0.121874  0.205920      0.320609     0.320609  4   \n",
       "224    0.060290  0.109956   0.155376  0.188408      0.315098     0.315098  4   \n",
       "225    0.036099  0.117303   0.167340  0.187771      0.319964     0.319964  4   \n",
       "226    0.001215  0.112958   0.167340  0.187771      0.314265     0.314265  4   \n",
       "227    0.111139  0.100302   0.167340  0.187771      0.315098     0.315098  4   \n",
       "228    0.044975  0.113763   0.156252  0.189114      0.306287     0.306287  4   \n",
       "229    0.014627  0.112609   0.167340  0.187771      0.305143     0.305143  4   \n",
       "230    0.103269  0.100473   0.161060  0.181682      0.313029     0.313029  4   \n",
       "231    0.025422  0.114414   0.167340  0.187771      0.315098     0.315098  4   \n",
       "232    0.173316  0.276404   0.268685  0.433022      0.666140     0.666140  4   \n",
       "233    0.197210  0.241789  -0.014556  0.357341      0.672963     0.672963  4   \n",
       "234    0.096414  0.267001   0.230581  0.376329      0.430391     0.659696  4   \n",
       "235    0.198854  0.399368   0.170480  0.444480      0.781330     0.781330  4   \n",
       "236    0.216522  0.241154  -0.014556  0.357341      0.648258     0.648258  4   \n",
       "237   -0.089010  0.228265   0.550887  0.550887      0.641430     0.641430  4   \n",
       "238    0.054499  0.266273   0.358222  0.364855      0.657085     0.657085  4   \n",
       "239    0.035965  0.108436   0.168093  0.215664      0.277625     0.280980  4   \n",
       "240    0.094424  0.123865   0.192678  0.216594      0.259361     0.259361  4   \n",
       "241    0.022701  0.130588   0.171841  0.203068      0.260910     0.260910  4   \n",
       "242    0.006743  0.126947   0.168093  0.215664      0.296378     0.283599  4   \n",
       "243    0.019414  0.121845   0.168093  0.215664      0.274222     0.274222  4   \n",
       "244    0.014764  0.133687   0.170075  0.195704      0.272700     0.272700  4   \n",
       "245    0.079961  0.126901   0.174508  0.229665      0.287653     0.287653  4   \n",
       "246    0.028182  0.118766   0.202669  0.226600      0.304143     0.304143  4   \n",
       "247    0.078701  0.122619   0.168093  0.215664      0.275436     0.275436  4   \n",
       "248    0.050420  0.133237   0.134689  0.213314      0.282350     0.282350  4   \n",
       "249    0.033442  0.134145   0.168093  0.215664      0.274222     0.274222  4   \n",
       "250   -0.021365  0.117157   0.168093  0.215664      0.280963     0.280963  4   \n",
       "251    0.029035  0.121994   0.168093  0.215664      0.274222     0.274222  4   \n",
       "252    0.056314  0.123431   0.174650  0.200196      0.269270     0.269270  4   \n",
       "253    0.008008  0.123461   0.162709  0.230189      0.258442     0.271519  4   \n",
       "254    0.066346  0.113010   0.168093  0.215664      0.267119     0.267119  4   \n",
       "255    0.108790  0.127344   0.130819  0.185219      0.285340     0.285340  4   \n",
       "256    0.025117  0.122159   0.168093  0.215664      0.274222     0.274222  4   \n",
       "257    0.055164  0.136273   0.168093  0.215664      0.274222     0.274222  4   \n",
       "258   -0.005146  0.127974   0.168093  0.215664      0.274222     0.274222  4   \n",
       "259    0.010207  0.115502   0.168093  0.215664      0.279474     0.279474  4   \n",
       "260    0.010207  0.115502   0.168093  0.215664      0.277651     0.277651  4   \n",
       "261   -0.027203  0.120545   0.168093  0.215664      0.277651     0.277651  4   \n",
       "262    0.025150  0.135950   0.136863  0.192888      0.274222     0.274222  4   \n",
       "263    0.038323  0.125180   0.168093  0.215664      0.272700     0.272700  4   \n",
       "264   -0.040617  0.127364   0.218476  0.219822      0.282211     0.282211  4   \n",
       "265    0.113687  0.126912   0.128217  0.212270      0.271458     0.271458  4   \n",
       "266    0.068868  0.124024   0.168093  0.215664      0.274222     0.274222  4   \n",
       "267    0.068868  0.124024   0.168093  0.215664      0.274222     0.274222  4   \n",
       "268    0.068868  0.124024   0.168093  0.215664      0.274222     0.274222  4   \n",
       "269    0.068868  0.124024   0.168093  0.215664      0.274222     0.274222  4   \n",
       "270    0.005829  0.114470   0.139412  0.208521      0.274222     0.274222  4   \n",
       "271    0.018063  0.115775   0.168093  0.215664      0.274222     0.274222  4   \n",
       "272    0.082995  0.117077   0.168093  0.215664      0.277633     0.277633  4   \n",
       "273    0.109341  0.125919   0.204120  0.231289      0.283593     0.272889  4   \n",
       "274   -0.088864  0.132030   0.215089  0.225382      0.308411     0.292463  4   \n",
       "275    0.035965  0.108436   0.168093  0.215664      0.277625     0.280980  4   \n",
       "276    0.092494  0.124172   0.168093  0.215664      0.264552     0.264552  4   \n",
       "277    0.127619  0.125105   0.149738  0.200282      0.258442     0.271519  4   \n",
       "278    0.001799  0.129707   0.168093  0.215664      0.274222     0.274222  4   \n",
       "279    0.054810  0.116615   0.168093  0.215664      0.274222     0.274222  4   \n",
       "280   -0.006570  0.125438   0.144441  0.196252      0.260910     0.260910  4   \n",
       "281    0.056518  0.126903   0.209511  0.229153      0.282350     0.282350  4   \n",
       "282   -0.027912  0.136675   0.090882  0.185079      0.274222     0.274222  4   \n",
       "283    0.038437  0.124440   0.168093  0.215664      0.297459     0.276797  4   \n",
       "284   -0.069643  0.125707   0.168093  0.215664      0.292116     0.275380  4   \n",
       "285    0.027477  0.128951   0.168093  0.215664      0.274222     0.274222  4   \n",
       "286   -0.023001  0.124543   0.164396  0.171460      0.270010     0.270010  4   \n",
       "287    0.029891  0.127705   0.168093  0.215664      0.261614     0.261614  4   \n",
       "288    0.068224  0.126527   0.194752  0.214788      0.258442     0.271519  4   \n",
       "289    0.057031  0.120254   0.168093  0.215664      0.274222     0.274222  4   \n",
       "290    0.153248  0.141424   0.299404  0.357598      0.440365     0.440365  4   \n",
       "291    0.137762  0.224171   0.036177  0.311827      0.501335     0.501335  4   \n",
       "292    0.151481  0.242657   0.339720  0.399204      0.483812     0.483812  4   \n",
       "293    0.194079  0.137573   0.287850  0.369134      0.462545     0.462545  4   \n",
       "294    0.071431  0.153480   0.287850  0.369134      0.445564     0.445564  4   \n",
       "295    0.047577  0.225302   0.287850  0.369134      0.454658     0.454658  4   \n",
       "296    0.195497  0.144523   0.287300  0.367461      0.428302     0.428302  4   \n",
       "297    0.184525  0.154531   0.278668  0.422844      0.409217     0.409217  4   \n",
       "298    0.008270  0.234161   0.287850  0.369134      0.452090     0.452090  4   \n",
       "299    0.252432  0.151986   0.287850  0.369134      0.445564     0.445564  4   \n",
       "300    0.069583  0.239322   0.321536  0.383210      0.432426     0.432426  4   \n",
       "301   -0.051760  0.227794   0.287850  0.369134      0.431260     0.431260  4   \n",
       "302    0.122149  0.129964   0.132781  0.378132      0.392889     0.392889  4   \n",
       "303    0.182395  0.224839   0.401957  0.401458      0.454709     0.454709  4   \n",
       "304    0.176885  0.220143   0.287850  0.369134      0.425694     0.425694  4   \n",
       "305    0.181013  0.135590   0.299404  0.357598      0.437608     0.437608  4   \n",
       "306    0.119049  0.135174   0.311106  0.368675      0.443157     0.443157  4   \n",
       "307    0.112535  0.132789   0.261834  0.374880      0.440365     0.440365  4   \n",
       "308   -0.022086  0.165853   0.287850  0.369134      0.445874     0.445874  4   \n",
       "309    0.017218  0.150718   0.173861  0.319230      0.233098     0.325465  4   \n",
       "310    0.058598  0.150575   0.313749  0.344809      0.363711     0.354658  4   \n",
       "311    0.030212  0.166836   0.173861  0.319230      0.359645     0.359645  4   \n",
       "312    0.050230  0.166437   0.173861  0.319230      0.306930     0.306930  4   \n",
       "313    0.026038  0.170098   0.338399  0.336732      0.226190     0.306836  4   \n",
       "314    0.032884  0.165966   0.337680  0.338193      0.234903     0.318345  4   \n",
       "315    0.049923  0.164731   0.173861  0.319230      0.306930     0.306930  4   \n",
       "316    0.065061  0.164108   0.269515  0.310786      0.242113     0.322178  4   \n",
       "317    0.085905  0.152272   0.173861  0.319230      0.306930     0.306930  4   \n",
       "318    0.074770  0.138711   0.173861  0.319230      0.306930     0.306930  4   \n",
       "319    0.067504  0.164538   0.173861  0.319230      0.306930     0.306930  4   \n",
       "320    0.029772  0.137492   0.173861  0.319230      0.224739     0.282312  4   \n",
       "321    0.029772  0.137492   0.173861  0.319230      0.223959     0.276676  4   \n",
       "322    0.058994  0.140374   0.173861  0.319230      0.223959     0.276676  4   \n",
       "323    0.132042  0.165609   0.206570  0.271159      0.306930     0.306930  4   \n",
       "324    0.002351  0.167935   0.173861  0.319230      0.226190     0.306836  4   \n",
       "325    0.106046  0.165364   0.323185  0.353816      0.249821     0.329853  4   \n",
       "326    0.056902  0.169146   0.295917  0.295990      0.297124     0.297124  4   \n",
       "327    0.030340  0.164295   0.173861  0.319230      0.306930     0.306930  4   \n",
       "328    0.030340  0.164295   0.173861  0.319230      0.306930     0.306930  4   \n",
       "329    0.030340  0.164295   0.173861  0.319230      0.306930     0.306930  4   \n",
       "330    0.030340  0.164295   0.173861  0.319230      0.306930     0.306930  4   \n",
       "331    0.145004  0.169162   0.322669  0.347844      0.306930     0.306930  4   \n",
       "332    0.032807  0.152619   0.173861  0.319230      0.321725     0.321725  4   \n",
       "333    0.166453  0.153263   0.319424  0.362207      0.247781     0.332203  4   \n",
       "334    0.057354  0.168251   0.272776  0.355125      0.250245     0.330546  4   \n",
       "335    0.017218  0.150718   0.173861  0.319230      0.233098     0.325465  4   \n",
       "336    0.038291  0.169463   0.173861  0.319230      0.297228     0.297228  4   \n",
       "337    0.076702  0.144614   0.234766  0.275195      0.225237     0.306137  4   \n",
       "338    0.089819  0.151407   0.173861  0.319230      0.306930     0.306930  4   \n",
       "339    0.008247  0.151455   0.173861  0.319230      0.306930     0.306930  4   \n",
       "340    0.078462  0.154076   0.313524  0.304720      0.234903     0.318345  4   \n",
       "341    0.144094  0.153850   0.350885  0.352348      0.306930     0.306930  4   \n",
       "342   -0.025146  0.159653   0.173861  0.319230      0.322630     0.341854  4   \n",
       "343   -0.002001  0.157414   0.173861  0.319230      0.212142     0.304797  4   \n",
       "344    0.028814  0.154730   0.173861  0.319230      0.306930     0.306930  4   \n",
       "345    0.038162  0.168242   0.289822  0.306019      0.311404     0.311404  4   \n",
       "346    0.091454  0.121762   0.228638  0.279167      0.225237     0.306137  4   \n",
       "347    0.091729  0.155585   0.173861  0.319230      0.306930     0.306930  4   \n",
       "348    0.019937  0.105846   0.190475  0.190475      0.316115     0.316115  5   \n",
       "349   -0.077081  0.123750   0.122963  0.201543      0.300120     0.300120  5   \n",
       "350    0.024071  0.123589   0.174387  0.198648      0.301346     0.301346  5   \n",
       "351    0.054188  0.121049   0.190475  0.190475      0.321012     0.321012  5   \n",
       "352   -0.091573  0.123309   0.190475  0.190475      0.306917     0.306917  5   \n",
       "353    0.016221  0.123527   0.177661  0.200465      0.311477     0.311477  5   \n",
       "354    0.049465  0.120723   0.179240  0.233239      0.315817     0.315817  5   \n",
       "355    0.098124  0.105830   0.176272  0.199138      0.312681     0.312681  5   \n",
       "356    0.025277  0.101845   0.190475  0.190475      0.312924     0.312924  5   \n",
       "357    0.008742  0.122679   0.177394  0.201960      0.300235     0.300235  5   \n",
       "358    0.114077  0.115661   0.190475  0.190475      0.306917     0.306917  5   \n",
       "359    0.053455  0.119257   0.190475  0.190475      0.306247     0.306247  5   \n",
       "360    0.100891  0.118330   0.190475  0.190475      0.306917     0.306917  5   \n",
       "361    0.062145  0.111660   0.168299  0.189842      0.301359     0.301359  5   \n",
       "362    0.014880  0.096676   0.172816  0.190221      0.299833     0.299833  5   \n",
       "363    0.062610  0.115057   0.190475  0.190475      0.303695     0.303695  5   \n",
       "364   -0.010168  0.126202   0.175054  0.196418      0.270514     0.270514  5   \n",
       "365    0.007030  0.110354   0.190475  0.190475      0.306917     0.306917  5   \n",
       "366    0.042119  0.127480   0.190475  0.190475      0.306917     0.306917  5   \n",
       "367    0.052008  0.123381   0.190475  0.190475      0.306917     0.306917  5   \n",
       "368    0.047749  0.116389   0.190475  0.190475      0.315011     0.315011  5   \n",
       "369    0.047749  0.116389   0.190475  0.190475      0.313165     0.313165  5   \n",
       "370    0.052612  0.114188   0.190475  0.190475      0.313165     0.313165  5   \n",
       "371    0.046590  0.113037   0.148028  0.209356      0.306917     0.306917  5   \n",
       "372    0.017124  0.121850   0.190475  0.190475      0.311477     0.311477  5   \n",
       "373    0.076124  0.121676   0.206717  0.206717      0.319361     0.319361  5   \n",
       "374    0.032241  0.122780   0.167942  0.195495      0.309363     0.309363  5   \n",
       "375    0.049656  0.108423   0.190475  0.190475      0.306917     0.306917  5   \n",
       "376    0.049656  0.108423   0.190475  0.190475      0.306917     0.306917  5   \n",
       "377    0.049656  0.108423   0.190475  0.190475      0.306917     0.306917  5   \n",
       "378    0.049656  0.108423   0.190475  0.190475      0.306917     0.306917  5   \n",
       "379    0.033882  0.106490   0.169726  0.203535      0.306917     0.306917  5   \n",
       "380    0.046107  0.121986   0.190475  0.190475      0.306917     0.306917  5   \n",
       "381    0.064699  0.113735   0.190475  0.190475      0.313508     0.313508  5   \n",
       "382   -0.043712  0.117863   0.197948  0.216689      0.309147     0.309147  5   \n",
       "383    0.087133  0.122329   0.191887  0.191887      0.329861     0.329861  5   \n",
       "384    0.019937  0.105846   0.190475  0.190475      0.316115     0.316115  5   \n",
       "385    0.045268  0.121007   0.190475  0.190475      0.303707     0.303707  5   \n",
       "386    0.023420  0.119868   0.118642  0.180773      0.299833     0.299833  5   \n",
       "387   -0.054601  0.121860   0.190475  0.190475      0.306917     0.306917  5   \n",
       "388    0.044770  0.114371   0.133067  0.189649      0.301080     0.301080  5   \n",
       "389    0.075524  0.107476   0.190475  0.190475      0.300189     0.300189  5   \n",
       "390   -0.024919  0.132375   0.172707  0.196561      0.271133     0.271133  5   \n",
       "391    0.060041  0.117008   0.188704  0.188066      0.311989     0.311989  5   \n",
       "392    0.059894  0.114528   0.190475  0.190475      0.299296     0.299296  5   \n",
       "393    0.004787  0.123558   0.174387  0.198648      0.300424     0.300424  5   \n",
       "394    0.046049  0.122523   0.171124  0.189457      0.302829     0.302829  5   \n",
       "395    0.053428  0.117318   0.190475  0.190475      0.306917     0.306917  5   \n",
       "396    0.037061  0.122076   0.174005  0.202656      0.301346     0.301346  5   \n",
       "397    0.037472  0.122897   0.199898  0.217794      0.300235     0.300235  5   \n",
       "398    0.028952  0.121175   0.151679  0.191665      0.306917     0.306917  5   \n",
       "399    0.021605  0.119781   0.190475  0.190475      0.313608     0.313608  5   \n",
       "400   -0.045294  0.111679   0.190475  0.190475      0.307052     0.307052  5   \n",
       "401    0.073530  0.121048   0.190475  0.190475      0.306917     0.306917  5   \n",
       "402    0.026831  0.118916   0.154941  0.187643      0.299578     0.299578  5   \n",
       "403    0.055158  0.107066   0.190475  0.190475      0.299209     0.299209  5   \n",
       "404    0.023358  0.114779   0.191578  0.191578      0.299833     0.299833  5   \n",
       "405    0.022123  0.121062   0.190475  0.190475      0.306917     0.306917  5   \n",
       "406    0.126108  0.232277   0.424232  0.491928      0.644220     0.644220  5   \n",
       "407    0.199591  0.263016   0.064068  0.429905      0.662429     0.662429  5   \n",
       "408    0.109811  0.271057   0.311268  0.445470      0.435506     0.575621  5   \n",
       "409   -0.079962  0.335940   0.520646  0.404968      0.698454     0.698454  5   \n",
       "410    0.066778  0.276691   0.064068  0.429905      0.631296     0.631296  5   \n",
       "411    0.079014  0.241365   0.519276  0.519276      0.624940     0.624940  5   \n",
       "412   -0.016976  0.236397   0.040824  0.434213      0.640167     0.640167  5   \n",
       "413   -0.020598  0.119020   0.159886  0.193872      0.232555     0.274827  5   \n",
       "414    0.059842  0.140260   0.226299  0.226299      0.248450     0.248450  5   \n",
       "415    0.004605  0.133306   0.204456  0.223564      0.250099     0.250099  5   \n",
       "416    0.055351  0.133153   0.159886  0.193872      0.210550     0.275946  5   \n",
       "417    0.122181  0.139363   0.159886  0.193872      0.263601     0.263601  5   \n",
       "418    0.046477  0.133187   0.217738  0.217738      0.270042     0.270042  5   \n",
       "419    0.124848  0.116387   0.164338  0.201152      0.280080     0.280080  5   \n",
       "420   -0.023761  0.109484   0.187128  0.222544      0.283015     0.283015  5   \n",
       "421    0.121156  0.141733   0.159886  0.193872      0.266726     0.266726  5   \n",
       "422    0.039111  0.130516   0.234060  0.234060      0.237164     0.237164  5   \n",
       "423    0.080384  0.141382   0.159886  0.193872      0.263601     0.263601  5   \n",
       "424    0.034771  0.127886   0.159886  0.193872      0.275373     0.275373  5   \n",
       "425   -0.016498  0.118410   0.159886  0.193872      0.263601     0.263601  5   \n",
       "426   -0.009426  0.130034   0.199313  0.208923      0.264261     0.264261  5   \n",
       "427    0.063956  0.139225   0.210506  0.223029      0.255061     0.255061  5   \n",
       "428    0.119504  0.134013   0.159886  0.193872      0.266897     0.266897  5   \n",
       "429    0.055759  0.136534   0.201281  0.174637      0.257463     0.257463  5   \n",
       "430   -0.088925  0.134910   0.159886  0.193872      0.263601     0.263601  5   \n",
       "431    0.021312  0.130892   0.159886  0.193872      0.263601     0.263601  5   \n",
       "432    0.078186  0.135386   0.159886  0.193872      0.263601     0.263601  5   \n",
       "433    0.085798  0.116486   0.159886  0.193872      0.272254     0.272254  5   \n",
       "434    0.085798  0.116486   0.159886  0.193872      0.269310     0.269310  5   \n",
       "435    0.049314  0.119164   0.159886  0.193872      0.269310     0.269310  5   \n",
       "436    0.031850  0.131308   0.217878  0.217878      0.263601     0.263601  5   \n",
       "437    0.026256  0.132249   0.159886  0.193872      0.270042     0.270042  5   \n",
       "438    0.061440  0.141977   0.227388  0.230629      0.279065     0.279065  5   \n",
       "439    0.027689  0.132984   0.225902  0.235404      0.265293     0.265293  5   \n",
       "440    0.048582  0.127368   0.159886  0.193872      0.263601     0.263601  5   \n",
       "441    0.048582  0.127368   0.159886  0.193872      0.263601     0.263601  5   \n",
       "442    0.048582  0.127368   0.159886  0.193872      0.263601     0.263601  5   \n",
       "443    0.048582  0.127368   0.159886  0.193872      0.263601     0.263601  5   \n",
       "444    0.034091  0.116847   0.212286  0.191077      0.263601     0.263601  5   \n",
       "445    0.054267  0.140983   0.159886  0.193872      0.263601     0.263601  5   \n",
       "446    0.039315  0.125627   0.159886  0.193872      0.277176     0.277176  5   \n",
       "447    0.065172  0.137202   0.210831  0.242028      0.265690     0.265690  5   \n",
       "448    0.033865  0.132388   0.255605  0.252566      0.288495     0.288495  5   \n",
       "449   -0.020598  0.119020   0.159886  0.193872      0.232555     0.274827  5   \n",
       "450    0.039151  0.131194   0.159886  0.193872      0.263202     0.263202  5   \n",
       "451    0.009930  0.108618   0.222025  0.220154      0.255061     0.255061  5   \n",
       "452    0.005192  0.135488   0.159886  0.193872      0.263601     0.263601  5   \n",
       "453    0.042779  0.125953   0.159886  0.193872      0.263601     0.263601  5   \n",
       "454   -0.047879  0.137441   0.188014  0.215859      0.250099     0.250099  5   \n",
       "455    0.066124  0.137407   0.218838  0.240243      0.237164     0.237164  5   \n",
       "456    0.035762  0.130778   0.120951  0.197679      0.263601     0.263601  5   \n",
       "457   -0.034247  0.132096   0.159886  0.193872      0.274199     0.274199  5   \n",
       "458    0.001577  0.124374   0.159886  0.193872      0.270983     0.270983  5   \n",
       "459    0.009906  0.123822   0.159886  0.193872      0.263601     0.263601  5   \n",
       "460    0.052525  0.141109   0.198647  0.220314      0.266749     0.266749  5   \n",
       "461    0.116119  0.140443   0.159886  0.193872      0.254981     0.254981  5   \n",
       "462    0.045213  0.121251   0.148776  0.234327      0.255061     0.255061  5   \n",
       "463    0.113081  0.140675   0.159886  0.193872      0.263601     0.263601  5   \n",
       "464    0.092713  0.169730   0.254193  0.351541      0.363459     0.363459  5   \n",
       "465    0.153543  0.137870   0.177285  0.274877      0.435061     0.435061  5   \n",
       "466    0.117764  0.201754   0.389297  0.389297      0.427145     0.427145  5   \n",
       "467    0.072674  0.147081   0.276429  0.350547      0.385092     0.385092  5   \n",
       "468    0.072861  0.129108   0.276429  0.350547      0.386803     0.386803  5   \n",
       "469    0.168056  0.140759   0.276429  0.350547      0.397581     0.397581  5   \n",
       "470    0.129522  0.150179   0.277385  0.355320      0.370806     0.370806  5   \n",
       "471    0.108243  0.142353   0.293945  0.363255      0.350457     0.350457  5   \n",
       "472   -0.044428  0.141116   0.276429  0.350547      0.392591     0.392591  5   \n",
       "473    0.069220  0.149635   0.276429  0.350547      0.386803     0.386803  5   \n",
       "474   -0.016587  0.153734   0.271824  0.373891      0.374910     0.374910  5   \n",
       "475    0.171036  0.154512   0.276429  0.350547      0.365530     0.365530  5   \n",
       "476    0.015937  0.141383   0.084126  0.358651      0.337198     0.337198  5   \n",
       "477    0.149896  0.121266   0.345510  0.398781      0.396858     0.396858  5   \n",
       "478   -0.031848  0.137396   0.276429  0.350547      0.367318     0.367318  5   \n",
       "479    0.136843  0.159652   0.254193  0.351541      0.386377     0.386377  5   \n",
       "480    0.211469  0.171731   0.288067  0.351742      0.366306     0.366306  5   \n",
       "481    0.072061  0.127985   0.071334  0.368005      0.363459     0.363459  5   \n",
       "482    0.138729  0.138702   0.276429  0.350547      0.387830     0.387830  5   \n",
       "483    0.060864  0.153622   0.330093  0.339213      0.332985     0.332985  5   \n",
       "484    0.067365  0.162824   0.390904  0.390904      0.343104     0.343104  5   \n",
       "485    0.070453  0.174998   0.330093  0.339213      0.351055     0.351055  5   \n",
       "486    0.039336  0.155718   0.330093  0.339213      0.311537     0.311537  5   \n",
       "487    0.064510  0.149837   0.361144  0.361144      0.320906     0.320906  5   \n",
       "488    0.139950  0.150257   0.340254  0.349724      0.295282     0.295282  5   \n",
       "489    0.108116  0.162514   0.330093  0.339213      0.311537     0.311537  5   \n",
       "490    0.046786  0.159596   0.358266  0.347219      0.304409     0.311218  5   \n",
       "491    0.080241  0.157390   0.330093  0.339213      0.311537     0.311537  5   \n",
       "492    0.126221  0.166911   0.330093  0.339213      0.311537     0.311537  5   \n",
       "493    0.110314  0.160405   0.330093  0.339213      0.311537     0.311537  5   \n",
       "494    0.061682  0.144609   0.330093  0.339213      0.240351     0.297752  5   \n",
       "495    0.061682  0.144609   0.330093  0.339213      0.236462     0.295411  5   \n",
       "496    0.056610  0.121950   0.330093  0.339213      0.236462     0.295411  5   \n",
       "497    0.063180  0.170334   0.271742  0.294794      0.311537     0.311537  5   \n",
       "498    0.106294  0.155334   0.330093  0.339213      0.320906     0.320906  5   \n",
       "499    0.006772  0.156595   0.364892  0.374380      0.349626     0.349626  5   \n",
       "500    0.172237  0.169392   0.343251  0.354560      0.309750     0.309750  5   \n",
       "501    0.094856  0.156382   0.330093  0.339213      0.311537     0.311537  5   \n",
       "502    0.094856  0.156382   0.330093  0.339213      0.311537     0.311537  5   \n",
       "503    0.094856  0.156382   0.330093  0.339213      0.311537     0.311537  5   \n",
       "504    0.094856  0.156382   0.330093  0.339213      0.311537     0.311537  5   \n",
       "505    0.075756  0.157046   0.296429  0.361211      0.311537     0.311537  5   \n",
       "506    0.090128  0.147893   0.330093  0.339213      0.263281     0.340491  5   \n",
       "507    0.112166  0.169524   0.342406  0.373107      0.308318     0.308318  5   \n",
       "508    0.050206  0.163046   0.391588  0.432696      0.342148     0.342148  5   \n",
       "509    0.060864  0.153622   0.330093  0.339213      0.332985     0.332985  5   \n",
       "510    0.001666  0.161417   0.330093  0.339213      0.309750     0.309750  5   \n",
       "511   -0.037347  0.148170   0.318916  0.318916      0.302115     0.302115  5   \n",
       "512    0.061025  0.163565   0.330093  0.339213      0.311537     0.311537  5   \n",
       "513    0.077050  0.156981   0.330093  0.339213      0.311537     0.311537  5   \n",
       "514    0.146842  0.162256   0.343393  0.373837      0.295282     0.295282  5   \n",
       "515    0.112279  0.170520   0.360382  0.365106      0.311537     0.311537  5   \n",
       "516    0.059870  0.119097   0.330093  0.339213      0.246536     0.246536  5   \n",
       "517    0.042818  0.152494   0.330093  0.339213      0.313840     0.313840  5   \n",
       "518   -0.019160  0.165140   0.330093  0.339213      0.311537     0.311537  5   \n",
       "519    0.003438  0.168484   0.315524  0.315524      0.319391     0.319391  5   \n",
       "520    0.076141  0.154155   0.276683  0.335843      0.302115     0.302115  5   \n",
       "521    0.083192  0.164867   0.330093  0.339213      0.311537     0.311537  5   \n",
       "522    0.092415  0.108209   0.207409  0.203593      0.278201     0.278201  6   \n",
       "523    0.030577  0.124768   0.183901  0.183910      0.260968     0.260968  6   \n",
       "524    0.066137  0.129663   0.211258  0.219338      0.262127     0.262127  6   \n",
       "525    0.026713  0.118359   0.207409  0.203593      0.282985     0.282985  6   \n",
       "526    0.043035  0.129696   0.207409  0.203593      0.265692     0.265692  6   \n",
       "527    0.054439  0.109120   0.201549  0.217234      0.270252     0.270252  6   \n",
       "528    0.043394  0.127532   0.204417  0.204417      0.277512     0.277512  6   \n",
       "529   -0.030416  0.102473   0.153505  0.209035      0.281054     0.281054  6   \n",
       "530   -0.013314  0.115786   0.207409  0.203593      0.273871     0.273871  6   \n",
       "531    0.004773  0.133934   0.208311  0.186604      0.261859     0.261859  6   \n",
       "532    0.059555  0.094987   0.207409  0.203593      0.265692     0.265692  6   \n",
       "533    0.081726  0.128172   0.207409  0.203593      0.270103     0.270103  6   \n",
       "534    0.091520  0.097222   0.207409  0.203593      0.265692     0.265692  6   \n",
       "535    0.041937  0.129442   0.101750  0.199974      0.261819     0.261819  6   \n",
       "536    0.025878  0.117753   0.163722  0.208042      0.258607     0.258607  6   \n",
       "537    0.051882  0.117608   0.207409  0.203593      0.263995     0.263995  6   \n",
       "538    0.020621  0.135287   0.196992  0.213148      0.256772     0.256772  6   \n",
       "539   -0.026500  0.109176   0.207409  0.203593      0.265692     0.265692  6   \n",
       "540    0.071044  0.111078   0.207409  0.203593      0.265692     0.265692  6   \n",
       "541    0.078522  0.099301   0.207409  0.203593      0.265692     0.265692  6   \n",
       "542    0.060227  0.110946   0.207409  0.203593      0.279389     0.279389  6   \n",
       "543    0.060227  0.110946   0.207409  0.203593      0.274926     0.274926  6   \n",
       "544    0.051358  0.102651   0.207409  0.203593      0.274926     0.274926  6   \n",
       "545    0.042195  0.129197   0.226141  0.226141      0.265692     0.265692  6   \n",
       "546    0.041674  0.120306   0.207409  0.203593      0.270252     0.270252  6   \n",
       "547    0.058861  0.116792   0.190657  0.224398      0.278135     0.278135  6   \n",
       "548    0.012194  0.122371   0.126147  0.192683      0.269602     0.269602  6   \n",
       "549    0.062020  0.117054   0.207409  0.203593      0.265692     0.265692  6   \n",
       "550    0.062020  0.117054   0.207409  0.203593      0.265692     0.265692  6   \n",
       "551    0.062020  0.117054   0.207409  0.203593      0.265692     0.265692  6   \n",
       "552    0.062020  0.117054   0.207409  0.203593      0.265692     0.265692  6   \n",
       "553   -0.138748  0.110276   0.173570  0.193385      0.265692     0.265692  6   \n",
       "554    0.020397  0.123837   0.207409  0.203593      0.265692     0.265692  6   \n",
       "555    0.048003  0.120696   0.207409  0.203593      0.272282     0.272282  6   \n",
       "556    0.022520  0.094966   0.159639  0.187227      0.273327     0.273327  6   \n",
       "557    0.036818  0.116378   0.197835  0.239227      0.288635     0.288635  6   \n",
       "558    0.092415  0.108209   0.207409  0.203593      0.278201     0.278201  6   \n",
       "559    0.014213  0.102577   0.207409  0.203593      0.262482     0.262482  6   \n",
       "560    0.059238  0.135021   0.174570  0.194280      0.258607     0.258607  6   \n",
       "561   -0.008812  0.120076   0.207409  0.203593      0.265692     0.265692  6   \n",
       "562    0.059634  0.123432   0.177956  0.182440      0.272099     0.272099  6   \n",
       "563   -0.009911  0.113166   0.207409  0.203593      0.263002     0.263002  6   \n",
       "564    0.033912  0.095265   0.192802  0.231553      0.252306     0.252306  6   \n",
       "565   -0.011167  0.086857   0.205091  0.205091      0.271280     0.271280  6   \n",
       "566   -0.005227  0.093350   0.207409  0.203593      0.261899     0.261899  6   \n",
       "567    0.066005  0.095368   0.211258  0.219338      0.261383     0.261383  6   \n",
       "568   -0.015855  0.129001   0.101770  0.201102      0.263602     0.263602  6   \n",
       "569    0.063996  0.117134   0.207409  0.203593      0.265692     0.265692  6   \n",
       "570    0.027669  0.124851   0.221166  0.224416      0.262127     0.262127  6   \n",
       "571    0.070918  0.120819   0.206900  0.206900      0.261859     0.261859  6   \n",
       "572    0.028616  0.133892   0.156650  0.203774      0.265692     0.265692  6   \n",
       "573    0.018360  0.120005   0.207409  0.203593      0.279199     0.279199  6   \n",
       "574    0.016424  0.126147   0.207409  0.203593      0.270966     0.270966  6   \n",
       "575    0.087924  0.128066   0.207409  0.203593      0.265692     0.265692  6   \n",
       "576    0.117448  0.118199   0.157139  0.195688      0.261090     0.261090  6   \n",
       "577    0.012604  0.093334   0.207409  0.203593      0.261565     0.261565  6   \n",
       "578    0.024615  0.107744   0.157473  0.207249      0.258607     0.258607  6   \n",
       "579    0.014063  0.122689   0.207409  0.203593      0.265692     0.265692  6   \n",
       "580    0.129871  0.273063   0.169976  0.470936      0.565772     0.565772  6   \n",
       "581    0.213485  0.277090   0.165137  0.495681      0.568255     0.568255  6   \n",
       "582    0.155438  0.293943   0.299816  0.493309      0.514241     0.514241  6   \n",
       "583    0.192755  0.317003   0.092793  0.401288      0.565909     0.565909  6   \n",
       "584    0.150591  0.279608   0.165137  0.495681      0.550193     0.550193  6   \n",
       "585   -0.169894  0.256951   0.332727  0.504181      0.545525     0.545525  6   \n",
       "586   -0.100141  0.248947   0.343976  0.469337      0.554646     0.554646  6   \n",
       "587   -0.115937  0.123265   0.246536  0.246536      0.234724     0.234724  6   \n",
       "588   -0.096004  0.131804   0.248604  0.248604      0.228556     0.228556  6   \n",
       "589    0.080004  0.148884   0.259574  0.259574      0.229989     0.229989  6   \n",
       "590    0.036666  0.131878   0.246536  0.246536      0.268314     0.268314  6   \n",
       "591    0.038068  0.141108   0.246536  0.246536      0.235857     0.235857  6   \n",
       "592   -0.071475  0.132967   0.236678  0.236678      0.241251     0.241251  6   \n",
       "593    0.002263  0.140651   0.254227  0.254227      0.235819     0.235819  6   \n",
       "594   -0.029269  0.127101   0.237280  0.245568      0.261562     0.261562  6   \n",
       "595   -0.089385  0.132615   0.246536  0.246536      0.245315     0.245315  6   \n",
       "596    0.037141  0.126065   0.247653  0.245421      0.226948     0.226948  6   \n",
       "597    0.061333  0.119749   0.246536  0.246536      0.235857     0.235857  6   \n",
       "598   -0.023216  0.124011   0.246536  0.246536      0.256027     0.256027  6   \n",
       "599    0.089407  0.122401   0.246536  0.246536      0.235857     0.235857  6   \n",
       "600    0.072346  0.133548   0.235801  0.235801      0.229969     0.229969  6   \n",
       "601    0.012163  0.113836   0.207836  0.221171      0.227208     0.227208  6   \n",
       "602    0.028911  0.115182   0.246536  0.246536      0.232588     0.232588  6   \n",
       "603    0.020811  0.136276   0.229206  0.229206      0.239476     0.239476  6   \n",
       "604    0.016866  0.137675   0.246536  0.246536      0.235857     0.235857  6   \n",
       "605    0.015234  0.142694   0.246536  0.246536      0.235857     0.235857  6   \n",
       "606    0.059498  0.124905   0.246536  0.246536      0.235857     0.235857  6   \n",
       "607   -0.042333  0.128107   0.246536  0.246536      0.251683     0.251683  6   \n",
       "608   -0.042333  0.128107   0.246536  0.246536      0.249014     0.249014  6   \n",
       "609   -0.043399  0.120614   0.246536  0.246536      0.249014     0.249014  6   \n",
       "610    0.017438  0.129544   0.223411  0.223411      0.235857     0.235857  6   \n",
       "611    0.004725  0.130293   0.246536  0.246536      0.241251     0.241251  6   \n",
       "612    0.052777  0.133564   0.271169  0.271169      0.250020     0.250020  6   \n",
       "613    0.027834  0.140460   0.200007  0.208782      0.238899     0.238899  6   \n",
       "614   -0.005989  0.128067   0.246536  0.246536      0.235857     0.235857  6   \n",
       "615   -0.005989  0.128067   0.246536  0.246536      0.235857     0.235857  6   \n",
       "616   -0.005989  0.128067   0.246536  0.246536      0.235857     0.235857  6   \n",
       "617   -0.005989  0.128067   0.246536  0.246536      0.235857     0.235857  6   \n",
       "618    0.023598  0.129678   0.227995  0.251214      0.235857     0.235857  6   \n",
       "619    0.068818  0.128721   0.246536  0.246536      0.235857     0.235857  6   \n",
       "620    0.002154  0.122259   0.246536  0.246536      0.246255     0.246255  6   \n",
       "621    0.002561  0.127176   0.233420  0.233411      0.242758     0.242758  6   \n",
       "622    0.004207  0.130430   0.244571  0.244571      0.260718     0.260718  6   \n",
       "623   -0.115937  0.123265   0.246536  0.246536      0.234724     0.234724  6   \n",
       "624   -0.067397  0.130679   0.246536  0.246536      0.232360     0.232360  6   \n",
       "625   -0.004231  0.127811   0.235503  0.235503      0.227208     0.227208  6   \n",
       "626    0.029534  0.135051   0.246536  0.246536      0.235857     0.235857  6   \n",
       "627    0.046899  0.133108   0.246536  0.246536      0.235857     0.235857  6   \n",
       "628    0.045851  0.152098   0.246038  0.246038      0.229989     0.229989  6   \n",
       "629    0.017627  0.140138   0.266143  0.266143      0.226948     0.226948  6   \n",
       "630    0.023797  0.127765   0.172095  0.185345      0.235857     0.235857  6   \n",
       "631   -0.022954  0.127946   0.246536  0.246536      0.259875     0.259875  6   \n",
       "632   -0.075736  0.131458   0.246536  0.246536      0.240571     0.240571  6   \n",
       "633    0.024891  0.118983   0.246536  0.246536      0.235857     0.235857  6   \n",
       "634    0.124345  0.139666   0.186387  0.170466      0.250060     0.250060  6   \n",
       "635   -0.029535  0.138772   0.246536  0.246536      0.229545     0.229545  6   \n",
       "636    0.020494  0.137560   0.240747  0.240747      0.227208     0.227208  6   \n",
       "637    0.040618  0.141981   0.246536  0.246536      0.235857     0.235857  6   \n",
       "638   -0.174803  0.151961   0.278532  0.289313      0.314152     0.314152  6   \n",
       "639   -0.061029  0.164195   0.135529  0.280682      0.334164     0.334164  6   \n",
       "640    0.152184  0.148118   0.318005  0.373240      0.367111     0.367111  6   \n",
       "641    0.117664  0.157533   0.308252  0.308252      0.380623     0.380623  6   \n",
       "642    0.185738  0.153484   0.308252  0.308252      0.314152     0.314152  6   \n",
       "643    0.029894  0.134010   0.308252  0.308252      0.276927     0.335033  6   \n",
       "644    0.056687  0.144664   0.206188  0.313422      0.302604     0.302604  6   \n",
       "645    0.176521  0.147586   0.367936  0.367936      0.285824     0.285824  6   \n",
       "646    0.175068  0.149788   0.308252  0.308252      0.355316     0.355316  6   \n",
       "647   -0.054193  0.167426   0.308252  0.308252      0.314152     0.314152  6   \n",
       "648    0.165812  0.153460   0.126904  0.291047      0.307583     0.307583  6   \n",
       "649    0.181360  0.154789   0.308252  0.308252      0.307754     0.307754  6   \n",
       "650    0.083913  0.136147   0.250954  0.291333      0.300742     0.269633  6   \n",
       "651    0.116668  0.152297   0.358724  0.357063      0.336034     0.336034  6   \n",
       "652   -0.114938  0.137822   0.308252  0.308252      0.304067     0.304067  6   \n",
       "653   -0.025327  0.145113   0.278532  0.289313      0.314152     0.314152  6   \n",
       "654   -0.023694  0.149150   0.078142  0.312810      0.314152     0.314152  6   \n",
       "655    0.055903  0.149615   0.263099  0.330161      0.314152     0.314152  6   \n",
       "656    0.056747  0.136857   0.308252  0.308252      0.311665     0.311665  6   \n",
       "657    0.090995  0.166401   0.382929  0.363934      0.326994     0.326994  6   \n",
       "658    0.096003  0.182951   0.363272  0.411884      0.344582     0.344582  6   \n",
       "659    0.123061  0.181043   0.382929  0.363934      0.356988     0.356988  6   \n",
       "660    0.081416  0.163232   0.382929  0.363934      0.304594     0.304594  6   \n",
       "661    0.031068  0.180132   0.405065  0.405065      0.251558     0.315118  6   \n",
       "662    0.078434  0.172074   0.405548  0.403666      0.263291     0.263291  6   \n",
       "663    0.051836  0.158103   0.382929  0.363934      0.305602     0.305602  6   \n",
       "664    0.050777  0.167731   0.384668  0.384668      0.270288     0.270288  6   \n",
       "665    0.096654  0.174245   0.382929  0.363934      0.305602     0.305602  6   \n",
       "666    0.093419  0.175032   0.382929  0.363934      0.305602     0.305602  6   \n",
       "667    0.041629  0.162674   0.382929  0.363934      0.305602     0.305602  6   \n",
       "668    0.057691  0.150695   0.382929  0.363934      0.292553     0.292553  6   \n",
       "669    0.057691  0.150695   0.382929  0.363934      0.251555     0.251555  6   \n",
       "670    0.052907  0.163246   0.382929  0.363934      0.251555     0.251555  6   \n",
       "671    0.100432  0.165260   0.322922  0.316366      0.305602     0.305602  6   \n",
       "672    0.119450  0.148281   0.382929  0.363934      0.251558     0.315118  6   \n",
       "673    0.164025  0.176225   0.385311  0.399253      0.280400     0.280400  6   \n",
       "674    0.096667  0.120211   0.366523  0.382258      0.303593     0.303593  6   \n",
       "675    0.076202  0.173323   0.382929  0.363934      0.305602     0.305602  6   \n",
       "676    0.076202  0.173323   0.382929  0.363934      0.305602     0.305602  6   \n",
       "677    0.076202  0.173323   0.382929  0.363934      0.305602     0.305602  6   \n",
       "678    0.076202  0.173323   0.382929  0.363934      0.305602     0.305602  6   \n",
       "679    0.062801  0.171814   0.400643  0.400643      0.305602     0.305602  6   \n",
       "680    0.093545  0.124098   0.382929  0.363934      0.334359     0.334359  6   \n",
       "681   -0.022864  0.148632   0.404644  0.402241      0.273077     0.309699  6   \n",
       "682    0.034551  0.175883   0.449460  0.449460      0.336052     0.336052  6   \n",
       "683    0.090995  0.166401   0.382929  0.363934      0.326994     0.326994  6   \n",
       "684    0.068735  0.177779   0.382929  0.363934      0.303593     0.303593  6   \n",
       "685    0.069566  0.168662   0.371841  0.371841      0.295945     0.295945  6   \n",
       "686    0.126155  0.160605   0.382929  0.363934      0.305602     0.305602  6   \n",
       "687    0.063345  0.148209   0.382929  0.363934      0.305602     0.305602  6   \n",
       "688    0.048456  0.155894   0.460809  0.410261      0.263291     0.263291  6   \n",
       "689    0.054227  0.167725   0.390405  0.390405      0.305602     0.305602  6   \n",
       "690    0.100992  0.165467   0.382929  0.363934      0.302750     0.297951  6   \n",
       "691    0.036445  0.176312   0.382929  0.363934      0.319982     0.319982  6   \n",
       "692    0.106511  0.150712   0.382929  0.363934      0.305602     0.305602  6   \n",
       "693    0.097158  0.170562   0.375922  0.375922      0.316427     0.316427  6   \n",
       "694    0.047326  0.153810   0.347251  0.397019      0.295945     0.295945  6   \n",
       "695    0.087845  0.156619   0.382929  0.363934      0.305602     0.305602  6   \n",
       "696    0.021064  0.112621   0.184854  0.207206      0.276543     0.276543  7   \n",
       "697    0.013804  0.139102   0.177495  0.177495      0.245808     0.245808  7   \n",
       "698    0.070967  0.095352   0.165237  0.200397      0.246967     0.246967  7   \n",
       "699    0.037924  0.123586   0.184854  0.207206      0.267825     0.267825  7   \n",
       "700   -0.040982  0.131216   0.184854  0.207206      0.250532     0.250532  7   \n",
       "701   -0.010972  0.122489   0.164138  0.200675      0.257899     0.257899  7   \n",
       "702    0.012361  0.128900   0.211844  0.211844      0.275566     0.275566  7   \n",
       "703    0.039939  0.119575   0.214215  0.210199      0.268628     0.268628  7   \n",
       "704    0.021676  0.128839   0.184854  0.207206      0.258923     0.258923  7   \n",
       "705   -0.006685  0.120179   0.179971  0.206010      0.245384     0.245384  7   \n",
       "706    0.029928  0.118429   0.184854  0.207206      0.250532     0.250532  7   \n",
       "707    0.066106  0.120794   0.184854  0.207206      0.258427     0.258427  7   \n",
       "708    0.054831  0.128956   0.184854  0.207206      0.250532     0.250532  7   \n",
       "709    0.015478  0.136713   0.183868  0.203319      0.247527     0.247527  7   \n",
       "710    0.056502  0.122254   0.184813  0.214135      0.243134     0.243134  7   \n",
       "711    0.090623  0.116815   0.184854  0.207206      0.242398     0.242398  7   \n",
       "712    0.047661  0.136467   0.147790  0.176359      0.233984     0.233984  7   \n",
       "713   -0.001867  0.126857   0.184854  0.207206      0.250532     0.250532  7   \n",
       "714   -0.093923  0.126374   0.184854  0.207206      0.250532     0.250532  7   \n",
       "715    0.047008  0.091309   0.184854  0.207206      0.250532     0.250532  7   \n",
       "716   -0.010436  0.079530   0.184854  0.207206      0.259701     0.259701  7   \n",
       "717   -0.010436  0.079530   0.184854  0.207206      0.253829     0.253829  7   \n",
       "718   -0.057592  0.119244   0.184854  0.207206      0.253829     0.253829  7   \n",
       "719   -0.004174  0.104800   0.177672  0.200559      0.250532     0.250532  7   \n",
       "720    0.010570  0.123468   0.184854  0.207206      0.257899     0.257899  7   \n",
       "721    0.086148  0.117724   0.212726  0.229249      0.266121     0.266121  7   \n",
       "722    0.059292  0.130205   0.149380  0.171108      0.249072     0.249072  7   \n",
       "723    0.029961  0.122014   0.184854  0.207206      0.250532     0.250532  7   \n",
       "724    0.029961  0.122014   0.184854  0.207206      0.250532     0.250532  7   \n",
       "725    0.029961  0.122014   0.184854  0.207206      0.250532     0.250532  7   \n",
       "726    0.029961  0.122014   0.184854  0.207206      0.250532     0.250532  7   \n",
       "727    0.019919  0.128182   0.202608  0.202608      0.250532     0.250532  7   \n",
       "728    0.043264  0.126415   0.184854  0.207206      0.250532     0.250532  7   \n",
       "729    0.012474  0.120589   0.184854  0.207206      0.259027     0.259027  7   \n",
       "730   -0.049964  0.130310   0.160620  0.174349      0.217479     0.217479  7   \n",
       "731    0.047872  0.129626   0.204417  0.227585      0.273493     0.273493  7   \n",
       "732    0.021064  0.112621   0.184854  0.207206      0.276543     0.276543  7   \n",
       "733    0.009995  0.136670   0.184854  0.207206      0.249072     0.249072  7   \n",
       "734    0.025280  0.114601   0.198122  0.198122      0.243134     0.243134  7   \n",
       "735    0.025037  0.123322   0.184854  0.207206      0.250532     0.250532  7   \n",
       "736    0.000484  0.130287   0.202479  0.202479      0.256265     0.256265  7   \n",
       "737    0.015631  0.134562   0.184854  0.207206      0.248989     0.248989  7   \n",
       "738    0.055841  0.110430   0.195370  0.195370      0.237991     0.237991  7   \n",
       "739    0.046698  0.114634   0.198983  0.198441      0.254733     0.254733  7   \n",
       "740    0.052112  0.136333   0.184854  0.207206      0.249118     0.249118  7   \n",
       "741    0.033257  0.126218   0.165237  0.200397      0.246223     0.246223  7   \n",
       "742    0.080396  0.131500   0.180865  0.203140      0.248442     0.248442  7   \n",
       "743   -0.008397  0.129700   0.184854  0.207206      0.250532     0.250532  7   \n",
       "744   -0.010885  0.120585   0.208904  0.214297      0.246967     0.246967  7   \n",
       "745   -0.037661  0.125608   0.186495  0.206997      0.245384     0.245384  7   \n",
       "746    0.075707  0.132924   0.194135  0.194135      0.250532     0.250532  7   \n",
       "747   -0.066038  0.136622   0.184854  0.207206      0.268947     0.268947  7   \n",
       "748    0.063295  0.105753   0.184854  0.207206      0.257320     0.257320  7   \n",
       "749   -0.002214  0.123703   0.184854  0.207206      0.250532     0.250532  7   \n",
       "750   -0.004546  0.136588   0.182994  0.182994      0.247175     0.247175  7   \n",
       "751    0.010371  0.109394   0.184854  0.207206      0.248849     0.248849  7   \n",
       "752    0.023381  0.132654   0.197715  0.205461      0.243134     0.243134  7   \n",
       "753    0.006365  0.122394   0.184854  0.207206      0.250532     0.250532  7   \n",
       "754    0.015196  0.279752  -0.112759  0.422395      0.296983     0.488964  7   \n",
       "755   -0.033987  0.281805   0.253522  0.465129      0.266975     0.492265  7   \n",
       "756    0.062800  0.301533   0.157268  0.490916      0.387891     0.387891  7   \n",
       "757    0.115600  0.243450   0.316345  0.374594      0.434397     0.434397  7   \n",
       "758    0.125645  0.290796   0.253522  0.465129      0.474517     0.474517  7   \n",
       "759   -0.021732  0.248136   0.353331  0.431133      0.466487     0.466487  7   \n",
       "760   -0.150439  0.223694   0.238360  0.445319      0.475608     0.475608  7   \n",
       "761    0.035091  0.119344   0.247386  0.247386      0.254302     0.254302  7   \n",
       "762    0.072122  0.141598   0.210123  0.201421      0.223338     0.223338  7   \n",
       "763    0.023593  0.141471   0.226335  0.257990      0.225226     0.225226  7   \n",
       "764   -0.009874  0.127004   0.247386  0.247386      0.253620     0.253620  7   \n",
       "765   -0.021978  0.144837   0.247386  0.247386      0.232356     0.232356  7   \n",
       "766    0.056406  0.130513   0.227486  0.244974      0.240326     0.240326  7   \n",
       "767    0.050057  0.140974   0.231599  0.249029      0.247968     0.247968  7   \n",
       "768    0.015962  0.111680   0.271665  0.271665      0.244935     0.244935  7   \n",
       "769    0.001856  0.142497   0.247386  0.247386      0.242226     0.242226  7   \n",
       "770    0.026657  0.120737   0.224926  0.224926      0.215683     0.215683  7   \n",
       "771    0.017695  0.113345   0.247386  0.247386      0.232356     0.232356  7   \n",
       "772    0.007231  0.125449   0.247386  0.247386      0.250309     0.250309  7   \n",
       "773    0.028528  0.117187   0.247386  0.247386      0.232356     0.232356  7   \n",
       "774    0.048387  0.132785   0.239047  0.239047      0.232823     0.232823  7   \n",
       "775    0.007049  0.118687   0.207870  0.243410      0.223521     0.223521  7   \n",
       "776    0.018586  0.112522   0.247386  0.247386      0.234876     0.234876  7   \n",
       "777   -0.000318  0.132209   0.216063  0.240924      0.201879     0.201879  7   \n",
       "778   -0.006272  0.117934   0.247386  0.247386      0.232356     0.232356  7   \n",
       "779    0.018708  0.121340   0.247386  0.247386      0.232356     0.232356  7   \n",
       "780    0.021762  0.125641   0.247386  0.247386      0.232356     0.232356  7   \n",
       "781    0.028631  0.107635   0.247386  0.247386      0.231401     0.231401  7   \n",
       "782    0.028631  0.107635   0.247386  0.247386      0.211797     0.211797  7   \n",
       "783    0.014146  0.103661   0.247386  0.247386      0.211797     0.211797  7   \n",
       "784    0.073369  0.132721   0.209680  0.240842      0.232356     0.232356  7   \n",
       "785    0.064170  0.145074   0.247386  0.247386      0.240326     0.240326  7   \n",
       "786    0.023089  0.134047   0.254833  0.272412      0.249483     0.249483  7   \n",
       "787    0.021335  0.131113   0.191547  0.219127      0.230142     0.230142  7   \n",
       "788    0.037686  0.131765   0.247386  0.247386      0.232356     0.232356  7   \n",
       "789    0.037686  0.131765   0.247386  0.247386      0.232356     0.232356  7   \n",
       "790    0.037686  0.131765   0.247386  0.247386      0.232356     0.232356  7   \n",
       "791    0.037686  0.131765   0.247386  0.247386      0.232356     0.232356  7   \n",
       "792   -0.105782  0.123079   0.265997  0.241797      0.232356     0.232356  7   \n",
       "793    0.010695  0.143981   0.247386  0.247386      0.232356     0.232356  7   \n",
       "794    0.028821  0.119588   0.247386  0.247386      0.244767     0.244767  7   \n",
       "795   -0.008521  0.135832   0.213855  0.239039      0.224565     0.224565  7   \n",
       "796   -0.015565  0.132115   0.249243  0.267906      0.257180     0.257180  7   \n",
       "797    0.035091  0.119344   0.247386  0.247386      0.254302     0.254302  7   \n",
       "798   -0.030302  0.142494   0.247386  0.247386      0.230737     0.230737  7   \n",
       "799    0.012906  0.117088   0.219208  0.236745      0.223521     0.223521  7   \n",
       "800   -0.004751  0.136102   0.247386  0.247386      0.232356     0.232356  7   \n",
       "801    0.050390  0.121410   0.247386  0.247386      0.232356     0.232356  7   \n",
       "802    0.043528  0.114799   0.256292  0.256292      0.225226     0.225226  7   \n",
       "803   -0.014811  0.131992   0.268194  0.268194      0.215683     0.215683  7   \n",
       "804   -0.025961  0.147719   0.184739  0.184739      0.232356     0.232356  7   \n",
       "805    0.019010  0.121224   0.247386  0.247386      0.223332     0.223332  7   \n",
       "806    0.051154  0.125187   0.247386  0.247386      0.234396     0.234396  7   \n",
       "807    0.026308  0.125693   0.247386  0.247386      0.232356     0.232356  7   \n",
       "808    0.005607  0.125447   0.190041  0.192159      0.235984     0.235984  7   \n",
       "809    0.038387  0.112207   0.247386  0.247386      0.235043     0.235043  7   \n",
       "810    0.093528  0.123259   0.225713  0.243105      0.223521     0.223521  7   \n",
       "811    0.041136  0.134074   0.247386  0.247386      0.232356     0.232356  7   \n",
       "812    0.142749  0.140545   0.288911  0.288911      0.310745     0.310745  7   \n",
       "813    0.052479  0.159303   0.213059  0.275755      0.364000     0.287954  7   \n",
       "814    0.118535  0.154687   0.347082  0.347082      0.266618     0.266618  7   \n",
       "815    0.149993  0.161741   0.175109  0.289698      0.308595     0.308595  7   \n",
       "816    0.090298  0.158051   0.175109  0.289698      0.310745     0.310745  7   \n",
       "817    0.134902  0.171022   0.175109  0.289698      0.343274     0.343274  7   \n",
       "818    0.068877  0.152631   0.260675  0.269125      0.304013     0.304013  7   \n",
       "819    0.167004  0.152011   0.209623  0.363168      0.253482     0.282417  7   \n",
       "820    0.142134  0.163329   0.175109  0.289698      0.318400     0.318400  7   \n",
       "821   -0.108669  0.151345   0.175109  0.289698      0.310745     0.310745  7   \n",
       "822    0.134901  0.137939   0.297332  0.320166      0.307636     0.307636  7   \n",
       "823   -0.087060  0.174961   0.175109  0.289698      0.311838     0.311838  7   \n",
       "824   -0.095126  0.149512   0.284828  0.325294      0.243491     0.275018  7   \n",
       "825    0.101260  0.136335   0.271879  0.339375      0.334719     0.334719  7   \n",
       "826    0.149056  0.169342   0.175109  0.289698      0.312569     0.312569  7   \n",
       "827    0.098247  0.161244   0.288911  0.288911      0.310745     0.310745  7   \n",
       "828    0.088131  0.142910   0.232501  0.268966      0.310745     0.310745  7   \n",
       "829    0.163758  0.143204   0.262484  0.308784      0.310745     0.310745  7   \n",
       "830   -0.094322  0.166126   0.175109  0.289698      0.307491     0.307491  7   \n",
       "831    0.075543  0.135299   0.408323  0.408323      0.256397     0.256397  7   \n",
       "832    0.077903  0.168291   0.382726  0.412986      0.341201     0.341201  7   \n",
       "833    0.074335  0.176383   0.408323  0.408323      0.353401     0.353401  7   \n",
       "834    0.067465  0.172628   0.408323  0.408323      0.250980     0.300451  7   \n",
       "835    0.057658  0.154074   0.411299  0.411299      0.290049     0.290049  7   \n",
       "836    0.118325  0.179360   0.426272  0.426272      0.250840     0.300451  7   \n",
       "837    0.095832  0.174999   0.408323  0.408323      0.250980     0.300451  7   \n",
       "838    0.082230  0.179555   0.406837  0.406837      0.246187     0.295657  7   \n",
       "839   -0.018937  0.174302   0.408323  0.408323      0.250980     0.300451  7   \n",
       "840    0.130740  0.179921   0.408323  0.408323      0.250980     0.300451  7   \n",
       "841    0.163496  0.185737   0.408323  0.408323      0.250980     0.300451  7   \n",
       "842    0.094865  0.154150   0.408323  0.408323      0.291097     0.291097  7   \n",
       "843    0.094865  0.154150   0.408323  0.408323      0.296728     0.296728  7   \n",
       "844    0.053474  0.165453   0.408323  0.408323      0.296728     0.296728  7   \n",
       "845    0.064815  0.177957   0.421017  0.421017      0.250980     0.300451  7   \n",
       "846    0.069478  0.180090   0.408323  0.408323      0.290049     0.290049  7   \n",
       "847    0.118619  0.179680   0.446708  0.446708      0.350060     0.350060  7   \n",
       "848    0.106628  0.137891   0.409778  0.409778      0.250980     0.300451  7   \n",
       "849    0.028059  0.174214   0.408323  0.408323      0.250980     0.300451  7   \n",
       "850    0.028059  0.174214   0.408323  0.408323      0.250980     0.300451  7   \n",
       "851    0.028059  0.174214   0.408323  0.408323      0.250980     0.300451  7   \n",
       "852    0.028059  0.174214   0.408323  0.408323      0.250980     0.300451  7   \n",
       "853    0.070489  0.176746   0.401255  0.401255      0.250980     0.300451  7   \n",
       "854    0.094730  0.174290   0.408323  0.408323      0.346884     0.346884  7   \n",
       "855    0.046421  0.123496   0.434640  0.434640      0.245294     0.300451  7   \n",
       "856    0.122611  0.164464   0.475001  0.488764      0.291110     0.291110  7   \n",
       "857    0.075543  0.135299   0.408323  0.408323      0.256397     0.256397  7   \n",
       "858    0.114077  0.180661   0.408323  0.408323      0.250980     0.300451  7   \n",
       "859    0.080884  0.179499   0.394834  0.394834      0.300451     0.300451  7   \n",
       "860    0.106734  0.178964   0.408323  0.408323      0.250980     0.300451  7   \n",
       "861    0.049794  0.172112   0.408323  0.408323      0.250980     0.300451  7   \n",
       "862    0.050160  0.164405   0.457786  0.513556      0.250840     0.300451  7   \n",
       "863    0.081245  0.182716   0.386328  0.386328      0.250980     0.300451  7   \n",
       "864    0.014980  0.174280   0.408323  0.408323      0.250460     0.259083  7   \n",
       "865    0.016303  0.172712   0.408323  0.408323      0.316502     0.316502  7   \n",
       "866    0.053871  0.146358   0.408323  0.408323      0.250980     0.300451  7   \n",
       "867    0.091179  0.176519   0.371868  0.371868      0.312772     0.312772  7   \n",
       "868    0.056143  0.174845   0.402568  0.402568      0.300451     0.300451  7   \n",
       "869    0.087376  0.180661   0.408323  0.408323      0.250980     0.300451  7   \n",
       "870    0.020306  0.112655   0.192727  0.196270      0.222439     0.222439  8   \n",
       "871   -0.005442  0.117219   0.206256  0.227806      0.191705     0.191705  8   \n",
       "872    0.045023  0.113308   0.209540  0.208512      0.192863     0.192863  8   \n",
       "873    0.055734  0.133665   0.192727  0.196270      0.213721     0.213721  8   \n",
       "874   -0.003159  0.107305   0.192727  0.196270      0.196428     0.196428  8   \n",
       "875    0.034676  0.121112   0.183250  0.180390      0.182532     0.182532  8   \n",
       "876    0.049713  0.120358   0.189324  0.189324      0.228752     0.228752  8   \n",
       "877   -0.036662  0.102037   0.217566  0.186915      0.213676     0.213676  8   \n",
       "878    0.032060  0.143889   0.192727  0.196270      0.205106     0.205106  8   \n",
       "879   -0.003803  0.127321   0.169920  0.180478      0.196428     0.196428  8   \n",
       "880    0.002689  0.131475   0.192727  0.196270      0.196428     0.196428  8   \n",
       "881    0.030015  0.137480   0.192727  0.196270      0.211886     0.211886  8   \n",
       "882    0.009878  0.100007   0.192727  0.196270      0.196428     0.196428  8   \n",
       "883    0.001371  0.102576   0.197291  0.197291      0.194360     0.194360  8   \n",
       "884    0.010554  0.140543   0.187728  0.189755      0.196428     0.196428  8   \n",
       "885    0.022288  0.089904   0.192727  0.196270      0.194106     0.194106  8   \n",
       "886    0.001192  0.103816   0.178136  0.175611      0.196428     0.196428  8   \n",
       "887    0.046227  0.116088   0.192727  0.196270      0.196428     0.196428  8   \n",
       "888   -0.029356  0.118584   0.192727  0.196270      0.196428     0.196428  8   \n",
       "889   -0.061860  0.125166   0.192727  0.196270      0.196428     0.196428  8   \n",
       "890   -0.073450  0.110937   0.192727  0.196270      0.205597     0.205597  8   \n",
       "891   -0.073450  0.110937   0.192727  0.196270      0.201261     0.201261  8   \n",
       "892    0.047345  0.110166   0.192727  0.196270      0.201261     0.201261  8   \n",
       "893    0.058045  0.116338   0.191554  0.191554      0.196428     0.196428  8   \n",
       "894   -0.049267  0.104078   0.192727  0.196270      0.182532     0.182532  8   \n",
       "895    0.014313  0.116810   0.218471  0.255519      0.206816     0.206816  8   \n",
       "896    0.093257  0.088454   0.177472  0.221584      0.196428     0.196428  8   \n",
       "897    0.016285  0.115972   0.192727  0.196270      0.196428     0.196428  8   \n",
       "898    0.016285  0.115972   0.192727  0.196270      0.196428     0.196428  8   \n",
       "899    0.016285  0.115972   0.192727  0.196270      0.196428     0.196428  8   \n",
       "900    0.016285  0.115972   0.192727  0.196270      0.196428     0.196428  8   \n",
       "901   -0.090225  0.118332   0.184814  0.184562      0.196428     0.196428  8   \n",
       "902    0.011509  0.139378   0.192727  0.196270      0.196428     0.196428  8   \n",
       "903    0.035354  0.108277   0.192727  0.196270      0.211463     0.211463  8   \n",
       "904    0.077096  0.130349   0.171849  0.180773      0.196428     0.196428  8   \n",
       "905    0.063727  0.145929   0.255945  0.255945      0.246066     0.246066  8   \n",
       "906    0.020306  0.112655   0.192727  0.196270      0.222439     0.222439  8   \n",
       "907    0.045614  0.131239   0.192727  0.196270      0.196428     0.196428  8   \n",
       "908    0.018206  0.121443   0.172805  0.176456      0.196428     0.196428  8   \n",
       "909    0.032016  0.120755   0.192727  0.196270      0.196428     0.196428  8   \n",
       "910    0.006985  0.134788   0.196933  0.185379      0.202969     0.202969  8   \n",
       "911    0.048970  0.141463   0.192727  0.196270      0.194895     0.194895  8   \n",
       "912   -0.005645  0.099813   0.205334  0.205334      0.192660     0.192660  8   \n",
       "913    0.010006  0.126340   0.209225  0.210952      0.208406     0.208406  8   \n",
       "914    0.051915  0.102652   0.192727  0.196270      0.195571     0.195571  8   \n",
       "915    0.073396  0.136838   0.209540  0.208512      0.192119     0.192119  8   \n",
       "916    0.025010  0.110274   0.198255  0.185113      0.194339     0.194339  8   \n",
       "917    0.066149  0.117962   0.192727  0.196270      0.196428     0.196428  8   \n",
       "918    0.067596  0.123943   0.202863  0.204912      0.192863     0.192863  8   \n",
       "919    0.015419  0.120922   0.202303  0.202303      0.196428     0.196428  8   \n",
       "920    0.056505  0.143383   0.212255  0.234388      0.196428     0.196428  8   \n",
       "921    0.069697  0.133275   0.192727  0.196270      0.214843     0.214843  8   \n",
       "922    0.007055  0.113576   0.192727  0.196270      0.203217     0.203217  8   \n",
       "923    0.015122  0.109554   0.192727  0.196270      0.196428     0.196428  8   \n",
       "924   -0.008865  0.119087   0.161598  0.173334      0.193071     0.193071  8   \n",
       "925   -0.027971  0.124319   0.192727  0.196270      0.195049     0.195049  8   \n",
       "926    0.037058  0.139155   0.179801  0.184777      0.196428     0.196428  8   \n",
       "927   -0.028164  0.108531   0.192727  0.196270      0.196428     0.196428  8   \n",
       "928    0.046309  0.237214   0.073265  0.412195      0.382443     0.382443  8   \n",
       "929    0.127380  0.284490   0.138073  0.451978      0.347117     0.347117  8   \n",
       "930    0.046998  0.287480   0.207953  0.472280      0.358819     0.358819  8   \n",
       "931    0.174557  0.253933   0.340272  0.371867      0.404456     0.404456  8   \n",
       "932    0.024326  0.272840   0.138073  0.451978      0.374480     0.374480  8   \n",
       "933   -0.071788  0.263205   0.230192  0.397084      0.343044     0.343044  8   \n",
       "934    0.034300  0.248685   0.092870  0.444215      0.343044     0.343044  8   \n",
       "935    0.008715  0.100801   0.192266  0.227173      0.218674     0.218674  8   \n",
       "936    0.034970  0.131021   0.237326  0.237326      0.186243     0.186243  8   \n",
       "937    0.037661  0.135668   0.263202  0.263202      0.188131     0.188131  8   \n",
       "938    0.081751  0.141276   0.192266  0.227173      0.216525     0.216525  8   \n",
       "939    0.060127  0.142096   0.192266  0.227173      0.195261     0.195261  8   \n",
       "940    0.064655  0.142268   0.240192  0.240192      0.181888     0.181888  8   \n",
       "941    0.016130  0.127470   0.228159  0.245239      0.219283     0.219283  8   \n",
       "942    0.035142  0.132218   0.261615  0.261615      0.207664     0.207664  8   \n",
       "943    0.043252  0.140992   0.192266  0.227173      0.205308     0.205308  8   \n",
       "944    0.036880  0.139379   0.241445  0.241445      0.192320     0.192320  8   \n",
       "945    0.027929  0.118362   0.192266  0.227173      0.195261     0.195261  8   \n",
       "946    0.019142  0.097108   0.192266  0.227173      0.221441     0.221441  8   \n",
       "947    0.006141  0.140507   0.192266  0.227173      0.195261     0.195261  8   \n",
       "948    0.009869  0.130233   0.207752  0.233592      0.197632     0.197632  8   \n",
       "949    0.021247  0.136029   0.221206  0.237391      0.195261     0.195261  8   \n",
       "950    0.053291  0.131053   0.192266  0.227173      0.200803     0.200803  8   \n",
       "951    0.031115  0.118646   0.235526  0.235526      0.195261     0.195261  8   \n",
       "952    0.005311  0.137436   0.192266  0.227173      0.195261     0.195261  8   \n",
       "953   -0.019593  0.126695   0.192266  0.227173      0.195261     0.195261  8   \n",
       "954    0.076816  0.150118   0.192266  0.227173      0.195261     0.195261  8   \n",
       "955   -0.018462  0.126593   0.192266  0.227173      0.195773     0.195773  8   \n",
       "956   -0.018462  0.126593   0.192266  0.227173      0.188015     0.188015  8   \n",
       "957    0.038685  0.118337   0.192266  0.227173      0.188015     0.188015  8   \n",
       "958    0.066489  0.143141   0.244875  0.244875      0.195261     0.195261  8   \n",
       "959    0.034932  0.127901   0.192266  0.227173      0.181888     0.181888  8   \n",
       "960    0.062541  0.142482   0.261043  0.261043      0.207027     0.207027  8   \n",
       "961   -0.009548  0.148124   0.270719  0.270719      0.194667     0.194667  8   \n",
       "962    0.012908  0.129339   0.192266  0.227173      0.195261     0.195261  8   \n",
       "963    0.012908  0.129339   0.192266  0.227173      0.195261     0.195261  8   \n",
       "964    0.012908  0.129339   0.192266  0.227173      0.195261     0.195261  8   \n",
       "965    0.012908  0.129339   0.192266  0.227173      0.195261     0.195261  8   \n",
       "966   -0.029594  0.112028   0.211729  0.211729      0.195261     0.195261  8   \n",
       "967    0.008680  0.147473   0.192266  0.227173      0.195261     0.195261  8   \n",
       "968   -0.008186  0.129936   0.192266  0.227173      0.216268     0.216268  8   \n",
       "969    0.083951  0.148129   0.217061  0.217061      0.187470     0.187470  8   \n",
       "970    0.076787  0.139216   0.241609  0.259586      0.227069     0.227069  8   \n",
       "971    0.008715  0.100801   0.192266  0.227173      0.218674     0.218674  8   \n",
       "972    0.055081  0.122705   0.192266  0.227173      0.195261     0.195261  8   \n",
       "973    0.026182  0.131354   0.230220  0.230220      0.195261     0.195261  8   \n",
       "974   -0.029774  0.135546   0.192266  0.227173      0.195261     0.195261  8   \n",
       "975    0.043430  0.110546   0.192266  0.227173      0.195261     0.195261  8   \n",
       "976    0.077282  0.135624   0.232785  0.250990      0.188131     0.188131  8   \n",
       "977    0.057986  0.136856   0.241933  0.261007      0.192320     0.192320  8   \n",
       "978    0.025703  0.139526   0.225433  0.225433      0.195261     0.195261  8   \n",
       "979    0.004002  0.132833   0.192266  0.227173      0.205842     0.205842  8   \n",
       "980    0.070776  0.119561   0.192266  0.227173      0.198209     0.198209  8   \n",
       "981    0.078256  0.132668   0.192266  0.227173      0.195261     0.195261  8   \n",
       "982    0.038094  0.121151   0.199191  0.221655      0.199704     0.199704  8   \n",
       "983    0.035254  0.129824   0.192266  0.227173      0.198171     0.198171  8   \n",
       "984    0.096349  0.135951   0.227453  0.227453      0.195261     0.195261  8   \n",
       "985    0.035548  0.135382   0.192266  0.227173      0.195261     0.195261  8   \n",
       "986    0.120805  0.137043   0.187889  0.317455      0.252473     0.252473  8   \n",
       "987    0.087812  0.170517   0.256111  0.319095      0.246758     0.246758  8   \n",
       "988    0.068282  0.159604   0.133100  0.344380      0.223007     0.223007  8   \n",
       "989   -0.126392  0.165567   0.215876  0.292149      0.250323     0.250323  8   \n",
       "990    0.112911  0.137208   0.215876  0.292149      0.252473     0.252473  8   \n",
       "991    0.159031  0.160650   0.215876  0.292149      0.223853     0.223853  8   \n",
       "992    0.062770  0.158731   0.156638  0.286236      0.249481     0.249481  8   \n",
       "993    0.126939  0.152870   0.265766  0.384913      0.252473     0.252473  8   \n",
       "994    0.010317  0.190741   0.215876  0.292149      0.260788     0.260788  8   \n",
       "995    0.080438  0.168776   0.215876  0.292149      0.252473     0.252473  8   \n",
       "996    0.131887  0.145658   0.183654  0.285181      0.252705     0.252705  8   \n",
       "997    0.173604  0.158903   0.215876  0.292149      0.253566     0.253566  8   \n",
       "998    0.114776  0.150607   0.250677  0.323409      0.246901     0.246901  8   \n",
       "999   -0.023204  0.139046   0.296367  0.334677      0.301342     0.301342  8   \n",
       "1000   0.065270  0.159956   0.215876  0.292149      0.256775     0.256775  8   \n",
       "1001   0.108806  0.142730   0.187889  0.317455      0.252473     0.252473  8   \n",
       "1002   0.037090  0.150994   0.141212  0.298064      0.252473     0.252473  8   \n",
       "1003   0.104517  0.152114   0.285335  0.285335      0.252473     0.252473  8   \n",
       "1004  -0.205450  0.167269   0.215876  0.292149      0.249219     0.249219  8   \n",
       "1005   0.006411  0.152235   0.408935  0.408935      0.251960     0.239175  8   \n",
       "1006   0.107188  0.171999   0.436862  0.436862      0.315861     0.315861  8   \n",
       "1007   0.082154  0.182247   0.408935  0.408935      0.363058     0.363058  8   \n",
       "1008   0.093875  0.166726   0.408935  0.408935      0.258316     0.258316  8   \n",
       "1009   0.071305  0.172592   0.415403  0.415403      0.247913     0.247913  8   \n",
       "1010   0.134314  0.160032   0.426524  0.426524      0.258316     0.258316  8   \n",
       "1011   0.075702  0.166847   0.408935  0.408935      0.258316     0.258316  8   \n",
       "1012   0.104254  0.171504   0.407868  0.407868      0.253522     0.253522  8   \n",
       "1013   0.102818  0.173773   0.408935  0.408935      0.258316     0.258316  8   \n",
       "1014   0.115990  0.173406   0.408935  0.408935      0.258316     0.258316  8   \n",
       "1015   0.135031  0.180794   0.408935  0.408935      0.258316     0.258316  8   \n",
       "1016   0.001413  0.162499   0.408935  0.408935      0.254842     0.254842  8   \n",
       "1017   0.001413  0.162499   0.408935  0.408935      0.257937     0.257937  8   \n",
       "1018   0.046913  0.154824   0.408935  0.408935      0.257937     0.257937  8   \n",
       "1019   0.092810  0.163228   0.444893  0.432024      0.258316     0.258316  8   \n",
       "1020   0.109187  0.144058   0.408935  0.408935      0.247913     0.247913  8   \n",
       "1021   0.085201  0.181925   0.468887  0.468887      0.307925     0.307925  8   \n",
       "1022   0.142844  0.175440   0.399734  0.399734      0.258316     0.258316  8   \n",
       "1023   0.045868  0.158413   0.408935  0.408935      0.258316     0.258316  8   \n",
       "1024   0.045868  0.158413   0.408935  0.408935      0.258316     0.258316  8   \n",
       "1025   0.045868  0.158413   0.408935  0.408935      0.258316     0.258316  8   \n",
       "1026   0.045868  0.158413   0.408935  0.408935      0.258316     0.258316  8   \n",
       "1027   0.078825  0.167963   0.419030  0.419030      0.258316     0.258316  8   \n",
       "1028   0.156082  0.173182   0.408935  0.408935      0.304749     0.304749  8   \n",
       "1029   0.097325  0.168566   0.435570  0.435570      0.258316     0.258316  8   \n",
       "1030   0.111542  0.170025   0.478967  0.478967      0.201899     0.202590  8   \n",
       "1031   0.006411  0.152235   0.408935  0.408935      0.251960     0.239175  8   \n",
       "1032   0.096239  0.157541   0.408935  0.408935      0.258316     0.258316  8   \n",
       "1033   0.057466  0.154561   0.399144  0.399144      0.258316     0.258316  8   \n",
       "1034   0.092866  0.170270   0.408935  0.408935      0.258316     0.258316  8   \n",
       "1035   0.120113  0.165393   0.408935  0.408935      0.258316     0.258316  8   \n",
       "1036   0.023063  0.159879   0.501942  0.501942      0.258316     0.258316  8   \n",
       "1037   0.067362  0.150081   0.389451  0.389451      0.258316     0.258316  8   \n",
       "1038   0.032497  0.173641   0.408935  0.408935      0.246093     0.246093  8   \n",
       "1039   0.124549  0.165833   0.408935  0.408935      0.279872     0.279872  8   \n",
       "1040   0.028975  0.172320   0.408935  0.408935      0.258316     0.258316  8   \n",
       "1041   0.126363  0.170702   0.309196  0.377096      0.277300     0.277300  8   \n",
       "1042   0.120372  0.187217   0.409813  0.409813      0.258316     0.258316  8   \n",
       "1043   0.181814  0.186997   0.408935  0.408935      0.258316     0.258316  8   \n",
       "\n",
       "                          col         og_col  \n",
       "0                    playable        all_col  \n",
       "1                    aoe_bool        all_col  \n",
       "2                  aoe_radius        all_col  \n",
       "3           death_damage_bool        all_col  \n",
       "4                    fly_bool        all_col  \n",
       "5                  spawn_bool        all_col  \n",
       "6                  can_evolve        all_col  \n",
       "7                  elixircost        all_col  \n",
       "8                   hit_speed        all_col  \n",
       "9              special_damage        all_col  \n",
       "10                      count        all_col  \n",
       "11                  hitpoints        all_col  \n",
       "12                shield_bool        all_col  \n",
       "13                     damage        all_col  \n",
       "14               attack_count        all_col  \n",
       "15                      range        all_col  \n",
       "16             affected_crown        all_col  \n",
       "17               has_lifetime        all_col  \n",
       "18                  invisible        all_col  \n",
       "19                has_ability        all_col  \n",
       "20                 any_target        all_col  \n",
       "21            building_target        all_col  \n",
       "22              ground_target        all_col  \n",
       "23    has_upon_breaking_spawn        all_col  \n",
       "24       has_upon_death_spawn        all_col  \n",
       "25         has_periodic_spawn        all_col  \n",
       "26         single_damage_type        all_col  \n",
       "27                   is_troop        all_col  \n",
       "28                   is_spell        all_col  \n",
       "29                is_building        all_col  \n",
       "30             is_tower_troop        all_col  \n",
       "31                 is_spawned        all_col  \n",
       "32                      speed        all_col  \n",
       "33          has_ranged_attack        all_col  \n",
       "34        special_attack_type        all_col  \n",
       "35          has_friendly_buff        all_col  \n",
       "36               is_free_card        all_col  \n",
       "37               no_hit_speed        all_col  \n",
       "38                  no_attack        all_col  \n",
       "39               no_hitpoints        all_col  \n",
       "40          damage_per_elixir        all_col  \n",
       "41          damage_per_second        all_col  \n",
       "42              damage_output        all_col  \n",
       "43              hp_per_elixir        all_col  \n",
       "44        damage_by_hitpoints        all_col  \n",
       "45               aoe_by_range        all_col  \n",
       "46              aoe_by_damage        all_col  \n",
       "47                    win_con        all_col  \n",
       "48             aoe_per_elixir        all_col  \n",
       "49            control_special        all_col  \n",
       "50                dps_special        all_col  \n",
       "51                air_control        all_col  \n",
       "52                 ground_dps        all_col  \n",
       "53                win_con_dmg        all_col  \n",
       "54                   high_dps        all_col  \n",
       "55           damage_output_ps        all_col  \n",
       "56                    support        all_col  \n",
       "57                  mini_tank        all_col  \n",
       "58          damage_per_elixir     engineered  \n",
       "59          damage_per_second     engineered  \n",
       "60              damage_output     engineered  \n",
       "61              hp_per_elixir     engineered  \n",
       "62        damage_by_hitpoints     engineered  \n",
       "63               aoe_by_range     engineered  \n",
       "64              aoe_by_damage     engineered  \n",
       "65                   playable       original  \n",
       "66                   aoe_bool       original  \n",
       "67                 aoe_radius       original  \n",
       "68          death_damage_bool       original  \n",
       "69                   fly_bool       original  \n",
       "70                 spawn_bool       original  \n",
       "71                 can_evolve       original  \n",
       "72                 elixircost       original  \n",
       "73                  hit_speed       original  \n",
       "74             special_damage       original  \n",
       "75                      count       original  \n",
       "76                  hitpoints       original  \n",
       "77                shield_bool       original  \n",
       "78                     damage       original  \n",
       "79               attack_count       original  \n",
       "80                      range       original  \n",
       "81             affected_crown       original  \n",
       "82               has_lifetime       original  \n",
       "83                  invisible       original  \n",
       "84                has_ability       original  \n",
       "85                 any_target       original  \n",
       "86            building_target       original  \n",
       "87              ground_target       original  \n",
       "88    has_upon_breaking_spawn       original  \n",
       "89       has_upon_death_spawn       original  \n",
       "90         has_periodic_spawn       original  \n",
       "91         single_damage_type       original  \n",
       "92                   is_troop       original  \n",
       "93                   is_spell       original  \n",
       "94                is_building       original  \n",
       "95             is_tower_troop       original  \n",
       "96                 is_spawned       original  \n",
       "97                      speed       original  \n",
       "98          has_ranged_attack       original  \n",
       "99        special_attack_type       original  \n",
       "100         has_friendly_buff       original  \n",
       "101              is_free_card       original  \n",
       "102              no_hit_speed       original  \n",
       "103                 no_attack       original  \n",
       "104              no_hitpoints       original  \n",
       "105                   win_con       original  \n",
       "106            aoe_per_elixir       original  \n",
       "107           control_special       original  \n",
       "108               dps_special       original  \n",
       "109               air_control       original  \n",
       "110                ground_dps       original  \n",
       "111               win_con_dmg       original  \n",
       "112                  high_dps       original  \n",
       "113          damage_output_ps       original  \n",
       "114                   support       original  \n",
       "115                 mini_tank       original  \n",
       "116                aoe_radius   num_features  \n",
       "117                can_evolve   num_features  \n",
       "118                elixircost   num_features  \n",
       "119                 hit_speed   num_features  \n",
       "120                     count   num_features  \n",
       "121                 hitpoints   num_features  \n",
       "122                    damage   num_features  \n",
       "123              attack_count   num_features  \n",
       "124                     range   num_features  \n",
       "125                     speed   num_features  \n",
       "126         damage_per_elixir   num_features  \n",
       "127         damage_per_second   num_features  \n",
       "128             damage_output   num_features  \n",
       "129             hp_per_elixir   num_features  \n",
       "130       damage_by_hitpoints   num_features  \n",
       "131              aoe_by_range   num_features  \n",
       "132             aoe_by_damage   num_features  \n",
       "133            aoe_per_elixir   num_features  \n",
       "134          damage_output_ps   num_features  \n",
       "135                  playable  bool_features  \n",
       "136                  aoe_bool  bool_features  \n",
       "137         death_damage_bool  bool_features  \n",
       "138                  fly_bool  bool_features  \n",
       "139                spawn_bool  bool_features  \n",
       "140            special_damage  bool_features  \n",
       "141               shield_bool  bool_features  \n",
       "142            affected_crown  bool_features  \n",
       "143              has_lifetime  bool_features  \n",
       "144                 invisible  bool_features  \n",
       "145               has_ability  bool_features  \n",
       "146                any_target  bool_features  \n",
       "147           building_target  bool_features  \n",
       "148             ground_target  bool_features  \n",
       "149   has_upon_breaking_spawn  bool_features  \n",
       "150      has_upon_death_spawn  bool_features  \n",
       "151        has_periodic_spawn  bool_features  \n",
       "152        single_damage_type  bool_features  \n",
       "153                  is_troop  bool_features  \n",
       "154                  is_spell  bool_features  \n",
       "155               is_building  bool_features  \n",
       "156            is_tower_troop  bool_features  \n",
       "157                is_spawned  bool_features  \n",
       "158         has_ranged_attack  bool_features  \n",
       "159       special_attack_type  bool_features  \n",
       "160         has_friendly_buff  bool_features  \n",
       "161              is_free_card  bool_features  \n",
       "162              no_hit_speed  bool_features  \n",
       "163                 no_attack  bool_features  \n",
       "164              no_hitpoints  bool_features  \n",
       "165                   win_con  bool_features  \n",
       "166           control_special  bool_features  \n",
       "167               dps_special  bool_features  \n",
       "168               air_control  bool_features  \n",
       "169                ground_dps  bool_features  \n",
       "170               win_con_dmg  bool_features  \n",
       "171                  high_dps  bool_features  \n",
       "172                   support  bool_features  \n",
       "173                 mini_tank  bool_features  \n",
       "174                  playable        all_col  \n",
       "175                  aoe_bool        all_col  \n",
       "176                aoe_radius        all_col  \n",
       "177         death_damage_bool        all_col  \n",
       "178                  fly_bool        all_col  \n",
       "179                spawn_bool        all_col  \n",
       "180                can_evolve        all_col  \n",
       "181                elixircost        all_col  \n",
       "182                 hit_speed        all_col  \n",
       "183            special_damage        all_col  \n",
       "184                     count        all_col  \n",
       "185                 hitpoints        all_col  \n",
       "186               shield_bool        all_col  \n",
       "187                    damage        all_col  \n",
       "188              attack_count        all_col  \n",
       "189                     range        all_col  \n",
       "190            affected_crown        all_col  \n",
       "191              has_lifetime        all_col  \n",
       "192                 invisible        all_col  \n",
       "193               has_ability        all_col  \n",
       "194                any_target        all_col  \n",
       "195           building_target        all_col  \n",
       "196             ground_target        all_col  \n",
       "197   has_upon_breaking_spawn        all_col  \n",
       "198      has_upon_death_spawn        all_col  \n",
       "199        has_periodic_spawn        all_col  \n",
       "200        single_damage_type        all_col  \n",
       "201                  is_troop        all_col  \n",
       "202                  is_spell        all_col  \n",
       "203               is_building        all_col  \n",
       "204            is_tower_troop        all_col  \n",
       "205                is_spawned        all_col  \n",
       "206                     speed        all_col  \n",
       "207         has_ranged_attack        all_col  \n",
       "208       special_attack_type        all_col  \n",
       "209         has_friendly_buff        all_col  \n",
       "210              is_free_card        all_col  \n",
       "211              no_hit_speed        all_col  \n",
       "212                 no_attack        all_col  \n",
       "213              no_hitpoints        all_col  \n",
       "214         damage_per_elixir        all_col  \n",
       "215         damage_per_second        all_col  \n",
       "216             damage_output        all_col  \n",
       "217             hp_per_elixir        all_col  \n",
       "218       damage_by_hitpoints        all_col  \n",
       "219              aoe_by_range        all_col  \n",
       "220             aoe_by_damage        all_col  \n",
       "221                   win_con        all_col  \n",
       "222            aoe_per_elixir        all_col  \n",
       "223           control_special        all_col  \n",
       "224               dps_special        all_col  \n",
       "225               air_control        all_col  \n",
       "226                ground_dps        all_col  \n",
       "227               win_con_dmg        all_col  \n",
       "228                  high_dps        all_col  \n",
       "229          damage_output_ps        all_col  \n",
       "230                   support        all_col  \n",
       "231                 mini_tank        all_col  \n",
       "232         damage_per_elixir     engineered  \n",
       "233         damage_per_second     engineered  \n",
       "234             damage_output     engineered  \n",
       "235             hp_per_elixir     engineered  \n",
       "236       damage_by_hitpoints     engineered  \n",
       "237              aoe_by_range     engineered  \n",
       "238             aoe_by_damage     engineered  \n",
       "239                  playable       original  \n",
       "240                  aoe_bool       original  \n",
       "241                aoe_radius       original  \n",
       "242         death_damage_bool       original  \n",
       "243                  fly_bool       original  \n",
       "244                spawn_bool       original  \n",
       "245                can_evolve       original  \n",
       "246                elixircost       original  \n",
       "247                 hit_speed       original  \n",
       "248            special_damage       original  \n",
       "249                     count       original  \n",
       "250                 hitpoints       original  \n",
       "251               shield_bool       original  \n",
       "252                    damage       original  \n",
       "253              attack_count       original  \n",
       "254                     range       original  \n",
       "255            affected_crown       original  \n",
       "256              has_lifetime       original  \n",
       "257                 invisible       original  \n",
       "258               has_ability       original  \n",
       "259                any_target       original  \n",
       "260           building_target       original  \n",
       "261             ground_target       original  \n",
       "262   has_upon_breaking_spawn       original  \n",
       "263      has_upon_death_spawn       original  \n",
       "264        has_periodic_spawn       original  \n",
       "265        single_damage_type       original  \n",
       "266                  is_troop       original  \n",
       "267                  is_spell       original  \n",
       "268               is_building       original  \n",
       "269            is_tower_troop       original  \n",
       "270                is_spawned       original  \n",
       "271                     speed       original  \n",
       "272         has_ranged_attack       original  \n",
       "273       special_attack_type       original  \n",
       "274         has_friendly_buff       original  \n",
       "275              is_free_card       original  \n",
       "276              no_hit_speed       original  \n",
       "277                 no_attack       original  \n",
       "278              no_hitpoints       original  \n",
       "279                   win_con       original  \n",
       "280            aoe_per_elixir       original  \n",
       "281           control_special       original  \n",
       "282               dps_special       original  \n",
       "283               air_control       original  \n",
       "284                ground_dps       original  \n",
       "285               win_con_dmg       original  \n",
       "286                  high_dps       original  \n",
       "287          damage_output_ps       original  \n",
       "288                   support       original  \n",
       "289                 mini_tank       original  \n",
       "290                aoe_radius   num_features  \n",
       "291                can_evolve   num_features  \n",
       "292                elixircost   num_features  \n",
       "293                 hit_speed   num_features  \n",
       "294                     count   num_features  \n",
       "295                 hitpoints   num_features  \n",
       "296                    damage   num_features  \n",
       "297              attack_count   num_features  \n",
       "298                     range   num_features  \n",
       "299                     speed   num_features  \n",
       "300         damage_per_elixir   num_features  \n",
       "301         damage_per_second   num_features  \n",
       "302             damage_output   num_features  \n",
       "303             hp_per_elixir   num_features  \n",
       "304       damage_by_hitpoints   num_features  \n",
       "305              aoe_by_range   num_features  \n",
       "306             aoe_by_damage   num_features  \n",
       "307            aoe_per_elixir   num_features  \n",
       "308          damage_output_ps   num_features  \n",
       "309                  playable  bool_features  \n",
       "310                  aoe_bool  bool_features  \n",
       "311         death_damage_bool  bool_features  \n",
       "312                  fly_bool  bool_features  \n",
       "313                spawn_bool  bool_features  \n",
       "314            special_damage  bool_features  \n",
       "315               shield_bool  bool_features  \n",
       "316            affected_crown  bool_features  \n",
       "317              has_lifetime  bool_features  \n",
       "318                 invisible  bool_features  \n",
       "319               has_ability  bool_features  \n",
       "320                any_target  bool_features  \n",
       "321           building_target  bool_features  \n",
       "322             ground_target  bool_features  \n",
       "323   has_upon_breaking_spawn  bool_features  \n",
       "324      has_upon_death_spawn  bool_features  \n",
       "325        has_periodic_spawn  bool_features  \n",
       "326        single_damage_type  bool_features  \n",
       "327                  is_troop  bool_features  \n",
       "328                  is_spell  bool_features  \n",
       "329               is_building  bool_features  \n",
       "330            is_tower_troop  bool_features  \n",
       "331                is_spawned  bool_features  \n",
       "332         has_ranged_attack  bool_features  \n",
       "333       special_attack_type  bool_features  \n",
       "334         has_friendly_buff  bool_features  \n",
       "335              is_free_card  bool_features  \n",
       "336              no_hit_speed  bool_features  \n",
       "337                 no_attack  bool_features  \n",
       "338              no_hitpoints  bool_features  \n",
       "339                   win_con  bool_features  \n",
       "340           control_special  bool_features  \n",
       "341               dps_special  bool_features  \n",
       "342               air_control  bool_features  \n",
       "343                ground_dps  bool_features  \n",
       "344               win_con_dmg  bool_features  \n",
       "345                  high_dps  bool_features  \n",
       "346                   support  bool_features  \n",
       "347                 mini_tank  bool_features  \n",
       "348                  playable        all_col  \n",
       "349                  aoe_bool        all_col  \n",
       "350                aoe_radius        all_col  \n",
       "351         death_damage_bool        all_col  \n",
       "352                  fly_bool        all_col  \n",
       "353                spawn_bool        all_col  \n",
       "354                can_evolve        all_col  \n",
       "355                elixircost        all_col  \n",
       "356                 hit_speed        all_col  \n",
       "357            special_damage        all_col  \n",
       "358                     count        all_col  \n",
       "359                 hitpoints        all_col  \n",
       "360               shield_bool        all_col  \n",
       "361                    damage        all_col  \n",
       "362              attack_count        all_col  \n",
       "363                     range        all_col  \n",
       "364            affected_crown        all_col  \n",
       "365              has_lifetime        all_col  \n",
       "366                 invisible        all_col  \n",
       "367               has_ability        all_col  \n",
       "368                any_target        all_col  \n",
       "369           building_target        all_col  \n",
       "370             ground_target        all_col  \n",
       "371   has_upon_breaking_spawn        all_col  \n",
       "372      has_upon_death_spawn        all_col  \n",
       "373        has_periodic_spawn        all_col  \n",
       "374        single_damage_type        all_col  \n",
       "375                  is_troop        all_col  \n",
       "376                  is_spell        all_col  \n",
       "377               is_building        all_col  \n",
       "378            is_tower_troop        all_col  \n",
       "379                is_spawned        all_col  \n",
       "380                     speed        all_col  \n",
       "381         has_ranged_attack        all_col  \n",
       "382       special_attack_type        all_col  \n",
       "383         has_friendly_buff        all_col  \n",
       "384              is_free_card        all_col  \n",
       "385              no_hit_speed        all_col  \n",
       "386                 no_attack        all_col  \n",
       "387              no_hitpoints        all_col  \n",
       "388         damage_per_elixir        all_col  \n",
       "389         damage_per_second        all_col  \n",
       "390             damage_output        all_col  \n",
       "391             hp_per_elixir        all_col  \n",
       "392       damage_by_hitpoints        all_col  \n",
       "393              aoe_by_range        all_col  \n",
       "394             aoe_by_damage        all_col  \n",
       "395                   win_con        all_col  \n",
       "396            aoe_per_elixir        all_col  \n",
       "397           control_special        all_col  \n",
       "398               dps_special        all_col  \n",
       "399               air_control        all_col  \n",
       "400                ground_dps        all_col  \n",
       "401               win_con_dmg        all_col  \n",
       "402                  high_dps        all_col  \n",
       "403          damage_output_ps        all_col  \n",
       "404                   support        all_col  \n",
       "405                 mini_tank        all_col  \n",
       "406         damage_per_elixir     engineered  \n",
       "407         damage_per_second     engineered  \n",
       "408             damage_output     engineered  \n",
       "409             hp_per_elixir     engineered  \n",
       "410       damage_by_hitpoints     engineered  \n",
       "411              aoe_by_range     engineered  \n",
       "412             aoe_by_damage     engineered  \n",
       "413                  playable       original  \n",
       "414                  aoe_bool       original  \n",
       "415                aoe_radius       original  \n",
       "416         death_damage_bool       original  \n",
       "417                  fly_bool       original  \n",
       "418                spawn_bool       original  \n",
       "419                can_evolve       original  \n",
       "420                elixircost       original  \n",
       "421                 hit_speed       original  \n",
       "422            special_damage       original  \n",
       "423                     count       original  \n",
       "424                 hitpoints       original  \n",
       "425               shield_bool       original  \n",
       "426                    damage       original  \n",
       "427              attack_count       original  \n",
       "428                     range       original  \n",
       "429            affected_crown       original  \n",
       "430              has_lifetime       original  \n",
       "431                 invisible       original  \n",
       "432               has_ability       original  \n",
       "433                any_target       original  \n",
       "434           building_target       original  \n",
       "435             ground_target       original  \n",
       "436   has_upon_breaking_spawn       original  \n",
       "437      has_upon_death_spawn       original  \n",
       "438        has_periodic_spawn       original  \n",
       "439        single_damage_type       original  \n",
       "440                  is_troop       original  \n",
       "441                  is_spell       original  \n",
       "442               is_building       original  \n",
       "443            is_tower_troop       original  \n",
       "444                is_spawned       original  \n",
       "445                     speed       original  \n",
       "446         has_ranged_attack       original  \n",
       "447       special_attack_type       original  \n",
       "448         has_friendly_buff       original  \n",
       "449              is_free_card       original  \n",
       "450              no_hit_speed       original  \n",
       "451                 no_attack       original  \n",
       "452              no_hitpoints       original  \n",
       "453                   win_con       original  \n",
       "454            aoe_per_elixir       original  \n",
       "455           control_special       original  \n",
       "456               dps_special       original  \n",
       "457               air_control       original  \n",
       "458                ground_dps       original  \n",
       "459               win_con_dmg       original  \n",
       "460                  high_dps       original  \n",
       "461          damage_output_ps       original  \n",
       "462                   support       original  \n",
       "463                 mini_tank       original  \n",
       "464                aoe_radius   num_features  \n",
       "465                can_evolve   num_features  \n",
       "466                elixircost   num_features  \n",
       "467                 hit_speed   num_features  \n",
       "468                     count   num_features  \n",
       "469                 hitpoints   num_features  \n",
       "470                    damage   num_features  \n",
       "471              attack_count   num_features  \n",
       "472                     range   num_features  \n",
       "473                     speed   num_features  \n",
       "474         damage_per_elixir   num_features  \n",
       "475         damage_per_second   num_features  \n",
       "476             damage_output   num_features  \n",
       "477             hp_per_elixir   num_features  \n",
       "478       damage_by_hitpoints   num_features  \n",
       "479              aoe_by_range   num_features  \n",
       "480             aoe_by_damage   num_features  \n",
       "481            aoe_per_elixir   num_features  \n",
       "482          damage_output_ps   num_features  \n",
       "483                  playable  bool_features  \n",
       "484                  aoe_bool  bool_features  \n",
       "485         death_damage_bool  bool_features  \n",
       "486                  fly_bool  bool_features  \n",
       "487                spawn_bool  bool_features  \n",
       "488            special_damage  bool_features  \n",
       "489               shield_bool  bool_features  \n",
       "490            affected_crown  bool_features  \n",
       "491              has_lifetime  bool_features  \n",
       "492                 invisible  bool_features  \n",
       "493               has_ability  bool_features  \n",
       "494                any_target  bool_features  \n",
       "495           building_target  bool_features  \n",
       "496             ground_target  bool_features  \n",
       "497   has_upon_breaking_spawn  bool_features  \n",
       "498      has_upon_death_spawn  bool_features  \n",
       "499        has_periodic_spawn  bool_features  \n",
       "500        single_damage_type  bool_features  \n",
       "501                  is_troop  bool_features  \n",
       "502                  is_spell  bool_features  \n",
       "503               is_building  bool_features  \n",
       "504            is_tower_troop  bool_features  \n",
       "505                is_spawned  bool_features  \n",
       "506         has_ranged_attack  bool_features  \n",
       "507       special_attack_type  bool_features  \n",
       "508         has_friendly_buff  bool_features  \n",
       "509              is_free_card  bool_features  \n",
       "510              no_hit_speed  bool_features  \n",
       "511                 no_attack  bool_features  \n",
       "512              no_hitpoints  bool_features  \n",
       "513                   win_con  bool_features  \n",
       "514           control_special  bool_features  \n",
       "515               dps_special  bool_features  \n",
       "516               air_control  bool_features  \n",
       "517                ground_dps  bool_features  \n",
       "518               win_con_dmg  bool_features  \n",
       "519                  high_dps  bool_features  \n",
       "520                   support  bool_features  \n",
       "521                 mini_tank  bool_features  \n",
       "522                  playable        all_col  \n",
       "523                  aoe_bool        all_col  \n",
       "524                aoe_radius        all_col  \n",
       "525         death_damage_bool        all_col  \n",
       "526                  fly_bool        all_col  \n",
       "527                spawn_bool        all_col  \n",
       "528                can_evolve        all_col  \n",
       "529                elixircost        all_col  \n",
       "530                 hit_speed        all_col  \n",
       "531            special_damage        all_col  \n",
       "532                     count        all_col  \n",
       "533                 hitpoints        all_col  \n",
       "534               shield_bool        all_col  \n",
       "535                    damage        all_col  \n",
       "536              attack_count        all_col  \n",
       "537                     range        all_col  \n",
       "538            affected_crown        all_col  \n",
       "539              has_lifetime        all_col  \n",
       "540                 invisible        all_col  \n",
       "541               has_ability        all_col  \n",
       "542                any_target        all_col  \n",
       "543           building_target        all_col  \n",
       "544             ground_target        all_col  \n",
       "545   has_upon_breaking_spawn        all_col  \n",
       "546      has_upon_death_spawn        all_col  \n",
       "547        has_periodic_spawn        all_col  \n",
       "548        single_damage_type        all_col  \n",
       "549                  is_troop        all_col  \n",
       "550                  is_spell        all_col  \n",
       "551               is_building        all_col  \n",
       "552            is_tower_troop        all_col  \n",
       "553                is_spawned        all_col  \n",
       "554                     speed        all_col  \n",
       "555         has_ranged_attack        all_col  \n",
       "556       special_attack_type        all_col  \n",
       "557         has_friendly_buff        all_col  \n",
       "558              is_free_card        all_col  \n",
       "559              no_hit_speed        all_col  \n",
       "560                 no_attack        all_col  \n",
       "561              no_hitpoints        all_col  \n",
       "562         damage_per_elixir        all_col  \n",
       "563         damage_per_second        all_col  \n",
       "564             damage_output        all_col  \n",
       "565             hp_per_elixir        all_col  \n",
       "566       damage_by_hitpoints        all_col  \n",
       "567              aoe_by_range        all_col  \n",
       "568             aoe_by_damage        all_col  \n",
       "569                   win_con        all_col  \n",
       "570            aoe_per_elixir        all_col  \n",
       "571           control_special        all_col  \n",
       "572               dps_special        all_col  \n",
       "573               air_control        all_col  \n",
       "574                ground_dps        all_col  \n",
       "575               win_con_dmg        all_col  \n",
       "576                  high_dps        all_col  \n",
       "577          damage_output_ps        all_col  \n",
       "578                   support        all_col  \n",
       "579                 mini_tank        all_col  \n",
       "580         damage_per_elixir     engineered  \n",
       "581         damage_per_second     engineered  \n",
       "582             damage_output     engineered  \n",
       "583             hp_per_elixir     engineered  \n",
       "584       damage_by_hitpoints     engineered  \n",
       "585              aoe_by_range     engineered  \n",
       "586             aoe_by_damage     engineered  \n",
       "587                  playable       original  \n",
       "588                  aoe_bool       original  \n",
       "589                aoe_radius       original  \n",
       "590         death_damage_bool       original  \n",
       "591                  fly_bool       original  \n",
       "592                spawn_bool       original  \n",
       "593                can_evolve       original  \n",
       "594                elixircost       original  \n",
       "595                 hit_speed       original  \n",
       "596            special_damage       original  \n",
       "597                     count       original  \n",
       "598                 hitpoints       original  \n",
       "599               shield_bool       original  \n",
       "600                    damage       original  \n",
       "601              attack_count       original  \n",
       "602                     range       original  \n",
       "603            affected_crown       original  \n",
       "604              has_lifetime       original  \n",
       "605                 invisible       original  \n",
       "606               has_ability       original  \n",
       "607                any_target       original  \n",
       "608           building_target       original  \n",
       "609             ground_target       original  \n",
       "610   has_upon_breaking_spawn       original  \n",
       "611      has_upon_death_spawn       original  \n",
       "612        has_periodic_spawn       original  \n",
       "613        single_damage_type       original  \n",
       "614                  is_troop       original  \n",
       "615                  is_spell       original  \n",
       "616               is_building       original  \n",
       "617            is_tower_troop       original  \n",
       "618                is_spawned       original  \n",
       "619                     speed       original  \n",
       "620         has_ranged_attack       original  \n",
       "621       special_attack_type       original  \n",
       "622         has_friendly_buff       original  \n",
       "623              is_free_card       original  \n",
       "624              no_hit_speed       original  \n",
       "625                 no_attack       original  \n",
       "626              no_hitpoints       original  \n",
       "627                   win_con       original  \n",
       "628            aoe_per_elixir       original  \n",
       "629           control_special       original  \n",
       "630               dps_special       original  \n",
       "631               air_control       original  \n",
       "632                ground_dps       original  \n",
       "633               win_con_dmg       original  \n",
       "634                  high_dps       original  \n",
       "635          damage_output_ps       original  \n",
       "636                   support       original  \n",
       "637                 mini_tank       original  \n",
       "638                aoe_radius   num_features  \n",
       "639                can_evolve   num_features  \n",
       "640                elixircost   num_features  \n",
       "641                 hit_speed   num_features  \n",
       "642                     count   num_features  \n",
       "643                 hitpoints   num_features  \n",
       "644                    damage   num_features  \n",
       "645              attack_count   num_features  \n",
       "646                     range   num_features  \n",
       "647                     speed   num_features  \n",
       "648         damage_per_elixir   num_features  \n",
       "649         damage_per_second   num_features  \n",
       "650             damage_output   num_features  \n",
       "651             hp_per_elixir   num_features  \n",
       "652       damage_by_hitpoints   num_features  \n",
       "653              aoe_by_range   num_features  \n",
       "654             aoe_by_damage   num_features  \n",
       "655            aoe_per_elixir   num_features  \n",
       "656          damage_output_ps   num_features  \n",
       "657                  playable  bool_features  \n",
       "658                  aoe_bool  bool_features  \n",
       "659         death_damage_bool  bool_features  \n",
       "660                  fly_bool  bool_features  \n",
       "661                spawn_bool  bool_features  \n",
       "662            special_damage  bool_features  \n",
       "663               shield_bool  bool_features  \n",
       "664            affected_crown  bool_features  \n",
       "665              has_lifetime  bool_features  \n",
       "666                 invisible  bool_features  \n",
       "667               has_ability  bool_features  \n",
       "668                any_target  bool_features  \n",
       "669           building_target  bool_features  \n",
       "670             ground_target  bool_features  \n",
       "671   has_upon_breaking_spawn  bool_features  \n",
       "672      has_upon_death_spawn  bool_features  \n",
       "673        has_periodic_spawn  bool_features  \n",
       "674        single_damage_type  bool_features  \n",
       "675                  is_troop  bool_features  \n",
       "676                  is_spell  bool_features  \n",
       "677               is_building  bool_features  \n",
       "678            is_tower_troop  bool_features  \n",
       "679                is_spawned  bool_features  \n",
       "680         has_ranged_attack  bool_features  \n",
       "681       special_attack_type  bool_features  \n",
       "682         has_friendly_buff  bool_features  \n",
       "683              is_free_card  bool_features  \n",
       "684              no_hit_speed  bool_features  \n",
       "685                 no_attack  bool_features  \n",
       "686              no_hitpoints  bool_features  \n",
       "687                   win_con  bool_features  \n",
       "688           control_special  bool_features  \n",
       "689               dps_special  bool_features  \n",
       "690               air_control  bool_features  \n",
       "691                ground_dps  bool_features  \n",
       "692               win_con_dmg  bool_features  \n",
       "693                  high_dps  bool_features  \n",
       "694                   support  bool_features  \n",
       "695                 mini_tank  bool_features  \n",
       "696                  playable        all_col  \n",
       "697                  aoe_bool        all_col  \n",
       "698                aoe_radius        all_col  \n",
       "699         death_damage_bool        all_col  \n",
       "700                  fly_bool        all_col  \n",
       "701                spawn_bool        all_col  \n",
       "702                can_evolve        all_col  \n",
       "703                elixircost        all_col  \n",
       "704                 hit_speed        all_col  \n",
       "705            special_damage        all_col  \n",
       "706                     count        all_col  \n",
       "707                 hitpoints        all_col  \n",
       "708               shield_bool        all_col  \n",
       "709                    damage        all_col  \n",
       "710              attack_count        all_col  \n",
       "711                     range        all_col  \n",
       "712            affected_crown        all_col  \n",
       "713              has_lifetime        all_col  \n",
       "714                 invisible        all_col  \n",
       "715               has_ability        all_col  \n",
       "716                any_target        all_col  \n",
       "717           building_target        all_col  \n",
       "718             ground_target        all_col  \n",
       "719   has_upon_breaking_spawn        all_col  \n",
       "720      has_upon_death_spawn        all_col  \n",
       "721        has_periodic_spawn        all_col  \n",
       "722        single_damage_type        all_col  \n",
       "723                  is_troop        all_col  \n",
       "724                  is_spell        all_col  \n",
       "725               is_building        all_col  \n",
       "726            is_tower_troop        all_col  \n",
       "727                is_spawned        all_col  \n",
       "728                     speed        all_col  \n",
       "729         has_ranged_attack        all_col  \n",
       "730       special_attack_type        all_col  \n",
       "731         has_friendly_buff        all_col  \n",
       "732              is_free_card        all_col  \n",
       "733              no_hit_speed        all_col  \n",
       "734                 no_attack        all_col  \n",
       "735              no_hitpoints        all_col  \n",
       "736         damage_per_elixir        all_col  \n",
       "737         damage_per_second        all_col  \n",
       "738             damage_output        all_col  \n",
       "739             hp_per_elixir        all_col  \n",
       "740       damage_by_hitpoints        all_col  \n",
       "741              aoe_by_range        all_col  \n",
       "742             aoe_by_damage        all_col  \n",
       "743                   win_con        all_col  \n",
       "744            aoe_per_elixir        all_col  \n",
       "745           control_special        all_col  \n",
       "746               dps_special        all_col  \n",
       "747               air_control        all_col  \n",
       "748                ground_dps        all_col  \n",
       "749               win_con_dmg        all_col  \n",
       "750                  high_dps        all_col  \n",
       "751          damage_output_ps        all_col  \n",
       "752                   support        all_col  \n",
       "753                 mini_tank        all_col  \n",
       "754         damage_per_elixir     engineered  \n",
       "755         damage_per_second     engineered  \n",
       "756             damage_output     engineered  \n",
       "757             hp_per_elixir     engineered  \n",
       "758       damage_by_hitpoints     engineered  \n",
       "759              aoe_by_range     engineered  \n",
       "760             aoe_by_damage     engineered  \n",
       "761                  playable       original  \n",
       "762                  aoe_bool       original  \n",
       "763                aoe_radius       original  \n",
       "764         death_damage_bool       original  \n",
       "765                  fly_bool       original  \n",
       "766                spawn_bool       original  \n",
       "767                can_evolve       original  \n",
       "768                elixircost       original  \n",
       "769                 hit_speed       original  \n",
       "770            special_damage       original  \n",
       "771                     count       original  \n",
       "772                 hitpoints       original  \n",
       "773               shield_bool       original  \n",
       "774                    damage       original  \n",
       "775              attack_count       original  \n",
       "776                     range       original  \n",
       "777            affected_crown       original  \n",
       "778              has_lifetime       original  \n",
       "779                 invisible       original  \n",
       "780               has_ability       original  \n",
       "781                any_target       original  \n",
       "782           building_target       original  \n",
       "783             ground_target       original  \n",
       "784   has_upon_breaking_spawn       original  \n",
       "785      has_upon_death_spawn       original  \n",
       "786        has_periodic_spawn       original  \n",
       "787        single_damage_type       original  \n",
       "788                  is_troop       original  \n",
       "789                  is_spell       original  \n",
       "790               is_building       original  \n",
       "791            is_tower_troop       original  \n",
       "792                is_spawned       original  \n",
       "793                     speed       original  \n",
       "794         has_ranged_attack       original  \n",
       "795       special_attack_type       original  \n",
       "796         has_friendly_buff       original  \n",
       "797              is_free_card       original  \n",
       "798              no_hit_speed       original  \n",
       "799                 no_attack       original  \n",
       "800              no_hitpoints       original  \n",
       "801                   win_con       original  \n",
       "802            aoe_per_elixir       original  \n",
       "803           control_special       original  \n",
       "804               dps_special       original  \n",
       "805               air_control       original  \n",
       "806                ground_dps       original  \n",
       "807               win_con_dmg       original  \n",
       "808                  high_dps       original  \n",
       "809          damage_output_ps       original  \n",
       "810                   support       original  \n",
       "811                 mini_tank       original  \n",
       "812                aoe_radius   num_features  \n",
       "813                can_evolve   num_features  \n",
       "814                elixircost   num_features  \n",
       "815                 hit_speed   num_features  \n",
       "816                     count   num_features  \n",
       "817                 hitpoints   num_features  \n",
       "818                    damage   num_features  \n",
       "819              attack_count   num_features  \n",
       "820                     range   num_features  \n",
       "821                     speed   num_features  \n",
       "822         damage_per_elixir   num_features  \n",
       "823         damage_per_second   num_features  \n",
       "824             damage_output   num_features  \n",
       "825             hp_per_elixir   num_features  \n",
       "826       damage_by_hitpoints   num_features  \n",
       "827              aoe_by_range   num_features  \n",
       "828             aoe_by_damage   num_features  \n",
       "829            aoe_per_elixir   num_features  \n",
       "830          damage_output_ps   num_features  \n",
       "831                  playable  bool_features  \n",
       "832                  aoe_bool  bool_features  \n",
       "833         death_damage_bool  bool_features  \n",
       "834                  fly_bool  bool_features  \n",
       "835                spawn_bool  bool_features  \n",
       "836            special_damage  bool_features  \n",
       "837               shield_bool  bool_features  \n",
       "838            affected_crown  bool_features  \n",
       "839              has_lifetime  bool_features  \n",
       "840                 invisible  bool_features  \n",
       "841               has_ability  bool_features  \n",
       "842                any_target  bool_features  \n",
       "843           building_target  bool_features  \n",
       "844             ground_target  bool_features  \n",
       "845   has_upon_breaking_spawn  bool_features  \n",
       "846      has_upon_death_spawn  bool_features  \n",
       "847        has_periodic_spawn  bool_features  \n",
       "848        single_damage_type  bool_features  \n",
       "849                  is_troop  bool_features  \n",
       "850                  is_spell  bool_features  \n",
       "851               is_building  bool_features  \n",
       "852            is_tower_troop  bool_features  \n",
       "853                is_spawned  bool_features  \n",
       "854         has_ranged_attack  bool_features  \n",
       "855       special_attack_type  bool_features  \n",
       "856         has_friendly_buff  bool_features  \n",
       "857              is_free_card  bool_features  \n",
       "858              no_hit_speed  bool_features  \n",
       "859                 no_attack  bool_features  \n",
       "860              no_hitpoints  bool_features  \n",
       "861                   win_con  bool_features  \n",
       "862           control_special  bool_features  \n",
       "863               dps_special  bool_features  \n",
       "864               air_control  bool_features  \n",
       "865                ground_dps  bool_features  \n",
       "866               win_con_dmg  bool_features  \n",
       "867                  high_dps  bool_features  \n",
       "868                   support  bool_features  \n",
       "869                 mini_tank  bool_features  \n",
       "870                  playable        all_col  \n",
       "871                  aoe_bool        all_col  \n",
       "872                aoe_radius        all_col  \n",
       "873         death_damage_bool        all_col  \n",
       "874                  fly_bool        all_col  \n",
       "875                spawn_bool        all_col  \n",
       "876                can_evolve        all_col  \n",
       "877                elixircost        all_col  \n",
       "878                 hit_speed        all_col  \n",
       "879            special_damage        all_col  \n",
       "880                     count        all_col  \n",
       "881                 hitpoints        all_col  \n",
       "882               shield_bool        all_col  \n",
       "883                    damage        all_col  \n",
       "884              attack_count        all_col  \n",
       "885                     range        all_col  \n",
       "886            affected_crown        all_col  \n",
       "887              has_lifetime        all_col  \n",
       "888                 invisible        all_col  \n",
       "889               has_ability        all_col  \n",
       "890                any_target        all_col  \n",
       "891           building_target        all_col  \n",
       "892             ground_target        all_col  \n",
       "893   has_upon_breaking_spawn        all_col  \n",
       "894      has_upon_death_spawn        all_col  \n",
       "895        has_periodic_spawn        all_col  \n",
       "896        single_damage_type        all_col  \n",
       "897                  is_troop        all_col  \n",
       "898                  is_spell        all_col  \n",
       "899               is_building        all_col  \n",
       "900            is_tower_troop        all_col  \n",
       "901                is_spawned        all_col  \n",
       "902                     speed        all_col  \n",
       "903         has_ranged_attack        all_col  \n",
       "904       special_attack_type        all_col  \n",
       "905         has_friendly_buff        all_col  \n",
       "906              is_free_card        all_col  \n",
       "907              no_hit_speed        all_col  \n",
       "908                 no_attack        all_col  \n",
       "909              no_hitpoints        all_col  \n",
       "910         damage_per_elixir        all_col  \n",
       "911         damage_per_second        all_col  \n",
       "912             damage_output        all_col  \n",
       "913             hp_per_elixir        all_col  \n",
       "914       damage_by_hitpoints        all_col  \n",
       "915              aoe_by_range        all_col  \n",
       "916             aoe_by_damage        all_col  \n",
       "917                   win_con        all_col  \n",
       "918            aoe_per_elixir        all_col  \n",
       "919           control_special        all_col  \n",
       "920               dps_special        all_col  \n",
       "921               air_control        all_col  \n",
       "922                ground_dps        all_col  \n",
       "923               win_con_dmg        all_col  \n",
       "924                  high_dps        all_col  \n",
       "925          damage_output_ps        all_col  \n",
       "926                   support        all_col  \n",
       "927                 mini_tank        all_col  \n",
       "928         damage_per_elixir     engineered  \n",
       "929         damage_per_second     engineered  \n",
       "930             damage_output     engineered  \n",
       "931             hp_per_elixir     engineered  \n",
       "932       damage_by_hitpoints     engineered  \n",
       "933              aoe_by_range     engineered  \n",
       "934             aoe_by_damage     engineered  \n",
       "935                  playable       original  \n",
       "936                  aoe_bool       original  \n",
       "937                aoe_radius       original  \n",
       "938         death_damage_bool       original  \n",
       "939                  fly_bool       original  \n",
       "940                spawn_bool       original  \n",
       "941                can_evolve       original  \n",
       "942                elixircost       original  \n",
       "943                 hit_speed       original  \n",
       "944            special_damage       original  \n",
       "945                     count       original  \n",
       "946                 hitpoints       original  \n",
       "947               shield_bool       original  \n",
       "948                    damage       original  \n",
       "949              attack_count       original  \n",
       "950                     range       original  \n",
       "951            affected_crown       original  \n",
       "952              has_lifetime       original  \n",
       "953                 invisible       original  \n",
       "954               has_ability       original  \n",
       "955                any_target       original  \n",
       "956           building_target       original  \n",
       "957             ground_target       original  \n",
       "958   has_upon_breaking_spawn       original  \n",
       "959      has_upon_death_spawn       original  \n",
       "960        has_periodic_spawn       original  \n",
       "961        single_damage_type       original  \n",
       "962                  is_troop       original  \n",
       "963                  is_spell       original  \n",
       "964               is_building       original  \n",
       "965            is_tower_troop       original  \n",
       "966                is_spawned       original  \n",
       "967                     speed       original  \n",
       "968         has_ranged_attack       original  \n",
       "969       special_attack_type       original  \n",
       "970         has_friendly_buff       original  \n",
       "971              is_free_card       original  \n",
       "972              no_hit_speed       original  \n",
       "973                 no_attack       original  \n",
       "974              no_hitpoints       original  \n",
       "975                   win_con       original  \n",
       "976            aoe_per_elixir       original  \n",
       "977           control_special       original  \n",
       "978               dps_special       original  \n",
       "979               air_control       original  \n",
       "980                ground_dps       original  \n",
       "981               win_con_dmg       original  \n",
       "982                  high_dps       original  \n",
       "983          damage_output_ps       original  \n",
       "984                   support       original  \n",
       "985                 mini_tank       original  \n",
       "986                aoe_radius   num_features  \n",
       "987                can_evolve   num_features  \n",
       "988                elixircost   num_features  \n",
       "989                 hit_speed   num_features  \n",
       "990                     count   num_features  \n",
       "991                 hitpoints   num_features  \n",
       "992                    damage   num_features  \n",
       "993              attack_count   num_features  \n",
       "994                     range   num_features  \n",
       "995                     speed   num_features  \n",
       "996         damage_per_elixir   num_features  \n",
       "997         damage_per_second   num_features  \n",
       "998             damage_output   num_features  \n",
       "999             hp_per_elixir   num_features  \n",
       "1000      damage_by_hitpoints   num_features  \n",
       "1001             aoe_by_range   num_features  \n",
       "1002            aoe_by_damage   num_features  \n",
       "1003           aoe_per_elixir   num_features  \n",
       "1004         damage_output_ps   num_features  \n",
       "1005                 playable  bool_features  \n",
       "1006                 aoe_bool  bool_features  \n",
       "1007        death_damage_bool  bool_features  \n",
       "1008                 fly_bool  bool_features  \n",
       "1009               spawn_bool  bool_features  \n",
       "1010           special_damage  bool_features  \n",
       "1011              shield_bool  bool_features  \n",
       "1012           affected_crown  bool_features  \n",
       "1013             has_lifetime  bool_features  \n",
       "1014                invisible  bool_features  \n",
       "1015              has_ability  bool_features  \n",
       "1016               any_target  bool_features  \n",
       "1017          building_target  bool_features  \n",
       "1018            ground_target  bool_features  \n",
       "1019  has_upon_breaking_spawn  bool_features  \n",
       "1020     has_upon_death_spawn  bool_features  \n",
       "1021       has_periodic_spawn  bool_features  \n",
       "1022       single_damage_type  bool_features  \n",
       "1023                 is_troop  bool_features  \n",
       "1024                 is_spell  bool_features  \n",
       "1025              is_building  bool_features  \n",
       "1026           is_tower_troop  bool_features  \n",
       "1027               is_spawned  bool_features  \n",
       "1028        has_ranged_attack  bool_features  \n",
       "1029      special_attack_type  bool_features  \n",
       "1030        has_friendly_buff  bool_features  \n",
       "1031             is_free_card  bool_features  \n",
       "1032             no_hit_speed  bool_features  \n",
       "1033                no_attack  bool_features  \n",
       "1034             no_hitpoints  bool_features  \n",
       "1035                  win_con  bool_features  \n",
       "1036          control_special  bool_features  \n",
       "1037              dps_special  bool_features  \n",
       "1038              air_control  bool_features  \n",
       "1039               ground_dps  bool_features  \n",
       "1040              win_con_dmg  bool_features  \n",
       "1041                 high_dps  bool_features  \n",
       "1042                  support  bool_features  \n",
       "1043                mini_tank  bool_features  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de8df116-03a4-4847-99d6-2d1cf85ef148",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d415919-7697-4a25-8bdc-08c5747c58d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "73926989-15a7-45c6-b813-d085d6f29632",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "col\n",
      "aoe_by_damage         -0.020267\n",
      "is_spawned            -0.011287\n",
      "speed                 -0.003281\n",
      "aoe_by_range          -0.003241\n",
      "special_attack_type   -0.001641\n",
      "damage_output_ps      -0.000958\n",
      "has_lifetime           0.009991\n",
      "air_control            0.010725\n",
      "ground_target          0.011816\n",
      "can_evolve             0.016588\n",
      "ground_dps             0.017981\n",
      "no_hit_speed           0.018220\n",
      "spawn_bool             0.019521\n",
      "control_special        0.022448\n",
      "fly_bool               0.027837\n",
      "hit_speed              0.031415\n",
      "building_target        0.031441\n",
      "any_target             0.031441\n",
      "aoe_bool               0.032401\n",
      "is_free_card           0.033195\n",
      "Name: gmm_troop, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "troop_impact = (\n",
    "    sim[sim['K'].isin([6, 7])]\n",
    "    .groupby('col')['gmm_troop']\n",
    "    .mean()\n",
    "    .sort_values()\n",
    ")\n",
    "print(troop_impact.head(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "83ba0a69-af2d-4c8a-b3f3-e81872d6f407",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "col\n",
      "can_evolve                 0.117799\n",
      "has_upon_breaking_spawn    0.157633\n",
      "no_attack                  0.160526\n",
      "win_con_dmg                0.161814\n",
      "ground_target              0.161814\n",
      "ground_dps                 0.161814\n",
      "fly_bool                   0.161814\n",
      "win_con                    0.161814\n",
      "has_ranged_attack          0.161814\n",
      "death_damage_bool          0.161814\n",
      "has_upon_death_spawn       0.161814\n",
      "invisible                  0.161814\n",
      "is_building                0.161814\n",
      "is_free_card               0.161814\n",
      "is_spell                   0.161814\n",
      "is_tower_troop             0.161814\n",
      "is_troop                   0.161814\n",
      "building_target            0.161814\n",
      "mini_tank                  0.161814\n",
      "no_hit_speed               0.161814\n",
      "Name: gmm_spell, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "spell_impact = (\n",
    "    sim[sim['K'].isin([3, 4])]\n",
    "    .groupby('col')['gmm_spell']\n",
    "    .mean()\n",
    "    .sort_values()\n",
    ")\n",
    "print(spell_impact.head(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7de5753d-5ce9-45fa-a384-74faa6ec392c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "col\n",
      "can_evolve                 0.117799\n",
      "has_upon_breaking_spawn    0.157633\n",
      "no_attack                  0.160526\n",
      "win_con_dmg                0.161814\n",
      "ground_target              0.161814\n",
      "ground_dps                 0.161814\n",
      "fly_bool                   0.161814\n",
      "win_con                    0.161814\n",
      "has_ranged_attack          0.161814\n",
      "death_damage_bool          0.161814\n",
      "has_upon_death_spawn       0.161814\n",
      "invisible                  0.161814\n",
      "is_building                0.161814\n",
      "is_free_card               0.161814\n",
      "is_spell                   0.161814\n",
      "is_tower_troop             0.161814\n",
      "is_troop                   0.161814\n",
      "building_target            0.161814\n",
      "mini_tank                  0.161814\n",
      "no_hit_speed               0.161814\n",
      "Name: gmm_spell, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "building_impact = (\n",
    "    sim[sim['K'].isin([3, 4])]\n",
    "    .groupby('col')['gmm_building']\n",
    "    .mean()\n",
    "    .sort_values()\n",
    ")\n",
    "print(spell_impact.head(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "444de903-6079-4595-93a3-f1014c401c18",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.23727053784978042"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "troop_col = [\n",
    "    'elixircost',             # Cost is critical\n",
    "    'damage_per_second',      # Core damage\n",
    "    'range',                  # Ranged vs melee\n",
    "    'spawn_bool',             # Swarmers / spawners\n",
    "    'hitpoints',              # Tankiness\n",
    "    'has_ranged_attack',      # Categorical indicator\n",
    "    'aoe_bool',\n",
    "    'win_con',\n",
    "    'attack_count',\n",
    "    'has_ability',\n",
    "    'dps_special',\n",
    "]\n",
    "\n",
    "spell_features_final = [\n",
    "    'damage', 'speed', 'hit_speed', 'hitpoints', 'range', 'count',\n",
    "    'damage_output', 'aoe_per_elixir', 'damage_per_second', 'damage_by_hitpoints'\n",
    "]\n",
    "building_features_final = [\n",
    "    'damage', 'damage_output', 'damage_per_second', 'damage_by_hitpoints',\n",
    "    'hitpoints', 'hp_per_elixir', 'aoe_per_elixir', 'elixircost',\n",
    "    'spawn_bool', 'has_upon_death_spawn'\n",
    "]\n",
    "final_troop = create_clusters('troop', 8, troop_col)\n",
    "final_spell = create_clusters('spell', 3, spell_features_final)\n",
    "final_building = create_clusters('building', 4, building_features_final)\n",
    "\n",
    "def plot_feature_k_sensitivity(sim, colname, unit_type):\n",
    "    df = sim[sim['col'] == colname]\n",
    "    sns.lineplot(data=df, x='K', y=f'gmm_{unit_type}')\n",
    "    plt.title(f'Silhouette after removing {colname} ({unit_type})')\n",
    "    plt.ylim(0, 1)\n",
    "    plt.show()\n",
    "\n",
    "final_troop['sil_km']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "602f5dd5-e2d4-41d2-848a-8a84d25e7d04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster 0: 18 cards (17.82%)\n",
      "Cluster 1: 12 cards (11.88%)\n",
      "Cluster 2: 13 cards (12.87%)\n",
      "Cluster 3: 18 cards (17.82%)\n",
      "Cluster 4: 18 cards (17.82%)\n",
      "Cluster 5: 8 cards (7.92%)\n",
      "Cluster 6: 8 cards (7.92%)\n",
      "Cluster 7: 6 cards (5.94%)\n"
     ]
    }
   ],
   "source": [
    "def print_cluster_sizes(labels):\n",
    "    from collections import Counter\n",
    "    size_dict = Counter(labels)\n",
    "    total = sum(size_dict.values())\n",
    "    for k, v in sorted(size_dict.items()):\n",
    "        print(f\"Cluster {k}: {v} cards ({v/total:.2%})\")\n",
    "troop_result = create_clusters('troop', 8, troop_col)\n",
    "print_cluster_sizes(troop_result['km_labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ea61781d-f339-4de2-8589-6a27cd3c941d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Cluster 0 (18 cards):\n",
      "Archers, Cannon Cart, Dart Goblin, Electro Dragon, Electro Wizard, Flying Machine, Furnace, Inferno Dragon, Mega Minion, Minions, Mother Witch, Musketeer, Rascals, Spear Goblins, Spirit Empress (Ranged), Three Musketeers, Zappies, Rascal Girl\n",
      "\n",
      "Cluster 1 (12 cards):\n",
      "Barbarians, Bats, Electro Spirit, Goblin Gang, Goblins, Guards, Hunter, Minion Horde, Royal Recruits, Skeleton Army, Skeletons, Lava Pup\n",
      "\n",
      "Cluster 2 (13 cards):\n",
      "Elixir Golem, Hog Rider, Ice Golem, Royal Hogs, Rune Giant, Skeleton Barrel, Suspicious Bush, Wall Breakers, Cursed Hog, Elixir Blob, Elixir Golemite, Golemite, Monster\n",
      "\n",
      "Cluster 3 (18 cards):\n",
      "Balloon, Bandit, Berserker, Elite Barbarians, Fisherman, Knight, Lumberjack, Miner, Mini P.E.K.K.A, Night Witch, P.E.K.K.A, Spirit Empress (Melee), Valkyrie, Bush Goblins, Goblin Brawler, Guardienne, Reborn Phoenix, Rascal Boy\n",
      "\n",
      "Cluster 4 (18 cards):\n",
      "Baby Dragon, Battle Healer, Bomber, Executioner, Fire Spirit, Firecracker, Goblin Demolisher, Goblin Machine, Heal Spirit, Ice Spirit, Ice Wizard, Magic Archer, Princess, Royal Ghost, Skeleton Dragons, Sparky, Witch, Wizard\n",
      "\n",
      "Cluster 5 (8 cards):\n",
      "Archer Queen, Boss Bandit, Goblinstein, Golden Knight, Little Prince, Mighty Miner, Monk, Skeleton King\n",
      "\n",
      "Cluster 6 (8 cards):\n",
      "Battle Ram, Bowler, Dark Prince, Giant Skeleton, Mega Knight, Phoenix, Prince, Ram Rider\n",
      "\n",
      "Cluster 7 (6 cards):\n",
      "Electro Giant, Giant, Goblin Giant, Golem, Lava Hound, Royal Giant\n"
     ]
    }
   ],
   "source": [
    "for i, cluster in enumerate(troop_result['km_clusters']):\n",
    "    print(f\"\\nCluster {i} ({len(cluster)} cards):\")\n",
    "    print(\", \".join(cluster))  # no .values or .flatten needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0feb3b0d-17f4-48b9-9aee-8ee120842be8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Archers',\n",
       "  'Cannon Cart',\n",
       "  'Dart Goblin',\n",
       "  'Electro Dragon',\n",
       "  'Electro Wizard',\n",
       "  'Flying Machine',\n",
       "  'Furnace',\n",
       "  'Inferno Dragon',\n",
       "  'Mega Minion',\n",
       "  'Minions',\n",
       "  'Mother Witch',\n",
       "  'Musketeer',\n",
       "  'Rascals',\n",
       "  'Spear Goblins',\n",
       "  'Spirit Empress (Ranged)',\n",
       "  'Three Musketeers',\n",
       "  'Zappies',\n",
       "  'Rascal Girl'],\n",
       " ['Barbarians',\n",
       "  'Bats',\n",
       "  'Electro Spirit',\n",
       "  'Goblin Gang',\n",
       "  'Goblins',\n",
       "  'Guards',\n",
       "  'Hunter',\n",
       "  'Minion Horde',\n",
       "  'Royal Recruits',\n",
       "  'Skeleton Army',\n",
       "  'Skeletons',\n",
       "  'Lava Pup'],\n",
       " ['Elixir Golem',\n",
       "  'Hog Rider',\n",
       "  'Ice Golem',\n",
       "  'Royal Hogs',\n",
       "  'Rune Giant',\n",
       "  'Skeleton Barrel',\n",
       "  'Suspicious Bush',\n",
       "  'Wall Breakers',\n",
       "  'Cursed Hog',\n",
       "  'Elixir Blob',\n",
       "  'Elixir Golemite',\n",
       "  'Golemite',\n",
       "  'Monster'],\n",
       " ['Balloon',\n",
       "  'Bandit',\n",
       "  'Berserker',\n",
       "  'Elite Barbarians',\n",
       "  'Fisherman',\n",
       "  'Knight',\n",
       "  'Lumberjack',\n",
       "  'Miner',\n",
       "  'Mini P.E.K.K.A',\n",
       "  'Night Witch',\n",
       "  'P.E.K.K.A',\n",
       "  'Spirit Empress (Melee)',\n",
       "  'Valkyrie',\n",
       "  'Bush Goblins',\n",
       "  'Goblin Brawler',\n",
       "  'Guardienne',\n",
       "  'Reborn Phoenix',\n",
       "  'Rascal Boy'],\n",
       " ['Baby Dragon',\n",
       "  'Battle Healer',\n",
       "  'Bomber',\n",
       "  'Executioner',\n",
       "  'Fire Spirit',\n",
       "  'Firecracker',\n",
       "  'Goblin Demolisher',\n",
       "  'Goblin Machine',\n",
       "  'Heal Spirit',\n",
       "  'Ice Spirit',\n",
       "  'Ice Wizard',\n",
       "  'Magic Archer',\n",
       "  'Princess',\n",
       "  'Royal Ghost',\n",
       "  'Skeleton Dragons',\n",
       "  'Sparky',\n",
       "  'Witch',\n",
       "  'Wizard'],\n",
       " ['Archer Queen',\n",
       "  'Boss Bandit',\n",
       "  'Goblinstein',\n",
       "  'Golden Knight',\n",
       "  'Little Prince',\n",
       "  'Mighty Miner',\n",
       "  'Monk',\n",
       "  'Skeleton King'],\n",
       " ['Battle Ram',\n",
       "  'Bowler',\n",
       "  'Dark Prince',\n",
       "  'Giant Skeleton',\n",
       "  'Mega Knight',\n",
       "  'Phoenix',\n",
       "  'Prince',\n",
       "  'Ram Rider'],\n",
       " ['Electro Giant',\n",
       "  'Giant',\n",
       "  'Goblin Giant',\n",
       "  'Golem',\n",
       "  'Lava Hound',\n",
       "  'Royal Giant']]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "troop_result['km_clusters']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1df06fab-e5f1-4af9-a849-08be17acd2d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster 0: 16 cards (15.84%)\n",
      "Cluster 1: 8 cards (7.92%)\n",
      "Cluster 2: 3 cards (2.97%)\n",
      "Cluster 3: 3 cards (2.97%)\n",
      "Cluster 4: 59 cards (58.42%)\n",
      "Cluster 5: 4 cards (3.96%)\n",
      "Cluster 6: 7 cards (6.93%)\n",
      "Cluster 7: 1 cards (0.99%)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import SpectralClustering\n",
    "\n",
    "X = cards[cards['is_troop']][troop_col]\n",
    "Xs = StandardScaler().fit_transform(X)\n",
    "\n",
    "spec = SpectralClustering(n_clusters=8, assign_labels='kmeans', random_state=42)\n",
    "spec_labels = spec.fit_predict(Xs)\n",
    "\n",
    "print_cluster_sizes(spec_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4e7a8263-4081-412b-ac3d-881a35a8c5ea",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Archers',\n",
       "  'Cannon Cart',\n",
       "  'Dart Goblin',\n",
       "  'Electro Dragon',\n",
       "  'Electro Wizard',\n",
       "  'Flying Machine',\n",
       "  'Furnace',\n",
       "  'Inferno Dragon',\n",
       "  'Mega Minion',\n",
       "  'Minions',\n",
       "  'Mother Witch',\n",
       "  'Musketeer',\n",
       "  'Rascals',\n",
       "  'Spear Goblins',\n",
       "  'Spirit Empress (Ranged)',\n",
       "  'Three Musketeers',\n",
       "  'Zappies',\n",
       "  'Rascal Girl'],\n",
       " ['Barbarians',\n",
       "  'Bats',\n",
       "  'Electro Spirit',\n",
       "  'Goblin Gang',\n",
       "  'Goblins',\n",
       "  'Guards',\n",
       "  'Hunter',\n",
       "  'Minion Horde',\n",
       "  'Royal Recruits',\n",
       "  'Skeleton Army',\n",
       "  'Skeletons',\n",
       "  'Lava Pup'],\n",
       " ['Elixir Golem',\n",
       "  'Hog Rider',\n",
       "  'Ice Golem',\n",
       "  'Royal Hogs',\n",
       "  'Rune Giant',\n",
       "  'Skeleton Barrel',\n",
       "  'Suspicious Bush',\n",
       "  'Wall Breakers',\n",
       "  'Cursed Hog',\n",
       "  'Elixir Blob',\n",
       "  'Elixir Golemite',\n",
       "  'Golemite',\n",
       "  'Monster'],\n",
       " ['Balloon',\n",
       "  'Bandit',\n",
       "  'Berserker',\n",
       "  'Elite Barbarians',\n",
       "  'Fisherman',\n",
       "  'Knight',\n",
       "  'Lumberjack',\n",
       "  'Miner',\n",
       "  'Mini P.E.K.K.A',\n",
       "  'Night Witch',\n",
       "  'P.E.K.K.A',\n",
       "  'Spirit Empress (Melee)',\n",
       "  'Valkyrie',\n",
       "  'Bush Goblins',\n",
       "  'Goblin Brawler',\n",
       "  'Guardienne',\n",
       "  'Reborn Phoenix',\n",
       "  'Rascal Boy'],\n",
       " ['Baby Dragon',\n",
       "  'Battle Healer',\n",
       "  'Bomber',\n",
       "  'Executioner',\n",
       "  'Fire Spirit',\n",
       "  'Firecracker',\n",
       "  'Goblin Demolisher',\n",
       "  'Goblin Machine',\n",
       "  'Heal Spirit',\n",
       "  'Ice Spirit',\n",
       "  'Ice Wizard',\n",
       "  'Magic Archer',\n",
       "  'Princess',\n",
       "  'Royal Ghost',\n",
       "  'Skeleton Dragons',\n",
       "  'Sparky',\n",
       "  'Witch',\n",
       "  'Wizard'],\n",
       " ['Archer Queen',\n",
       "  'Boss Bandit',\n",
       "  'Goblinstein',\n",
       "  'Golden Knight',\n",
       "  'Little Prince',\n",
       "  'Mighty Miner',\n",
       "  'Monk',\n",
       "  'Skeleton King'],\n",
       " ['Battle Ram',\n",
       "  'Bowler',\n",
       "  'Dark Prince',\n",
       "  'Giant Skeleton',\n",
       "  'Mega Knight',\n",
       "  'Phoenix',\n",
       "  'Prince',\n",
       "  'Ram Rider'],\n",
       " ['Electro Giant',\n",
       "  'Giant',\n",
       "  'Goblin Giant',\n",
       "  'Golem',\n",
       "  'Lava Hound',\n",
       "  'Royal Giant']]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "troop_result['km_clusters']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "062e977b-bf3e-48eb-8924-d1f102b4848a",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_groups = {\n",
    "    'core_identity': [\n",
    "        'playable', 'is_spawned',\n",
    "        'no_hit_speed', 'no_attack', 'has_ranged_attack'\n",
    "    ],\n",
    "    'combat_core_stats': [\n",
    "        'elixircost', 'damage', 'hitpoints', 'hit_speed', 'attack_count',\n",
    "        'range', 'speed', 'count'\n",
    "    ],\n",
    "    'targeting_behavior': [\n",
    "        'any_target', 'ground_target', 'building_target'\n",
    "    ],\n",
    "    'special_attack_mechanics': [\n",
    "        'special_damage', 'special_attack_type', 'has_ranged_attack',\n",
    "        'has_ability', 'has_friendly_buff', 'invisible', 'aoe_bool'\n",
    "    ],\n",
    "    'boolean_effects_and_traits': [\n",
    "        'aoe_bool', 'death_damage_bool', 'fly_bool', 'spawn_bool', 'can_evolve',\n",
    "        'shield_bool', 'has_lifetime', 'has_upon_breaking_spawn',\n",
    "        'has_upon_death_spawn', 'has_periodic_spawn', 'single_damage_type'\n",
    "    ],\n",
    "    'engineered_features': [\n",
    "        'damage_per_elixir', 'damage_per_second', 'damage_output',\n",
    "        'hp_per_elixir', 'damage_by_hitpoints', 'aoe_by_range',\n",
    "        'aoe_by_damage', 'aoe_per_elixir', 'control_special',\n",
    "        'dps_special', 'air_control', 'ground_dps', 'damage_output_ps'\n",
    "    ],\n",
    "    'role_labels': [\n",
    "        'win_con', 'win_con_dmg', 'support', 'mini_tank', 'high_dps',\n",
    "    ],\n",
    "    \n",
    "    'highest_troop': [\n",
    "        'elixircost', 'damage_per_second',\n",
    "        'range', 'spawn_bool', 'hitpoints',\n",
    "        'has_ranged_attack', 'aoe_bool', 'win_con',\n",
    "        'attack_count', 'has_ability', 'dps_special',\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "11838180-d6ce-49ac-ad28-1293dc724fea",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (3). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (3). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (3). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (3). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (3). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (3). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (3). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (3). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (3). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (3). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (3). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (3). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (3). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (3). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (3). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (3). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (3). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (3). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (3). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (3). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (3). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (3). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (3). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (3). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (3). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (3). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (3). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (3). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (3). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (3). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (3). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (3). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (3). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (3). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (3). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (3). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (3). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (3). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (3). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (3). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (3). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (3). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (3). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (3). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (3). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (3). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (3). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (3). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (3). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (3). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (3). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (3). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (3). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (3). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (3). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (3). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (3). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (3). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (3). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (3). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (3). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (3). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (3). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (3). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (3). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (3). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (3). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (3). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (3). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (3). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (3). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (3). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (3). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (3). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (3). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (3). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (3). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (3). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (3). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (3). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (3). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (3). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (3). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (3). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (3). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (3). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (3). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (3). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (3). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (3). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (3). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (3). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (3). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (3). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (3). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (3). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (3). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (3). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (3). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (3). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (3). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (3). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (3). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (3). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (3). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (3). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (3). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (3). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (3). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (3). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (3). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (3). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (3). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (3). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (3). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (3). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (3). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (3). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (3). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (3). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (3). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (4) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (4) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (4) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (4) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (4) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (4) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (4) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (4) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (4) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (4) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (4) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (4) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (4) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (4) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (4) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (4) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (4) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (4) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (4) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (4) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (4) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (4) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (4) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (4) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (4) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (4) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (4) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (4) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (4) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (4) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (4) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (4) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (4) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (4) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (4) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (4) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (4) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (4) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (4) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (4) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (4) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (4) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (4) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (4) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (5) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (5) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (5) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (5) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (5) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (5) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (5) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (5) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (5) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (5) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (5) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (5) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (5) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (5) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (5) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (5) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (5) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (5) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (5) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (5) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (5) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (5) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (4) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (4) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (4) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (4) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (4) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (4) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (4) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (4) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (4) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (4) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (4) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (4) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (4) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (4) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (4) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (4) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (4) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (4) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (4) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (4) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (4) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (4) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (5) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (5) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (5) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (5) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (5) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (5) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (5) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (5) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (5) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (5) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (5) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (5) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (5) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (5) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (5) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (5) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (5) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (5) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (5) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (5) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (5) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (5) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (5) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (5) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (5) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (5) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (5) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (5) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (5) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (5) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (5) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (5) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (5) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (5) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (5) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (5) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (5) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (5) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (5) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (5) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (5) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (5) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (5) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (5) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (5) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (5) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (5) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (5) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (5) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (5) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (5) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (5) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (5) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (5) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (5) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (5) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (5) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (5) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (5) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (5) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (5) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (5) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (5) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (5) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (5) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (5) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (5) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (5) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (5) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (5) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (5) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (5) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (5) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (5) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (5) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (5) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (5) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (4) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (4) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (4) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (4) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (4) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (4) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (4) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (4) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (4) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (4) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (4) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (5) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (5) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (5) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (5) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (5) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (5) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (5) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (5) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (5) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (5) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (5) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (5) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (5) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (5) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (5) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (5) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (5) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (5) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (5) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (5) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (5) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (5) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (4) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (4) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (4) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (4) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (4) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (4) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (4) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (4) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (4) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (4) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (4) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (4) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (4) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (4) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (4) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (4) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (4) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (4) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (4) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (4) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (4) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (4) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (5) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (5) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (5) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (5) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (5) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (5) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (5) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (5) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (5) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (5) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (5) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (5) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (5) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (5) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (5) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (5) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (5) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (5) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (5) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (5) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (5) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (5) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (5) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (5) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (5) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (5) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (5) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (5) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (5) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (5) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (5) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (5) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (5) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (6) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (6) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (6) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (6) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (6) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (6) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (6) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (6) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (6) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (6) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (6) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (5) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (5) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (5) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (5) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (5) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (5) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (5) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (5) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (5) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (5) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (5) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (6) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (6) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (6) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (6) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (6) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (6) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (6) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (6) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (6) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (6) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (6) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (5) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (5) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (5) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (5) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (5) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (5) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (5) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (5) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (5) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (5) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (5) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (5) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (5) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (5) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (5) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (5) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (5) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (5) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (5) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (5) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (5) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (5) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (6) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (6) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (6) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (6) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (6) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (6) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (6) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (6) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (6) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (6) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (6) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (5) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (5) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (5) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (5) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (5) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (5) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (5) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (5) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (5) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (5) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (5) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (6) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (6) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (6) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (6) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (6) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (6) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (6) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (6) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (6) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (6) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (6) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (6) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (6) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (6) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (6) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (6) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (6) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (6) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (6) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (6) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (6) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (6) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (4) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (4) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (4) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (4) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (4) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (4) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (4) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (4) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (4) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (4) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (4) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (7) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (7) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (7) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (7) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (7) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (7) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (7) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (7) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (7) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (7) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (7) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (5) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (5) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (5) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (5) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (5) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (5) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (5) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (5) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (5) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (5) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (5) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (5) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (5) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (5) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (5) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (5) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (5) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (5) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (5) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (5) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (5) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (5) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (4) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (4) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (4) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (4) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (4) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (4) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (4) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (4) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (4) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (4) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (4) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (7) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (7) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (7) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (7) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (7) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (7) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (7) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (7) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (7) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (7) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (7) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (4) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (4) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (4) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (4) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (4) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (4) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (4) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (4) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (4) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (4) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (4) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (5) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (5) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (5) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (5) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (5) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (5) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (5) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (5) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (5) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (5) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (5) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (5) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (5) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (5) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (5) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (5) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (5) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (5) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (5) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (5) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (5) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (5) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (5) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (5) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (5) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (5) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (5) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (5) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (5) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (5) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (5) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (5) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (5) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (6) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (6) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (6) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (6) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (6) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (6) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (6) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (6) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (6) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (6) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (6) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (5) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (5) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (5) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (5) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (5) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (5) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (5) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (5) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (5) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (5) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (5) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (6) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (6) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (6) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (6) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (6) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (6) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (6) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (6) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (6) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (6) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (6) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (5) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (5) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (5) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (5) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (5) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (5) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (5) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (5) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (5) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (5) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (5) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (5) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (5) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (5) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (5) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (5) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (5) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (5) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (5) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (5) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (5) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (5) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (6) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (6) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (6) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (6) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (6) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (6) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (6) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (6) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (6) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (6) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (6) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (7) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (7) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (7) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (7) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (7) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (7) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (7) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (7) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (7) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (7) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (7) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (5) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (5) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (5) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (5) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (5) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (5) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (5) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (5) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (5) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (5) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (5) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (7) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (7) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (7) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (7) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (7) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (7) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (7) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (7) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (7) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (7) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (7) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (7) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (7) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (7) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (7) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (7) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (7) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (7) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (7) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (7) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (7) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (7) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (7) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (7) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (7) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (7) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (7) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (7) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (7) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (7) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (7) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (7) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (7) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (7) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (7) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (7) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (7) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (7) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (7) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (7) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (7) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (7) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (7) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (7) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (6) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (6) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (6) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (6) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (6) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (6) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (6) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (6) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (6) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (6) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (6) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (7) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (7) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (7) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (7) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (7) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (7) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (7) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (7) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (7) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (7) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (7) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (7) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (7) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (7) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (7) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (7) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (7) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (7) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (7) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (7) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (7) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (7) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (7) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (7) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (7) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (7) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (7) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (7) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (7) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (7) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (7) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (7) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (7) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (7) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (7) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (7) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (7) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (7) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (7) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (7) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (7) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (7) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (7) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (7) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (7) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (7) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (7) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (7) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (7) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (7) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (7) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (7) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (7) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (7) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (7) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (6) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (6) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (6) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (6) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (6) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (6) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (6) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (6) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (6) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (6) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (6) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "def simulation_n(add_col=[]):\n",
    "    simulation = []\n",
    "    for k in range(3, 9):\n",
    "        for title, num_col in feature_groups.items():\n",
    "            for col in num_col:\n",
    "                test_col = num_col.copy()\n",
    "                test_col.remove(col)\n",
    "                \n",
    "            \n",
    "                sim_troop = create_clusters('troop', k, test_col + add_col)\n",
    "                sil_gmm_troop = sim_troop['sil_gmm']\n",
    "                sil_km_troop = sim_troop['sil_km']\n",
    "\n",
    "                sim_spell = create_clusters('spell', k, test_col + add_col)\n",
    "                sil_gmm_spell = sim_spell['sil_gmm']\n",
    "                sil_km_spell = sim_spell['sil_km']\n",
    "\n",
    "                sim_building = create_clusters('building', k, test_col + add_col)\n",
    "                sil_gmm_building = sim_building['sil_gmm']\n",
    "                sil_km_building = sim_building['sil_km']\n",
    "\n",
    "                simulation.append(\n",
    "                    {\n",
    "                    'gmm_troop':sil_gmm_troop, \n",
    "                    'km_troop': sil_km_troop, \n",
    "                    'gmm_spell': sil_gmm_spell, \n",
    "                    'km_spell':sil_km_spell, \n",
    "                    'gmm_building':sil_gmm_building, \n",
    "                    'km_building':sil_km_building, \n",
    "                    'K': k,\n",
    "                    'col': col,\n",
    "                    'og_col': title\n",
    "                    }\n",
    "                )\n",
    "    \n",
    "    simulation_df = pd.DataFrame(simulation)\n",
    "    \n",
    "    return simulation_df\n",
    "sim2 = simulation_n()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f5f5f577-6567-4810-a5e3-5465b2542f51",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gmm_troop</th>\n",
       "      <th>km_troop</th>\n",
       "      <th>gmm_spell</th>\n",
       "      <th>km_spell</th>\n",
       "      <th>gmm_building</th>\n",
       "      <th>km_building</th>\n",
       "      <th>K</th>\n",
       "      <th>col</th>\n",
       "      <th>og_col</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.575372</td>\n",
       "      <td>0.603388</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>0.791102</td>\n",
       "      <td>0.791102</td>\n",
       "      <td>3</td>\n",
       "      <td>playable</td>\n",
       "      <td>core_identity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.714769</td>\n",
       "      <td>0.619159</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.732222</td>\n",
       "      <td>0.732222</td>\n",
       "      <td>3</td>\n",
       "      <td>is_spawned</td>\n",
       "      <td>core_identity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.624338</td>\n",
       "      <td>0.770655</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>0.664868</td>\n",
       "      <td>0.664868</td>\n",
       "      <td>3</td>\n",
       "      <td>no_hit_speed</td>\n",
       "      <td>core_identity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.653460</td>\n",
       "      <td>0.648924</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>0.794282</td>\n",
       "      <td>0.794282</td>\n",
       "      <td>3</td>\n",
       "      <td>no_attack</td>\n",
       "      <td>core_identity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.827262</td>\n",
       "      <td>0.754081</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>0.794282</td>\n",
       "      <td>0.794282</td>\n",
       "      <td>3</td>\n",
       "      <td>has_ranged_attack</td>\n",
       "      <td>core_identity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.100138</td>\n",
       "      <td>0.243560</td>\n",
       "      <td>0.292380</td>\n",
       "      <td>0.643807</td>\n",
       "      <td>0.441692</td>\n",
       "      <td>0.441692</td>\n",
       "      <td>3</td>\n",
       "      <td>elixircost</td>\n",
       "      <td>combat_core_stats</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.197039</td>\n",
       "      <td>0.240286</td>\n",
       "      <td>0.172046</td>\n",
       "      <td>0.494932</td>\n",
       "      <td>0.157421</td>\n",
       "      <td>0.325686</td>\n",
       "      <td>3</td>\n",
       "      <td>damage</td>\n",
       "      <td>combat_core_stats</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.105611</td>\n",
       "      <td>0.220023</td>\n",
       "      <td>0.512957</td>\n",
       "      <td>0.497479</td>\n",
       "      <td>0.418001</td>\n",
       "      <td>0.418001</td>\n",
       "      <td>3</td>\n",
       "      <td>hitpoints</td>\n",
       "      <td>combat_core_stats</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.154633</td>\n",
       "      <td>0.232560</td>\n",
       "      <td>0.512957</td>\n",
       "      <td>0.497479</td>\n",
       "      <td>0.391532</td>\n",
       "      <td>0.443722</td>\n",
       "      <td>3</td>\n",
       "      <td>hit_speed</td>\n",
       "      <td>combat_core_stats</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.149723</td>\n",
       "      <td>0.227099</td>\n",
       "      <td>0.333605</td>\n",
       "      <td>0.465754</td>\n",
       "      <td>0.249178</td>\n",
       "      <td>0.362853</td>\n",
       "      <td>3</td>\n",
       "      <td>attack_count</td>\n",
       "      <td>combat_core_stats</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.169734</td>\n",
       "      <td>0.302895</td>\n",
       "      <td>0.512957</td>\n",
       "      <td>0.497479</td>\n",
       "      <td>0.271765</td>\n",
       "      <td>0.350854</td>\n",
       "      <td>3</td>\n",
       "      <td>range</td>\n",
       "      <td>combat_core_stats</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.052213</td>\n",
       "      <td>0.253891</td>\n",
       "      <td>0.512957</td>\n",
       "      <td>0.497479</td>\n",
       "      <td>0.321431</td>\n",
       "      <td>0.397378</td>\n",
       "      <td>3</td>\n",
       "      <td>speed</td>\n",
       "      <td>combat_core_stats</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.030681</td>\n",
       "      <td>0.223366</td>\n",
       "      <td>0.512957</td>\n",
       "      <td>0.497479</td>\n",
       "      <td>0.321431</td>\n",
       "      <td>0.397378</td>\n",
       "      <td>3</td>\n",
       "      <td>count</td>\n",
       "      <td>combat_core_stats</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>any_target</td>\n",
       "      <td>targeting_behavior</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>ground_target</td>\n",
       "      <td>targeting_behavior</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>building_target</td>\n",
       "      <td>targeting_behavior</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.388728</td>\n",
       "      <td>0.426589</td>\n",
       "      <td>0.778173</td>\n",
       "      <td>0.667585</td>\n",
       "      <td>0.570642</td>\n",
       "      <td>0.528489</td>\n",
       "      <td>3</td>\n",
       "      <td>special_damage</td>\n",
       "      <td>special_attack_mechanics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.499177</td>\n",
       "      <td>0.386423</td>\n",
       "      <td>0.633967</td>\n",
       "      <td>0.646138</td>\n",
       "      <td>0.550752</td>\n",
       "      <td>0.498834</td>\n",
       "      <td>3</td>\n",
       "      <td>special_attack_type</td>\n",
       "      <td>special_attack_mechanics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.454041</td>\n",
       "      <td>0.474010</td>\n",
       "      <td>0.497831</td>\n",
       "      <td>0.443093</td>\n",
       "      <td>0.587654</td>\n",
       "      <td>0.562244</td>\n",
       "      <td>3</td>\n",
       "      <td>has_ranged_attack</td>\n",
       "      <td>special_attack_mechanics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.450878</td>\n",
       "      <td>0.410077</td>\n",
       "      <td>0.497831</td>\n",
       "      <td>0.443093</td>\n",
       "      <td>0.417663</td>\n",
       "      <td>0.417663</td>\n",
       "      <td>3</td>\n",
       "      <td>has_ability</td>\n",
       "      <td>special_attack_mechanics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.371609</td>\n",
       "      <td>0.387726</td>\n",
       "      <td>0.722229</td>\n",
       "      <td>0.600958</td>\n",
       "      <td>0.529355</td>\n",
       "      <td>0.529355</td>\n",
       "      <td>3</td>\n",
       "      <td>has_friendly_buff</td>\n",
       "      <td>special_attack_mechanics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.349775</td>\n",
       "      <td>0.405287</td>\n",
       "      <td>0.497831</td>\n",
       "      <td>0.443093</td>\n",
       "      <td>0.417663</td>\n",
       "      <td>0.417663</td>\n",
       "      <td>3</td>\n",
       "      <td>invisible</td>\n",
       "      <td>special_attack_mechanics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.427953</td>\n",
       "      <td>0.449138</td>\n",
       "      <td>0.569794</td>\n",
       "      <td>0.594702</td>\n",
       "      <td>0.596046</td>\n",
       "      <td>0.596046</td>\n",
       "      <td>3</td>\n",
       "      <td>aoe_bool</td>\n",
       "      <td>special_attack_mechanics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.534952</td>\n",
       "      <td>0.516108</td>\n",
       "      <td>0.521020</td>\n",
       "      <td>0.516034</td>\n",
       "      <td>0.503921</td>\n",
       "      <td>0.513474</td>\n",
       "      <td>3</td>\n",
       "      <td>aoe_bool</td>\n",
       "      <td>boolean_effects_and_traits</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.470776</td>\n",
       "      <td>0.443525</td>\n",
       "      <td>0.449310</td>\n",
       "      <td>0.460137</td>\n",
       "      <td>0.431058</td>\n",
       "      <td>0.480580</td>\n",
       "      <td>3</td>\n",
       "      <td>death_damage_bool</td>\n",
       "      <td>boolean_effects_and_traits</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.270587</td>\n",
       "      <td>0.409476</td>\n",
       "      <td>0.449310</td>\n",
       "      <td>0.460137</td>\n",
       "      <td>0.402778</td>\n",
       "      <td>0.462231</td>\n",
       "      <td>3</td>\n",
       "      <td>fly_bool</td>\n",
       "      <td>boolean_effects_and_traits</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.449333</td>\n",
       "      <td>0.591048</td>\n",
       "      <td>0.525021</td>\n",
       "      <td>0.502748</td>\n",
       "      <td>0.341169</td>\n",
       "      <td>0.397738</td>\n",
       "      <td>3</td>\n",
       "      <td>spawn_bool</td>\n",
       "      <td>boolean_effects_and_traits</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.526738</td>\n",
       "      <td>0.510444</td>\n",
       "      <td>0.577313</td>\n",
       "      <td>0.534584</td>\n",
       "      <td>0.617879</td>\n",
       "      <td>0.602780</td>\n",
       "      <td>3</td>\n",
       "      <td>can_evolve</td>\n",
       "      <td>boolean_effects_and_traits</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.308575</td>\n",
       "      <td>0.302929</td>\n",
       "      <td>0.449310</td>\n",
       "      <td>0.460137</td>\n",
       "      <td>0.402778</td>\n",
       "      <td>0.462231</td>\n",
       "      <td>3</td>\n",
       "      <td>shield_bool</td>\n",
       "      <td>boolean_effects_and_traits</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.420208</td>\n",
       "      <td>0.471753</td>\n",
       "      <td>0.449310</td>\n",
       "      <td>0.460137</td>\n",
       "      <td>0.402778</td>\n",
       "      <td>0.462231</td>\n",
       "      <td>3</td>\n",
       "      <td>has_lifetime</td>\n",
       "      <td>boolean_effects_and_traits</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.276465</td>\n",
       "      <td>0.434946</td>\n",
       "      <td>0.445733</td>\n",
       "      <td>0.405644</td>\n",
       "      <td>0.402778</td>\n",
       "      <td>0.462231</td>\n",
       "      <td>3</td>\n",
       "      <td>has_upon_breaking_spawn</td>\n",
       "      <td>boolean_effects_and_traits</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.429582</td>\n",
       "      <td>0.410711</td>\n",
       "      <td>0.449310</td>\n",
       "      <td>0.460137</td>\n",
       "      <td>0.341169</td>\n",
       "      <td>0.397738</td>\n",
       "      <td>3</td>\n",
       "      <td>has_upon_death_spawn</td>\n",
       "      <td>boolean_effects_and_traits</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.204670</td>\n",
       "      <td>0.292103</td>\n",
       "      <td>0.491274</td>\n",
       "      <td>0.506761</td>\n",
       "      <td>0.424988</td>\n",
       "      <td>0.462053</td>\n",
       "      <td>3</td>\n",
       "      <td>has_periodic_spawn</td>\n",
       "      <td>boolean_effects_and_traits</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.464553</td>\n",
       "      <td>0.479777</td>\n",
       "      <td>0.565626</td>\n",
       "      <td>0.577650</td>\n",
       "      <td>0.450755</td>\n",
       "      <td>0.512118</td>\n",
       "      <td>3</td>\n",
       "      <td>single_damage_type</td>\n",
       "      <td>boolean_effects_and_traits</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.302721</td>\n",
       "      <td>0.225016</td>\n",
       "      <td>-0.042496</td>\n",
       "      <td>0.346045</td>\n",
       "      <td>0.378457</td>\n",
       "      <td>0.422221</td>\n",
       "      <td>3</td>\n",
       "      <td>damage_per_elixir</td>\n",
       "      <td>engineered_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.244611</td>\n",
       "      <td>0.214450</td>\n",
       "      <td>0.175815</td>\n",
       "      <td>0.331043</td>\n",
       "      <td>0.426278</td>\n",
       "      <td>0.426278</td>\n",
       "      <td>3</td>\n",
       "      <td>damage_per_second</td>\n",
       "      <td>engineered_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.171187</td>\n",
       "      <td>0.228797</td>\n",
       "      <td>0.250367</td>\n",
       "      <td>0.375498</td>\n",
       "      <td>0.419000</td>\n",
       "      <td>0.499311</td>\n",
       "      <td>3</td>\n",
       "      <td>damage_output</td>\n",
       "      <td>engineered_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.186156</td>\n",
       "      <td>0.245031</td>\n",
       "      <td>0.396275</td>\n",
       "      <td>0.412327</td>\n",
       "      <td>0.511453</td>\n",
       "      <td>0.511453</td>\n",
       "      <td>3</td>\n",
       "      <td>hp_per_elixir</td>\n",
       "      <td>engineered_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.170166</td>\n",
       "      <td>0.228821</td>\n",
       "      <td>0.175815</td>\n",
       "      <td>0.331043</td>\n",
       "      <td>0.354727</td>\n",
       "      <td>0.398938</td>\n",
       "      <td>3</td>\n",
       "      <td>damage_by_hitpoints</td>\n",
       "      <td>engineered_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0.142707</td>\n",
       "      <td>0.212078</td>\n",
       "      <td>0.397667</td>\n",
       "      <td>0.397667</td>\n",
       "      <td>0.445433</td>\n",
       "      <td>0.445433</td>\n",
       "      <td>3</td>\n",
       "      <td>aoe_by_range</td>\n",
       "      <td>engineered_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0.212108</td>\n",
       "      <td>0.218393</td>\n",
       "      <td>0.169797</td>\n",
       "      <td>0.333231</td>\n",
       "      <td>0.452672</td>\n",
       "      <td>0.452672</td>\n",
       "      <td>3</td>\n",
       "      <td>aoe_by_damage</td>\n",
       "      <td>engineered_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0.241675</td>\n",
       "      <td>0.205103</td>\n",
       "      <td>0.383570</td>\n",
       "      <td>0.383570</td>\n",
       "      <td>0.447824</td>\n",
       "      <td>0.447824</td>\n",
       "      <td>3</td>\n",
       "      <td>aoe_per_elixir</td>\n",
       "      <td>engineered_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0.165010</td>\n",
       "      <td>0.234539</td>\n",
       "      <td>0.392473</td>\n",
       "      <td>0.392473</td>\n",
       "      <td>0.384653</td>\n",
       "      <td>0.487017</td>\n",
       "      <td>3</td>\n",
       "      <td>control_special</td>\n",
       "      <td>engineered_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0.216566</td>\n",
       "      <td>0.205165</td>\n",
       "      <td>0.389247</td>\n",
       "      <td>0.389247</td>\n",
       "      <td>0.451002</td>\n",
       "      <td>0.451002</td>\n",
       "      <td>3</td>\n",
       "      <td>dps_special</td>\n",
       "      <td>engineered_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>0.222908</td>\n",
       "      <td>0.234331</td>\n",
       "      <td>0.175815</td>\n",
       "      <td>0.331043</td>\n",
       "      <td>0.394974</td>\n",
       "      <td>0.456118</td>\n",
       "      <td>3</td>\n",
       "      <td>air_control</td>\n",
       "      <td>engineered_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>0.186915</td>\n",
       "      <td>0.254735</td>\n",
       "      <td>0.175815</td>\n",
       "      <td>0.331043</td>\n",
       "      <td>0.433302</td>\n",
       "      <td>0.433302</td>\n",
       "      <td>3</td>\n",
       "      <td>ground_dps</td>\n",
       "      <td>engineered_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>0.211823</td>\n",
       "      <td>0.224194</td>\n",
       "      <td>0.175815</td>\n",
       "      <td>0.331043</td>\n",
       "      <td>0.397673</td>\n",
       "      <td>0.461428</td>\n",
       "      <td>3</td>\n",
       "      <td>damage_output_ps</td>\n",
       "      <td>engineered_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>0.605104</td>\n",
       "      <td>0.605104</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>win_con</td>\n",
       "      <td>role_labels</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>0.546726</td>\n",
       "      <td>0.546726</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>win_con_dmg</td>\n",
       "      <td>role_labels</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>0.592794</td>\n",
       "      <td>0.592794</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>support</td>\n",
       "      <td>role_labels</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>0.733210</td>\n",
       "      <td>0.733210</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>mini_tank</td>\n",
       "      <td>role_labels</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>0.746604</td>\n",
       "      <td>0.746604</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>high_dps</td>\n",
       "      <td>role_labels</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>0.220851</td>\n",
       "      <td>0.229908</td>\n",
       "      <td>0.550392</td>\n",
       "      <td>0.445714</td>\n",
       "      <td>0.419621</td>\n",
       "      <td>0.424881</td>\n",
       "      <td>3</td>\n",
       "      <td>elixircost</td>\n",
       "      <td>highest_troop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>0.204936</td>\n",
       "      <td>0.224117</td>\n",
       "      <td>0.320816</td>\n",
       "      <td>0.320816</td>\n",
       "      <td>0.109217</td>\n",
       "      <td>0.314201</td>\n",
       "      <td>3</td>\n",
       "      <td>damage_per_second</td>\n",
       "      <td>highest_troop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>0.162434</td>\n",
       "      <td>0.159455</td>\n",
       "      <td>0.320816</td>\n",
       "      <td>0.320816</td>\n",
       "      <td>0.384308</td>\n",
       "      <td>0.384308</td>\n",
       "      <td>3</td>\n",
       "      <td>range</td>\n",
       "      <td>highest_troop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>0.226611</td>\n",
       "      <td>0.228361</td>\n",
       "      <td>0.404047</td>\n",
       "      <td>0.404047</td>\n",
       "      <td>0.222257</td>\n",
       "      <td>0.382505</td>\n",
       "      <td>3</td>\n",
       "      <td>spawn_bool</td>\n",
       "      <td>highest_troop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>0.195169</td>\n",
       "      <td>0.227540</td>\n",
       "      <td>0.320816</td>\n",
       "      <td>0.320816</td>\n",
       "      <td>0.394012</td>\n",
       "      <td>0.394012</td>\n",
       "      <td>3</td>\n",
       "      <td>hitpoints</td>\n",
       "      <td>highest_troop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>0.235143</td>\n",
       "      <td>0.138090</td>\n",
       "      <td>0.320816</td>\n",
       "      <td>0.320816</td>\n",
       "      <td>0.383759</td>\n",
       "      <td>0.383759</td>\n",
       "      <td>3</td>\n",
       "      <td>has_ranged_attack</td>\n",
       "      <td>highest_troop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>0.202418</td>\n",
       "      <td>0.226154</td>\n",
       "      <td>0.403741</td>\n",
       "      <td>0.403741</td>\n",
       "      <td>0.394574</td>\n",
       "      <td>0.394574</td>\n",
       "      <td>3</td>\n",
       "      <td>aoe_bool</td>\n",
       "      <td>highest_troop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>0.226701</td>\n",
       "      <td>0.189052</td>\n",
       "      <td>0.320816</td>\n",
       "      <td>0.320816</td>\n",
       "      <td>0.386543</td>\n",
       "      <td>0.386543</td>\n",
       "      <td>3</td>\n",
       "      <td>win_con</td>\n",
       "      <td>highest_troop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>0.263489</td>\n",
       "      <td>0.223330</td>\n",
       "      <td>0.427920</td>\n",
       "      <td>0.427920</td>\n",
       "      <td>0.193182</td>\n",
       "      <td>0.381776</td>\n",
       "      <td>3</td>\n",
       "      <td>attack_count</td>\n",
       "      <td>highest_troop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>0.228465</td>\n",
       "      <td>0.224394</td>\n",
       "      <td>0.320816</td>\n",
       "      <td>0.320816</td>\n",
       "      <td>0.386543</td>\n",
       "      <td>0.386543</td>\n",
       "      <td>3</td>\n",
       "      <td>has_ability</td>\n",
       "      <td>highest_troop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>0.214026</td>\n",
       "      <td>0.214026</td>\n",
       "      <td>0.391304</td>\n",
       "      <td>0.391304</td>\n",
       "      <td>0.386543</td>\n",
       "      <td>0.386543</td>\n",
       "      <td>3</td>\n",
       "      <td>dps_special</td>\n",
       "      <td>highest_troop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>0.790331</td>\n",
       "      <td>0.790331</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>0.846154</td>\n",
       "      <td>0.846154</td>\n",
       "      <td>4</td>\n",
       "      <td>playable</td>\n",
       "      <td>core_identity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>0.793393</td>\n",
       "      <td>0.793393</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.714179</td>\n",
       "      <td>0.714179</td>\n",
       "      <td>4</td>\n",
       "      <td>is_spawned</td>\n",
       "      <td>core_identity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>0.810426</td>\n",
       "      <td>0.810426</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>0.692308</td>\n",
       "      <td>0.692308</td>\n",
       "      <td>4</td>\n",
       "      <td>no_hit_speed</td>\n",
       "      <td>core_identity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>0.802987</td>\n",
       "      <td>0.802987</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>0.846154</td>\n",
       "      <td>0.846154</td>\n",
       "      <td>4</td>\n",
       "      <td>no_attack</td>\n",
       "      <td>core_identity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>0.851404</td>\n",
       "      <td>0.851404</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>0.846154</td>\n",
       "      <td>0.846154</td>\n",
       "      <td>4</td>\n",
       "      <td>has_ranged_attack</td>\n",
       "      <td>core_identity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>0.100746</td>\n",
       "      <td>0.252706</td>\n",
       "      <td>0.427667</td>\n",
       "      <td>0.576878</td>\n",
       "      <td>0.460964</td>\n",
       "      <td>0.491134</td>\n",
       "      <td>4</td>\n",
       "      <td>elixircost</td>\n",
       "      <td>combat_core_stats</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>0.106935</td>\n",
       "      <td>0.235896</td>\n",
       "      <td>0.174960</td>\n",
       "      <td>0.441186</td>\n",
       "      <td>0.342844</td>\n",
       "      <td>0.342844</td>\n",
       "      <td>4</td>\n",
       "      <td>damage</td>\n",
       "      <td>combat_core_stats</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>0.031436</td>\n",
       "      <td>0.219981</td>\n",
       "      <td>0.206924</td>\n",
       "      <td>0.320874</td>\n",
       "      <td>0.206860</td>\n",
       "      <td>0.443607</td>\n",
       "      <td>4</td>\n",
       "      <td>hitpoints</td>\n",
       "      <td>combat_core_stats</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>0.129562</td>\n",
       "      <td>0.245161</td>\n",
       "      <td>0.206924</td>\n",
       "      <td>0.320874</td>\n",
       "      <td>0.356671</td>\n",
       "      <td>0.393559</td>\n",
       "      <td>4</td>\n",
       "      <td>hit_speed</td>\n",
       "      <td>combat_core_stats</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>0.016746</td>\n",
       "      <td>0.230048</td>\n",
       "      <td>0.148456</td>\n",
       "      <td>0.524794</td>\n",
       "      <td>0.383802</td>\n",
       "      <td>0.383802</td>\n",
       "      <td>4</td>\n",
       "      <td>attack_count</td>\n",
       "      <td>combat_core_stats</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>0.103097</td>\n",
       "      <td>0.259873</td>\n",
       "      <td>0.206924</td>\n",
       "      <td>0.320874</td>\n",
       "      <td>0.374934</td>\n",
       "      <td>0.374934</td>\n",
       "      <td>4</td>\n",
       "      <td>range</td>\n",
       "      <td>combat_core_stats</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>0.091846</td>\n",
       "      <td>0.259710</td>\n",
       "      <td>0.206924</td>\n",
       "      <td>0.320874</td>\n",
       "      <td>0.360371</td>\n",
       "      <td>0.388112</td>\n",
       "      <td>4</td>\n",
       "      <td>speed</td>\n",
       "      <td>combat_core_stats</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>0.027826</td>\n",
       "      <td>0.228192</td>\n",
       "      <td>0.206924</td>\n",
       "      <td>0.320874</td>\n",
       "      <td>0.360371</td>\n",
       "      <td>0.388112</td>\n",
       "      <td>4</td>\n",
       "      <td>count</td>\n",
       "      <td>combat_core_stats</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4</td>\n",
       "      <td>any_target</td>\n",
       "      <td>targeting_behavior</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4</td>\n",
       "      <td>ground_target</td>\n",
       "      <td>targeting_behavior</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4</td>\n",
       "      <td>building_target</td>\n",
       "      <td>targeting_behavior</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>0.443592</td>\n",
       "      <td>0.480570</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.570305</td>\n",
       "      <td>0.570305</td>\n",
       "      <td>4</td>\n",
       "      <td>special_damage</td>\n",
       "      <td>special_attack_mechanics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>0.520939</td>\n",
       "      <td>0.423573</td>\n",
       "      <td>0.841009</td>\n",
       "      <td>0.841009</td>\n",
       "      <td>0.590207</td>\n",
       "      <td>0.590207</td>\n",
       "      <td>4</td>\n",
       "      <td>special_attack_type</td>\n",
       "      <td>special_attack_mechanics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>0.499959</td>\n",
       "      <td>0.522229</td>\n",
       "      <td>0.521106</td>\n",
       "      <td>0.580786</td>\n",
       "      <td>0.712419</td>\n",
       "      <td>0.712419</td>\n",
       "      <td>4</td>\n",
       "      <td>has_ranged_attack</td>\n",
       "      <td>special_attack_mechanics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>0.428217</td>\n",
       "      <td>0.433765</td>\n",
       "      <td>0.521106</td>\n",
       "      <td>0.580786</td>\n",
       "      <td>0.458135</td>\n",
       "      <td>0.458135</td>\n",
       "      <td>4</td>\n",
       "      <td>has_ability</td>\n",
       "      <td>special_attack_mechanics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>0.462818</td>\n",
       "      <td>0.458895</td>\n",
       "      <td>0.868852</td>\n",
       "      <td>0.868852</td>\n",
       "      <td>0.757568</td>\n",
       "      <td>0.757568</td>\n",
       "      <td>4</td>\n",
       "      <td>has_friendly_buff</td>\n",
       "      <td>special_attack_mechanics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>0.469824</td>\n",
       "      <td>0.465355</td>\n",
       "      <td>0.521106</td>\n",
       "      <td>0.580786</td>\n",
       "      <td>0.458135</td>\n",
       "      <td>0.458135</td>\n",
       "      <td>4</td>\n",
       "      <td>invisible</td>\n",
       "      <td>special_attack_mechanics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>0.516474</td>\n",
       "      <td>0.511894</td>\n",
       "      <td>0.760956</td>\n",
       "      <td>0.760956</td>\n",
       "      <td>0.680645</td>\n",
       "      <td>0.680645</td>\n",
       "      <td>4</td>\n",
       "      <td>aoe_bool</td>\n",
       "      <td>special_attack_mechanics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>0.359296</td>\n",
       "      <td>0.521074</td>\n",
       "      <td>0.587524</td>\n",
       "      <td>0.570015</td>\n",
       "      <td>0.577208</td>\n",
       "      <td>0.577208</td>\n",
       "      <td>4</td>\n",
       "      <td>aoe_bool</td>\n",
       "      <td>boolean_effects_and_traits</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>0.335173</td>\n",
       "      <td>0.454982</td>\n",
       "      <td>0.470154</td>\n",
       "      <td>0.486863</td>\n",
       "      <td>0.546021</td>\n",
       "      <td>0.546021</td>\n",
       "      <td>4</td>\n",
       "      <td>death_damage_bool</td>\n",
       "      <td>boolean_effects_and_traits</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>0.372485</td>\n",
       "      <td>0.345241</td>\n",
       "      <td>0.470154</td>\n",
       "      <td>0.486863</td>\n",
       "      <td>0.466925</td>\n",
       "      <td>0.466925</td>\n",
       "      <td>4</td>\n",
       "      <td>fly_bool</td>\n",
       "      <td>boolean_effects_and_traits</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>0.361537</td>\n",
       "      <td>0.324476</td>\n",
       "      <td>0.559562</td>\n",
       "      <td>0.559562</td>\n",
       "      <td>0.418902</td>\n",
       "      <td>0.418902</td>\n",
       "      <td>4</td>\n",
       "      <td>spawn_bool</td>\n",
       "      <td>boolean_effects_and_traits</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>0.498685</td>\n",
       "      <td>0.476872</td>\n",
       "      <td>0.636966</td>\n",
       "      <td>0.636966</td>\n",
       "      <td>0.610954</td>\n",
       "      <td>0.651172</td>\n",
       "      <td>4</td>\n",
       "      <td>can_evolve</td>\n",
       "      <td>boolean_effects_and_traits</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>0.320592</td>\n",
       "      <td>0.494142</td>\n",
       "      <td>0.470154</td>\n",
       "      <td>0.486863</td>\n",
       "      <td>0.466925</td>\n",
       "      <td>0.466925</td>\n",
       "      <td>4</td>\n",
       "      <td>shield_bool</td>\n",
       "      <td>boolean_effects_and_traits</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>0.258825</td>\n",
       "      <td>0.288484</td>\n",
       "      <td>0.470154</td>\n",
       "      <td>0.486863</td>\n",
       "      <td>0.466925</td>\n",
       "      <td>0.466925</td>\n",
       "      <td>4</td>\n",
       "      <td>has_lifetime</td>\n",
       "      <td>boolean_effects_and_traits</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>0.311856</td>\n",
       "      <td>0.426613</td>\n",
       "      <td>0.468686</td>\n",
       "      <td>0.408515</td>\n",
       "      <td>0.466925</td>\n",
       "      <td>0.466925</td>\n",
       "      <td>4</td>\n",
       "      <td>has_upon_breaking_spawn</td>\n",
       "      <td>boolean_effects_and_traits</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>0.277882</td>\n",
       "      <td>0.256278</td>\n",
       "      <td>0.470154</td>\n",
       "      <td>0.486863</td>\n",
       "      <td>0.418902</td>\n",
       "      <td>0.418902</td>\n",
       "      <td>4</td>\n",
       "      <td>has_upon_death_spawn</td>\n",
       "      <td>boolean_effects_and_traits</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>0.204809</td>\n",
       "      <td>0.283648</td>\n",
       "      <td>0.550871</td>\n",
       "      <td>0.550871</td>\n",
       "      <td>0.496980</td>\n",
       "      <td>0.496980</td>\n",
       "      <td>4</td>\n",
       "      <td>has_periodic_spawn</td>\n",
       "      <td>boolean_effects_and_traits</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.382262</td>\n",
       "      <td>0.504642</td>\n",
       "      <td>0.573611</td>\n",
       "      <td>0.611049</td>\n",
       "      <td>0.480611</td>\n",
       "      <td>0.500930</td>\n",
       "      <td>4</td>\n",
       "      <td>single_damage_type</td>\n",
       "      <td>boolean_effects_and_traits</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>0.199513</td>\n",
       "      <td>0.205534</td>\n",
       "      <td>0.068750</td>\n",
       "      <td>0.383558</td>\n",
       "      <td>0.502972</td>\n",
       "      <td>0.502972</td>\n",
       "      <td>4</td>\n",
       "      <td>damage_per_elixir</td>\n",
       "      <td>engineered_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>0.076424</td>\n",
       "      <td>0.252438</td>\n",
       "      <td>0.291781</td>\n",
       "      <td>0.381884</td>\n",
       "      <td>0.514473</td>\n",
       "      <td>0.514473</td>\n",
       "      <td>4</td>\n",
       "      <td>damage_per_second</td>\n",
       "      <td>engineered_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>0.179359</td>\n",
       "      <td>0.267692</td>\n",
       "      <td>0.401768</td>\n",
       "      <td>0.401768</td>\n",
       "      <td>0.546118</td>\n",
       "      <td>0.546118</td>\n",
       "      <td>4</td>\n",
       "      <td>damage_output</td>\n",
       "      <td>engineered_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>0.063599</td>\n",
       "      <td>0.254426</td>\n",
       "      <td>0.465225</td>\n",
       "      <td>0.465225</td>\n",
       "      <td>0.584866</td>\n",
       "      <td>0.584866</td>\n",
       "      <td>4</td>\n",
       "      <td>hp_per_elixir</td>\n",
       "      <td>engineered_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>0.199188</td>\n",
       "      <td>0.255396</td>\n",
       "      <td>0.291781</td>\n",
       "      <td>0.381884</td>\n",
       "      <td>0.487291</td>\n",
       "      <td>0.487291</td>\n",
       "      <td>4</td>\n",
       "      <td>damage_by_hitpoints</td>\n",
       "      <td>engineered_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>0.267321</td>\n",
       "      <td>0.207927</td>\n",
       "      <td>0.348544</td>\n",
       "      <td>0.362090</td>\n",
       "      <td>0.508945</td>\n",
       "      <td>0.508945</td>\n",
       "      <td>4</td>\n",
       "      <td>aoe_by_range</td>\n",
       "      <td>engineered_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>0.031133</td>\n",
       "      <td>0.209235</td>\n",
       "      <td>0.288326</td>\n",
       "      <td>0.379620</td>\n",
       "      <td>0.516182</td>\n",
       "      <td>0.516182</td>\n",
       "      <td>4</td>\n",
       "      <td>aoe_by_damage</td>\n",
       "      <td>engineered_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>0.169216</td>\n",
       "      <td>0.226591</td>\n",
       "      <td>0.315073</td>\n",
       "      <td>0.342348</td>\n",
       "      <td>0.511333</td>\n",
       "      <td>0.511333</td>\n",
       "      <td>4</td>\n",
       "      <td>aoe_per_elixir</td>\n",
       "      <td>engineered_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>0.222424</td>\n",
       "      <td>0.233508</td>\n",
       "      <td>0.313780</td>\n",
       "      <td>0.334447</td>\n",
       "      <td>0.541246</td>\n",
       "      <td>0.541246</td>\n",
       "      <td>4</td>\n",
       "      <td>control_special</td>\n",
       "      <td>engineered_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>0.131678</td>\n",
       "      <td>0.236811</td>\n",
       "      <td>0.419998</td>\n",
       "      <td>0.419998</td>\n",
       "      <td>0.514517</td>\n",
       "      <td>0.514517</td>\n",
       "      <td>4</td>\n",
       "      <td>dps_special</td>\n",
       "      <td>engineered_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>0.250806</td>\n",
       "      <td>0.236863</td>\n",
       "      <td>0.291781</td>\n",
       "      <td>0.381884</td>\n",
       "      <td>0.557270</td>\n",
       "      <td>0.557270</td>\n",
       "      <td>4</td>\n",
       "      <td>air_control</td>\n",
       "      <td>engineered_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>0.215707</td>\n",
       "      <td>0.248365</td>\n",
       "      <td>0.291781</td>\n",
       "      <td>0.381884</td>\n",
       "      <td>0.518763</td>\n",
       "      <td>0.518763</td>\n",
       "      <td>4</td>\n",
       "      <td>ground_dps</td>\n",
       "      <td>engineered_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>0.135758</td>\n",
       "      <td>0.272490</td>\n",
       "      <td>0.291781</td>\n",
       "      <td>0.381884</td>\n",
       "      <td>0.532339</td>\n",
       "      <td>0.532339</td>\n",
       "      <td>4</td>\n",
       "      <td>damage_output_ps</td>\n",
       "      <td>engineered_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>0.712851</td>\n",
       "      <td>0.698885</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4</td>\n",
       "      <td>win_con</td>\n",
       "      <td>role_labels</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>0.676387</td>\n",
       "      <td>0.676387</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4</td>\n",
       "      <td>win_con_dmg</td>\n",
       "      <td>role_labels</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>0.730102</td>\n",
       "      <td>0.730102</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4</td>\n",
       "      <td>support</td>\n",
       "      <td>role_labels</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>0.841795</td>\n",
       "      <td>0.841795</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4</td>\n",
       "      <td>mini_tank</td>\n",
       "      <td>role_labels</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>0.819843</td>\n",
       "      <td>0.840026</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4</td>\n",
       "      <td>high_dps</td>\n",
       "      <td>role_labels</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>0.210011</td>\n",
       "      <td>0.249336</td>\n",
       "      <td>0.602248</td>\n",
       "      <td>0.602248</td>\n",
       "      <td>0.488117</td>\n",
       "      <td>0.488117</td>\n",
       "      <td>4</td>\n",
       "      <td>elixircost</td>\n",
       "      <td>highest_troop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>0.252094</td>\n",
       "      <td>0.254964</td>\n",
       "      <td>0.384592</td>\n",
       "      <td>0.385909</td>\n",
       "      <td>0.426360</td>\n",
       "      <td>0.426360</td>\n",
       "      <td>4</td>\n",
       "      <td>damage_per_second</td>\n",
       "      <td>highest_troop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>0.200512</td>\n",
       "      <td>0.184434</td>\n",
       "      <td>0.384592</td>\n",
       "      <td>0.385909</td>\n",
       "      <td>0.419179</td>\n",
       "      <td>0.419179</td>\n",
       "      <td>4</td>\n",
       "      <td>range</td>\n",
       "      <td>highest_troop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>0.219812</td>\n",
       "      <td>0.247881</td>\n",
       "      <td>0.464056</td>\n",
       "      <td>0.464056</td>\n",
       "      <td>0.438352</td>\n",
       "      <td>0.438352</td>\n",
       "      <td>4</td>\n",
       "      <td>spawn_bool</td>\n",
       "      <td>highest_troop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>0.213078</td>\n",
       "      <td>0.224627</td>\n",
       "      <td>0.384592</td>\n",
       "      <td>0.385909</td>\n",
       "      <td>0.442664</td>\n",
       "      <td>0.442664</td>\n",
       "      <td>4</td>\n",
       "      <td>hitpoints</td>\n",
       "      <td>highest_troop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>0.167916</td>\n",
       "      <td>0.174363</td>\n",
       "      <td>0.384592</td>\n",
       "      <td>0.385909</td>\n",
       "      <td>0.438790</td>\n",
       "      <td>0.438790</td>\n",
       "      <td>4</td>\n",
       "      <td>has_ranged_attack</td>\n",
       "      <td>highest_troop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>0.249904</td>\n",
       "      <td>0.242067</td>\n",
       "      <td>0.456718</td>\n",
       "      <td>0.456718</td>\n",
       "      <td>0.250911</td>\n",
       "      <td>0.309807</td>\n",
       "      <td>4</td>\n",
       "      <td>aoe_bool</td>\n",
       "      <td>highest_troop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>0.245481</td>\n",
       "      <td>0.223107</td>\n",
       "      <td>0.384592</td>\n",
       "      <td>0.385909</td>\n",
       "      <td>0.436381</td>\n",
       "      <td>0.436381</td>\n",
       "      <td>4</td>\n",
       "      <td>win_con</td>\n",
       "      <td>highest_troop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>0.189882</td>\n",
       "      <td>0.247959</td>\n",
       "      <td>0.538438</td>\n",
       "      <td>0.538438</td>\n",
       "      <td>0.436798</td>\n",
       "      <td>0.436798</td>\n",
       "      <td>4</td>\n",
       "      <td>attack_count</td>\n",
       "      <td>highest_troop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>0.234776</td>\n",
       "      <td>0.239880</td>\n",
       "      <td>0.384592</td>\n",
       "      <td>0.385909</td>\n",
       "      <td>0.436381</td>\n",
       "      <td>0.436381</td>\n",
       "      <td>4</td>\n",
       "      <td>has_ability</td>\n",
       "      <td>highest_troop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>0.236842</td>\n",
       "      <td>0.234882</td>\n",
       "      <td>0.435613</td>\n",
       "      <td>0.443225</td>\n",
       "      <td>0.436381</td>\n",
       "      <td>0.436381</td>\n",
       "      <td>4</td>\n",
       "      <td>dps_special</td>\n",
       "      <td>highest_troop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>0.940180</td>\n",
       "      <td>0.940180</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>0.846154</td>\n",
       "      <td>0.846154</td>\n",
       "      <td>5</td>\n",
       "      <td>playable</td>\n",
       "      <td>core_identity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>0.952958</td>\n",
       "      <td>0.952958</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>5</td>\n",
       "      <td>is_spawned</td>\n",
       "      <td>core_identity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>0.918261</td>\n",
       "      <td>0.918261</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>5</td>\n",
       "      <td>no_hit_speed</td>\n",
       "      <td>core_identity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>0.898363</td>\n",
       "      <td>0.898363</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>0.846154</td>\n",
       "      <td>0.846154</td>\n",
       "      <td>5</td>\n",
       "      <td>no_attack</td>\n",
       "      <td>core_identity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>0.931576</td>\n",
       "      <td>0.931576</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>0.846154</td>\n",
       "      <td>0.846154</td>\n",
       "      <td>5</td>\n",
       "      <td>has_ranged_attack</td>\n",
       "      <td>core_identity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>0.128901</td>\n",
       "      <td>0.266414</td>\n",
       "      <td>0.292380</td>\n",
       "      <td>0.529107</td>\n",
       "      <td>0.416493</td>\n",
       "      <td>0.416493</td>\n",
       "      <td>5</td>\n",
       "      <td>elixircost</td>\n",
       "      <td>combat_core_stats</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>0.112750</td>\n",
       "      <td>0.261857</td>\n",
       "      <td>0.317923</td>\n",
       "      <td>0.555557</td>\n",
       "      <td>0.301669</td>\n",
       "      <td>0.301669</td>\n",
       "      <td>5</td>\n",
       "      <td>damage</td>\n",
       "      <td>combat_core_stats</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>0.135202</td>\n",
       "      <td>0.228326</td>\n",
       "      <td>-0.043007</td>\n",
       "      <td>0.360304</td>\n",
       "      <td>0.399086</td>\n",
       "      <td>0.418000</td>\n",
       "      <td>5</td>\n",
       "      <td>hitpoints</td>\n",
       "      <td>combat_core_stats</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>-0.056364</td>\n",
       "      <td>0.261607</td>\n",
       "      <td>-0.043007</td>\n",
       "      <td>0.360304</td>\n",
       "      <td>0.338401</td>\n",
       "      <td>0.375578</td>\n",
       "      <td>5</td>\n",
       "      <td>hit_speed</td>\n",
       "      <td>combat_core_stats</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>0.075572</td>\n",
       "      <td>0.242594</td>\n",
       "      <td>0.155673</td>\n",
       "      <td>0.573874</td>\n",
       "      <td>0.348519</td>\n",
       "      <td>0.348519</td>\n",
       "      <td>5</td>\n",
       "      <td>attack_count</td>\n",
       "      <td>combat_core_stats</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>0.167066</td>\n",
       "      <td>0.219916</td>\n",
       "      <td>-0.043007</td>\n",
       "      <td>0.360304</td>\n",
       "      <td>0.388069</td>\n",
       "      <td>0.383106</td>\n",
       "      <td>5</td>\n",
       "      <td>range</td>\n",
       "      <td>combat_core_stats</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>0.083785</td>\n",
       "      <td>0.260690</td>\n",
       "      <td>-0.043007</td>\n",
       "      <td>0.360304</td>\n",
       "      <td>0.338596</td>\n",
       "      <td>0.338596</td>\n",
       "      <td>5</td>\n",
       "      <td>speed</td>\n",
       "      <td>combat_core_stats</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>0.082473</td>\n",
       "      <td>0.228469</td>\n",
       "      <td>-0.043007</td>\n",
       "      <td>0.360304</td>\n",
       "      <td>0.338596</td>\n",
       "      <td>0.338596</td>\n",
       "      <td>5</td>\n",
       "      <td>count</td>\n",
       "      <td>combat_core_stats</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5</td>\n",
       "      <td>any_target</td>\n",
       "      <td>targeting_behavior</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5</td>\n",
       "      <td>ground_target</td>\n",
       "      <td>targeting_behavior</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5</td>\n",
       "      <td>building_target</td>\n",
       "      <td>targeting_behavior</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>0.578713</td>\n",
       "      <td>0.582444</td>\n",
       "      <td>0.904762</td>\n",
       "      <td>0.904762</td>\n",
       "      <td>0.846154</td>\n",
       "      <td>0.846154</td>\n",
       "      <td>5</td>\n",
       "      <td>special_damage</td>\n",
       "      <td>special_attack_mechanics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>0.475553</td>\n",
       "      <td>0.479470</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>0.808982</td>\n",
       "      <td>0.808982</td>\n",
       "      <td>5</td>\n",
       "      <td>special_attack_type</td>\n",
       "      <td>special_attack_mechanics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>0.576891</td>\n",
       "      <td>0.596428</td>\n",
       "      <td>0.712405</td>\n",
       "      <td>0.712405</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>5</td>\n",
       "      <td>has_ranged_attack</td>\n",
       "      <td>special_attack_mechanics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>0.501772</td>\n",
       "      <td>0.501772</td>\n",
       "      <td>0.712405</td>\n",
       "      <td>0.712405</td>\n",
       "      <td>0.680645</td>\n",
       "      <td>0.680645</td>\n",
       "      <td>5</td>\n",
       "      <td>has_ability</td>\n",
       "      <td>special_attack_mechanics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>0.505393</td>\n",
       "      <td>0.505393</td>\n",
       "      <td>0.904762</td>\n",
       "      <td>0.904762</td>\n",
       "      <td>0.846154</td>\n",
       "      <td>0.846154</td>\n",
       "      <td>5</td>\n",
       "      <td>has_friendly_buff</td>\n",
       "      <td>special_attack_mechanics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>0.508284</td>\n",
       "      <td>0.508284</td>\n",
       "      <td>0.712405</td>\n",
       "      <td>0.712405</td>\n",
       "      <td>0.680645</td>\n",
       "      <td>0.680645</td>\n",
       "      <td>5</td>\n",
       "      <td>invisible</td>\n",
       "      <td>special_attack_mechanics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>0.623537</td>\n",
       "      <td>0.592721</td>\n",
       "      <td>0.785322</td>\n",
       "      <td>0.785322</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>5</td>\n",
       "      <td>aoe_bool</td>\n",
       "      <td>special_attack_mechanics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>0.387082</td>\n",
       "      <td>0.522796</td>\n",
       "      <td>0.720473</td>\n",
       "      <td>0.720473</td>\n",
       "      <td>0.614674</td>\n",
       "      <td>0.614674</td>\n",
       "      <td>5</td>\n",
       "      <td>aoe_bool</td>\n",
       "      <td>boolean_effects_and_traits</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>0.397133</td>\n",
       "      <td>0.334914</td>\n",
       "      <td>0.530004</td>\n",
       "      <td>0.530004</td>\n",
       "      <td>0.583487</td>\n",
       "      <td>0.583487</td>\n",
       "      <td>5</td>\n",
       "      <td>death_damage_bool</td>\n",
       "      <td>boolean_effects_and_traits</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>0.469061</td>\n",
       "      <td>0.482200</td>\n",
       "      <td>0.530004</td>\n",
       "      <td>0.530004</td>\n",
       "      <td>0.497546</td>\n",
       "      <td>0.497546</td>\n",
       "      <td>5</td>\n",
       "      <td>fly_bool</td>\n",
       "      <td>boolean_effects_and_traits</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>0.338683</td>\n",
       "      <td>0.338470</td>\n",
       "      <td>0.562626</td>\n",
       "      <td>0.620820</td>\n",
       "      <td>0.424004</td>\n",
       "      <td>0.424004</td>\n",
       "      <td>5</td>\n",
       "      <td>spawn_bool</td>\n",
       "      <td>boolean_effects_and_traits</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>0.403886</td>\n",
       "      <td>0.466965</td>\n",
       "      <td>0.709792</td>\n",
       "      <td>0.709792</td>\n",
       "      <td>0.742848</td>\n",
       "      <td>0.742848</td>\n",
       "      <td>5</td>\n",
       "      <td>can_evolve</td>\n",
       "      <td>boolean_effects_and_traits</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>0.277772</td>\n",
       "      <td>0.317242</td>\n",
       "      <td>0.530004</td>\n",
       "      <td>0.530004</td>\n",
       "      <td>0.497546</td>\n",
       "      <td>0.497546</td>\n",
       "      <td>5</td>\n",
       "      <td>shield_bool</td>\n",
       "      <td>boolean_effects_and_traits</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>0.304080</td>\n",
       "      <td>0.315609</td>\n",
       "      <td>0.530004</td>\n",
       "      <td>0.530004</td>\n",
       "      <td>0.497546</td>\n",
       "      <td>0.497546</td>\n",
       "      <td>5</td>\n",
       "      <td>has_lifetime</td>\n",
       "      <td>boolean_effects_and_traits</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>0.336159</td>\n",
       "      <td>0.305168</td>\n",
       "      <td>0.521934</td>\n",
       "      <td>0.528575</td>\n",
       "      <td>0.497546</td>\n",
       "      <td>0.497546</td>\n",
       "      <td>5</td>\n",
       "      <td>has_upon_breaking_spawn</td>\n",
       "      <td>boolean_effects_and_traits</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>0.383027</td>\n",
       "      <td>0.474610</td>\n",
       "      <td>0.530004</td>\n",
       "      <td>0.530004</td>\n",
       "      <td>0.424004</td>\n",
       "      <td>0.424004</td>\n",
       "      <td>5</td>\n",
       "      <td>has_upon_death_spawn</td>\n",
       "      <td>boolean_effects_and_traits</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>0.425261</td>\n",
       "      <td>0.455366</td>\n",
       "      <td>0.691362</td>\n",
       "      <td>0.691362</td>\n",
       "      <td>0.533605</td>\n",
       "      <td>0.533605</td>\n",
       "      <td>5</td>\n",
       "      <td>has_periodic_spawn</td>\n",
       "      <td>boolean_effects_and_traits</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>0.384026</td>\n",
       "      <td>0.455226</td>\n",
       "      <td>0.662570</td>\n",
       "      <td>0.700377</td>\n",
       "      <td>0.544886</td>\n",
       "      <td>0.544886</td>\n",
       "      <td>5</td>\n",
       "      <td>single_damage_type</td>\n",
       "      <td>boolean_effects_and_traits</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>0.108164</td>\n",
       "      <td>0.226450</td>\n",
       "      <td>0.170411</td>\n",
       "      <td>0.374444</td>\n",
       "      <td>0.569133</td>\n",
       "      <td>0.569133</td>\n",
       "      <td>5</td>\n",
       "      <td>damage_per_elixir</td>\n",
       "      <td>engineered_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>0.202764</td>\n",
       "      <td>0.305047</td>\n",
       "      <td>0.363091</td>\n",
       "      <td>0.346788</td>\n",
       "      <td>0.562746</td>\n",
       "      <td>0.562746</td>\n",
       "      <td>5</td>\n",
       "      <td>damage_per_second</td>\n",
       "      <td>engineered_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>0.258611</td>\n",
       "      <td>0.238664</td>\n",
       "      <td>0.249220</td>\n",
       "      <td>0.399992</td>\n",
       "      <td>0.587710</td>\n",
       "      <td>0.587710</td>\n",
       "      <td>5</td>\n",
       "      <td>damage_output</td>\n",
       "      <td>engineered_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>0.236472</td>\n",
       "      <td>0.297664</td>\n",
       "      <td>0.257606</td>\n",
       "      <td>0.445088</td>\n",
       "      <td>0.630839</td>\n",
       "      <td>0.630839</td>\n",
       "      <td>5</td>\n",
       "      <td>hp_per_elixir</td>\n",
       "      <td>engineered_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>0.251805</td>\n",
       "      <td>0.286634</td>\n",
       "      <td>0.363091</td>\n",
       "      <td>0.346788</td>\n",
       "      <td>0.545147</td>\n",
       "      <td>0.545147</td>\n",
       "      <td>5</td>\n",
       "      <td>damage_by_hitpoints</td>\n",
       "      <td>engineered_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>0.226443</td>\n",
       "      <td>0.263067</td>\n",
       "      <td>0.372780</td>\n",
       "      <td>0.391810</td>\n",
       "      <td>0.546639</td>\n",
       "      <td>0.546639</td>\n",
       "      <td>5</td>\n",
       "      <td>aoe_by_range</td>\n",
       "      <td>engineered_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>0.140890</td>\n",
       "      <td>0.270342</td>\n",
       "      <td>0.219887</td>\n",
       "      <td>0.364006</td>\n",
       "      <td>0.554989</td>\n",
       "      <td>0.554989</td>\n",
       "      <td>5</td>\n",
       "      <td>aoe_by_damage</td>\n",
       "      <td>engineered_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>0.132144</td>\n",
       "      <td>0.252029</td>\n",
       "      <td>0.120633</td>\n",
       "      <td>0.355642</td>\n",
       "      <td>0.549771</td>\n",
       "      <td>0.549771</td>\n",
       "      <td>5</td>\n",
       "      <td>aoe_per_elixir</td>\n",
       "      <td>engineered_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.212259</td>\n",
       "      <td>0.226037</td>\n",
       "      <td>0.305058</td>\n",
       "      <td>0.328212</td>\n",
       "      <td>0.581351</td>\n",
       "      <td>0.581351</td>\n",
       "      <td>5</td>\n",
       "      <td>control_special</td>\n",
       "      <td>engineered_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>0.264305</td>\n",
       "      <td>0.267562</td>\n",
       "      <td>0.151118</td>\n",
       "      <td>0.370621</td>\n",
       "      <td>0.553619</td>\n",
       "      <td>0.553619</td>\n",
       "      <td>5</td>\n",
       "      <td>dps_special</td>\n",
       "      <td>engineered_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>0.240086</td>\n",
       "      <td>0.317453</td>\n",
       "      <td>0.363091</td>\n",
       "      <td>0.346788</td>\n",
       "      <td>0.530059</td>\n",
       "      <td>0.530059</td>\n",
       "      <td>5</td>\n",
       "      <td>air_control</td>\n",
       "      <td>engineered_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>0.239425</td>\n",
       "      <td>0.266512</td>\n",
       "      <td>0.363091</td>\n",
       "      <td>0.346788</td>\n",
       "      <td>0.537272</td>\n",
       "      <td>0.537272</td>\n",
       "      <td>5</td>\n",
       "      <td>ground_dps</td>\n",
       "      <td>engineered_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>0.211961</td>\n",
       "      <td>0.270321</td>\n",
       "      <td>0.363091</td>\n",
       "      <td>0.346788</td>\n",
       "      <td>0.571968</td>\n",
       "      <td>0.571968</td>\n",
       "      <td>5</td>\n",
       "      <td>damage_output_ps</td>\n",
       "      <td>engineered_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>0.909294</td>\n",
       "      <td>0.909294</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5</td>\n",
       "      <td>win_con</td>\n",
       "      <td>role_labels</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>0.813908</td>\n",
       "      <td>0.813908</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5</td>\n",
       "      <td>win_con_dmg</td>\n",
       "      <td>role_labels</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>0.878519</td>\n",
       "      <td>0.878519</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5</td>\n",
       "      <td>support</td>\n",
       "      <td>role_labels</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>0.989594</td>\n",
       "      <td>0.989594</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5</td>\n",
       "      <td>mini_tank</td>\n",
       "      <td>role_labels</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>0.918789</td>\n",
       "      <td>0.917980</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5</td>\n",
       "      <td>high_dps</td>\n",
       "      <td>role_labels</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>0.225655</td>\n",
       "      <td>0.258317</td>\n",
       "      <td>0.623860</td>\n",
       "      <td>0.707116</td>\n",
       "      <td>0.378626</td>\n",
       "      <td>0.378626</td>\n",
       "      <td>5</td>\n",
       "      <td>elixircost</td>\n",
       "      <td>highest_troop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>0.250832</td>\n",
       "      <td>0.254394</td>\n",
       "      <td>0.437556</td>\n",
       "      <td>0.437556</td>\n",
       "      <td>0.298579</td>\n",
       "      <td>0.353789</td>\n",
       "      <td>5</td>\n",
       "      <td>damage_per_second</td>\n",
       "      <td>highest_troop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>0.226212</td>\n",
       "      <td>0.209954</td>\n",
       "      <td>0.437556</td>\n",
       "      <td>0.437556</td>\n",
       "      <td>0.315782</td>\n",
       "      <td>0.371066</td>\n",
       "      <td>5</td>\n",
       "      <td>range</td>\n",
       "      <td>highest_troop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>0.270728</td>\n",
       "      <td>0.268611</td>\n",
       "      <td>0.277573</td>\n",
       "      <td>0.496746</td>\n",
       "      <td>0.336186</td>\n",
       "      <td>0.371261</td>\n",
       "      <td>5</td>\n",
       "      <td>spawn_bool</td>\n",
       "      <td>highest_troop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>0.190737</td>\n",
       "      <td>0.248464</td>\n",
       "      <td>0.437556</td>\n",
       "      <td>0.437556</td>\n",
       "      <td>0.271945</td>\n",
       "      <td>0.311778</td>\n",
       "      <td>5</td>\n",
       "      <td>hitpoints</td>\n",
       "      <td>highest_troop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>0.164642</td>\n",
       "      <td>0.190983</td>\n",
       "      <td>0.437556</td>\n",
       "      <td>0.437556</td>\n",
       "      <td>0.310190</td>\n",
       "      <td>0.351409</td>\n",
       "      <td>5</td>\n",
       "      <td>has_ranged_attack</td>\n",
       "      <td>highest_troop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>0.239405</td>\n",
       "      <td>0.268203</td>\n",
       "      <td>0.460031</td>\n",
       "      <td>0.510175</td>\n",
       "      <td>0.216506</td>\n",
       "      <td>0.273003</td>\n",
       "      <td>5</td>\n",
       "      <td>aoe_bool</td>\n",
       "      <td>highest_troop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>0.112362</td>\n",
       "      <td>0.234653</td>\n",
       "      <td>0.437556</td>\n",
       "      <td>0.437556</td>\n",
       "      <td>0.285347</td>\n",
       "      <td>0.339857</td>\n",
       "      <td>5</td>\n",
       "      <td>win_con</td>\n",
       "      <td>highest_troop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>0.247193</td>\n",
       "      <td>0.249768</td>\n",
       "      <td>0.633951</td>\n",
       "      <td>0.633951</td>\n",
       "      <td>0.356364</td>\n",
       "      <td>0.356364</td>\n",
       "      <td>5</td>\n",
       "      <td>attack_count</td>\n",
       "      <td>highest_troop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>0.202900</td>\n",
       "      <td>0.222124</td>\n",
       "      <td>0.437556</td>\n",
       "      <td>0.437556</td>\n",
       "      <td>0.285347</td>\n",
       "      <td>0.339857</td>\n",
       "      <td>5</td>\n",
       "      <td>has_ability</td>\n",
       "      <td>highest_troop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>0.101054</td>\n",
       "      <td>0.237499</td>\n",
       "      <td>0.503735</td>\n",
       "      <td>0.503735</td>\n",
       "      <td>0.285347</td>\n",
       "      <td>0.339857</td>\n",
       "      <td>5</td>\n",
       "      <td>dps_special</td>\n",
       "      <td>highest_troop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>0.947019</td>\n",
       "      <td>0.954092</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>0.846154</td>\n",
       "      <td>0.846154</td>\n",
       "      <td>6</td>\n",
       "      <td>playable</td>\n",
       "      <td>core_identity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>0.977233</td>\n",
       "      <td>0.977233</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>6</td>\n",
       "      <td>is_spawned</td>\n",
       "      <td>core_identity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>0.952210</td>\n",
       "      <td>0.952210</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>6</td>\n",
       "      <td>no_hit_speed</td>\n",
       "      <td>core_identity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>0.932801</td>\n",
       "      <td>0.932801</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>0.846154</td>\n",
       "      <td>0.846154</td>\n",
       "      <td>6</td>\n",
       "      <td>no_attack</td>\n",
       "      <td>core_identity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>0.974648</td>\n",
       "      <td>0.974648</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>0.846154</td>\n",
       "      <td>0.846154</td>\n",
       "      <td>6</td>\n",
       "      <td>has_ranged_attack</td>\n",
       "      <td>core_identity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>0.041270</td>\n",
       "      <td>0.264256</td>\n",
       "      <td>0.581787</td>\n",
       "      <td>0.571640</td>\n",
       "      <td>0.099219</td>\n",
       "      <td>0.444169</td>\n",
       "      <td>6</td>\n",
       "      <td>elixircost</td>\n",
       "      <td>combat_core_stats</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>0.055068</td>\n",
       "      <td>0.267818</td>\n",
       "      <td>0.499061</td>\n",
       "      <td>0.593600</td>\n",
       "      <td>-0.043084</td>\n",
       "      <td>0.326343</td>\n",
       "      <td>6</td>\n",
       "      <td>damage</td>\n",
       "      <td>combat_core_stats</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>0.104754</td>\n",
       "      <td>0.223250</td>\n",
       "      <td>0.134451</td>\n",
       "      <td>0.380204</td>\n",
       "      <td>0.192781</td>\n",
       "      <td>0.383398</td>\n",
       "      <td>6</td>\n",
       "      <td>hitpoints</td>\n",
       "      <td>combat_core_stats</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>0.081260</td>\n",
       "      <td>0.274081</td>\n",
       "      <td>0.134451</td>\n",
       "      <td>0.380204</td>\n",
       "      <td>0.331007</td>\n",
       "      <td>0.331007</td>\n",
       "      <td>6</td>\n",
       "      <td>hit_speed</td>\n",
       "      <td>combat_core_stats</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>0.070763</td>\n",
       "      <td>0.246139</td>\n",
       "      <td>0.634112</td>\n",
       "      <td>0.634112</td>\n",
       "      <td>0.350436</td>\n",
       "      <td>0.350436</td>\n",
       "      <td>6</td>\n",
       "      <td>attack_count</td>\n",
       "      <td>combat_core_stats</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>0.045242</td>\n",
       "      <td>0.216336</td>\n",
       "      <td>0.134451</td>\n",
       "      <td>0.380204</td>\n",
       "      <td>0.390133</td>\n",
       "      <td>0.390133</td>\n",
       "      <td>6</td>\n",
       "      <td>range</td>\n",
       "      <td>combat_core_stats</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>0.123497</td>\n",
       "      <td>0.250396</td>\n",
       "      <td>0.134451</td>\n",
       "      <td>0.380204</td>\n",
       "      <td>0.316557</td>\n",
       "      <td>0.326849</td>\n",
       "      <td>6</td>\n",
       "      <td>speed</td>\n",
       "      <td>combat_core_stats</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>0.106228</td>\n",
       "      <td>0.240191</td>\n",
       "      <td>0.134451</td>\n",
       "      <td>0.380204</td>\n",
       "      <td>0.316557</td>\n",
       "      <td>0.326849</td>\n",
       "      <td>6</td>\n",
       "      <td>count</td>\n",
       "      <td>combat_core_stats</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6</td>\n",
       "      <td>any_target</td>\n",
       "      <td>targeting_behavior</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6</td>\n",
       "      <td>ground_target</td>\n",
       "      <td>targeting_behavior</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6</td>\n",
       "      <td>building_target</td>\n",
       "      <td>targeting_behavior</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205</th>\n",
       "      <td>0.638490</td>\n",
       "      <td>0.624402</td>\n",
       "      <td>0.904762</td>\n",
       "      <td>0.904762</td>\n",
       "      <td>0.846154</td>\n",
       "      <td>0.846154</td>\n",
       "      <td>6</td>\n",
       "      <td>special_damage</td>\n",
       "      <td>special_attack_mechanics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206</th>\n",
       "      <td>0.593269</td>\n",
       "      <td>0.593269</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>6</td>\n",
       "      <td>special_attack_type</td>\n",
       "      <td>special_attack_mechanics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207</th>\n",
       "      <td>0.697156</td>\n",
       "      <td>0.661949</td>\n",
       "      <td>0.737703</td>\n",
       "      <td>0.737703</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>6</td>\n",
       "      <td>has_ranged_attack</td>\n",
       "      <td>special_attack_mechanics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208</th>\n",
       "      <td>0.585882</td>\n",
       "      <td>0.585882</td>\n",
       "      <td>0.737703</td>\n",
       "      <td>0.737703</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>6</td>\n",
       "      <td>has_ability</td>\n",
       "      <td>special_attack_mechanics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209</th>\n",
       "      <td>0.569162</td>\n",
       "      <td>0.594941</td>\n",
       "      <td>0.904762</td>\n",
       "      <td>0.904762</td>\n",
       "      <td>0.846154</td>\n",
       "      <td>0.846154</td>\n",
       "      <td>6</td>\n",
       "      <td>has_friendly_buff</td>\n",
       "      <td>special_attack_mechanics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210</th>\n",
       "      <td>0.593084</td>\n",
       "      <td>0.593084</td>\n",
       "      <td>0.771390</td>\n",
       "      <td>0.771390</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>6</td>\n",
       "      <td>invisible</td>\n",
       "      <td>special_attack_mechanics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211</th>\n",
       "      <td>0.630425</td>\n",
       "      <td>0.655076</td>\n",
       "      <td>0.821233</td>\n",
       "      <td>0.821233</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>6</td>\n",
       "      <td>aoe_bool</td>\n",
       "      <td>special_attack_mechanics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212</th>\n",
       "      <td>0.468334</td>\n",
       "      <td>0.537001</td>\n",
       "      <td>0.759207</td>\n",
       "      <td>0.759207</td>\n",
       "      <td>0.786401</td>\n",
       "      <td>0.786401</td>\n",
       "      <td>6</td>\n",
       "      <td>aoe_bool</td>\n",
       "      <td>boolean_effects_and_traits</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213</th>\n",
       "      <td>0.344613</td>\n",
       "      <td>0.388901</td>\n",
       "      <td>0.678677</td>\n",
       "      <td>0.678677</td>\n",
       "      <td>0.749228</td>\n",
       "      <td>0.749228</td>\n",
       "      <td>6</td>\n",
       "      <td>death_damage_bool</td>\n",
       "      <td>boolean_effects_and_traits</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214</th>\n",
       "      <td>0.438071</td>\n",
       "      <td>0.390103</td>\n",
       "      <td>0.678677</td>\n",
       "      <td>0.678677</td>\n",
       "      <td>0.537751</td>\n",
       "      <td>0.537751</td>\n",
       "      <td>6</td>\n",
       "      <td>fly_bool</td>\n",
       "      <td>boolean_effects_and_traits</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>215</th>\n",
       "      <td>0.269745</td>\n",
       "      <td>0.351471</td>\n",
       "      <td>0.798822</td>\n",
       "      <td>0.798822</td>\n",
       "      <td>0.535527</td>\n",
       "      <td>0.535527</td>\n",
       "      <td>6</td>\n",
       "      <td>spawn_bool</td>\n",
       "      <td>boolean_effects_and_traits</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216</th>\n",
       "      <td>0.431785</td>\n",
       "      <td>0.398606</td>\n",
       "      <td>0.843597</td>\n",
       "      <td>0.843597</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>6</td>\n",
       "      <td>can_evolve</td>\n",
       "      <td>boolean_effects_and_traits</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>217</th>\n",
       "      <td>0.313050</td>\n",
       "      <td>0.341137</td>\n",
       "      <td>0.678677</td>\n",
       "      <td>0.678677</td>\n",
       "      <td>0.537751</td>\n",
       "      <td>0.537751</td>\n",
       "      <td>6</td>\n",
       "      <td>shield_bool</td>\n",
       "      <td>boolean_effects_and_traits</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218</th>\n",
       "      <td>0.265737</td>\n",
       "      <td>0.359570</td>\n",
       "      <td>0.678677</td>\n",
       "      <td>0.678677</td>\n",
       "      <td>0.537751</td>\n",
       "      <td>0.537751</td>\n",
       "      <td>6</td>\n",
       "      <td>has_lifetime</td>\n",
       "      <td>boolean_effects_and_traits</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>219</th>\n",
       "      <td>0.306644</td>\n",
       "      <td>0.337373</td>\n",
       "      <td>0.694001</td>\n",
       "      <td>0.694001</td>\n",
       "      <td>0.537751</td>\n",
       "      <td>0.537751</td>\n",
       "      <td>6</td>\n",
       "      <td>has_upon_breaking_spawn</td>\n",
       "      <td>boolean_effects_and_traits</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220</th>\n",
       "      <td>0.307986</td>\n",
       "      <td>0.313715</td>\n",
       "      <td>0.678677</td>\n",
       "      <td>0.678677</td>\n",
       "      <td>0.535527</td>\n",
       "      <td>0.535527</td>\n",
       "      <td>6</td>\n",
       "      <td>has_upon_death_spawn</td>\n",
       "      <td>boolean_effects_and_traits</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221</th>\n",
       "      <td>0.345615</td>\n",
       "      <td>0.337043</td>\n",
       "      <td>0.863523</td>\n",
       "      <td>0.863523</td>\n",
       "      <td>0.674428</td>\n",
       "      <td>0.674428</td>\n",
       "      <td>6</td>\n",
       "      <td>has_periodic_spawn</td>\n",
       "      <td>boolean_effects_and_traits</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222</th>\n",
       "      <td>0.372477</td>\n",
       "      <td>0.387006</td>\n",
       "      <td>0.819497</td>\n",
       "      <td>0.819497</td>\n",
       "      <td>0.707948</td>\n",
       "      <td>0.707948</td>\n",
       "      <td>6</td>\n",
       "      <td>single_damage_type</td>\n",
       "      <td>boolean_effects_and_traits</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223</th>\n",
       "      <td>0.273261</td>\n",
       "      <td>0.290203</td>\n",
       "      <td>0.223147</td>\n",
       "      <td>0.406593</td>\n",
       "      <td>0.543459</td>\n",
       "      <td>0.543459</td>\n",
       "      <td>6</td>\n",
       "      <td>damage_per_elixir</td>\n",
       "      <td>engineered_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>224</th>\n",
       "      <td>0.222751</td>\n",
       "      <td>0.332506</td>\n",
       "      <td>0.384363</td>\n",
       "      <td>0.384363</td>\n",
       "      <td>0.535876</td>\n",
       "      <td>0.535876</td>\n",
       "      <td>6</td>\n",
       "      <td>damage_per_second</td>\n",
       "      <td>engineered_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225</th>\n",
       "      <td>0.063366</td>\n",
       "      <td>0.269288</td>\n",
       "      <td>0.339133</td>\n",
       "      <td>0.370872</td>\n",
       "      <td>0.417687</td>\n",
       "      <td>0.582416</td>\n",
       "      <td>6</td>\n",
       "      <td>damage_output</td>\n",
       "      <td>engineered_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>226</th>\n",
       "      <td>0.264207</td>\n",
       "      <td>0.325435</td>\n",
       "      <td>0.269887</td>\n",
       "      <td>0.395925</td>\n",
       "      <td>0.633168</td>\n",
       "      <td>0.633168</td>\n",
       "      <td>6</td>\n",
       "      <td>hp_per_elixir</td>\n",
       "      <td>engineered_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>227</th>\n",
       "      <td>0.260244</td>\n",
       "      <td>0.315556</td>\n",
       "      <td>0.384363</td>\n",
       "      <td>0.384363</td>\n",
       "      <td>0.520524</td>\n",
       "      <td>0.520524</td>\n",
       "      <td>6</td>\n",
       "      <td>damage_by_hitpoints</td>\n",
       "      <td>engineered_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228</th>\n",
       "      <td>0.131150</td>\n",
       "      <td>0.271503</td>\n",
       "      <td>0.363012</td>\n",
       "      <td>0.422560</td>\n",
       "      <td>0.519287</td>\n",
       "      <td>0.519287</td>\n",
       "      <td>6</td>\n",
       "      <td>aoe_by_range</td>\n",
       "      <td>engineered_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>229</th>\n",
       "      <td>0.186386</td>\n",
       "      <td>0.324226</td>\n",
       "      <td>0.279019</td>\n",
       "      <td>0.381225</td>\n",
       "      <td>0.527628</td>\n",
       "      <td>0.527628</td>\n",
       "      <td>6</td>\n",
       "      <td>aoe_by_damage</td>\n",
       "      <td>engineered_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230</th>\n",
       "      <td>0.279209</td>\n",
       "      <td>0.248412</td>\n",
       "      <td>0.368070</td>\n",
       "      <td>0.366141</td>\n",
       "      <td>0.522405</td>\n",
       "      <td>0.522405</td>\n",
       "      <td>6</td>\n",
       "      <td>aoe_per_elixir</td>\n",
       "      <td>engineered_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>231</th>\n",
       "      <td>0.140734</td>\n",
       "      <td>0.263609</td>\n",
       "      <td>0.165500</td>\n",
       "      <td>0.366711</td>\n",
       "      <td>0.495575</td>\n",
       "      <td>0.495575</td>\n",
       "      <td>6</td>\n",
       "      <td>control_special</td>\n",
       "      <td>engineered_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232</th>\n",
       "      <td>0.214840</td>\n",
       "      <td>0.273310</td>\n",
       "      <td>0.087071</td>\n",
       "      <td>0.433943</td>\n",
       "      <td>0.526282</td>\n",
       "      <td>0.526282</td>\n",
       "      <td>6</td>\n",
       "      <td>dps_special</td>\n",
       "      <td>engineered_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233</th>\n",
       "      <td>0.187081</td>\n",
       "      <td>0.277604</td>\n",
       "      <td>0.384363</td>\n",
       "      <td>0.384363</td>\n",
       "      <td>0.443765</td>\n",
       "      <td>0.443765</td>\n",
       "      <td>6</td>\n",
       "      <td>air_control</td>\n",
       "      <td>engineered_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>234</th>\n",
       "      <td>-0.043515</td>\n",
       "      <td>0.229580</td>\n",
       "      <td>0.384363</td>\n",
       "      <td>0.384363</td>\n",
       "      <td>0.518899</td>\n",
       "      <td>0.518899</td>\n",
       "      <td>6</td>\n",
       "      <td>ground_dps</td>\n",
       "      <td>engineered_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>0.235327</td>\n",
       "      <td>0.223573</td>\n",
       "      <td>0.384363</td>\n",
       "      <td>0.384363</td>\n",
       "      <td>0.570085</td>\n",
       "      <td>0.570085</td>\n",
       "      <td>6</td>\n",
       "      <td>damage_output_ps</td>\n",
       "      <td>engineered_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236</th>\n",
       "      <td>0.974202</td>\n",
       "      <td>0.974202</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6</td>\n",
       "      <td>win_con</td>\n",
       "      <td>role_labels</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237</th>\n",
       "      <td>0.858477</td>\n",
       "      <td>0.858477</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6</td>\n",
       "      <td>win_con_dmg</td>\n",
       "      <td>role_labels</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>0.933315</td>\n",
       "      <td>0.933315</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6</td>\n",
       "      <td>support</td>\n",
       "      <td>role_labels</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239</th>\n",
       "      <td>0.990099</td>\n",
       "      <td>0.990099</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6</td>\n",
       "      <td>mini_tank</td>\n",
       "      <td>role_labels</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240</th>\n",
       "      <td>0.963795</td>\n",
       "      <td>0.963795</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6</td>\n",
       "      <td>high_dps</td>\n",
       "      <td>role_labels</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>241</th>\n",
       "      <td>0.259052</td>\n",
       "      <td>0.248835</td>\n",
       "      <td>0.687331</td>\n",
       "      <td>0.687331</td>\n",
       "      <td>0.371311</td>\n",
       "      <td>0.388470</td>\n",
       "      <td>6</td>\n",
       "      <td>elixircost</td>\n",
       "      <td>highest_troop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242</th>\n",
       "      <td>0.252556</td>\n",
       "      <td>0.242026</td>\n",
       "      <td>0.436384</td>\n",
       "      <td>0.489616</td>\n",
       "      <td>0.376188</td>\n",
       "      <td>0.376188</td>\n",
       "      <td>6</td>\n",
       "      <td>damage_per_second</td>\n",
       "      <td>highest_troop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>243</th>\n",
       "      <td>0.193616</td>\n",
       "      <td>0.209171</td>\n",
       "      <td>0.436384</td>\n",
       "      <td>0.489616</td>\n",
       "      <td>0.325886</td>\n",
       "      <td>0.367608</td>\n",
       "      <td>6</td>\n",
       "      <td>range</td>\n",
       "      <td>highest_troop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244</th>\n",
       "      <td>0.234316</td>\n",
       "      <td>0.267535</td>\n",
       "      <td>0.453133</td>\n",
       "      <td>0.453133</td>\n",
       "      <td>0.343943</td>\n",
       "      <td>0.384083</td>\n",
       "      <td>6</td>\n",
       "      <td>spawn_bool</td>\n",
       "      <td>highest_troop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245</th>\n",
       "      <td>0.241932</td>\n",
       "      <td>0.239568</td>\n",
       "      <td>0.436384</td>\n",
       "      <td>0.489616</td>\n",
       "      <td>0.264493</td>\n",
       "      <td>0.290329</td>\n",
       "      <td>6</td>\n",
       "      <td>hitpoints</td>\n",
       "      <td>highest_troop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246</th>\n",
       "      <td>0.202498</td>\n",
       "      <td>0.193271</td>\n",
       "      <td>0.436384</td>\n",
       "      <td>0.489616</td>\n",
       "      <td>0.354178</td>\n",
       "      <td>0.354178</td>\n",
       "      <td>6</td>\n",
       "      <td>has_ranged_attack</td>\n",
       "      <td>highest_troop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247</th>\n",
       "      <td>0.212991</td>\n",
       "      <td>0.279966</td>\n",
       "      <td>0.335032</td>\n",
       "      <td>0.499783</td>\n",
       "      <td>0.216560</td>\n",
       "      <td>0.279995</td>\n",
       "      <td>6</td>\n",
       "      <td>aoe_bool</td>\n",
       "      <td>highest_troop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>0.161119</td>\n",
       "      <td>0.239357</td>\n",
       "      <td>0.436384</td>\n",
       "      <td>0.489616</td>\n",
       "      <td>0.295731</td>\n",
       "      <td>0.337348</td>\n",
       "      <td>6</td>\n",
       "      <td>win_con</td>\n",
       "      <td>highest_troop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>0.246467</td>\n",
       "      <td>0.255115</td>\n",
       "      <td>0.635673</td>\n",
       "      <td>0.635673</td>\n",
       "      <td>0.287337</td>\n",
       "      <td>0.359292</td>\n",
       "      <td>6</td>\n",
       "      <td>attack_count</td>\n",
       "      <td>highest_troop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250</th>\n",
       "      <td>0.129807</td>\n",
       "      <td>0.213772</td>\n",
       "      <td>0.436384</td>\n",
       "      <td>0.489616</td>\n",
       "      <td>0.295731</td>\n",
       "      <td>0.337348</td>\n",
       "      <td>6</td>\n",
       "      <td>has_ability</td>\n",
       "      <td>highest_troop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251</th>\n",
       "      <td>0.206488</td>\n",
       "      <td>0.210136</td>\n",
       "      <td>0.353263</td>\n",
       "      <td>0.493561</td>\n",
       "      <td>0.295731</td>\n",
       "      <td>0.337348</td>\n",
       "      <td>6</td>\n",
       "      <td>dps_special</td>\n",
       "      <td>highest_troop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252</th>\n",
       "      <td>0.965680</td>\n",
       "      <td>0.965680</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>0.846154</td>\n",
       "      <td>0.846154</td>\n",
       "      <td>7</td>\n",
       "      <td>playable</td>\n",
       "      <td>core_identity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253</th>\n",
       "      <td>0.980198</td>\n",
       "      <td>0.980198</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>7</td>\n",
       "      <td>is_spawned</td>\n",
       "      <td>core_identity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>254</th>\n",
       "      <td>0.976407</td>\n",
       "      <td>0.976407</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>7</td>\n",
       "      <td>no_hit_speed</td>\n",
       "      <td>core_identity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>255</th>\n",
       "      <td>0.950301</td>\n",
       "      <td>0.950301</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>0.846154</td>\n",
       "      <td>0.846154</td>\n",
       "      <td>7</td>\n",
       "      <td>no_attack</td>\n",
       "      <td>core_identity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>256</th>\n",
       "      <td>0.980198</td>\n",
       "      <td>0.980198</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>0.846154</td>\n",
       "      <td>0.846154</td>\n",
       "      <td>7</td>\n",
       "      <td>has_ranged_attack</td>\n",
       "      <td>core_identity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>257</th>\n",
       "      <td>0.119384</td>\n",
       "      <td>0.265591</td>\n",
       "      <td>0.258429</td>\n",
       "      <td>0.640142</td>\n",
       "      <td>0.059794</td>\n",
       "      <td>0.404744</td>\n",
       "      <td>7</td>\n",
       "      <td>elixircost</td>\n",
       "      <td>combat_core_stats</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>258</th>\n",
       "      <td>0.093670</td>\n",
       "      <td>0.257234</td>\n",
       "      <td>0.606309</td>\n",
       "      <td>0.678095</td>\n",
       "      <td>0.288374</td>\n",
       "      <td>0.288374</td>\n",
       "      <td>7</td>\n",
       "      <td>damage</td>\n",
       "      <td>combat_core_stats</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259</th>\n",
       "      <td>0.102362</td>\n",
       "      <td>0.242874</td>\n",
       "      <td>0.322875</td>\n",
       "      <td>0.485855</td>\n",
       "      <td>0.280935</td>\n",
       "      <td>0.471552</td>\n",
       "      <td>7</td>\n",
       "      <td>hitpoints</td>\n",
       "      <td>combat_core_stats</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260</th>\n",
       "      <td>0.002111</td>\n",
       "      <td>0.264097</td>\n",
       "      <td>0.322875</td>\n",
       "      <td>0.485855</td>\n",
       "      <td>0.296432</td>\n",
       "      <td>0.296432</td>\n",
       "      <td>7</td>\n",
       "      <td>hit_speed</td>\n",
       "      <td>combat_core_stats</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261</th>\n",
       "      <td>0.099489</td>\n",
       "      <td>0.244091</td>\n",
       "      <td>0.441891</td>\n",
       "      <td>0.652989</td>\n",
       "      <td>0.082481</td>\n",
       "      <td>0.301242</td>\n",
       "      <td>7</td>\n",
       "      <td>attack_count</td>\n",
       "      <td>combat_core_stats</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>262</th>\n",
       "      <td>0.080796</td>\n",
       "      <td>0.172534</td>\n",
       "      <td>0.322875</td>\n",
       "      <td>0.485855</td>\n",
       "      <td>0.325239</td>\n",
       "      <td>0.337735</td>\n",
       "      <td>7</td>\n",
       "      <td>range</td>\n",
       "      <td>combat_core_stats</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>263</th>\n",
       "      <td>0.198610</td>\n",
       "      <td>0.260281</td>\n",
       "      <td>0.322875</td>\n",
       "      <td>0.485855</td>\n",
       "      <td>0.099854</td>\n",
       "      <td>0.305243</td>\n",
       "      <td>7</td>\n",
       "      <td>speed</td>\n",
       "      <td>combat_core_stats</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>264</th>\n",
       "      <td>-0.012636</td>\n",
       "      <td>0.237665</td>\n",
       "      <td>0.322875</td>\n",
       "      <td>0.485855</td>\n",
       "      <td>0.099854</td>\n",
       "      <td>0.305243</td>\n",
       "      <td>7</td>\n",
       "      <td>count</td>\n",
       "      <td>combat_core_stats</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>265</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>7</td>\n",
       "      <td>any_target</td>\n",
       "      <td>targeting_behavior</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>266</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>7</td>\n",
       "      <td>ground_target</td>\n",
       "      <td>targeting_behavior</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>267</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>7</td>\n",
       "      <td>building_target</td>\n",
       "      <td>targeting_behavior</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>268</th>\n",
       "      <td>0.789360</td>\n",
       "      <td>0.789360</td>\n",
       "      <td>0.904762</td>\n",
       "      <td>0.904762</td>\n",
       "      <td>0.846154</td>\n",
       "      <td>0.846154</td>\n",
       "      <td>7</td>\n",
       "      <td>special_damage</td>\n",
       "      <td>special_attack_mechanics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>269</th>\n",
       "      <td>0.665342</td>\n",
       "      <td>0.678416</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>7</td>\n",
       "      <td>special_attack_type</td>\n",
       "      <td>special_attack_mechanics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>270</th>\n",
       "      <td>0.751498</td>\n",
       "      <td>0.751498</td>\n",
       "      <td>0.773614</td>\n",
       "      <td>0.773614</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>7</td>\n",
       "      <td>has_ranged_attack</td>\n",
       "      <td>special_attack_mechanics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>271</th>\n",
       "      <td>0.680048</td>\n",
       "      <td>0.680048</td>\n",
       "      <td>0.773614</td>\n",
       "      <td>0.773614</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>7</td>\n",
       "      <td>has_ability</td>\n",
       "      <td>special_attack_mechanics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>272</th>\n",
       "      <td>0.674404</td>\n",
       "      <td>0.672496</td>\n",
       "      <td>0.904762</td>\n",
       "      <td>0.904762</td>\n",
       "      <td>0.846154</td>\n",
       "      <td>0.846154</td>\n",
       "      <td>7</td>\n",
       "      <td>has_friendly_buff</td>\n",
       "      <td>special_attack_mechanics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>273</th>\n",
       "      <td>0.679752</td>\n",
       "      <td>0.679338</td>\n",
       "      <td>0.773614</td>\n",
       "      <td>0.773614</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>7</td>\n",
       "      <td>invisible</td>\n",
       "      <td>special_attack_mechanics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>274</th>\n",
       "      <td>0.799463</td>\n",
       "      <td>0.799463</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>7</td>\n",
       "      <td>aoe_bool</td>\n",
       "      <td>special_attack_mechanics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>275</th>\n",
       "      <td>0.468159</td>\n",
       "      <td>0.467143</td>\n",
       "      <td>0.904762</td>\n",
       "      <td>0.904762</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>7</td>\n",
       "      <td>aoe_bool</td>\n",
       "      <td>boolean_effects_and_traits</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>276</th>\n",
       "      <td>0.361364</td>\n",
       "      <td>0.393014</td>\n",
       "      <td>0.717410</td>\n",
       "      <td>0.717410</td>\n",
       "      <td>0.732058</td>\n",
       "      <td>0.732058</td>\n",
       "      <td>7</td>\n",
       "      <td>death_damage_bool</td>\n",
       "      <td>boolean_effects_and_traits</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>277</th>\n",
       "      <td>0.419154</td>\n",
       "      <td>0.461505</td>\n",
       "      <td>0.717410</td>\n",
       "      <td>0.717410</td>\n",
       "      <td>0.709477</td>\n",
       "      <td>0.709477</td>\n",
       "      <td>7</td>\n",
       "      <td>fly_bool</td>\n",
       "      <td>boolean_effects_and_traits</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278</th>\n",
       "      <td>0.384530</td>\n",
       "      <td>0.419974</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.707253</td>\n",
       "      <td>0.707253</td>\n",
       "      <td>7</td>\n",
       "      <td>spawn_bool</td>\n",
       "      <td>boolean_effects_and_traits</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279</th>\n",
       "      <td>0.445326</td>\n",
       "      <td>0.440612</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>7</td>\n",
       "      <td>can_evolve</td>\n",
       "      <td>boolean_effects_and_traits</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280</th>\n",
       "      <td>0.376096</td>\n",
       "      <td>0.402193</td>\n",
       "      <td>0.717410</td>\n",
       "      <td>0.717410</td>\n",
       "      <td>0.709477</td>\n",
       "      <td>0.709477</td>\n",
       "      <td>7</td>\n",
       "      <td>shield_bool</td>\n",
       "      <td>boolean_effects_and_traits</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281</th>\n",
       "      <td>0.398401</td>\n",
       "      <td>0.388223</td>\n",
       "      <td>0.717410</td>\n",
       "      <td>0.717410</td>\n",
       "      <td>0.709477</td>\n",
       "      <td>0.709477</td>\n",
       "      <td>7</td>\n",
       "      <td>has_lifetime</td>\n",
       "      <td>boolean_effects_and_traits</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>282</th>\n",
       "      <td>0.400069</td>\n",
       "      <td>0.386313</td>\n",
       "      <td>0.741223</td>\n",
       "      <td>0.741223</td>\n",
       "      <td>0.709477</td>\n",
       "      <td>0.709477</td>\n",
       "      <td>7</td>\n",
       "      <td>has_upon_breaking_spawn</td>\n",
       "      <td>boolean_effects_and_traits</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>283</th>\n",
       "      <td>0.385304</td>\n",
       "      <td>0.386481</td>\n",
       "      <td>0.717410</td>\n",
       "      <td>0.717410</td>\n",
       "      <td>0.707253</td>\n",
       "      <td>0.707253</td>\n",
       "      <td>7</td>\n",
       "      <td>has_upon_death_spawn</td>\n",
       "      <td>boolean_effects_and_traits</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284</th>\n",
       "      <td>0.277580</td>\n",
       "      <td>0.387338</td>\n",
       "      <td>0.904762</td>\n",
       "      <td>0.904762</td>\n",
       "      <td>0.846154</td>\n",
       "      <td>0.846154</td>\n",
       "      <td>7</td>\n",
       "      <td>has_periodic_spawn</td>\n",
       "      <td>boolean_effects_and_traits</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>285</th>\n",
       "      <td>0.414977</td>\n",
       "      <td>0.414977</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.692308</td>\n",
       "      <td>0.692308</td>\n",
       "      <td>7</td>\n",
       "      <td>single_damage_type</td>\n",
       "      <td>boolean_effects_and_traits</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>286</th>\n",
       "      <td>0.223677</td>\n",
       "      <td>0.289793</td>\n",
       "      <td>0.283954</td>\n",
       "      <td>0.394826</td>\n",
       "      <td>0.457539</td>\n",
       "      <td>0.457539</td>\n",
       "      <td>7</td>\n",
       "      <td>damage_per_elixir</td>\n",
       "      <td>engineered_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287</th>\n",
       "      <td>0.169339</td>\n",
       "      <td>0.339155</td>\n",
       "      <td>0.307585</td>\n",
       "      <td>0.392965</td>\n",
       "      <td>0.541779</td>\n",
       "      <td>0.541779</td>\n",
       "      <td>7</td>\n",
       "      <td>damage_per_second</td>\n",
       "      <td>engineered_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288</th>\n",
       "      <td>0.148194</td>\n",
       "      <td>0.317309</td>\n",
       "      <td>0.289202</td>\n",
       "      <td>0.380537</td>\n",
       "      <td>0.495941</td>\n",
       "      <td>0.495941</td>\n",
       "      <td>7</td>\n",
       "      <td>damage_output</td>\n",
       "      <td>engineered_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289</th>\n",
       "      <td>0.151705</td>\n",
       "      <td>0.329390</td>\n",
       "      <td>0.391999</td>\n",
       "      <td>0.391999</td>\n",
       "      <td>0.548162</td>\n",
       "      <td>0.548162</td>\n",
       "      <td>7</td>\n",
       "      <td>hp_per_elixir</td>\n",
       "      <td>engineered_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>290</th>\n",
       "      <td>0.223808</td>\n",
       "      <td>0.290615</td>\n",
       "      <td>0.307585</td>\n",
       "      <td>0.392965</td>\n",
       "      <td>0.434733</td>\n",
       "      <td>0.434733</td>\n",
       "      <td>7</td>\n",
       "      <td>damage_by_hitpoints</td>\n",
       "      <td>engineered_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>291</th>\n",
       "      <td>0.310467</td>\n",
       "      <td>0.333162</td>\n",
       "      <td>0.275711</td>\n",
       "      <td>0.395183</td>\n",
       "      <td>0.439437</td>\n",
       "      <td>0.439437</td>\n",
       "      <td>7</td>\n",
       "      <td>aoe_by_range</td>\n",
       "      <td>engineered_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>292</th>\n",
       "      <td>0.173842</td>\n",
       "      <td>0.327683</td>\n",
       "      <td>0.308614</td>\n",
       "      <td>0.389396</td>\n",
       "      <td>0.439615</td>\n",
       "      <td>0.439615</td>\n",
       "      <td>7</td>\n",
       "      <td>aoe_by_damage</td>\n",
       "      <td>engineered_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>293</th>\n",
       "      <td>0.148781</td>\n",
       "      <td>0.314263</td>\n",
       "      <td>0.269716</td>\n",
       "      <td>0.402388</td>\n",
       "      <td>0.439615</td>\n",
       "      <td>0.439615</td>\n",
       "      <td>7</td>\n",
       "      <td>aoe_per_elixir</td>\n",
       "      <td>engineered_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>294</th>\n",
       "      <td>0.218118</td>\n",
       "      <td>0.302144</td>\n",
       "      <td>0.186885</td>\n",
       "      <td>0.334566</td>\n",
       "      <td>0.471972</td>\n",
       "      <td>0.471972</td>\n",
       "      <td>7</td>\n",
       "      <td>control_special</td>\n",
       "      <td>engineered_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>0.053631</td>\n",
       "      <td>0.315865</td>\n",
       "      <td>0.312570</td>\n",
       "      <td>0.477538</td>\n",
       "      <td>0.439615</td>\n",
       "      <td>0.439615</td>\n",
       "      <td>7</td>\n",
       "      <td>dps_special</td>\n",
       "      <td>engineered_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>0.216562</td>\n",
       "      <td>0.324311</td>\n",
       "      <td>0.307585</td>\n",
       "      <td>0.392965</td>\n",
       "      <td>0.404298</td>\n",
       "      <td>0.404298</td>\n",
       "      <td>7</td>\n",
       "      <td>air_control</td>\n",
       "      <td>engineered_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>0.244068</td>\n",
       "      <td>0.278117</td>\n",
       "      <td>0.307585</td>\n",
       "      <td>0.392965</td>\n",
       "      <td>0.433522</td>\n",
       "      <td>0.433522</td>\n",
       "      <td>7</td>\n",
       "      <td>ground_dps</td>\n",
       "      <td>engineered_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>0.192879</td>\n",
       "      <td>0.240528</td>\n",
       "      <td>0.307585</td>\n",
       "      <td>0.392965</td>\n",
       "      <td>0.582585</td>\n",
       "      <td>0.582585</td>\n",
       "      <td>7</td>\n",
       "      <td>damage_output_ps</td>\n",
       "      <td>engineered_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>7</td>\n",
       "      <td>win_con</td>\n",
       "      <td>role_labels</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <td>0.915007</td>\n",
       "      <td>0.915007</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>7</td>\n",
       "      <td>win_con_dmg</td>\n",
       "      <td>role_labels</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301</th>\n",
       "      <td>0.977685</td>\n",
       "      <td>0.977685</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>7</td>\n",
       "      <td>support</td>\n",
       "      <td>role_labels</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>302</th>\n",
       "      <td>0.990099</td>\n",
       "      <td>0.990099</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>7</td>\n",
       "      <td>mini_tank</td>\n",
       "      <td>role_labels</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>303</th>\n",
       "      <td>0.989594</td>\n",
       "      <td>0.989594</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>7</td>\n",
       "      <td>high_dps</td>\n",
       "      <td>role_labels</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>304</th>\n",
       "      <td>0.219836</td>\n",
       "      <td>0.265049</td>\n",
       "      <td>0.753474</td>\n",
       "      <td>0.753474</td>\n",
       "      <td>0.395757</td>\n",
       "      <td>0.395757</td>\n",
       "      <td>7</td>\n",
       "      <td>elixircost</td>\n",
       "      <td>highest_troop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>305</th>\n",
       "      <td>0.214276</td>\n",
       "      <td>0.263699</td>\n",
       "      <td>0.479347</td>\n",
       "      <td>0.479347</td>\n",
       "      <td>0.382204</td>\n",
       "      <td>0.382204</td>\n",
       "      <td>7</td>\n",
       "      <td>damage_per_second</td>\n",
       "      <td>highest_troop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>306</th>\n",
       "      <td>0.195666</td>\n",
       "      <td>0.245993</td>\n",
       "      <td>0.479347</td>\n",
       "      <td>0.479347</td>\n",
       "      <td>0.396899</td>\n",
       "      <td>0.396899</td>\n",
       "      <td>7</td>\n",
       "      <td>range</td>\n",
       "      <td>highest_troop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307</th>\n",
       "      <td>0.238874</td>\n",
       "      <td>0.291519</td>\n",
       "      <td>0.281018</td>\n",
       "      <td>0.481781</td>\n",
       "      <td>0.441547</td>\n",
       "      <td>0.441547</td>\n",
       "      <td>7</td>\n",
       "      <td>spawn_bool</td>\n",
       "      <td>highest_troop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>308</th>\n",
       "      <td>0.180772</td>\n",
       "      <td>0.247415</td>\n",
       "      <td>0.479347</td>\n",
       "      <td>0.479347</td>\n",
       "      <td>0.263970</td>\n",
       "      <td>0.263970</td>\n",
       "      <td>7</td>\n",
       "      <td>hitpoints</td>\n",
       "      <td>highest_troop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>309</th>\n",
       "      <td>0.200751</td>\n",
       "      <td>0.237860</td>\n",
       "      <td>0.479347</td>\n",
       "      <td>0.479347</td>\n",
       "      <td>0.320223</td>\n",
       "      <td>0.320223</td>\n",
       "      <td>7</td>\n",
       "      <td>has_ranged_attack</td>\n",
       "      <td>highest_troop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>310</th>\n",
       "      <td>0.198341</td>\n",
       "      <td>0.282586</td>\n",
       "      <td>0.375843</td>\n",
       "      <td>0.459177</td>\n",
       "      <td>0.188061</td>\n",
       "      <td>0.247111</td>\n",
       "      <td>7</td>\n",
       "      <td>aoe_bool</td>\n",
       "      <td>highest_troop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>311</th>\n",
       "      <td>0.150218</td>\n",
       "      <td>0.215329</td>\n",
       "      <td>0.479347</td>\n",
       "      <td>0.479347</td>\n",
       "      <td>0.366575</td>\n",
       "      <td>0.366575</td>\n",
       "      <td>7</td>\n",
       "      <td>win_con</td>\n",
       "      <td>highest_troop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>312</th>\n",
       "      <td>0.182596</td>\n",
       "      <td>0.256211</td>\n",
       "      <td>0.656157</td>\n",
       "      <td>0.656157</td>\n",
       "      <td>0.252780</td>\n",
       "      <td>0.325336</td>\n",
       "      <td>7</td>\n",
       "      <td>attack_count</td>\n",
       "      <td>highest_troop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>313</th>\n",
       "      <td>0.162466</td>\n",
       "      <td>0.241931</td>\n",
       "      <td>0.479347</td>\n",
       "      <td>0.479347</td>\n",
       "      <td>0.366575</td>\n",
       "      <td>0.366575</td>\n",
       "      <td>7</td>\n",
       "      <td>has_ability</td>\n",
       "      <td>highest_troop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>314</th>\n",
       "      <td>0.154017</td>\n",
       "      <td>0.238757</td>\n",
       "      <td>0.445799</td>\n",
       "      <td>0.445799</td>\n",
       "      <td>0.366575</td>\n",
       "      <td>0.366575</td>\n",
       "      <td>7</td>\n",
       "      <td>dps_special</td>\n",
       "      <td>highest_troop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>315</th>\n",
       "      <td>0.970297</td>\n",
       "      <td>0.970297</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>0.846154</td>\n",
       "      <td>0.846154</td>\n",
       "      <td>8</td>\n",
       "      <td>playable</td>\n",
       "      <td>core_identity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>316</th>\n",
       "      <td>0.980198</td>\n",
       "      <td>0.980198</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>8</td>\n",
       "      <td>is_spawned</td>\n",
       "      <td>core_identity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>317</th>\n",
       "      <td>0.980198</td>\n",
       "      <td>0.980198</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>8</td>\n",
       "      <td>no_hit_speed</td>\n",
       "      <td>core_identity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>318</th>\n",
       "      <td>0.961889</td>\n",
       "      <td>0.961889</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>0.846154</td>\n",
       "      <td>0.846154</td>\n",
       "      <td>8</td>\n",
       "      <td>no_attack</td>\n",
       "      <td>core_identity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>319</th>\n",
       "      <td>0.980198</td>\n",
       "      <td>0.980198</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>0.846154</td>\n",
       "      <td>0.846154</td>\n",
       "      <td>8</td>\n",
       "      <td>has_ranged_attack</td>\n",
       "      <td>core_identity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>320</th>\n",
       "      <td>0.071525</td>\n",
       "      <td>0.281283</td>\n",
       "      <td>0.595991</td>\n",
       "      <td>0.604139</td>\n",
       "      <td>0.442018</td>\n",
       "      <td>0.442018</td>\n",
       "      <td>8</td>\n",
       "      <td>elixircost</td>\n",
       "      <td>combat_core_stats</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>321</th>\n",
       "      <td>0.052584</td>\n",
       "      <td>0.265235</td>\n",
       "      <td>0.682526</td>\n",
       "      <td>0.682526</td>\n",
       "      <td>0.234110</td>\n",
       "      <td>0.234110</td>\n",
       "      <td>8</td>\n",
       "      <td>damage</td>\n",
       "      <td>combat_core_stats</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>322</th>\n",
       "      <td>-0.171177</td>\n",
       "      <td>0.248215</td>\n",
       "      <td>0.364409</td>\n",
       "      <td>0.452496</td>\n",
       "      <td>0.461772</td>\n",
       "      <td>0.461772</td>\n",
       "      <td>8</td>\n",
       "      <td>hitpoints</td>\n",
       "      <td>combat_core_stats</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>323</th>\n",
       "      <td>0.038291</td>\n",
       "      <td>0.267381</td>\n",
       "      <td>0.364409</td>\n",
       "      <td>0.452496</td>\n",
       "      <td>0.203076</td>\n",
       "      <td>0.286308</td>\n",
       "      <td>8</td>\n",
       "      <td>hit_speed</td>\n",
       "      <td>combat_core_stats</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>324</th>\n",
       "      <td>0.119480</td>\n",
       "      <td>0.253038</td>\n",
       "      <td>0.393722</td>\n",
       "      <td>0.600436</td>\n",
       "      <td>0.352841</td>\n",
       "      <td>0.352841</td>\n",
       "      <td>8</td>\n",
       "      <td>attack_count</td>\n",
       "      <td>combat_core_stats</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>325</th>\n",
       "      <td>0.082711</td>\n",
       "      <td>0.235843</td>\n",
       "      <td>0.364409</td>\n",
       "      <td>0.452496</td>\n",
       "      <td>0.321762</td>\n",
       "      <td>0.321762</td>\n",
       "      <td>8</td>\n",
       "      <td>range</td>\n",
       "      <td>combat_core_stats</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>326</th>\n",
       "      <td>-0.081668</td>\n",
       "      <td>0.264510</td>\n",
       "      <td>0.364409</td>\n",
       "      <td>0.452496</td>\n",
       "      <td>0.283592</td>\n",
       "      <td>0.265491</td>\n",
       "      <td>8</td>\n",
       "      <td>speed</td>\n",
       "      <td>combat_core_stats</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>327</th>\n",
       "      <td>0.043977</td>\n",
       "      <td>0.244505</td>\n",
       "      <td>0.364409</td>\n",
       "      <td>0.452496</td>\n",
       "      <td>0.283592</td>\n",
       "      <td>0.265491</td>\n",
       "      <td>8</td>\n",
       "      <td>count</td>\n",
       "      <td>combat_core_stats</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>328</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>8</td>\n",
       "      <td>any_target</td>\n",
       "      <td>targeting_behavior</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>329</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>8</td>\n",
       "      <td>ground_target</td>\n",
       "      <td>targeting_behavior</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>330</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>8</td>\n",
       "      <td>building_target</td>\n",
       "      <td>targeting_behavior</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>331</th>\n",
       "      <td>0.800968</td>\n",
       "      <td>0.800968</td>\n",
       "      <td>0.904762</td>\n",
       "      <td>0.904762</td>\n",
       "      <td>0.846154</td>\n",
       "      <td>0.846154</td>\n",
       "      <td>8</td>\n",
       "      <td>special_damage</td>\n",
       "      <td>special_attack_mechanics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>332</th>\n",
       "      <td>0.772933</td>\n",
       "      <td>0.772933</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>8</td>\n",
       "      <td>special_attack_type</td>\n",
       "      <td>special_attack_mechanics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>333</th>\n",
       "      <td>0.840138</td>\n",
       "      <td>0.840138</td>\n",
       "      <td>0.809524</td>\n",
       "      <td>0.809524</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>8</td>\n",
       "      <td>has_ranged_attack</td>\n",
       "      <td>special_attack_mechanics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>334</th>\n",
       "      <td>0.670674</td>\n",
       "      <td>0.735259</td>\n",
       "      <td>0.809524</td>\n",
       "      <td>0.809524</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>8</td>\n",
       "      <td>has_ability</td>\n",
       "      <td>special_attack_mechanics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>335</th>\n",
       "      <td>0.682568</td>\n",
       "      <td>0.678607</td>\n",
       "      <td>0.904762</td>\n",
       "      <td>0.904762</td>\n",
       "      <td>0.846154</td>\n",
       "      <td>0.846154</td>\n",
       "      <td>8</td>\n",
       "      <td>has_friendly_buff</td>\n",
       "      <td>special_attack_mechanics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>336</th>\n",
       "      <td>0.739612</td>\n",
       "      <td>0.739612</td>\n",
       "      <td>0.809524</td>\n",
       "      <td>0.809524</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>8</td>\n",
       "      <td>invisible</td>\n",
       "      <td>special_attack_mechanics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>337</th>\n",
       "      <td>0.808062</td>\n",
       "      <td>0.808062</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>8</td>\n",
       "      <td>aoe_bool</td>\n",
       "      <td>special_attack_mechanics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>338</th>\n",
       "      <td>0.498346</td>\n",
       "      <td>0.521949</td>\n",
       "      <td>0.904762</td>\n",
       "      <td>0.904762</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>8</td>\n",
       "      <td>aoe_bool</td>\n",
       "      <td>boolean_effects_and_traits</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>339</th>\n",
       "      <td>0.437123</td>\n",
       "      <td>0.463735</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.692308</td>\n",
       "      <td>0.692308</td>\n",
       "      <td>8</td>\n",
       "      <td>death_damage_bool</td>\n",
       "      <td>boolean_effects_and_traits</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>340</th>\n",
       "      <td>0.464379</td>\n",
       "      <td>0.495737</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.692308</td>\n",
       "      <td>0.692308</td>\n",
       "      <td>8</td>\n",
       "      <td>fly_bool</td>\n",
       "      <td>boolean_effects_and_traits</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341</th>\n",
       "      <td>0.430107</td>\n",
       "      <td>0.448201</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.692308</td>\n",
       "      <td>0.692308</td>\n",
       "      <td>8</td>\n",
       "      <td>spawn_bool</td>\n",
       "      <td>boolean_effects_and_traits</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>342</th>\n",
       "      <td>0.544129</td>\n",
       "      <td>0.525914</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>8</td>\n",
       "      <td>can_evolve</td>\n",
       "      <td>boolean_effects_and_traits</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>343</th>\n",
       "      <td>0.418465</td>\n",
       "      <td>0.447650</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.692308</td>\n",
       "      <td>0.692308</td>\n",
       "      <td>8</td>\n",
       "      <td>shield_bool</td>\n",
       "      <td>boolean_effects_and_traits</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>344</th>\n",
       "      <td>0.346912</td>\n",
       "      <td>0.446881</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.692308</td>\n",
       "      <td>0.692308</td>\n",
       "      <td>8</td>\n",
       "      <td>has_lifetime</td>\n",
       "      <td>boolean_effects_and_traits</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>345</th>\n",
       "      <td>0.435803</td>\n",
       "      <td>0.439977</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.692308</td>\n",
       "      <td>0.692308</td>\n",
       "      <td>8</td>\n",
       "      <td>has_upon_breaking_spawn</td>\n",
       "      <td>boolean_effects_and_traits</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>346</th>\n",
       "      <td>0.408788</td>\n",
       "      <td>0.421071</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.692308</td>\n",
       "      <td>0.692308</td>\n",
       "      <td>8</td>\n",
       "      <td>has_upon_death_spawn</td>\n",
       "      <td>boolean_effects_and_traits</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>347</th>\n",
       "      <td>0.388895</td>\n",
       "      <td>0.416527</td>\n",
       "      <td>0.904762</td>\n",
       "      <td>0.904762</td>\n",
       "      <td>0.846154</td>\n",
       "      <td>0.846154</td>\n",
       "      <td>8</td>\n",
       "      <td>has_periodic_spawn</td>\n",
       "      <td>boolean_effects_and_traits</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>348</th>\n",
       "      <td>0.468199</td>\n",
       "      <td>0.496972</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.692308</td>\n",
       "      <td>0.692308</td>\n",
       "      <td>8</td>\n",
       "      <td>single_damage_type</td>\n",
       "      <td>boolean_effects_and_traits</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>349</th>\n",
       "      <td>0.238606</td>\n",
       "      <td>0.330380</td>\n",
       "      <td>0.303714</td>\n",
       "      <td>0.359044</td>\n",
       "      <td>0.463989</td>\n",
       "      <td>0.463989</td>\n",
       "      <td>8</td>\n",
       "      <td>damage_per_elixir</td>\n",
       "      <td>engineered_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>350</th>\n",
       "      <td>0.193703</td>\n",
       "      <td>0.257811</td>\n",
       "      <td>0.357842</td>\n",
       "      <td>0.349770</td>\n",
       "      <td>0.450293</td>\n",
       "      <td>0.450293</td>\n",
       "      <td>8</td>\n",
       "      <td>damage_per_second</td>\n",
       "      <td>engineered_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>351</th>\n",
       "      <td>0.287863</td>\n",
       "      <td>0.310933</td>\n",
       "      <td>0.313898</td>\n",
       "      <td>0.386029</td>\n",
       "      <td>0.270801</td>\n",
       "      <td>0.435118</td>\n",
       "      <td>8</td>\n",
       "      <td>damage_output</td>\n",
       "      <td>engineered_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>352</th>\n",
       "      <td>0.266973</td>\n",
       "      <td>0.369815</td>\n",
       "      <td>0.240634</td>\n",
       "      <td>0.357953</td>\n",
       "      <td>0.494935</td>\n",
       "      <td>0.494935</td>\n",
       "      <td>8</td>\n",
       "      <td>hp_per_elixir</td>\n",
       "      <td>engineered_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>353</th>\n",
       "      <td>0.259807</td>\n",
       "      <td>0.251887</td>\n",
       "      <td>0.357842</td>\n",
       "      <td>0.349770</td>\n",
       "      <td>0.440065</td>\n",
       "      <td>0.440065</td>\n",
       "      <td>8</td>\n",
       "      <td>damage_by_hitpoints</td>\n",
       "      <td>engineered_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>354</th>\n",
       "      <td>0.111671</td>\n",
       "      <td>0.344146</td>\n",
       "      <td>0.274956</td>\n",
       "      <td>0.374322</td>\n",
       "      <td>0.446233</td>\n",
       "      <td>0.446233</td>\n",
       "      <td>8</td>\n",
       "      <td>aoe_by_range</td>\n",
       "      <td>engineered_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>355</th>\n",
       "      <td>0.102100</td>\n",
       "      <td>0.267817</td>\n",
       "      <td>0.364484</td>\n",
       "      <td>0.364484</td>\n",
       "      <td>0.446411</td>\n",
       "      <td>0.446411</td>\n",
       "      <td>8</td>\n",
       "      <td>aoe_by_damage</td>\n",
       "      <td>engineered_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>356</th>\n",
       "      <td>0.232767</td>\n",
       "      <td>0.281748</td>\n",
       "      <td>0.370495</td>\n",
       "      <td>0.370495</td>\n",
       "      <td>0.446411</td>\n",
       "      <td>0.446411</td>\n",
       "      <td>8</td>\n",
       "      <td>aoe_per_elixir</td>\n",
       "      <td>engineered_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>357</th>\n",
       "      <td>0.189691</td>\n",
       "      <td>0.284525</td>\n",
       "      <td>0.200232</td>\n",
       "      <td>0.320938</td>\n",
       "      <td>0.409225</td>\n",
       "      <td>0.409225</td>\n",
       "      <td>8</td>\n",
       "      <td>control_special</td>\n",
       "      <td>engineered_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>358</th>\n",
       "      <td>0.258909</td>\n",
       "      <td>0.308526</td>\n",
       "      <td>0.291300</td>\n",
       "      <td>0.391404</td>\n",
       "      <td>0.446411</td>\n",
       "      <td>0.446411</td>\n",
       "      <td>8</td>\n",
       "      <td>dps_special</td>\n",
       "      <td>engineered_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>359</th>\n",
       "      <td>0.197539</td>\n",
       "      <td>0.258086</td>\n",
       "      <td>0.357842</td>\n",
       "      <td>0.349770</td>\n",
       "      <td>0.411394</td>\n",
       "      <td>0.411394</td>\n",
       "      <td>8</td>\n",
       "      <td>air_control</td>\n",
       "      <td>engineered_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>360</th>\n",
       "      <td>0.228549</td>\n",
       "      <td>0.256409</td>\n",
       "      <td>0.357842</td>\n",
       "      <td>0.349770</td>\n",
       "      <td>0.440174</td>\n",
       "      <td>0.440174</td>\n",
       "      <td>8</td>\n",
       "      <td>ground_dps</td>\n",
       "      <td>engineered_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>361</th>\n",
       "      <td>0.291138</td>\n",
       "      <td>0.279266</td>\n",
       "      <td>0.357842</td>\n",
       "      <td>0.349770</td>\n",
       "      <td>0.491644</td>\n",
       "      <td>0.491644</td>\n",
       "      <td>8</td>\n",
       "      <td>damage_output_ps</td>\n",
       "      <td>engineered_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>362</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>8</td>\n",
       "      <td>win_con</td>\n",
       "      <td>role_labels</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>363</th>\n",
       "      <td>0.964627</td>\n",
       "      <td>0.964627</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>8</td>\n",
       "      <td>win_con_dmg</td>\n",
       "      <td>role_labels</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>364</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>8</td>\n",
       "      <td>support</td>\n",
       "      <td>role_labels</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>365</th>\n",
       "      <td>0.990099</td>\n",
       "      <td>0.990099</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>8</td>\n",
       "      <td>mini_tank</td>\n",
       "      <td>role_labels</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>366</th>\n",
       "      <td>0.990099</td>\n",
       "      <td>0.990099</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>8</td>\n",
       "      <td>high_dps</td>\n",
       "      <td>role_labels</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>367</th>\n",
       "      <td>0.222285</td>\n",
       "      <td>0.269742</td>\n",
       "      <td>0.824351</td>\n",
       "      <td>0.824351</td>\n",
       "      <td>0.332033</td>\n",
       "      <td>0.332033</td>\n",
       "      <td>8</td>\n",
       "      <td>elixircost</td>\n",
       "      <td>highest_troop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>368</th>\n",
       "      <td>0.111013</td>\n",
       "      <td>0.276350</td>\n",
       "      <td>0.318467</td>\n",
       "      <td>0.468174</td>\n",
       "      <td>0.340216</td>\n",
       "      <td>0.340216</td>\n",
       "      <td>8</td>\n",
       "      <td>damage_per_second</td>\n",
       "      <td>highest_troop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>369</th>\n",
       "      <td>0.171072</td>\n",
       "      <td>0.252363</td>\n",
       "      <td>0.318467</td>\n",
       "      <td>0.468174</td>\n",
       "      <td>0.369538</td>\n",
       "      <td>0.369538</td>\n",
       "      <td>8</td>\n",
       "      <td>range</td>\n",
       "      <td>highest_troop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>370</th>\n",
       "      <td>0.213371</td>\n",
       "      <td>0.283859</td>\n",
       "      <td>0.338721</td>\n",
       "      <td>0.473572</td>\n",
       "      <td>0.414321</td>\n",
       "      <td>0.414321</td>\n",
       "      <td>8</td>\n",
       "      <td>spawn_bool</td>\n",
       "      <td>highest_troop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>371</th>\n",
       "      <td>0.178096</td>\n",
       "      <td>0.248227</td>\n",
       "      <td>0.318467</td>\n",
       "      <td>0.468174</td>\n",
       "      <td>0.237325</td>\n",
       "      <td>0.237325</td>\n",
       "      <td>8</td>\n",
       "      <td>hitpoints</td>\n",
       "      <td>highest_troop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>372</th>\n",
       "      <td>0.157020</td>\n",
       "      <td>0.241359</td>\n",
       "      <td>0.318467</td>\n",
       "      <td>0.468174</td>\n",
       "      <td>0.324701</td>\n",
       "      <td>0.324701</td>\n",
       "      <td>8</td>\n",
       "      <td>has_ranged_attack</td>\n",
       "      <td>highest_troop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>373</th>\n",
       "      <td>0.219922</td>\n",
       "      <td>0.280536</td>\n",
       "      <td>0.289516</td>\n",
       "      <td>0.482232</td>\n",
       "      <td>0.269195</td>\n",
       "      <td>0.269195</td>\n",
       "      <td>8</td>\n",
       "      <td>aoe_bool</td>\n",
       "      <td>highest_troop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>374</th>\n",
       "      <td>0.054662</td>\n",
       "      <td>0.236730</td>\n",
       "      <td>0.318467</td>\n",
       "      <td>0.468174</td>\n",
       "      <td>0.328188</td>\n",
       "      <td>0.328188</td>\n",
       "      <td>8</td>\n",
       "      <td>win_con</td>\n",
       "      <td>highest_troop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>375</th>\n",
       "      <td>0.122769</td>\n",
       "      <td>0.266134</td>\n",
       "      <td>0.615987</td>\n",
       "      <td>0.615987</td>\n",
       "      <td>0.334374</td>\n",
       "      <td>0.334374</td>\n",
       "      <td>8</td>\n",
       "      <td>attack_count</td>\n",
       "      <td>highest_troop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>376</th>\n",
       "      <td>0.111641</td>\n",
       "      <td>0.236930</td>\n",
       "      <td>0.318467</td>\n",
       "      <td>0.468174</td>\n",
       "      <td>0.328188</td>\n",
       "      <td>0.328188</td>\n",
       "      <td>8</td>\n",
       "      <td>has_ability</td>\n",
       "      <td>highest_troop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>377</th>\n",
       "      <td>0.181583</td>\n",
       "      <td>0.231615</td>\n",
       "      <td>0.295774</td>\n",
       "      <td>0.446146</td>\n",
       "      <td>0.328188</td>\n",
       "      <td>0.328188</td>\n",
       "      <td>8</td>\n",
       "      <td>dps_special</td>\n",
       "      <td>highest_troop</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     gmm_troop  km_troop  gmm_spell  km_spell  gmm_building  km_building  K  \\\n",
       "0     0.575372  0.603388   0.952381  0.952381      0.791102     0.791102  3   \n",
       "1     0.714769  0.619159   1.000000  1.000000      0.732222     0.732222  3   \n",
       "2     0.624338  0.770655   0.952381  0.952381      0.664868     0.664868  3   \n",
       "3     0.653460  0.648924   0.952381  0.952381      0.794282     0.794282  3   \n",
       "4     0.827262  0.754081   0.952381  0.952381      0.794282     0.794282  3   \n",
       "5     0.100138  0.243560   0.292380  0.643807      0.441692     0.441692  3   \n",
       "6     0.197039  0.240286   0.172046  0.494932      0.157421     0.325686  3   \n",
       "7     0.105611  0.220023   0.512957  0.497479      0.418001     0.418001  3   \n",
       "8     0.154633  0.232560   0.512957  0.497479      0.391532     0.443722  3   \n",
       "9     0.149723  0.227099   0.333605  0.465754      0.249178     0.362853  3   \n",
       "10    0.169734  0.302895   0.512957  0.497479      0.271765     0.350854  3   \n",
       "11    0.052213  0.253891   0.512957  0.497479      0.321431     0.397378  3   \n",
       "12    0.030681  0.223366   0.512957  0.497479      0.321431     0.397378  3   \n",
       "13    1.000000  1.000000        NaN       NaN      1.000000     1.000000  3   \n",
       "14    1.000000  1.000000        NaN       NaN      1.000000     1.000000  3   \n",
       "15    1.000000  1.000000        NaN       NaN      1.000000     1.000000  3   \n",
       "16    0.388728  0.426589   0.778173  0.667585      0.570642     0.528489  3   \n",
       "17    0.499177  0.386423   0.633967  0.646138      0.550752     0.498834  3   \n",
       "18    0.454041  0.474010   0.497831  0.443093      0.587654     0.562244  3   \n",
       "19    0.450878  0.410077   0.497831  0.443093      0.417663     0.417663  3   \n",
       "20    0.371609  0.387726   0.722229  0.600958      0.529355     0.529355  3   \n",
       "21    0.349775  0.405287   0.497831  0.443093      0.417663     0.417663  3   \n",
       "22    0.427953  0.449138   0.569794  0.594702      0.596046     0.596046  3   \n",
       "23    0.534952  0.516108   0.521020  0.516034      0.503921     0.513474  3   \n",
       "24    0.470776  0.443525   0.449310  0.460137      0.431058     0.480580  3   \n",
       "25    0.270587  0.409476   0.449310  0.460137      0.402778     0.462231  3   \n",
       "26    0.449333  0.591048   0.525021  0.502748      0.341169     0.397738  3   \n",
       "27    0.526738  0.510444   0.577313  0.534584      0.617879     0.602780  3   \n",
       "28    0.308575  0.302929   0.449310  0.460137      0.402778     0.462231  3   \n",
       "29    0.420208  0.471753   0.449310  0.460137      0.402778     0.462231  3   \n",
       "30    0.276465  0.434946   0.445733  0.405644      0.402778     0.462231  3   \n",
       "31    0.429582  0.410711   0.449310  0.460137      0.341169     0.397738  3   \n",
       "32    0.204670  0.292103   0.491274  0.506761      0.424988     0.462053  3   \n",
       "33    0.464553  0.479777   0.565626  0.577650      0.450755     0.512118  3   \n",
       "34    0.302721  0.225016  -0.042496  0.346045      0.378457     0.422221  3   \n",
       "35    0.244611  0.214450   0.175815  0.331043      0.426278     0.426278  3   \n",
       "36    0.171187  0.228797   0.250367  0.375498      0.419000     0.499311  3   \n",
       "37    0.186156  0.245031   0.396275  0.412327      0.511453     0.511453  3   \n",
       "38    0.170166  0.228821   0.175815  0.331043      0.354727     0.398938  3   \n",
       "39    0.142707  0.212078   0.397667  0.397667      0.445433     0.445433  3   \n",
       "40    0.212108  0.218393   0.169797  0.333231      0.452672     0.452672  3   \n",
       "41    0.241675  0.205103   0.383570  0.383570      0.447824     0.447824  3   \n",
       "42    0.165010  0.234539   0.392473  0.392473      0.384653     0.487017  3   \n",
       "43    0.216566  0.205165   0.389247  0.389247      0.451002     0.451002  3   \n",
       "44    0.222908  0.234331   0.175815  0.331043      0.394974     0.456118  3   \n",
       "45    0.186915  0.254735   0.175815  0.331043      0.433302     0.433302  3   \n",
       "46    0.211823  0.224194   0.175815  0.331043      0.397673     0.461428  3   \n",
       "47    0.605104  0.605104   1.000000  1.000000      1.000000     1.000000  3   \n",
       "48    0.546726  0.546726   1.000000  1.000000      1.000000     1.000000  3   \n",
       "49    0.592794  0.592794   1.000000  1.000000      1.000000     1.000000  3   \n",
       "50    0.733210  0.733210   1.000000  1.000000      1.000000     1.000000  3   \n",
       "51    0.746604  0.746604   1.000000  1.000000      1.000000     1.000000  3   \n",
       "52    0.220851  0.229908   0.550392  0.445714      0.419621     0.424881  3   \n",
       "53    0.204936  0.224117   0.320816  0.320816      0.109217     0.314201  3   \n",
       "54    0.162434  0.159455   0.320816  0.320816      0.384308     0.384308  3   \n",
       "55    0.226611  0.228361   0.404047  0.404047      0.222257     0.382505  3   \n",
       "56    0.195169  0.227540   0.320816  0.320816      0.394012     0.394012  3   \n",
       "57    0.235143  0.138090   0.320816  0.320816      0.383759     0.383759  3   \n",
       "58    0.202418  0.226154   0.403741  0.403741      0.394574     0.394574  3   \n",
       "59    0.226701  0.189052   0.320816  0.320816      0.386543     0.386543  3   \n",
       "60    0.263489  0.223330   0.427920  0.427920      0.193182     0.381776  3   \n",
       "61    0.228465  0.224394   0.320816  0.320816      0.386543     0.386543  3   \n",
       "62    0.214026  0.214026   0.391304  0.391304      0.386543     0.386543  3   \n",
       "63    0.790331  0.790331   0.952381  0.952381      0.846154     0.846154  4   \n",
       "64    0.793393  0.793393   1.000000  1.000000      0.714179     0.714179  4   \n",
       "65    0.810426  0.810426   0.952381  0.952381      0.692308     0.692308  4   \n",
       "66    0.802987  0.802987   0.952381  0.952381      0.846154     0.846154  4   \n",
       "67    0.851404  0.851404   0.952381  0.952381      0.846154     0.846154  4   \n",
       "68    0.100746  0.252706   0.427667  0.576878      0.460964     0.491134  4   \n",
       "69    0.106935  0.235896   0.174960  0.441186      0.342844     0.342844  4   \n",
       "70    0.031436  0.219981   0.206924  0.320874      0.206860     0.443607  4   \n",
       "71    0.129562  0.245161   0.206924  0.320874      0.356671     0.393559  4   \n",
       "72    0.016746  0.230048   0.148456  0.524794      0.383802     0.383802  4   \n",
       "73    0.103097  0.259873   0.206924  0.320874      0.374934     0.374934  4   \n",
       "74    0.091846  0.259710   0.206924  0.320874      0.360371     0.388112  4   \n",
       "75    0.027826  0.228192   0.206924  0.320874      0.360371     0.388112  4   \n",
       "76    1.000000  1.000000        NaN       NaN      1.000000     1.000000  4   \n",
       "77    1.000000  1.000000        NaN       NaN      1.000000     1.000000  4   \n",
       "78    1.000000  1.000000        NaN       NaN      1.000000     1.000000  4   \n",
       "79    0.443592  0.480570   0.857143  0.857143      0.570305     0.570305  4   \n",
       "80    0.520939  0.423573   0.841009  0.841009      0.590207     0.590207  4   \n",
       "81    0.499959  0.522229   0.521106  0.580786      0.712419     0.712419  4   \n",
       "82    0.428217  0.433765   0.521106  0.580786      0.458135     0.458135  4   \n",
       "83    0.462818  0.458895   0.868852  0.868852      0.757568     0.757568  4   \n",
       "84    0.469824  0.465355   0.521106  0.580786      0.458135     0.458135  4   \n",
       "85    0.516474  0.511894   0.760956  0.760956      0.680645     0.680645  4   \n",
       "86    0.359296  0.521074   0.587524  0.570015      0.577208     0.577208  4   \n",
       "87    0.335173  0.454982   0.470154  0.486863      0.546021     0.546021  4   \n",
       "88    0.372485  0.345241   0.470154  0.486863      0.466925     0.466925  4   \n",
       "89    0.361537  0.324476   0.559562  0.559562      0.418902     0.418902  4   \n",
       "90    0.498685  0.476872   0.636966  0.636966      0.610954     0.651172  4   \n",
       "91    0.320592  0.494142   0.470154  0.486863      0.466925     0.466925  4   \n",
       "92    0.258825  0.288484   0.470154  0.486863      0.466925     0.466925  4   \n",
       "93    0.311856  0.426613   0.468686  0.408515      0.466925     0.466925  4   \n",
       "94    0.277882  0.256278   0.470154  0.486863      0.418902     0.418902  4   \n",
       "95    0.204809  0.283648   0.550871  0.550871      0.496980     0.496980  4   \n",
       "96    0.382262  0.504642   0.573611  0.611049      0.480611     0.500930  4   \n",
       "97    0.199513  0.205534   0.068750  0.383558      0.502972     0.502972  4   \n",
       "98    0.076424  0.252438   0.291781  0.381884      0.514473     0.514473  4   \n",
       "99    0.179359  0.267692   0.401768  0.401768      0.546118     0.546118  4   \n",
       "100   0.063599  0.254426   0.465225  0.465225      0.584866     0.584866  4   \n",
       "101   0.199188  0.255396   0.291781  0.381884      0.487291     0.487291  4   \n",
       "102   0.267321  0.207927   0.348544  0.362090      0.508945     0.508945  4   \n",
       "103   0.031133  0.209235   0.288326  0.379620      0.516182     0.516182  4   \n",
       "104   0.169216  0.226591   0.315073  0.342348      0.511333     0.511333  4   \n",
       "105   0.222424  0.233508   0.313780  0.334447      0.541246     0.541246  4   \n",
       "106   0.131678  0.236811   0.419998  0.419998      0.514517     0.514517  4   \n",
       "107   0.250806  0.236863   0.291781  0.381884      0.557270     0.557270  4   \n",
       "108   0.215707  0.248365   0.291781  0.381884      0.518763     0.518763  4   \n",
       "109   0.135758  0.272490   0.291781  0.381884      0.532339     0.532339  4   \n",
       "110   0.712851  0.698885   1.000000  1.000000      1.000000     1.000000  4   \n",
       "111   0.676387  0.676387   1.000000  1.000000      1.000000     1.000000  4   \n",
       "112   0.730102  0.730102   1.000000  1.000000      1.000000     1.000000  4   \n",
       "113   0.841795  0.841795   1.000000  1.000000      1.000000     1.000000  4   \n",
       "114   0.819843  0.840026   1.000000  1.000000      1.000000     1.000000  4   \n",
       "115   0.210011  0.249336   0.602248  0.602248      0.488117     0.488117  4   \n",
       "116   0.252094  0.254964   0.384592  0.385909      0.426360     0.426360  4   \n",
       "117   0.200512  0.184434   0.384592  0.385909      0.419179     0.419179  4   \n",
       "118   0.219812  0.247881   0.464056  0.464056      0.438352     0.438352  4   \n",
       "119   0.213078  0.224627   0.384592  0.385909      0.442664     0.442664  4   \n",
       "120   0.167916  0.174363   0.384592  0.385909      0.438790     0.438790  4   \n",
       "121   0.249904  0.242067   0.456718  0.456718      0.250911     0.309807  4   \n",
       "122   0.245481  0.223107   0.384592  0.385909      0.436381     0.436381  4   \n",
       "123   0.189882  0.247959   0.538438  0.538438      0.436798     0.436798  4   \n",
       "124   0.234776  0.239880   0.384592  0.385909      0.436381     0.436381  4   \n",
       "125   0.236842  0.234882   0.435613  0.443225      0.436381     0.436381  4   \n",
       "126   0.940180  0.940180   0.952381  0.952381      0.846154     0.846154  5   \n",
       "127   0.952958  0.952958   1.000000  1.000000      0.769231     0.769231  5   \n",
       "128   0.918261  0.918261   0.952381  0.952381      0.769231     0.769231  5   \n",
       "129   0.898363  0.898363   0.952381  0.952381      0.846154     0.846154  5   \n",
       "130   0.931576  0.931576   0.952381  0.952381      0.846154     0.846154  5   \n",
       "131   0.128901  0.266414   0.292380  0.529107      0.416493     0.416493  5   \n",
       "132   0.112750  0.261857   0.317923  0.555557      0.301669     0.301669  5   \n",
       "133   0.135202  0.228326  -0.043007  0.360304      0.399086     0.418000  5   \n",
       "134  -0.056364  0.261607  -0.043007  0.360304      0.338401     0.375578  5   \n",
       "135   0.075572  0.242594   0.155673  0.573874      0.348519     0.348519  5   \n",
       "136   0.167066  0.219916  -0.043007  0.360304      0.388069     0.383106  5   \n",
       "137   0.083785  0.260690  -0.043007  0.360304      0.338596     0.338596  5   \n",
       "138   0.082473  0.228469  -0.043007  0.360304      0.338596     0.338596  5   \n",
       "139   1.000000  1.000000        NaN       NaN      1.000000     1.000000  5   \n",
       "140   1.000000  1.000000        NaN       NaN      1.000000     1.000000  5   \n",
       "141   1.000000  1.000000        NaN       NaN      1.000000     1.000000  5   \n",
       "142   0.578713  0.582444   0.904762  0.904762      0.846154     0.846154  5   \n",
       "143   0.475553  0.479470   0.952381  0.952381      0.808982     0.808982  5   \n",
       "144   0.576891  0.596428   0.712405  0.712405      0.769231     0.769231  5   \n",
       "145   0.501772  0.501772   0.712405  0.712405      0.680645     0.680645  5   \n",
       "146   0.505393  0.505393   0.904762  0.904762      0.846154     0.846154  5   \n",
       "147   0.508284  0.508284   0.712405  0.712405      0.680645     0.680645  5   \n",
       "148   0.623537  0.592721   0.785322  0.785322      0.769231     0.769231  5   \n",
       "149   0.387082  0.522796   0.720473  0.720473      0.614674     0.614674  5   \n",
       "150   0.397133  0.334914   0.530004  0.530004      0.583487     0.583487  5   \n",
       "151   0.469061  0.482200   0.530004  0.530004      0.497546     0.497546  5   \n",
       "152   0.338683  0.338470   0.562626  0.620820      0.424004     0.424004  5   \n",
       "153   0.403886  0.466965   0.709792  0.709792      0.742848     0.742848  5   \n",
       "154   0.277772  0.317242   0.530004  0.530004      0.497546     0.497546  5   \n",
       "155   0.304080  0.315609   0.530004  0.530004      0.497546     0.497546  5   \n",
       "156   0.336159  0.305168   0.521934  0.528575      0.497546     0.497546  5   \n",
       "157   0.383027  0.474610   0.530004  0.530004      0.424004     0.424004  5   \n",
       "158   0.425261  0.455366   0.691362  0.691362      0.533605     0.533605  5   \n",
       "159   0.384026  0.455226   0.662570  0.700377      0.544886     0.544886  5   \n",
       "160   0.108164  0.226450   0.170411  0.374444      0.569133     0.569133  5   \n",
       "161   0.202764  0.305047   0.363091  0.346788      0.562746     0.562746  5   \n",
       "162   0.258611  0.238664   0.249220  0.399992      0.587710     0.587710  5   \n",
       "163   0.236472  0.297664   0.257606  0.445088      0.630839     0.630839  5   \n",
       "164   0.251805  0.286634   0.363091  0.346788      0.545147     0.545147  5   \n",
       "165   0.226443  0.263067   0.372780  0.391810      0.546639     0.546639  5   \n",
       "166   0.140890  0.270342   0.219887  0.364006      0.554989     0.554989  5   \n",
       "167   0.132144  0.252029   0.120633  0.355642      0.549771     0.549771  5   \n",
       "168   0.212259  0.226037   0.305058  0.328212      0.581351     0.581351  5   \n",
       "169   0.264305  0.267562   0.151118  0.370621      0.553619     0.553619  5   \n",
       "170   0.240086  0.317453   0.363091  0.346788      0.530059     0.530059  5   \n",
       "171   0.239425  0.266512   0.363091  0.346788      0.537272     0.537272  5   \n",
       "172   0.211961  0.270321   0.363091  0.346788      0.571968     0.571968  5   \n",
       "173   0.909294  0.909294   1.000000  1.000000      1.000000     1.000000  5   \n",
       "174   0.813908  0.813908   1.000000  1.000000      1.000000     1.000000  5   \n",
       "175   0.878519  0.878519   1.000000  1.000000      1.000000     1.000000  5   \n",
       "176   0.989594  0.989594   1.000000  1.000000      1.000000     1.000000  5   \n",
       "177   0.918789  0.917980   1.000000  1.000000      1.000000     1.000000  5   \n",
       "178   0.225655  0.258317   0.623860  0.707116      0.378626     0.378626  5   \n",
       "179   0.250832  0.254394   0.437556  0.437556      0.298579     0.353789  5   \n",
       "180   0.226212  0.209954   0.437556  0.437556      0.315782     0.371066  5   \n",
       "181   0.270728  0.268611   0.277573  0.496746      0.336186     0.371261  5   \n",
       "182   0.190737  0.248464   0.437556  0.437556      0.271945     0.311778  5   \n",
       "183   0.164642  0.190983   0.437556  0.437556      0.310190     0.351409  5   \n",
       "184   0.239405  0.268203   0.460031  0.510175      0.216506     0.273003  5   \n",
       "185   0.112362  0.234653   0.437556  0.437556      0.285347     0.339857  5   \n",
       "186   0.247193  0.249768   0.633951  0.633951      0.356364     0.356364  5   \n",
       "187   0.202900  0.222124   0.437556  0.437556      0.285347     0.339857  5   \n",
       "188   0.101054  0.237499   0.503735  0.503735      0.285347     0.339857  5   \n",
       "189   0.947019  0.954092   0.952381  0.952381      0.846154     0.846154  6   \n",
       "190   0.977233  0.977233   1.000000  1.000000      0.769231     0.769231  6   \n",
       "191   0.952210  0.952210   0.952381  0.952381      0.769231     0.769231  6   \n",
       "192   0.932801  0.932801   0.952381  0.952381      0.846154     0.846154  6   \n",
       "193   0.974648  0.974648   0.952381  0.952381      0.846154     0.846154  6   \n",
       "194   0.041270  0.264256   0.581787  0.571640      0.099219     0.444169  6   \n",
       "195   0.055068  0.267818   0.499061  0.593600     -0.043084     0.326343  6   \n",
       "196   0.104754  0.223250   0.134451  0.380204      0.192781     0.383398  6   \n",
       "197   0.081260  0.274081   0.134451  0.380204      0.331007     0.331007  6   \n",
       "198   0.070763  0.246139   0.634112  0.634112      0.350436     0.350436  6   \n",
       "199   0.045242  0.216336   0.134451  0.380204      0.390133     0.390133  6   \n",
       "200   0.123497  0.250396   0.134451  0.380204      0.316557     0.326849  6   \n",
       "201   0.106228  0.240191   0.134451  0.380204      0.316557     0.326849  6   \n",
       "202   1.000000  1.000000        NaN       NaN      1.000000     1.000000  6   \n",
       "203   1.000000  1.000000        NaN       NaN      1.000000     1.000000  6   \n",
       "204   1.000000  1.000000        NaN       NaN      1.000000     1.000000  6   \n",
       "205   0.638490  0.624402   0.904762  0.904762      0.846154     0.846154  6   \n",
       "206   0.593269  0.593269   0.952381  0.952381      0.769231     0.769231  6   \n",
       "207   0.697156  0.661949   0.737703  0.737703      0.769231     0.769231  6   \n",
       "208   0.585882  0.585882   0.737703  0.737703      0.769231     0.769231  6   \n",
       "209   0.569162  0.594941   0.904762  0.904762      0.846154     0.846154  6   \n",
       "210   0.593084  0.593084   0.771390  0.771390      0.769231     0.769231  6   \n",
       "211   0.630425  0.655076   0.821233  0.821233      0.769231     0.769231  6   \n",
       "212   0.468334  0.537001   0.759207  0.759207      0.786401     0.786401  6   \n",
       "213   0.344613  0.388901   0.678677  0.678677      0.749228     0.749228  6   \n",
       "214   0.438071  0.390103   0.678677  0.678677      0.537751     0.537751  6   \n",
       "215   0.269745  0.351471   0.798822  0.798822      0.535527     0.535527  6   \n",
       "216   0.431785  0.398606   0.843597  0.843597      0.769231     0.769231  6   \n",
       "217   0.313050  0.341137   0.678677  0.678677      0.537751     0.537751  6   \n",
       "218   0.265737  0.359570   0.678677  0.678677      0.537751     0.537751  6   \n",
       "219   0.306644  0.337373   0.694001  0.694001      0.537751     0.537751  6   \n",
       "220   0.307986  0.313715   0.678677  0.678677      0.535527     0.535527  6   \n",
       "221   0.345615  0.337043   0.863523  0.863523      0.674428     0.674428  6   \n",
       "222   0.372477  0.387006   0.819497  0.819497      0.707948     0.707948  6   \n",
       "223   0.273261  0.290203   0.223147  0.406593      0.543459     0.543459  6   \n",
       "224   0.222751  0.332506   0.384363  0.384363      0.535876     0.535876  6   \n",
       "225   0.063366  0.269288   0.339133  0.370872      0.417687     0.582416  6   \n",
       "226   0.264207  0.325435   0.269887  0.395925      0.633168     0.633168  6   \n",
       "227   0.260244  0.315556   0.384363  0.384363      0.520524     0.520524  6   \n",
       "228   0.131150  0.271503   0.363012  0.422560      0.519287     0.519287  6   \n",
       "229   0.186386  0.324226   0.279019  0.381225      0.527628     0.527628  6   \n",
       "230   0.279209  0.248412   0.368070  0.366141      0.522405     0.522405  6   \n",
       "231   0.140734  0.263609   0.165500  0.366711      0.495575     0.495575  6   \n",
       "232   0.214840  0.273310   0.087071  0.433943      0.526282     0.526282  6   \n",
       "233   0.187081  0.277604   0.384363  0.384363      0.443765     0.443765  6   \n",
       "234  -0.043515  0.229580   0.384363  0.384363      0.518899     0.518899  6   \n",
       "235   0.235327  0.223573   0.384363  0.384363      0.570085     0.570085  6   \n",
       "236   0.974202  0.974202   1.000000  1.000000      1.000000     1.000000  6   \n",
       "237   0.858477  0.858477   1.000000  1.000000      1.000000     1.000000  6   \n",
       "238   0.933315  0.933315   1.000000  1.000000      1.000000     1.000000  6   \n",
       "239   0.990099  0.990099   1.000000  1.000000      1.000000     1.000000  6   \n",
       "240   0.963795  0.963795   1.000000  1.000000      1.000000     1.000000  6   \n",
       "241   0.259052  0.248835   0.687331  0.687331      0.371311     0.388470  6   \n",
       "242   0.252556  0.242026   0.436384  0.489616      0.376188     0.376188  6   \n",
       "243   0.193616  0.209171   0.436384  0.489616      0.325886     0.367608  6   \n",
       "244   0.234316  0.267535   0.453133  0.453133      0.343943     0.384083  6   \n",
       "245   0.241932  0.239568   0.436384  0.489616      0.264493     0.290329  6   \n",
       "246   0.202498  0.193271   0.436384  0.489616      0.354178     0.354178  6   \n",
       "247   0.212991  0.279966   0.335032  0.499783      0.216560     0.279995  6   \n",
       "248   0.161119  0.239357   0.436384  0.489616      0.295731     0.337348  6   \n",
       "249   0.246467  0.255115   0.635673  0.635673      0.287337     0.359292  6   \n",
       "250   0.129807  0.213772   0.436384  0.489616      0.295731     0.337348  6   \n",
       "251   0.206488  0.210136   0.353263  0.493561      0.295731     0.337348  6   \n",
       "252   0.965680  0.965680   0.952381  0.952381      0.846154     0.846154  7   \n",
       "253   0.980198  0.980198   1.000000  1.000000      0.769231     0.769231  7   \n",
       "254   0.976407  0.976407   0.952381  0.952381      0.769231     0.769231  7   \n",
       "255   0.950301  0.950301   0.952381  0.952381      0.846154     0.846154  7   \n",
       "256   0.980198  0.980198   0.952381  0.952381      0.846154     0.846154  7   \n",
       "257   0.119384  0.265591   0.258429  0.640142      0.059794     0.404744  7   \n",
       "258   0.093670  0.257234   0.606309  0.678095      0.288374     0.288374  7   \n",
       "259   0.102362  0.242874   0.322875  0.485855      0.280935     0.471552  7   \n",
       "260   0.002111  0.264097   0.322875  0.485855      0.296432     0.296432  7   \n",
       "261   0.099489  0.244091   0.441891  0.652989      0.082481     0.301242  7   \n",
       "262   0.080796  0.172534   0.322875  0.485855      0.325239     0.337735  7   \n",
       "263   0.198610  0.260281   0.322875  0.485855      0.099854     0.305243  7   \n",
       "264  -0.012636  0.237665   0.322875  0.485855      0.099854     0.305243  7   \n",
       "265   1.000000  1.000000        NaN       NaN      1.000000     1.000000  7   \n",
       "266   1.000000  1.000000        NaN       NaN      1.000000     1.000000  7   \n",
       "267   1.000000  1.000000        NaN       NaN      1.000000     1.000000  7   \n",
       "268   0.789360  0.789360   0.904762  0.904762      0.846154     0.846154  7   \n",
       "269   0.665342  0.678416   0.952381  0.952381      0.769231     0.769231  7   \n",
       "270   0.751498  0.751498   0.773614  0.773614      0.769231     0.769231  7   \n",
       "271   0.680048  0.680048   0.773614  0.773614      0.769231     0.769231  7   \n",
       "272   0.674404  0.672496   0.904762  0.904762      0.846154     0.846154  7   \n",
       "273   0.679752  0.679338   0.773614  0.773614      0.769231     0.769231  7   \n",
       "274   0.799463  0.799463   0.857143  0.857143      0.769231     0.769231  7   \n",
       "275   0.468159  0.467143   0.904762  0.904762      0.769231     0.769231  7   \n",
       "276   0.361364  0.393014   0.717410  0.717410      0.732058     0.732058  7   \n",
       "277   0.419154  0.461505   0.717410  0.717410      0.709477     0.709477  7   \n",
       "278   0.384530  0.419974   0.857143  0.857143      0.707253     0.707253  7   \n",
       "279   0.445326  0.440612   0.857143  0.857143      0.769231     0.769231  7   \n",
       "280   0.376096  0.402193   0.717410  0.717410      0.709477     0.709477  7   \n",
       "281   0.398401  0.388223   0.717410  0.717410      0.709477     0.709477  7   \n",
       "282   0.400069  0.386313   0.741223  0.741223      0.709477     0.709477  7   \n",
       "283   0.385304  0.386481   0.717410  0.717410      0.707253     0.707253  7   \n",
       "284   0.277580  0.387338   0.904762  0.904762      0.846154     0.846154  7   \n",
       "285   0.414977  0.414977   0.857143  0.857143      0.692308     0.692308  7   \n",
       "286   0.223677  0.289793   0.283954  0.394826      0.457539     0.457539  7   \n",
       "287   0.169339  0.339155   0.307585  0.392965      0.541779     0.541779  7   \n",
       "288   0.148194  0.317309   0.289202  0.380537      0.495941     0.495941  7   \n",
       "289   0.151705  0.329390   0.391999  0.391999      0.548162     0.548162  7   \n",
       "290   0.223808  0.290615   0.307585  0.392965      0.434733     0.434733  7   \n",
       "291   0.310467  0.333162   0.275711  0.395183      0.439437     0.439437  7   \n",
       "292   0.173842  0.327683   0.308614  0.389396      0.439615     0.439615  7   \n",
       "293   0.148781  0.314263   0.269716  0.402388      0.439615     0.439615  7   \n",
       "294   0.218118  0.302144   0.186885  0.334566      0.471972     0.471972  7   \n",
       "295   0.053631  0.315865   0.312570  0.477538      0.439615     0.439615  7   \n",
       "296   0.216562  0.324311   0.307585  0.392965      0.404298     0.404298  7   \n",
       "297   0.244068  0.278117   0.307585  0.392965      0.433522     0.433522  7   \n",
       "298   0.192879  0.240528   0.307585  0.392965      0.582585     0.582585  7   \n",
       "299   1.000000  1.000000   1.000000  1.000000      1.000000     1.000000  7   \n",
       "300   0.915007  0.915007   1.000000  1.000000      1.000000     1.000000  7   \n",
       "301   0.977685  0.977685   1.000000  1.000000      1.000000     1.000000  7   \n",
       "302   0.990099  0.990099   1.000000  1.000000      1.000000     1.000000  7   \n",
       "303   0.989594  0.989594   1.000000  1.000000      1.000000     1.000000  7   \n",
       "304   0.219836  0.265049   0.753474  0.753474      0.395757     0.395757  7   \n",
       "305   0.214276  0.263699   0.479347  0.479347      0.382204     0.382204  7   \n",
       "306   0.195666  0.245993   0.479347  0.479347      0.396899     0.396899  7   \n",
       "307   0.238874  0.291519   0.281018  0.481781      0.441547     0.441547  7   \n",
       "308   0.180772  0.247415   0.479347  0.479347      0.263970     0.263970  7   \n",
       "309   0.200751  0.237860   0.479347  0.479347      0.320223     0.320223  7   \n",
       "310   0.198341  0.282586   0.375843  0.459177      0.188061     0.247111  7   \n",
       "311   0.150218  0.215329   0.479347  0.479347      0.366575     0.366575  7   \n",
       "312   0.182596  0.256211   0.656157  0.656157      0.252780     0.325336  7   \n",
       "313   0.162466  0.241931   0.479347  0.479347      0.366575     0.366575  7   \n",
       "314   0.154017  0.238757   0.445799  0.445799      0.366575     0.366575  7   \n",
       "315   0.970297  0.970297   0.952381  0.952381      0.846154     0.846154  8   \n",
       "316   0.980198  0.980198   1.000000  1.000000      0.769231     0.769231  8   \n",
       "317   0.980198  0.980198   0.952381  0.952381      0.769231     0.769231  8   \n",
       "318   0.961889  0.961889   0.952381  0.952381      0.846154     0.846154  8   \n",
       "319   0.980198  0.980198   0.952381  0.952381      0.846154     0.846154  8   \n",
       "320   0.071525  0.281283   0.595991  0.604139      0.442018     0.442018  8   \n",
       "321   0.052584  0.265235   0.682526  0.682526      0.234110     0.234110  8   \n",
       "322  -0.171177  0.248215   0.364409  0.452496      0.461772     0.461772  8   \n",
       "323   0.038291  0.267381   0.364409  0.452496      0.203076     0.286308  8   \n",
       "324   0.119480  0.253038   0.393722  0.600436      0.352841     0.352841  8   \n",
       "325   0.082711  0.235843   0.364409  0.452496      0.321762     0.321762  8   \n",
       "326  -0.081668  0.264510   0.364409  0.452496      0.283592     0.265491  8   \n",
       "327   0.043977  0.244505   0.364409  0.452496      0.283592     0.265491  8   \n",
       "328   1.000000  1.000000        NaN       NaN      1.000000     1.000000  8   \n",
       "329   1.000000  1.000000        NaN       NaN      1.000000     1.000000  8   \n",
       "330   1.000000  1.000000        NaN       NaN      1.000000     1.000000  8   \n",
       "331   0.800968  0.800968   0.904762  0.904762      0.846154     0.846154  8   \n",
       "332   0.772933  0.772933   0.952381  0.952381      0.769231     0.769231  8   \n",
       "333   0.840138  0.840138   0.809524  0.809524      0.769231     0.769231  8   \n",
       "334   0.670674  0.735259   0.809524  0.809524      0.769231     0.769231  8   \n",
       "335   0.682568  0.678607   0.904762  0.904762      0.846154     0.846154  8   \n",
       "336   0.739612  0.739612   0.809524  0.809524      0.769231     0.769231  8   \n",
       "337   0.808062  0.808062   0.857143  0.857143      0.769231     0.769231  8   \n",
       "338   0.498346  0.521949   0.904762  0.904762      0.769231     0.769231  8   \n",
       "339   0.437123  0.463735   0.857143  0.857143      0.692308     0.692308  8   \n",
       "340   0.464379  0.495737   0.857143  0.857143      0.692308     0.692308  8   \n",
       "341   0.430107  0.448201   0.857143  0.857143      0.692308     0.692308  8   \n",
       "342   0.544129  0.525914   0.857143  0.857143      0.769231     0.769231  8   \n",
       "343   0.418465  0.447650   0.857143  0.857143      0.692308     0.692308  8   \n",
       "344   0.346912  0.446881   0.857143  0.857143      0.692308     0.692308  8   \n",
       "345   0.435803  0.439977   0.857143  0.857143      0.692308     0.692308  8   \n",
       "346   0.408788  0.421071   0.857143  0.857143      0.692308     0.692308  8   \n",
       "347   0.388895  0.416527   0.904762  0.904762      0.846154     0.846154  8   \n",
       "348   0.468199  0.496972   0.857143  0.857143      0.692308     0.692308  8   \n",
       "349   0.238606  0.330380   0.303714  0.359044      0.463989     0.463989  8   \n",
       "350   0.193703  0.257811   0.357842  0.349770      0.450293     0.450293  8   \n",
       "351   0.287863  0.310933   0.313898  0.386029      0.270801     0.435118  8   \n",
       "352   0.266973  0.369815   0.240634  0.357953      0.494935     0.494935  8   \n",
       "353   0.259807  0.251887   0.357842  0.349770      0.440065     0.440065  8   \n",
       "354   0.111671  0.344146   0.274956  0.374322      0.446233     0.446233  8   \n",
       "355   0.102100  0.267817   0.364484  0.364484      0.446411     0.446411  8   \n",
       "356   0.232767  0.281748   0.370495  0.370495      0.446411     0.446411  8   \n",
       "357   0.189691  0.284525   0.200232  0.320938      0.409225     0.409225  8   \n",
       "358   0.258909  0.308526   0.291300  0.391404      0.446411     0.446411  8   \n",
       "359   0.197539  0.258086   0.357842  0.349770      0.411394     0.411394  8   \n",
       "360   0.228549  0.256409   0.357842  0.349770      0.440174     0.440174  8   \n",
       "361   0.291138  0.279266   0.357842  0.349770      0.491644     0.491644  8   \n",
       "362   1.000000  1.000000   1.000000  1.000000      1.000000     1.000000  8   \n",
       "363   0.964627  0.964627   1.000000  1.000000      1.000000     1.000000  8   \n",
       "364   1.000000  1.000000   1.000000  1.000000      1.000000     1.000000  8   \n",
       "365   0.990099  0.990099   1.000000  1.000000      1.000000     1.000000  8   \n",
       "366   0.990099  0.990099   1.000000  1.000000      1.000000     1.000000  8   \n",
       "367   0.222285  0.269742   0.824351  0.824351      0.332033     0.332033  8   \n",
       "368   0.111013  0.276350   0.318467  0.468174      0.340216     0.340216  8   \n",
       "369   0.171072  0.252363   0.318467  0.468174      0.369538     0.369538  8   \n",
       "370   0.213371  0.283859   0.338721  0.473572      0.414321     0.414321  8   \n",
       "371   0.178096  0.248227   0.318467  0.468174      0.237325     0.237325  8   \n",
       "372   0.157020  0.241359   0.318467  0.468174      0.324701     0.324701  8   \n",
       "373   0.219922  0.280536   0.289516  0.482232      0.269195     0.269195  8   \n",
       "374   0.054662  0.236730   0.318467  0.468174      0.328188     0.328188  8   \n",
       "375   0.122769  0.266134   0.615987  0.615987      0.334374     0.334374  8   \n",
       "376   0.111641  0.236930   0.318467  0.468174      0.328188     0.328188  8   \n",
       "377   0.181583  0.231615   0.295774  0.446146      0.328188     0.328188  8   \n",
       "\n",
       "                         col                      og_col  \n",
       "0                   playable               core_identity  \n",
       "1                 is_spawned               core_identity  \n",
       "2               no_hit_speed               core_identity  \n",
       "3                  no_attack               core_identity  \n",
       "4          has_ranged_attack               core_identity  \n",
       "5                 elixircost           combat_core_stats  \n",
       "6                     damage           combat_core_stats  \n",
       "7                  hitpoints           combat_core_stats  \n",
       "8                  hit_speed           combat_core_stats  \n",
       "9               attack_count           combat_core_stats  \n",
       "10                     range           combat_core_stats  \n",
       "11                     speed           combat_core_stats  \n",
       "12                     count           combat_core_stats  \n",
       "13                any_target          targeting_behavior  \n",
       "14             ground_target          targeting_behavior  \n",
       "15           building_target          targeting_behavior  \n",
       "16            special_damage    special_attack_mechanics  \n",
       "17       special_attack_type    special_attack_mechanics  \n",
       "18         has_ranged_attack    special_attack_mechanics  \n",
       "19               has_ability    special_attack_mechanics  \n",
       "20         has_friendly_buff    special_attack_mechanics  \n",
       "21                 invisible    special_attack_mechanics  \n",
       "22                  aoe_bool    special_attack_mechanics  \n",
       "23                  aoe_bool  boolean_effects_and_traits  \n",
       "24         death_damage_bool  boolean_effects_and_traits  \n",
       "25                  fly_bool  boolean_effects_and_traits  \n",
       "26                spawn_bool  boolean_effects_and_traits  \n",
       "27                can_evolve  boolean_effects_and_traits  \n",
       "28               shield_bool  boolean_effects_and_traits  \n",
       "29              has_lifetime  boolean_effects_and_traits  \n",
       "30   has_upon_breaking_spawn  boolean_effects_and_traits  \n",
       "31      has_upon_death_spawn  boolean_effects_and_traits  \n",
       "32        has_periodic_spawn  boolean_effects_and_traits  \n",
       "33        single_damage_type  boolean_effects_and_traits  \n",
       "34         damage_per_elixir         engineered_features  \n",
       "35         damage_per_second         engineered_features  \n",
       "36             damage_output         engineered_features  \n",
       "37             hp_per_elixir         engineered_features  \n",
       "38       damage_by_hitpoints         engineered_features  \n",
       "39              aoe_by_range         engineered_features  \n",
       "40             aoe_by_damage         engineered_features  \n",
       "41            aoe_per_elixir         engineered_features  \n",
       "42           control_special         engineered_features  \n",
       "43               dps_special         engineered_features  \n",
       "44               air_control         engineered_features  \n",
       "45                ground_dps         engineered_features  \n",
       "46          damage_output_ps         engineered_features  \n",
       "47                   win_con                 role_labels  \n",
       "48               win_con_dmg                 role_labels  \n",
       "49                   support                 role_labels  \n",
       "50                 mini_tank                 role_labels  \n",
       "51                  high_dps                 role_labels  \n",
       "52                elixircost               highest_troop  \n",
       "53         damage_per_second               highest_troop  \n",
       "54                     range               highest_troop  \n",
       "55                spawn_bool               highest_troop  \n",
       "56                 hitpoints               highest_troop  \n",
       "57         has_ranged_attack               highest_troop  \n",
       "58                  aoe_bool               highest_troop  \n",
       "59                   win_con               highest_troop  \n",
       "60              attack_count               highest_troop  \n",
       "61               has_ability               highest_troop  \n",
       "62               dps_special               highest_troop  \n",
       "63                  playable               core_identity  \n",
       "64                is_spawned               core_identity  \n",
       "65              no_hit_speed               core_identity  \n",
       "66                 no_attack               core_identity  \n",
       "67         has_ranged_attack               core_identity  \n",
       "68                elixircost           combat_core_stats  \n",
       "69                    damage           combat_core_stats  \n",
       "70                 hitpoints           combat_core_stats  \n",
       "71                 hit_speed           combat_core_stats  \n",
       "72              attack_count           combat_core_stats  \n",
       "73                     range           combat_core_stats  \n",
       "74                     speed           combat_core_stats  \n",
       "75                     count           combat_core_stats  \n",
       "76                any_target          targeting_behavior  \n",
       "77             ground_target          targeting_behavior  \n",
       "78           building_target          targeting_behavior  \n",
       "79            special_damage    special_attack_mechanics  \n",
       "80       special_attack_type    special_attack_mechanics  \n",
       "81         has_ranged_attack    special_attack_mechanics  \n",
       "82               has_ability    special_attack_mechanics  \n",
       "83         has_friendly_buff    special_attack_mechanics  \n",
       "84                 invisible    special_attack_mechanics  \n",
       "85                  aoe_bool    special_attack_mechanics  \n",
       "86                  aoe_bool  boolean_effects_and_traits  \n",
       "87         death_damage_bool  boolean_effects_and_traits  \n",
       "88                  fly_bool  boolean_effects_and_traits  \n",
       "89                spawn_bool  boolean_effects_and_traits  \n",
       "90                can_evolve  boolean_effects_and_traits  \n",
       "91               shield_bool  boolean_effects_and_traits  \n",
       "92              has_lifetime  boolean_effects_and_traits  \n",
       "93   has_upon_breaking_spawn  boolean_effects_and_traits  \n",
       "94      has_upon_death_spawn  boolean_effects_and_traits  \n",
       "95        has_periodic_spawn  boolean_effects_and_traits  \n",
       "96        single_damage_type  boolean_effects_and_traits  \n",
       "97         damage_per_elixir         engineered_features  \n",
       "98         damage_per_second         engineered_features  \n",
       "99             damage_output         engineered_features  \n",
       "100            hp_per_elixir         engineered_features  \n",
       "101      damage_by_hitpoints         engineered_features  \n",
       "102             aoe_by_range         engineered_features  \n",
       "103            aoe_by_damage         engineered_features  \n",
       "104           aoe_per_elixir         engineered_features  \n",
       "105          control_special         engineered_features  \n",
       "106              dps_special         engineered_features  \n",
       "107              air_control         engineered_features  \n",
       "108               ground_dps         engineered_features  \n",
       "109         damage_output_ps         engineered_features  \n",
       "110                  win_con                 role_labels  \n",
       "111              win_con_dmg                 role_labels  \n",
       "112                  support                 role_labels  \n",
       "113                mini_tank                 role_labels  \n",
       "114                 high_dps                 role_labels  \n",
       "115               elixircost               highest_troop  \n",
       "116        damage_per_second               highest_troop  \n",
       "117                    range               highest_troop  \n",
       "118               spawn_bool               highest_troop  \n",
       "119                hitpoints               highest_troop  \n",
       "120        has_ranged_attack               highest_troop  \n",
       "121                 aoe_bool               highest_troop  \n",
       "122                  win_con               highest_troop  \n",
       "123             attack_count               highest_troop  \n",
       "124              has_ability               highest_troop  \n",
       "125              dps_special               highest_troop  \n",
       "126                 playable               core_identity  \n",
       "127               is_spawned               core_identity  \n",
       "128             no_hit_speed               core_identity  \n",
       "129                no_attack               core_identity  \n",
       "130        has_ranged_attack               core_identity  \n",
       "131               elixircost           combat_core_stats  \n",
       "132                   damage           combat_core_stats  \n",
       "133                hitpoints           combat_core_stats  \n",
       "134                hit_speed           combat_core_stats  \n",
       "135             attack_count           combat_core_stats  \n",
       "136                    range           combat_core_stats  \n",
       "137                    speed           combat_core_stats  \n",
       "138                    count           combat_core_stats  \n",
       "139               any_target          targeting_behavior  \n",
       "140            ground_target          targeting_behavior  \n",
       "141          building_target          targeting_behavior  \n",
       "142           special_damage    special_attack_mechanics  \n",
       "143      special_attack_type    special_attack_mechanics  \n",
       "144        has_ranged_attack    special_attack_mechanics  \n",
       "145              has_ability    special_attack_mechanics  \n",
       "146        has_friendly_buff    special_attack_mechanics  \n",
       "147                invisible    special_attack_mechanics  \n",
       "148                 aoe_bool    special_attack_mechanics  \n",
       "149                 aoe_bool  boolean_effects_and_traits  \n",
       "150        death_damage_bool  boolean_effects_and_traits  \n",
       "151                 fly_bool  boolean_effects_and_traits  \n",
       "152               spawn_bool  boolean_effects_and_traits  \n",
       "153               can_evolve  boolean_effects_and_traits  \n",
       "154              shield_bool  boolean_effects_and_traits  \n",
       "155             has_lifetime  boolean_effects_and_traits  \n",
       "156  has_upon_breaking_spawn  boolean_effects_and_traits  \n",
       "157     has_upon_death_spawn  boolean_effects_and_traits  \n",
       "158       has_periodic_spawn  boolean_effects_and_traits  \n",
       "159       single_damage_type  boolean_effects_and_traits  \n",
       "160        damage_per_elixir         engineered_features  \n",
       "161        damage_per_second         engineered_features  \n",
       "162            damage_output         engineered_features  \n",
       "163            hp_per_elixir         engineered_features  \n",
       "164      damage_by_hitpoints         engineered_features  \n",
       "165             aoe_by_range         engineered_features  \n",
       "166            aoe_by_damage         engineered_features  \n",
       "167           aoe_per_elixir         engineered_features  \n",
       "168          control_special         engineered_features  \n",
       "169              dps_special         engineered_features  \n",
       "170              air_control         engineered_features  \n",
       "171               ground_dps         engineered_features  \n",
       "172         damage_output_ps         engineered_features  \n",
       "173                  win_con                 role_labels  \n",
       "174              win_con_dmg                 role_labels  \n",
       "175                  support                 role_labels  \n",
       "176                mini_tank                 role_labels  \n",
       "177                 high_dps                 role_labels  \n",
       "178               elixircost               highest_troop  \n",
       "179        damage_per_second               highest_troop  \n",
       "180                    range               highest_troop  \n",
       "181               spawn_bool               highest_troop  \n",
       "182                hitpoints               highest_troop  \n",
       "183        has_ranged_attack               highest_troop  \n",
       "184                 aoe_bool               highest_troop  \n",
       "185                  win_con               highest_troop  \n",
       "186             attack_count               highest_troop  \n",
       "187              has_ability               highest_troop  \n",
       "188              dps_special               highest_troop  \n",
       "189                 playable               core_identity  \n",
       "190               is_spawned               core_identity  \n",
       "191             no_hit_speed               core_identity  \n",
       "192                no_attack               core_identity  \n",
       "193        has_ranged_attack               core_identity  \n",
       "194               elixircost           combat_core_stats  \n",
       "195                   damage           combat_core_stats  \n",
       "196                hitpoints           combat_core_stats  \n",
       "197                hit_speed           combat_core_stats  \n",
       "198             attack_count           combat_core_stats  \n",
       "199                    range           combat_core_stats  \n",
       "200                    speed           combat_core_stats  \n",
       "201                    count           combat_core_stats  \n",
       "202               any_target          targeting_behavior  \n",
       "203            ground_target          targeting_behavior  \n",
       "204          building_target          targeting_behavior  \n",
       "205           special_damage    special_attack_mechanics  \n",
       "206      special_attack_type    special_attack_mechanics  \n",
       "207        has_ranged_attack    special_attack_mechanics  \n",
       "208              has_ability    special_attack_mechanics  \n",
       "209        has_friendly_buff    special_attack_mechanics  \n",
       "210                invisible    special_attack_mechanics  \n",
       "211                 aoe_bool    special_attack_mechanics  \n",
       "212                 aoe_bool  boolean_effects_and_traits  \n",
       "213        death_damage_bool  boolean_effects_and_traits  \n",
       "214                 fly_bool  boolean_effects_and_traits  \n",
       "215               spawn_bool  boolean_effects_and_traits  \n",
       "216               can_evolve  boolean_effects_and_traits  \n",
       "217              shield_bool  boolean_effects_and_traits  \n",
       "218             has_lifetime  boolean_effects_and_traits  \n",
       "219  has_upon_breaking_spawn  boolean_effects_and_traits  \n",
       "220     has_upon_death_spawn  boolean_effects_and_traits  \n",
       "221       has_periodic_spawn  boolean_effects_and_traits  \n",
       "222       single_damage_type  boolean_effects_and_traits  \n",
       "223        damage_per_elixir         engineered_features  \n",
       "224        damage_per_second         engineered_features  \n",
       "225            damage_output         engineered_features  \n",
       "226            hp_per_elixir         engineered_features  \n",
       "227      damage_by_hitpoints         engineered_features  \n",
       "228             aoe_by_range         engineered_features  \n",
       "229            aoe_by_damage         engineered_features  \n",
       "230           aoe_per_elixir         engineered_features  \n",
       "231          control_special         engineered_features  \n",
       "232              dps_special         engineered_features  \n",
       "233              air_control         engineered_features  \n",
       "234               ground_dps         engineered_features  \n",
       "235         damage_output_ps         engineered_features  \n",
       "236                  win_con                 role_labels  \n",
       "237              win_con_dmg                 role_labels  \n",
       "238                  support                 role_labels  \n",
       "239                mini_tank                 role_labels  \n",
       "240                 high_dps                 role_labels  \n",
       "241               elixircost               highest_troop  \n",
       "242        damage_per_second               highest_troop  \n",
       "243                    range               highest_troop  \n",
       "244               spawn_bool               highest_troop  \n",
       "245                hitpoints               highest_troop  \n",
       "246        has_ranged_attack               highest_troop  \n",
       "247                 aoe_bool               highest_troop  \n",
       "248                  win_con               highest_troop  \n",
       "249             attack_count               highest_troop  \n",
       "250              has_ability               highest_troop  \n",
       "251              dps_special               highest_troop  \n",
       "252                 playable               core_identity  \n",
       "253               is_spawned               core_identity  \n",
       "254             no_hit_speed               core_identity  \n",
       "255                no_attack               core_identity  \n",
       "256        has_ranged_attack               core_identity  \n",
       "257               elixircost           combat_core_stats  \n",
       "258                   damage           combat_core_stats  \n",
       "259                hitpoints           combat_core_stats  \n",
       "260                hit_speed           combat_core_stats  \n",
       "261             attack_count           combat_core_stats  \n",
       "262                    range           combat_core_stats  \n",
       "263                    speed           combat_core_stats  \n",
       "264                    count           combat_core_stats  \n",
       "265               any_target          targeting_behavior  \n",
       "266            ground_target          targeting_behavior  \n",
       "267          building_target          targeting_behavior  \n",
       "268           special_damage    special_attack_mechanics  \n",
       "269      special_attack_type    special_attack_mechanics  \n",
       "270        has_ranged_attack    special_attack_mechanics  \n",
       "271              has_ability    special_attack_mechanics  \n",
       "272        has_friendly_buff    special_attack_mechanics  \n",
       "273                invisible    special_attack_mechanics  \n",
       "274                 aoe_bool    special_attack_mechanics  \n",
       "275                 aoe_bool  boolean_effects_and_traits  \n",
       "276        death_damage_bool  boolean_effects_and_traits  \n",
       "277                 fly_bool  boolean_effects_and_traits  \n",
       "278               spawn_bool  boolean_effects_and_traits  \n",
       "279               can_evolve  boolean_effects_and_traits  \n",
       "280              shield_bool  boolean_effects_and_traits  \n",
       "281             has_lifetime  boolean_effects_and_traits  \n",
       "282  has_upon_breaking_spawn  boolean_effects_and_traits  \n",
       "283     has_upon_death_spawn  boolean_effects_and_traits  \n",
       "284       has_periodic_spawn  boolean_effects_and_traits  \n",
       "285       single_damage_type  boolean_effects_and_traits  \n",
       "286        damage_per_elixir         engineered_features  \n",
       "287        damage_per_second         engineered_features  \n",
       "288            damage_output         engineered_features  \n",
       "289            hp_per_elixir         engineered_features  \n",
       "290      damage_by_hitpoints         engineered_features  \n",
       "291             aoe_by_range         engineered_features  \n",
       "292            aoe_by_damage         engineered_features  \n",
       "293           aoe_per_elixir         engineered_features  \n",
       "294          control_special         engineered_features  \n",
       "295              dps_special         engineered_features  \n",
       "296              air_control         engineered_features  \n",
       "297               ground_dps         engineered_features  \n",
       "298         damage_output_ps         engineered_features  \n",
       "299                  win_con                 role_labels  \n",
       "300              win_con_dmg                 role_labels  \n",
       "301                  support                 role_labels  \n",
       "302                mini_tank                 role_labels  \n",
       "303                 high_dps                 role_labels  \n",
       "304               elixircost               highest_troop  \n",
       "305        damage_per_second               highest_troop  \n",
       "306                    range               highest_troop  \n",
       "307               spawn_bool               highest_troop  \n",
       "308                hitpoints               highest_troop  \n",
       "309        has_ranged_attack               highest_troop  \n",
       "310                 aoe_bool               highest_troop  \n",
       "311                  win_con               highest_troop  \n",
       "312             attack_count               highest_troop  \n",
       "313              has_ability               highest_troop  \n",
       "314              dps_special               highest_troop  \n",
       "315                 playable               core_identity  \n",
       "316               is_spawned               core_identity  \n",
       "317             no_hit_speed               core_identity  \n",
       "318                no_attack               core_identity  \n",
       "319        has_ranged_attack               core_identity  \n",
       "320               elixircost           combat_core_stats  \n",
       "321                   damage           combat_core_stats  \n",
       "322                hitpoints           combat_core_stats  \n",
       "323                hit_speed           combat_core_stats  \n",
       "324             attack_count           combat_core_stats  \n",
       "325                    range           combat_core_stats  \n",
       "326                    speed           combat_core_stats  \n",
       "327                    count           combat_core_stats  \n",
       "328               any_target          targeting_behavior  \n",
       "329            ground_target          targeting_behavior  \n",
       "330          building_target          targeting_behavior  \n",
       "331           special_damage    special_attack_mechanics  \n",
       "332      special_attack_type    special_attack_mechanics  \n",
       "333        has_ranged_attack    special_attack_mechanics  \n",
       "334              has_ability    special_attack_mechanics  \n",
       "335        has_friendly_buff    special_attack_mechanics  \n",
       "336                invisible    special_attack_mechanics  \n",
       "337                 aoe_bool    special_attack_mechanics  \n",
       "338                 aoe_bool  boolean_effects_and_traits  \n",
       "339        death_damage_bool  boolean_effects_and_traits  \n",
       "340                 fly_bool  boolean_effects_and_traits  \n",
       "341               spawn_bool  boolean_effects_and_traits  \n",
       "342               can_evolve  boolean_effects_and_traits  \n",
       "343              shield_bool  boolean_effects_and_traits  \n",
       "344             has_lifetime  boolean_effects_and_traits  \n",
       "345  has_upon_breaking_spawn  boolean_effects_and_traits  \n",
       "346     has_upon_death_spawn  boolean_effects_and_traits  \n",
       "347       has_periodic_spawn  boolean_effects_and_traits  \n",
       "348       single_damage_type  boolean_effects_and_traits  \n",
       "349        damage_per_elixir         engineered_features  \n",
       "350        damage_per_second         engineered_features  \n",
       "351            damage_output         engineered_features  \n",
       "352            hp_per_elixir         engineered_features  \n",
       "353      damage_by_hitpoints         engineered_features  \n",
       "354             aoe_by_range         engineered_features  \n",
       "355            aoe_by_damage         engineered_features  \n",
       "356           aoe_per_elixir         engineered_features  \n",
       "357          control_special         engineered_features  \n",
       "358              dps_special         engineered_features  \n",
       "359              air_control         engineered_features  \n",
       "360               ground_dps         engineered_features  \n",
       "361         damage_output_ps         engineered_features  \n",
       "362                  win_con                 role_labels  \n",
       "363              win_con_dmg                 role_labels  \n",
       "364                  support                 role_labels  \n",
       "365                mini_tank                 role_labels  \n",
       "366                 high_dps                 role_labels  \n",
       "367               elixircost               highest_troop  \n",
       "368        damage_per_second               highest_troop  \n",
       "369                    range               highest_troop  \n",
       "370               spawn_bool               highest_troop  \n",
       "371                hitpoints               highest_troop  \n",
       "372        has_ranged_attack               highest_troop  \n",
       "373                 aoe_bool               highest_troop  \n",
       "374                  win_con               highest_troop  \n",
       "375             attack_count               highest_troop  \n",
       "376              has_ability               highest_troop  \n",
       "377              dps_special               highest_troop  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sim2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3c3e12bf-2b87-44c9-8e0f-14edbf281e99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_feature_group_scores(sim_df, og_col_filter, unit_type):\n",
    "    df = sim_df[sim_df['og_col'] == og_col_filter]\n",
    "    sns.lineplot(data=df, x='K', y=f'gmm_{unit_type}', label='GMM')\n",
    "    sns.lineplot(data=df, x='K', y=f'km_{unit_type}', label='KMeans')\n",
    "    plt.title(f'Silhouette over K with feature group: {og_col_filter} ({unit_type})')\n",
    "    plt.ylim(0, 1)\n",
    "    plt.show()\n",
    "plot_feature_group_scores(sim2, 'combat_core_stats', 'spell')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ed38b111-f69d-4b2c-b142-61b26ec2d06c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster 0: 8 cards (7.92%)\n",
      "Cluster 1: 23 cards (22.77%)\n",
      "Cluster 2: 9 cards (8.91%)\n",
      "Cluster 3: 1 cards (0.99%)\n",
      "Cluster 4: 18 cards (17.82%)\n",
      "Cluster 5: 10 cards (9.90%)\n",
      "Cluster 6: 1 cards (0.99%)\n",
      "Cluster 7: 13 cards (12.87%)\n",
      "Cluster 8: 2 cards (1.98%)\n",
      "Cluster 9: 3 cards (2.97%)\n",
      "Cluster 10: 9 cards (8.91%)\n",
      "Cluster 11: 4 cards (3.96%)\n"
     ]
    }
   ],
   "source": [
    "combat_result = create_clusters('troop', 12, feature_groups['combat_core_stats'])\n",
    "print_cluster_sizes(combat_result['km_labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "98f4a2bc-bfcb-4656-98be-61907751b5b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster 0: 22 cards (21.78%)\n",
      "Cluster 1: 38 cards (37.62%)\n",
      "Cluster 2: 41 cards (40.59%)\n"
     ]
    }
   ],
   "source": [
    "target_result = create_clusters('troop', 3, feature_groups['targeting_behavior'])\n",
    "print_cluster_sizes(target_result['km_labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "179f84f8-2569-4182-9e58-0486f7edf0be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster 0: 32 cards (31.68%)\n",
      "Cluster 1: 5 cards (4.95%)\n",
      "Cluster 2: 3 cards (2.97%)\n",
      "Cluster 3: 3 cards (2.97%)\n",
      "Cluster 4: 2 cards (1.98%)\n",
      "Cluster 5: 15 cards (14.85%)\n",
      "Cluster 6: 3 cards (2.97%)\n",
      "Cluster 7: 4 cards (3.96%)\n",
      "Cluster 8: 8 cards (7.92%)\n",
      "Cluster 9: 5 cards (4.95%)\n",
      "Cluster 10: 6 cards (5.94%)\n",
      "Cluster 11: 2 cards (1.98%)\n",
      "Cluster 12: 3 cards (2.97%)\n",
      "Cluster 13: 2 cards (1.98%)\n",
      "Cluster 14: 2 cards (1.98%)\n",
      "Cluster 15: 1 cards (0.99%)\n",
      "Cluster 16: 2 cards (1.98%)\n",
      "Cluster 17: 3 cards (2.97%)\n"
     ]
    }
   ],
   "source": [
    "special_result = create_clusters('troop', 18, feature_groups['special_attack_mechanics'])\n",
    "print_cluster_sizes(special_result['gmm_labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0918d209-4637-4d24-8ae4-48df053c4880",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster 0: 6 cards (5.94%)\n",
      "Cluster 1: 30 cards (29.70%)\n",
      "Cluster 2: 3 cards (2.97%)\n",
      "Cluster 3: 1 cards (0.99%)\n",
      "Cluster 4: 1 cards (0.99%)\n",
      "Cluster 5: 3 cards (2.97%)\n",
      "Cluster 6: 2 cards (1.98%)\n",
      "Cluster 7: 3 cards (2.97%)\n",
      "Cluster 8: 4 cards (3.96%)\n",
      "Cluster 9: 7 cards (6.93%)\n",
      "Cluster 10: 4 cards (3.96%)\n",
      "Cluster 11: 2 cards (1.98%)\n",
      "Cluster 12: 9 cards (8.91%)\n",
      "Cluster 13: 8 cards (7.92%)\n",
      "Cluster 14: 4 cards (3.96%)\n",
      "Cluster 15: 1 cards (0.99%)\n",
      "Cluster 16: 2 cards (1.98%)\n",
      "Cluster 17: 1 cards (0.99%)\n",
      "Cluster 18: 2 cards (1.98%)\n",
      "Cluster 19: 2 cards (1.98%)\n",
      "Cluster 20: 3 cards (2.97%)\n",
      "Cluster 21: 1 cards (0.99%)\n",
      "Cluster 22: 2 cards (1.98%)\n"
     ]
    }
   ],
   "source": [
    "bool_result = create_clusters('troop', 23, feature_groups['boolean_effects_and_traits'])\n",
    "print_cluster_sizes(bool_result['gmm_labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "93a78fe4-7abb-4042-ab8d-40c1474a077a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster 0: 10 cards (9.90%)\n",
      "Cluster 1: 5 cards (4.95%)\n",
      "Cluster 2: 20 cards (19.80%)\n",
      "Cluster 3: 13 cards (12.87%)\n",
      "Cluster 4: 1 cards (0.99%)\n",
      "Cluster 5: 7 cards (6.93%)\n",
      "Cluster 6: 8 cards (7.92%)\n",
      "Cluster 7: 5 cards (4.95%)\n",
      "Cluster 8: 1 cards (0.99%)\n",
      "Cluster 9: 13 cards (12.87%)\n",
      "Cluster 10: 3 cards (2.97%)\n",
      "Cluster 11: 3 cards (2.97%)\n",
      "Cluster 12: 12 cards (11.88%)\n"
     ]
    }
   ],
   "source": [
    "eng_result = create_clusters('troop', 13, feature_groups['engineered_features'])\n",
    "print_cluster_sizes(eng_result['km_labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "49f8fb01-ebf0-499f-93e6-ec8543caeb3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster 0: 11 cards (10.89%)\n",
      "Cluster 1: 5 cards (4.95%)\n",
      "Cluster 2: 4 cards (3.96%)\n",
      "Cluster 3: 11 cards (10.89%)\n",
      "Cluster 4: 4 cards (3.96%)\n",
      "Cluster 5: 6 cards (5.94%)\n",
      "Cluster 6: 3 cards (2.97%)\n",
      "Cluster 7: 3 cards (2.97%)\n",
      "Cluster 8: 3 cards (2.97%)\n",
      "Cluster 9: 1 cards (0.99%)\n",
      "Cluster 10: 12 cards (11.88%)\n",
      "Cluster 11: 4 cards (3.96%)\n",
      "Cluster 12: 4 cards (3.96%)\n",
      "Cluster 13: 3 cards (2.97%)\n",
      "Cluster 14: 4 cards (3.96%)\n",
      "Cluster 15: 2 cards (1.98%)\n",
      "Cluster 16: 2 cards (1.98%)\n",
      "Cluster 17: 6 cards (5.94%)\n",
      "Cluster 18: 1 cards (0.99%)\n",
      "Cluster 19: 4 cards (3.96%)\n",
      "Cluster 20: 2 cards (1.98%)\n",
      "Cluster 21: 1 cards (0.99%)\n",
      "Cluster 22: 5 cards (4.95%)\n"
     ]
    }
   ],
   "source": [
    "test_result = create_clusters('troop', 23, feature_groups['highest_troop'])\n",
    "print_cluster_sizes(test_result['km_labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ee319209-b759-4e36-a17a-7fd4e5e98e42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster 0: 7 cards (6.93%)\n",
      "Cluster 1: 41 cards (40.59%)\n",
      "Cluster 2: 24 cards (23.76%)\n",
      "Cluster 3: 5 cards (4.95%)\n",
      "Cluster 4: 5 cards (4.95%)\n",
      "Cluster 5: 6 cards (5.94%)\n",
      "Cluster 6: 8 cards (7.92%)\n",
      "Cluster 7: 3 cards (2.97%)\n",
      "Cluster 8: 2 cards (1.98%)\n"
     ]
    }
   ],
   "source": [
    "role_result = create_clusters('troop', 9, feature_groups['role_labels'])\n",
    "print_cluster_sizes(role_result['gmm_labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "1cc4f589-af83-4ab9-8713-83a0f9c1a73a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster 0: 9 cards (8.91%)\n",
      "Cluster 1: 9 cards (8.91%)\n",
      "Cluster 2: 1 cards (0.99%)\n",
      "Cluster 3: 14 cards (13.86%)\n",
      "Cluster 4: 2 cards (1.98%)\n",
      "Cluster 5: 6 cards (5.94%)\n",
      "Cluster 6: 2 cards (1.98%)\n",
      "Cluster 7: 8 cards (7.92%)\n",
      "Cluster 8: 5 cards (4.95%)\n",
      "Cluster 9: 1 cards (0.99%)\n",
      "Cluster 10: 2 cards (1.98%)\n",
      "Cluster 11: 4 cards (3.96%)\n",
      "Cluster 12: 3 cards (2.97%)\n",
      "Cluster 13: 6 cards (5.94%)\n",
      "Cluster 14: 7 cards (6.93%)\n",
      "Cluster 15: 1 cards (0.99%)\n",
      "Cluster 16: 5 cards (4.95%)\n",
      "Cluster 17: 2 cards (1.98%)\n",
      "Cluster 18: 4 cards (3.96%)\n",
      "Cluster 19: 1 cards (0.99%)\n",
      "Cluster 20: 4 cards (3.96%)\n",
      "Cluster 21: 1 cards (0.99%)\n",
      "Cluster 22: 4 cards (3.96%)\n"
     ]
    }
   ],
   "source": [
    "combined_result = create_clusters('troop', 23, feature_groups['engineered_features'] + feature_groups['boolean_effects_and_traits'])\n",
    "print_cluster_sizes(combined_result['km_labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "74d35da9-2aab-4661-bd81-fa2ca1db374b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "combat_core_stats, K=6 -> score(gmm, km)=(-0.029, 0.206)\n",
      "combat_core_stats, K=7 -> score(gmm, km)=(0.099, 0.215)\n",
      "combat_core_stats, K=8 -> score(gmm, km)=(-0.006, 0.220)\n",
      "combat_core_stats, K=9 -> score(gmm, km)=(-0.019, 0.239)\n",
      "combat_core_stats, K=10 -> score(gmm, km)=(0.082, 0.249)\n",
      "combat_core_stats, K=11 -> score(gmm, km)=(0.052, 0.232)\n",
      "combat_core_stats, K=12 -> score(gmm, km)=(0.038, 0.250)\n",
      "combat_core_stats, K=13 -> score(gmm, km)=(0.073, 0.228)\n",
      "combat_core_stats, K=14 -> score(gmm, km)=(0.047, 0.210)\n",
      "combat_core_stats, K=15 -> score(gmm, km)=(0.053, 0.233)\n",
      "combat_core_stats, K=16 -> score(gmm, km)=(0.081, 0.243)\n",
      "combat_core_stats, K=17 -> score(gmm, km)=(-0.116, 0.221)\n",
      "combat_core_stats, K=18 -> score(gmm, km)=(-0.012, 0.217)\n",
      "combat_core_stats, K=19 -> score(gmm, km)=(0.037, 0.218)\n",
      "combat_core_stats, K=20 -> score(gmm, km)=(-0.243, 0.233)\n",
      "combat_core_stats, K=21 -> score(gmm, km)=(0.060, 0.205)\n",
      "combat_core_stats, K=22 -> score(gmm, km)=(-0.089, 0.219)\n",
      "combat_core_stats, K=23 -> score(gmm, km)=(0.041, 0.223)\n",
      "combat_core_stats, K=24 -> score(gmm, km)=(0.005, 0.206)\n",
      "combat_core_stats, K=25 -> score(gmm, km)=(-0.143, 0.221)\n",
      "combat_core_stats, K=26 -> score(gmm, km)=(-0.135, 0.222)\n",
      "combat_core_stats, K=27 -> score(gmm, km)=(-0.130, 0.226)\n",
      "combat_core_stats, K=28 -> score(gmm, km)=(-0.186, 0.226)\n",
      "combat_core_stats, K=29 -> score(gmm, km)=(-0.023, 0.225)\n",
      "targeting_behavior, K=6 -> score(gmm, km)=(1.000, 1.000)\n",
      "targeting_behavior, K=7 -> score(gmm, km)=(1.000, 1.000)\n",
      "targeting_behavior, K=8 -> score(gmm, km)=(1.000, 1.000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (9). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (9). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (9). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (9). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (9). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (9). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (9). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (9). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (9). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (9). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (9). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "targeting_behavior, K=9 -> score(gmm, km)=(1.000, 1.000)\n",
      "targeting_behavior, K=10 -> score(gmm, km)=(1.000, 1.000)\n",
      "targeting_behavior, K=11 -> score(gmm, km)=(1.000, 1.000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (10). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (10). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (10). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (10). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (10). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (10). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (10). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (10). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (10). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (10). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (10). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (11). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (11). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (11). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (11). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (11). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (11). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (11). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (11). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (11). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (11). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (11). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (12). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (12). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (12). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (12). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (12). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (12). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (12). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (12). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (12). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (12). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (12). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (13). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (13). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (13). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (13). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (13). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (13). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (13). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (13). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (13). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (13). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (13). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (14). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (14). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (14). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (14). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (14). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (14). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (14). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (14). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (14). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (14). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (14). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (15). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (15). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (15). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (15). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (15). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "targeting_behavior, K=12 -> score(gmm, km)=(1.000, 1.000)\n",
      "targeting_behavior, K=13 -> score(gmm, km)=(1.000, 1.000)\n",
      "targeting_behavior, K=14 -> score(gmm, km)=(1.000, 1.000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (15). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (15). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (15). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (15). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (15). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (15). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (16). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (16). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (16). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (16). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (16). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (16). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (16). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (16). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (16). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (16). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (16). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (17). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (17). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (17). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (17). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (17). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (17). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (17). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (17). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (17). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "targeting_behavior, K=15 -> score(gmm, km)=(1.000, 1.000)\n",
      "targeting_behavior, K=16 -> score(gmm, km)=(1.000, 1.000)\n",
      "targeting_behavior, K=17 -> score(gmm, km)=(1.000, 1.000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (17). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (17). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (18). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (18). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (18). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (18). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (18). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (18). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (18). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (18). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (18). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (18). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (18). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (19). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (19). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (19). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (19). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (19). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (19). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (19). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (19). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (19). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (19). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (19). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "targeting_behavior, K=18 -> score(gmm, km)=(1.000, 1.000)\n",
      "targeting_behavior, K=19 -> score(gmm, km)=(1.000, 1.000)\n",
      "targeting_behavior, K=20 -> score(gmm, km)=(1.000, 1.000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (20). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (20). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (20). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (20). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (20). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (20). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (20). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (20). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (20). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (20). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (20). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (21). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (21). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (21). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (21). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (21). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (21). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (21). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (21). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (21). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (21). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (21). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "targeting_behavior, K=21 -> score(gmm, km)=(1.000, 1.000)\n",
      "targeting_behavior, K=22 -> score(gmm, km)=(1.000, 1.000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (22). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (22). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (22). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (22). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (22). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (22). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (22). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (22). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (22). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (22). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (22). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (23). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (23). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (23). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (23). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (23). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (23). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (23). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (23). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (23). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (23). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (23). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (24). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (24). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (24). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (24). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (24). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (24). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (24). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (24). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (24). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (24). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (24). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (25). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (25). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (25). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (25). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "targeting_behavior, K=23 -> score(gmm, km)=(1.000, 1.000)\n",
      "targeting_behavior, K=24 -> score(gmm, km)=(1.000, 1.000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (25). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (25). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (25). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (25). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (25). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (25). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (25). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (26). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (26). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (26). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (26). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (26). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (26). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (26). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (26). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (26). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (26). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (26). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "targeting_behavior, K=25 -> score(gmm, km)=(1.000, 1.000)\n",
      "targeting_behavior, K=26 -> score(gmm, km)=(1.000, 1.000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (27). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (27). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (27). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (27). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (27). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (27). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (27). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (27). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (27). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (27). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (27). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (28). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (28). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (28). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (28). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (28). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (28). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (28). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "targeting_behavior, K=27 -> score(gmm, km)=(1.000, 1.000)\n",
      "targeting_behavior, K=28 -> score(gmm, km)=(1.000, 1.000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (28). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (28). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (28). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (28). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (29). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (29). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (29). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (29). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (29). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (29). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (29). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (29). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (29). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (29). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (29). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "targeting_behavior, K=29 -> score(gmm, km)=(1.000, 1.000)\n",
      "special_attack_mechanics, K=6 -> score(gmm, km)=(0.505, 0.505)\n",
      "special_attack_mechanics, K=7 -> score(gmm, km)=(0.545, 0.592)\n",
      "special_attack_mechanics, K=8 -> score(gmm, km)=(0.672, 0.669)\n",
      "special_attack_mechanics, K=9 -> score(gmm, km)=(0.726, 0.726)\n",
      "special_attack_mechanics, K=10 -> score(gmm, km)=(0.733, 0.733)\n",
      "special_attack_mechanics, K=11 -> score(gmm, km)=(0.753, 0.753)\n",
      "special_attack_mechanics, K=12 -> score(gmm, km)=(0.747, 0.752)\n",
      "special_attack_mechanics, K=13 -> score(gmm, km)=(0.768, 0.768)\n",
      "special_attack_mechanics, K=14 -> score(gmm, km)=(0.806, 0.806)\n",
      "special_attack_mechanics, K=15 -> score(gmm, km)=(0.838, 0.837)\n",
      "special_attack_mechanics, K=16 -> score(gmm, km)=(0.871, 0.877)\n",
      "special_attack_mechanics, K=17 -> score(gmm, km)=(0.876, 0.881)\n",
      "special_attack_mechanics, K=18 -> score(gmm, km)=(0.913, 0.913)\n",
      "special_attack_mechanics, K=19 -> score(gmm, km)=(0.905, 0.905)\n",
      "special_attack_mechanics, K=20 -> score(gmm, km)=(0.897, 0.897)\n",
      "special_attack_mechanics, K=21 -> score(gmm, km)=(0.906, 0.906)\n",
      "special_attack_mechanics, K=22 -> score(gmm, km)=(0.909, 0.909)\n",
      "special_attack_mechanics, K=23 -> score(gmm, km)=(0.905, 0.905)\n",
      "special_attack_mechanics, K=24 -> score(gmm, km)=(0.901, 0.901)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (24) found smaller than n_clusters (25). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (24) found smaller than n_clusters (25). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (24) found smaller than n_clusters (25). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (24) found smaller than n_clusters (25). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (24) found smaller than n_clusters (25). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (24) found smaller than n_clusters (25). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (24) found smaller than n_clusters (25). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (24) found smaller than n_clusters (25). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (24) found smaller than n_clusters (25). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (24) found smaller than n_clusters (25). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (24) found smaller than n_clusters (25). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (24) found smaller than n_clusters (26). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (24) found smaller than n_clusters (26). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (24) found smaller than n_clusters (26). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (24) found smaller than n_clusters (26). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (24) found smaller than n_clusters (26). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (24) found smaller than n_clusters (26). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "special_attack_mechanics, K=25 -> score(gmm, km)=(0.901, 0.901)\n",
      "special_attack_mechanics, K=26 -> score(gmm, km)=(0.901, 0.901)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (24) found smaller than n_clusters (26). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (24) found smaller than n_clusters (26). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (24) found smaller than n_clusters (26). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (24) found smaller than n_clusters (26). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (24) found smaller than n_clusters (26). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (24) found smaller than n_clusters (27). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (24) found smaller than n_clusters (27). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (24) found smaller than n_clusters (27). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (24) found smaller than n_clusters (27). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (24) found smaller than n_clusters (27). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (24) found smaller than n_clusters (27). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (24) found smaller than n_clusters (27). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (24) found smaller than n_clusters (27). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (24) found smaller than n_clusters (27). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (24) found smaller than n_clusters (27). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (24) found smaller than n_clusters (27). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "special_attack_mechanics, K=27 -> score(gmm, km)=(0.901, 0.901)\n",
      "special_attack_mechanics, K=28 -> score(gmm, km)=(0.901, 0.901)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (24) found smaller than n_clusters (28). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (24) found smaller than n_clusters (28). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (24) found smaller than n_clusters (28). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (24) found smaller than n_clusters (28). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (24) found smaller than n_clusters (28). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (24) found smaller than n_clusters (28). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (24) found smaller than n_clusters (28). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (24) found smaller than n_clusters (28). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (24) found smaller than n_clusters (28). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (24) found smaller than n_clusters (28). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (24) found smaller than n_clusters (28). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (24) found smaller than n_clusters (29). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (24) found smaller than n_clusters (29). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (24) found smaller than n_clusters (29). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (24) found smaller than n_clusters (29). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (24) found smaller than n_clusters (29). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (24) found smaller than n_clusters (29). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (24) found smaller than n_clusters (29). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (24) found smaller than n_clusters (29). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (24) found smaller than n_clusters (29). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (24) found smaller than n_clusters (29). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (24) found smaller than n_clusters (29). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "special_attack_mechanics, K=29 -> score(gmm, km)=(0.901, 0.901)\n",
      "boolean_effects_and_traits, K=6 -> score(gmm, km)=(0.293, 0.323)\n",
      "boolean_effects_and_traits, K=7 -> score(gmm, km)=(0.310, 0.346)\n",
      "boolean_effects_and_traits, K=8 -> score(gmm, km)=(0.376, 0.394)\n",
      "boolean_effects_and_traits, K=9 -> score(gmm, km)=(0.426, 0.449)\n",
      "boolean_effects_and_traits, K=10 -> score(gmm, km)=(0.429, 0.478)\n",
      "boolean_effects_and_traits, K=11 -> score(gmm, km)=(0.495, 0.503)\n",
      "boolean_effects_and_traits, K=12 -> score(gmm, km)=(0.541, 0.575)\n",
      "boolean_effects_and_traits, K=13 -> score(gmm, km)=(0.545, 0.634)\n",
      "boolean_effects_and_traits, K=14 -> score(gmm, km)=(0.649, 0.659)\n",
      "boolean_effects_and_traits, K=15 -> score(gmm, km)=(0.697, 0.697)\n",
      "boolean_effects_and_traits, K=16 -> score(gmm, km)=(0.637, 0.723)\n",
      "boolean_effects_and_traits, K=17 -> score(gmm, km)=(0.758, 0.758)\n",
      "boolean_effects_and_traits, K=18 -> score(gmm, km)=(0.770, 0.766)\n",
      "boolean_effects_and_traits, K=19 -> score(gmm, km)=(0.757, 0.757)\n",
      "boolean_effects_and_traits, K=20 -> score(gmm, km)=(0.772, 0.768)\n",
      "boolean_effects_and_traits, K=21 -> score(gmm, km)=(0.759, 0.759)\n",
      "boolean_effects_and_traits, K=22 -> score(gmm, km)=(0.771, 0.777)\n",
      "boolean_effects_and_traits, K=23 -> score(gmm, km)=(0.800, 0.800)\n",
      "boolean_effects_and_traits, K=24 -> score(gmm, km)=(0.795, 0.795)\n",
      "boolean_effects_and_traits, K=25 -> score(gmm, km)=(0.801, 0.801)\n",
      "boolean_effects_and_traits, K=26 -> score(gmm, km)=(0.787, 0.787)\n",
      "boolean_effects_and_traits, K=27 -> score(gmm, km)=(0.793, 0.793)\n",
      "boolean_effects_and_traits, K=28 -> score(gmm, km)=(0.798, 0.798)\n",
      "boolean_effects_and_traits, K=29 -> score(gmm, km)=(0.804, 0.804)\n",
      "engineered_features, K=6 -> score(gmm, km)=(0.286, 0.255)\n",
      "engineered_features, K=7 -> score(gmm, km)=(0.138, 0.284)\n",
      "engineered_features, K=8 -> score(gmm, km)=(0.224, 0.312)\n",
      "engineered_features, K=9 -> score(gmm, km)=(0.253, 0.268)\n",
      "engineered_features, K=10 -> score(gmm, km)=(0.182, 0.275)\n",
      "engineered_features, K=11 -> score(gmm, km)=(0.115, 0.251)\n",
      "engineered_features, K=12 -> score(gmm, km)=(0.174, 0.274)\n",
      "engineered_features, K=13 -> score(gmm, km)=(0.120, 0.266)\n",
      "engineered_features, K=14 -> score(gmm, km)=(0.236, 0.275)\n",
      "engineered_features, K=15 -> score(gmm, km)=(0.152, 0.276)\n",
      "engineered_features, K=16 -> score(gmm, km)=(0.156, 0.278)\n",
      "engineered_features, K=17 -> score(gmm, km)=(-0.009, 0.270)\n",
      "engineered_features, K=18 -> score(gmm, km)=(0.034, 0.271)\n",
      "engineered_features, K=19 -> score(gmm, km)=(0.176, 0.264)\n",
      "engineered_features, K=20 -> score(gmm, km)=(0.052, 0.284)\n",
      "engineered_features, K=21 -> score(gmm, km)=(0.122, 0.277)\n",
      "engineered_features, K=22 -> score(gmm, km)=(0.178, 0.279)\n",
      "engineered_features, K=23 -> score(gmm, km)=(0.154, 0.282)\n",
      "engineered_features, K=24 -> score(gmm, km)=(0.154, 0.298)\n",
      "engineered_features, K=25 -> score(gmm, km)=(0.157, 0.289)\n",
      "engineered_features, K=26 -> score(gmm, km)=(0.057, 0.263)\n",
      "engineered_features, K=27 -> score(gmm, km)=(0.087, 0.288)\n",
      "engineered_features, K=28 -> score(gmm, km)=(0.140, 0.290)\n",
      "engineered_features, K=29 -> score(gmm, km)=(0.139, 0.266)\n",
      "role_labels, K=6 -> score(gmm, km)=(0.873, 0.873)\n",
      "role_labels, K=7 -> score(gmm, km)=(0.923, 0.923)\n",
      "role_labels, K=8 -> score(gmm, km)=(0.967, 0.967)\n",
      "role_labels, K=9 -> score(gmm, km)=(0.990, 0.990)\n",
      "role_labels, K=10 -> score(gmm, km)=(0.990, 0.990)\n",
      "role_labels, K=11 -> score(gmm, km)=(0.990, 0.990)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (10) found smaller than n_clusters (11). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (10) found smaller than n_clusters (11). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (10) found smaller than n_clusters (11). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (10) found smaller than n_clusters (11). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (10) found smaller than n_clusters (11). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (10) found smaller than n_clusters (11). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (10) found smaller than n_clusters (11). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (10) found smaller than n_clusters (11). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (10) found smaller than n_clusters (11). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (10) found smaller than n_clusters (11). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (10) found smaller than n_clusters (11). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (10) found smaller than n_clusters (12). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (10) found smaller than n_clusters (12). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (10) found smaller than n_clusters (12). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (10) found smaller than n_clusters (12). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (10) found smaller than n_clusters (12). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (10) found smaller than n_clusters (12). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (10) found smaller than n_clusters (12). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (10) found smaller than n_clusters (12). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (10) found smaller than n_clusters (12). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (10) found smaller than n_clusters (12). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (10) found smaller than n_clusters (12). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (10) found smaller than n_clusters (13). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (10) found smaller than n_clusters (13). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (10) found smaller than n_clusters (13). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (10) found smaller than n_clusters (13). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (10) found smaller than n_clusters (13). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (10) found smaller than n_clusters (13). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (10) found smaller than n_clusters (13). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (10) found smaller than n_clusters (13). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (10) found smaller than n_clusters (13). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "role_labels, K=12 -> score(gmm, km)=(0.990, 0.990)\n",
      "role_labels, K=13 -> score(gmm, km)=(0.990, 0.990)\n",
      "role_labels, K=14 -> score(gmm, km)=(0.990, 0.990)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (10) found smaller than n_clusters (13). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (10) found smaller than n_clusters (13). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (10) found smaller than n_clusters (14). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (10) found smaller than n_clusters (14). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (10) found smaller than n_clusters (14). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (10) found smaller than n_clusters (14). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (10) found smaller than n_clusters (14). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (10) found smaller than n_clusters (14). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (10) found smaller than n_clusters (14). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (10) found smaller than n_clusters (14). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (10) found smaller than n_clusters (14). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (10) found smaller than n_clusters (14). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (10) found smaller than n_clusters (14). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (10) found smaller than n_clusters (15). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (10) found smaller than n_clusters (15). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (10) found smaller than n_clusters (15). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (10) found smaller than n_clusters (15). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (10) found smaller than n_clusters (15). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (10) found smaller than n_clusters (15). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (10) found smaller than n_clusters (15). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (10) found smaller than n_clusters (15). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (10) found smaller than n_clusters (15). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (10) found smaller than n_clusters (15). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (10) found smaller than n_clusters (15). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (10) found smaller than n_clusters (16). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (10) found smaller than n_clusters (16). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "role_labels, K=15 -> score(gmm, km)=(0.990, 0.990)\n",
      "role_labels, K=16 -> score(gmm, km)=(0.990, 0.990)\n",
      "role_labels, K=17 -> score(gmm, km)=(0.990, 0.990)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (10) found smaller than n_clusters (16). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (10) found smaller than n_clusters (16). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (10) found smaller than n_clusters (16). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (10) found smaller than n_clusters (16). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (10) found smaller than n_clusters (16). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (10) found smaller than n_clusters (16). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (10) found smaller than n_clusters (16). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (10) found smaller than n_clusters (16). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (10) found smaller than n_clusters (16). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (10) found smaller than n_clusters (17). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (10) found smaller than n_clusters (17). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (10) found smaller than n_clusters (17). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (10) found smaller than n_clusters (17). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (10) found smaller than n_clusters (17). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (10) found smaller than n_clusters (17). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (10) found smaller than n_clusters (17). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (10) found smaller than n_clusters (17). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (10) found smaller than n_clusters (17). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (10) found smaller than n_clusters (17). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (10) found smaller than n_clusters (17). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (10) found smaller than n_clusters (18). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (10) found smaller than n_clusters (18). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (10) found smaller than n_clusters (18). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (10) found smaller than n_clusters (18). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (10) found smaller than n_clusters (18). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (10) found smaller than n_clusters (18). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (10) found smaller than n_clusters (18). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (10) found smaller than n_clusters (18). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (10) found smaller than n_clusters (18). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (10) found smaller than n_clusters (18). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (10) found smaller than n_clusters (18). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (10) found smaller than n_clusters (19). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (10) found smaller than n_clusters (19). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (10) found smaller than n_clusters (19). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (10) found smaller than n_clusters (19). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (10) found smaller than n_clusters (19). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (10) found smaller than n_clusters (19). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (10) found smaller than n_clusters (19). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (10) found smaller than n_clusters (19). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (10) found smaller than n_clusters (19). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (10) found smaller than n_clusters (19). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (10) found smaller than n_clusters (19). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (10) found smaller than n_clusters (20). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (10) found smaller than n_clusters (20). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (10) found smaller than n_clusters (20). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (10) found smaller than n_clusters (20). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (10) found smaller than n_clusters (20). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "role_labels, K=18 -> score(gmm, km)=(0.990, 0.990)\n",
      "role_labels, K=19 -> score(gmm, km)=(0.990, 0.990)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (10) found smaller than n_clusters (20). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (10) found smaller than n_clusters (20). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (10) found smaller than n_clusters (20). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (10) found smaller than n_clusters (20). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (10) found smaller than n_clusters (20). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (10) found smaller than n_clusters (20). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (10) found smaller than n_clusters (21). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (10) found smaller than n_clusters (21). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (10) found smaller than n_clusters (21). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (10) found smaller than n_clusters (21). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (10) found smaller than n_clusters (21). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (10) found smaller than n_clusters (21). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (10) found smaller than n_clusters (21). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (10) found smaller than n_clusters (21). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (10) found smaller than n_clusters (21). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (10) found smaller than n_clusters (21). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (10) found smaller than n_clusters (21). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (10) found smaller than n_clusters (22). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (10) found smaller than n_clusters (22). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (10) found smaller than n_clusters (22). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "role_labels, K=20 -> score(gmm, km)=(0.990, 0.990)\n",
      "role_labels, K=21 -> score(gmm, km)=(0.990, 0.990)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (10) found smaller than n_clusters (22). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (10) found smaller than n_clusters (22). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (10) found smaller than n_clusters (22). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (10) found smaller than n_clusters (22). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (10) found smaller than n_clusters (22). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (10) found smaller than n_clusters (22). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (10) found smaller than n_clusters (22). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (10) found smaller than n_clusters (22). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (10) found smaller than n_clusters (23). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (10) found smaller than n_clusters (23). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (10) found smaller than n_clusters (23). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (10) found smaller than n_clusters (23). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (10) found smaller than n_clusters (23). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (10) found smaller than n_clusters (23). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (10) found smaller than n_clusters (23). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (10) found smaller than n_clusters (23). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (10) found smaller than n_clusters (23). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (10) found smaller than n_clusters (23). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (10) found smaller than n_clusters (23). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "role_labels, K=22 -> score(gmm, km)=(0.990, 0.990)\n",
      "role_labels, K=23 -> score(gmm, km)=(0.990, 0.990)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (10) found smaller than n_clusters (24). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (10) found smaller than n_clusters (24). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (10) found smaller than n_clusters (24). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (10) found smaller than n_clusters (24). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (10) found smaller than n_clusters (24). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (10) found smaller than n_clusters (24). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (10) found smaller than n_clusters (24). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (10) found smaller than n_clusters (24). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (10) found smaller than n_clusters (24). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (10) found smaller than n_clusters (24). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (10) found smaller than n_clusters (24). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (10) found smaller than n_clusters (25). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (10) found smaller than n_clusters (25). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (10) found smaller than n_clusters (25). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (10) found smaller than n_clusters (25). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (10) found smaller than n_clusters (25). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (10) found smaller than n_clusters (25). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (10) found smaller than n_clusters (25). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (10) found smaller than n_clusters (25). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (10) found smaller than n_clusters (25). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "role_labels, K=24 -> score(gmm, km)=(0.990, 0.990)\n",
      "role_labels, K=25 -> score(gmm, km)=(0.990, 0.990)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (10) found smaller than n_clusters (25). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (10) found smaller than n_clusters (25). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (10) found smaller than n_clusters (26). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (10) found smaller than n_clusters (26). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (10) found smaller than n_clusters (26). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (10) found smaller than n_clusters (26). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (10) found smaller than n_clusters (26). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (10) found smaller than n_clusters (26). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (10) found smaller than n_clusters (26). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (10) found smaller than n_clusters (26). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (10) found smaller than n_clusters (26). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (10) found smaller than n_clusters (26). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (10) found smaller than n_clusters (26). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (10) found smaller than n_clusters (27). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (10) found smaller than n_clusters (27). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (10) found smaller than n_clusters (27). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (10) found smaller than n_clusters (27). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "role_labels, K=26 -> score(gmm, km)=(0.990, 0.990)\n",
      "role_labels, K=27 -> score(gmm, km)=(0.990, 0.990)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (10) found smaller than n_clusters (27). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (10) found smaller than n_clusters (27). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (10) found smaller than n_clusters (27). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (10) found smaller than n_clusters (27). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (10) found smaller than n_clusters (27). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (10) found smaller than n_clusters (27). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (10) found smaller than n_clusters (27). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (10) found smaller than n_clusters (28). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (10) found smaller than n_clusters (28). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (10) found smaller than n_clusters (28). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (10) found smaller than n_clusters (28). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (10) found smaller than n_clusters (28). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (10) found smaller than n_clusters (28). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (10) found smaller than n_clusters (28). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (10) found smaller than n_clusters (28). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (10) found smaller than n_clusters (28). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (10) found smaller than n_clusters (28). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (10) found smaller than n_clusters (28). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "role_labels, K=28 -> score(gmm, km)=(0.990, 0.990)\n",
      "role_labels, K=29 -> score(gmm, km)=(0.990, 0.990)\n",
      "highest_troop, K=6 -> score(gmm, km)=(0.123, 0.228)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (10) found smaller than n_clusters (29). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (10) found smaller than n_clusters (29). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (10) found smaller than n_clusters (29). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (10) found smaller than n_clusters (29). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (10) found smaller than n_clusters (29). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (10) found smaller than n_clusters (29). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (10) found smaller than n_clusters (29). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (10) found smaller than n_clusters (29). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (10) found smaller than n_clusters (29). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (10) found smaller than n_clusters (29). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/marceloarcos/miniforge3/envs/clash-py311/lib/python3.11/site-packages/sklearn/base.py:1365: ConvergenceWarning: Number of distinct clusters (10) found smaller than n_clusters (29). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "highest_troop, K=7 -> score(gmm, km)=(0.220, 0.233)\n",
      "highest_troop, K=8 -> score(gmm, km)=(0.130, 0.237)\n",
      "highest_troop, K=9 -> score(gmm, km)=(0.083, 0.236)\n",
      "highest_troop, K=10 -> score(gmm, km)=(0.134, 0.235)\n",
      "highest_troop, K=11 -> score(gmm, km)=(0.120, 0.227)\n",
      "highest_troop, K=12 -> score(gmm, km)=(0.121, 0.247)\n",
      "highest_troop, K=13 -> score(gmm, km)=(0.141, 0.251)\n",
      "highest_troop, K=14 -> score(gmm, km)=(0.098, 0.270)\n",
      "highest_troop, K=15 -> score(gmm, km)=(0.126, 0.257)\n",
      "highest_troop, K=16 -> score(gmm, km)=(0.141, 0.254)\n",
      "highest_troop, K=17 -> score(gmm, km)=(0.100, 0.264)\n",
      "highest_troop, K=18 -> score(gmm, km)=(0.122, 0.261)\n",
      "highest_troop, K=19 -> score(gmm, km)=(0.205, 0.260)\n",
      "highest_troop, K=20 -> score(gmm, km)=(0.168, 0.263)\n",
      "highest_troop, K=21 -> score(gmm, km)=(0.159, 0.276)\n",
      "highest_troop, K=22 -> score(gmm, km)=(0.154, 0.267)\n",
      "highest_troop, K=23 -> score(gmm, km)=(0.171, 0.276)\n",
      "highest_troop, K=24 -> score(gmm, km)=(0.132, 0.275)\n",
      "highest_troop, K=25 -> score(gmm, km)=(0.206, 0.253)\n",
      "highest_troop, K=26 -> score(gmm, km)=(0.175, 0.261)\n",
      "highest_troop, K=27 -> score(gmm, km)=(0.196, 0.264)\n",
      "highest_troop, K=28 -> score(gmm, km)=(0.166, 0.256)\n",
      "highest_troop, K=29 -> score(gmm, km)=(0.189, 0.297)\n"
     ]
    }
   ],
   "source": [
    "for feature_group_name, col_list in list(feature_groups.items())[1:]:\n",
    "    for k in range(6, 30):\n",
    "        result = create_clusters('troop', k, col_list)\n",
    "        score = [result['sil_gmm'], result['sil_km']]\n",
    "        print(f\"{feature_group_name}, K={k} -> score(gmm, km)=({score[0]:.3f}, {score[1]:.3f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "3b914b60-c4f5-422f-89a4-6d0abb45aa69",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.25529890683483497, 0.28569148002718536, 6]\n",
      "[0.2842142903610734, 0.1379973898669904, 7]\n",
      "[0.31205214086515387, 0.22421136400073854, 8]\n",
      "[0.2675452139125733, 0.252850067555137, 9]\n",
      "[0.2746042222487986, 0.1817814525806021, 10]\n",
      "[0.25073284647827143, 0.11508405116162813, 11]\n",
      "[0.2742861102356721, 0.17418530656751977, 12]\n",
      "[0.2656102231929014, 0.11958772782510109, 13]\n",
      "[0.27501949608378534, 0.23575907020798617, 14]\n",
      "[0.2764905907174832, 0.15196420607138414, 15]\n",
      "[0.27762966740040296, 0.1564277167244731, 16]\n",
      "[0.26957840475446104, -0.008609694396590652, 17]\n",
      "[0.27124009298885815, 0.0335596909983225, 18]\n",
      "[0.2642181496999817, 0.1764340575693393, 19]\n",
      "[0.2842751375280769, 0.052428682501634516, 20]\n",
      "[0.27730208871123285, 0.12174053733123182, 21]\n",
      "[0.27921140626082797, 0.177704587348965, 22]\n",
      "[0.2821962959988222, 0.153847173877989, 23]\n",
      "[0.2978879173330056, 0.15371262811796407, 24]\n",
      "[0.2893897460668986, 0.15693325280658268, 25]\n",
      "[0.26324398604455496, 0.05667142035412106, 26]\n",
      "[0.28794713892553414, 0.08706952504636928, 27]\n",
      "[0.2902751729622305, 0.13982998061153004, 28]\n",
      "[0.2664237067134681, 0.13947485125441128, 29]\n"
     ]
    }
   ],
   "source": [
    "for k in range(6, 30):\n",
    "    test = create_clusters('troop', k, feature_groups['engineered_features'])\n",
    "    test = [test['sil_km'], test['sil_gmm'], k]\n",
    "    print(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7b66564-5f0a-4979-8c8c-a4e72bcd3a26",
   "metadata": {},
   "source": [
    "| Feature Group / Combo                     | Optimal K | Best Model   | Silhouette Score | Verdict / Notes                                |\n",
    "| ----------------------------------------- | --------- | ------------ | ---------------- | ---------------------------------------------- |\n",
    "| `core_identity`                           | 7         | GMM & KMeans | 0.980            | Tied; both strong â€“ choose either              |\n",
    "| `combat_core_stats`                       | 12        | KMeans       | 0.250            | GMM underperforms; use KMeans                  |\n",
    "| `targeting_behavior`                      | 3         | KMeans       | \\~0.24           | Simple categorical split                       |\n",
    "| `special_attack_mechanics`                | 18        | GMM          | **0.913**        | Exceptionally high score; use GMM              |\n",
    "| `boolean_effects_and_traits`              | 23        | GMM          | **0.800**        | Still climbing at high K; GMM preferred        |\n",
    "| `engineered_features`                     | 13        | KMeans       | \\~0.244          | GMM underperforms; KMeans stable and clean     |\n",
    "| `role_labels`                             | 10â€“13     | GMM & KMeans | **0.980**        | Saturates at 10; both models perfect           |\n",
    "| `highest_troop`                           | 21â€“23     | KMeans       | **0.276**        | Gradually climbs with K; KMeans clearly better |\n",
    "| `engineered + boolean_effects_and_traits` | 23        | KMeans       | **0.240**        | Stronger than lower K; GMM score too low       |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "cb2344e9-8f7a-4cf5-884e-f955d06c8536",
   "metadata": {},
   "outputs": [],
   "source": [
    "identity_clusters = create_clusters('troop', 8, feature_groups['core_identity']) # Dual\n",
    "combat_core_stats = create_clusters('troop', 12, feature_groups['combat_core_stats']) # Km\n",
    "targeting_behavior = create_clusters('troop', 3, feature_groups['targeting_behavior']) # Dual\n",
    "special_attack_mechanics = create_clusters('troop', 18, feature_groups['special_attack_mechanics']) # Dual\n",
    "boolean_effects_and_traits = create_clusters('troop', 23, feature_groups['boolean_effects_and_traits']) # Dual\n",
    "engineered_features_granular = create_clusters('troop', 24, feature_groups['engineered_features']) # Km\n",
    "engineered_features_tight = create_clusters('troop', 8, feature_groups['engineered_features']) # Km\n",
    "role_labels\t= create_clusters('troop', 9, feature_groups['role_labels']) # Dual\n",
    "highest_troop = create_clusters('troop', 23, feature_groups['highest_troop']) # Km\n",
    "engineered_and_boolean_effects_and_traits = create_clusters('troop', 9, feature_groups['engineered_features'] + feature_groups['boolean_effects_and_traits']) # Km"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "618eab85-60a8-4b94-8fd0-5ed390e44d6e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Cluster 0 (35 cards):\n",
      "Balloon, Bandit, Battle Healer, Berserker, Boss Bandit, Dark Prince, Electro Giant, Elite Barbarians, Elixir Golem, Fisherman, Giant, Giant Skeleton, Golden Knight, Golem, Guards, Hog Rider, Ice Golem, Knight, Lumberjack, Mega Knight, Mighty Miner, Miner, Mini P.E.K.K.A, Monk, Night Witch, P.E.K.K.A, Phoenix, Prince, Royal Ghost, Royal Hogs, Rune Giant, Skeleton Army, Skeleton King, Spirit Empress (Melee), Valkyrie\n",
      "\n",
      "Cluster 1 (9 cards):\n",
      "Bush Goblins, Cursed Hog, Elixir Blob, Elixir Golemite, Goblin Brawler, Golemite, Guardienne, Lava Pup, Reborn Phoenix\n",
      "\n",
      "Cluster 2 (39 cards):\n",
      "Archer Queen, Archers, Baby Dragon, Bomber, Bowler, Cannon Cart, Dart Goblin, Electro Dragon, Electro Wizard, Executioner, Firecracker, Flying Machine, Furnace, Goblin Demolisher, Goblin Gang, Goblin Giant, Goblin Machine, Goblinstein, Hunter, Ice Wizard, Inferno Dragon, Lava Hound, Little Prince, Magic Archer, Mega Minion, Minion Horde, Minions, Mother Witch, Musketeer, Princess, Ram Rider, Royal Giant, Skeleton Dragons, Sparky, Spirit Empress (Ranged), Three Musketeers, Witch, Wizard, Zappies\n",
      "\n",
      "Cluster 3 (1 cards):\n",
      "Suspicious Bush\n",
      "\n",
      "Cluster 4 (5 cards):\n",
      "Electro Spirit, Fire Spirit, Heal Spirit, Ice Spirit, Rascals\n",
      "\n",
      "Cluster 5 (6 cards):\n",
      "Barbarians, Bats, Goblins, Royal Recruits, Skeletons, Spear Goblins\n",
      "\n",
      "Cluster 6 (3 cards):\n",
      "Battle Ram, Skeleton Barrel, Wall Breakers\n",
      "\n",
      "Cluster 7 (3 cards):\n",
      "Monster, Rascal Boy, Rascal Girl\n",
      "0.9403995801751623\n"
     ]
    }
   ],
   "source": [
    "for i, cluster in enumerate(identity_clusters['clusters']):\n",
    "    print(f\"\\nCluster {i} ({len(cluster)} cards):\")\n",
    "    print(\", \".join(cluster))  # no .values or .flatten needed\n",
    "print(identity_clusters['sil_gmm'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "89a0915c-2322-426a-a77e-1af8ac4a3eb6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cluster_label_km</th>\n",
       "      <th>cluster_label_gmm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     cluster_label_km  cluster_label_gmm\n",
       "0                   2                  2\n",
       "1                   2                  2\n",
       "3                   2                  2\n",
       "4                   0                  0\n",
       "5                   0                  0\n",
       "8                   5                  5\n",
       "9                   5                  5\n",
       "10                  0                  0\n",
       "11                  6                  6\n",
       "12                  0                  0\n",
       "14                  2                  2\n",
       "15                  0                  0\n",
       "16                  2                  2\n",
       "18                  2                  2\n",
       "23                  0                  0\n",
       "24                  2                  2\n",
       "26                  2                  2\n",
       "27                  0                  0\n",
       "28                  4                  4\n",
       "29                  2                  2\n",
       "30                  0                  0\n",
       "32                  0                  0\n",
       "33                  2                  2\n",
       "34                  4                  4\n",
       "36                  2                  2\n",
       "37                  0                  0\n",
       "38                  2                  2\n",
       "40                  2                  2\n",
       "41                  0                  0\n",
       "42                  0                  0\n",
       "47                  2                  2\n",
       "49                  2                  2\n",
       "50                  2                  2\n",
       "52                  2                  2\n",
       "53                  5                  5\n",
       "54                  2                  2\n",
       "55                  0                  0\n",
       "56                  0                  0\n",
       "58                  0                  0\n",
       "59                  4                  4\n",
       "60                  0                  0\n",
       "61                  2                  2\n",
       "62                  0                  0\n",
       "63                  4                  4\n",
       "64                  2                  2\n",
       "65                  2                  2\n",
       "67                  0                  0\n",
       "68                  2                  2\n",
       "70                  2                  2\n",
       "71                  0                  0\n",
       "72                  2                  2\n",
       "73                  0                  0\n",
       "74                  2                  2\n",
       "75                  0                  0\n",
       "76                  0                  0\n",
       "77                  0                  0\n",
       "78                  2                  2\n",
       "79                  2                  2\n",
       "81                  0                  0\n",
       "83                  2                  2\n",
       "84                  2                  2\n",
       "85                  0                  0\n",
       "86                  0                  0\n",
       "87                  0                  0\n",
       "89                  0                  0\n",
       "90                  2                  2\n",
       "92                  2                  2\n",
       "93                  4                  4\n",
       "97                  0                  0\n",
       "98                  2                  2\n",
       "99                  0                  0\n",
       "100                 5                  5\n",
       "101                 0                  0\n",
       "102                 0                  0\n",
       "103                 6                  6\n",
       "104                 2                  2\n",
       "105                 0                  0\n",
       "106                 5                  5\n",
       "107                 2                  2\n",
       "108                 5                  5\n",
       "109                 0                  0\n",
       "110                 2                  2\n",
       "111                 3                  3\n",
       "114                 2                  2\n",
       "118                 0                  0\n",
       "121                 6                  6\n",
       "122                 2                  2\n",
       "123                 2                  2\n",
       "126                 2                  2\n",
       "127                 1                  1\n",
       "128                 1                  1\n",
       "129                 1                  1\n",
       "130                 1                  1\n",
       "131                 1                  1\n",
       "132                 1                  1\n",
       "133                 1                  1\n",
       "134                 1                  1\n",
       "135                 7                  7\n",
       "136                 1                  1\n",
       "137                 7                  7\n",
       "138                 7                  7"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def add_clusters(clusters, card_type, model=None):\n",
    "    X = cards[cards[f'is_{card_type}']].copy()\n",
    "    \n",
    "    # Always add both columns for consistency\n",
    "    X['cluster_label_km'] = clusters['km_labels']\n",
    "    X['cluster_label_gmm'] = clusters['gmm_labels']\n",
    "    \n",
    "    if model == 'km':\n",
    "        return X[['cluster_label_km']]\n",
    "    elif model == 'gmm':\n",
    "        return X[['cluster_label_gmm']]\n",
    "    else:\n",
    "        return X[['cluster_label_km', 'cluster_label_gmm']]\n",
    "\n",
    "add_clusters(identity_clusters, 'troop')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "c317bddd-0121-4cb7-9832-b131e6ae1f48",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'core_identity_km_labels': array([2, 2, 2, 0, 0, 5, 5, 0, 6, 0, 2, 0, 2, 2, 0, 2, 2, 0, 4, 2, 0, 0,\n",
       "        2, 4, 2, 0, 2, 2, 0, 0, 2, 2, 2, 2, 5, 2, 0, 0, 0, 4, 0, 2, 0, 4,\n",
       "        2, 2, 0, 2, 2, 0, 2, 0, 2, 0, 0, 0, 2, 2, 0, 2, 2, 0, 0, 0, 0, 2,\n",
       "        2, 4, 0, 2, 0, 5, 0, 0, 6, 2, 0, 5, 2, 5, 0, 2, 3, 2, 0, 6, 2, 2,\n",
       "        2, 1, 1, 1, 1, 1, 1, 1, 1, 7, 1, 7, 7], dtype=int32),\n",
       " 'core_identity_gmm_probs': array([2, 2, 2, 0, 0, 5, 5, 0, 6, 0, 2, 0, 2, 2, 0, 2, 2, 0, 4, 2, 0, 0,\n",
       "        2, 4, 2, 0, 2, 2, 0, 0, 2, 2, 2, 2, 5, 2, 0, 0, 0, 4, 0, 2, 0, 4,\n",
       "        2, 2, 0, 2, 2, 0, 2, 0, 2, 0, 0, 0, 2, 2, 0, 2, 2, 0, 0, 0, 0, 2,\n",
       "        2, 4, 0, 2, 0, 5, 0, 0, 6, 2, 0, 5, 2, 5, 0, 2, 3, 2, 0, 6, 2, 2,\n",
       "        2, 1, 1, 1, 1, 1, 1, 1, 1, 7, 1, 7, 7]),\n",
       " 'combat_core_stats_km_labels': array([ 4,  4,  4,  9,  7, 11,  2,  1,  1,  7,  4,  1, 10,  4,  1,  7, 10,\n",
       "         0,  8, 10,  1,  1, 10,  7, 10,  1,  4,  4,  0,  0,  4,  2,  0,  1,\n",
       "         2, 10,  1,  0,  2,  7,  7,  8,  5,  7,  4,  4,  1,  0,  4,  7,  4,\n",
       "         0,  1,  1,  7,  9, 11,  2,  1,  4,  4,  1,  9,  1,  1, 10,  1,  1,\n",
       "         1,  0,  2, 11,  1,  3,  7, 10,  1,  2,  6,  7,  1,  4,  5, 11,  1,\n",
       "         7,  4,  4, 10,  5,  7,  2,  5,  5,  5,  5,  2,  5,  5,  5,  4],\n",
       "       dtype=int32),\n",
       " 'combat_core_stats_gmm_probs': array([9, 4, 9, 9, 9, 2, 2, 9, 9, 9, 9, 9, 9, 9, 9, 9, 4, 9, 2, 4, 2, 9,\n",
       "        4, 9, 4, 9, 9, 9, 9, 9, 9, 2, 2, 1, 2, 4, 9, 9, 2, 9, 9, 2, 1, 9,\n",
       "        9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 2, 2, 9, 9, 9, 9, 9, 9, 9, 6,\n",
       "        2, 2, 9, 9, 2, 2, 9, 3, 9, 4, 9, 2, 6, 2, 9, 9, 1, 4, 9, 2, 9, 9,\n",
       "        4, 2, 9, 2, 1, 9, 1, 1, 2, 1, 1, 1, 4]),\n",
       " 'targeting_behavior_km_labels': array([1, 1, 1, 0, 2, 2, 1, 2, 0, 2, 2, 2, 2, 2, 2, 1, 1, 0, 1, 1, 2, 0,\n",
       "        1, 1, 1, 2, 1, 1, 0, 2, 2, 2, 0, 2, 2, 1, 2, 0, 2, 1, 0, 1, 0, 1,\n",
       "        1, 1, 2, 0, 1, 2, 1, 2, 1, 2, 2, 2, 1, 1, 2, 1, 1, 2, 2, 1, 2, 1,\n",
       "        0, 2, 2, 0, 0, 2, 0, 2, 0, 1, 2, 2, 2, 1, 2, 1, 0, 1, 2, 0, 1, 1,\n",
       "        1, 2, 0, 0, 0, 2, 0, 2, 1, 0, 1, 2, 1], dtype=int32),\n",
       " 'targeting_behavior_gmm_probs': array([1, 1, 1, 0, 2, 2, 1, 2, 0, 2, 2, 2, 2, 2, 2, 1, 1, 0, 1, 1, 2, 0,\n",
       "        1, 1, 1, 2, 1, 1, 0, 2, 2, 2, 0, 2, 2, 1, 2, 0, 2, 1, 0, 1, 0, 1,\n",
       "        1, 1, 2, 0, 1, 2, 1, 2, 1, 2, 2, 2, 1, 1, 2, 1, 1, 2, 2, 1, 2, 1,\n",
       "        0, 2, 2, 0, 0, 2, 0, 2, 0, 1, 2, 2, 2, 1, 2, 1, 0, 1, 2, 0, 1, 1,\n",
       "        1, 2, 0, 0, 0, 2, 0, 2, 1, 0, 1, 2, 1]),\n",
       " 'special_attack_mechanics_km_labels': array([11,  5,  8,  0,  6,  0,  0, 14, 10,  0,  8, 11,  1,  5, 12,  5,  9,\n",
       "        12,  9,  9,  0,  0,  7,  8,  7, 10,  5,  5,  0, 10,  1,  2,  2,  7,\n",
       "         0,  3,  3,  0,  0, 14,  0,  7, 10,  1,  1,  9,  0,  5,  3,  4,  1,\n",
       "        12,  5, 13,  0,  0,  5,  5, 13, 16,  5,  0,  0, 10, 10,  8,  9,  2,\n",
       "         6,  5,  0,  0,  4,  0, 17,  8, 15,  0,  8,  5,  0,  5,  6,  5, 17,\n",
       "        17,  8,  8, 16,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  5],\n",
       "       dtype=int32),\n",
       " 'special_attack_mechanics_gmm_probs': array([11,  5,  8,  0,  6,  0,  0, 14, 10,  0,  8, 11,  1,  5, 12,  5,  9,\n",
       "        12,  9,  9,  0,  0,  7,  8,  7, 10,  5,  5,  0, 10,  1,  2,  2,  7,\n",
       "         0,  3,  3,  0,  0, 14,  0,  7, 10,  1,  1,  9,  0,  5,  3,  4,  1,\n",
       "        12,  5, 13,  0,  0,  5,  5, 13, 16,  5,  0,  0, 10, 10,  8,  9,  2,\n",
       "         6,  5,  0,  0,  4,  0, 17,  8, 15,  0,  8,  5,  0,  5,  6,  5, 17,\n",
       "        17,  8,  8, 16,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  5]),\n",
       " 'boolean_effects_and_traits_km_labels': array([ 1, 13, 18, 14,  1, 13,  9, 12,  3,  1,  0,  1, 12,  1,  5, 13,  7,\n",
       "        12,  8, 20,  1,  2, 10, 12, 10,  1,  9,  6,  1, 14,  4, 20, 21, 10,\n",
       "         1,  1,  1, 16,  5, 12,  1, 10, 14,  0, 22,  7, 13,  2, 19, 16, 12,\n",
       "         0,  9,  8,  1,  1,  9,  9,  8, 19, 13, 15, 13, 11,  1, 12,  8, 20,\n",
       "        12, 13,  1,  5,  1,  1, 11, 18, 22, 13, 12,  1,  1,  7, 17,  1,  0,\n",
       "         0,  6,  0,  1,  1,  1,  1,  2,  1, 14,  1,  9,  1,  9,  1,  1],\n",
       "       dtype=int32),\n",
       " 'boolean_effects_and_traits_gmm_probs': array([ 1, 13, 18, 14,  1, 13,  9, 12,  3,  1,  0,  1, 12,  1,  5, 13,  7,\n",
       "        12,  8, 20,  1,  2, 10, 12, 10,  1,  9,  6,  1, 14,  4, 20, 21, 10,\n",
       "         1,  1,  1, 16,  5, 12,  1, 10, 14,  0, 22,  7, 13,  2, 19, 16, 12,\n",
       "         0,  9,  8,  1,  1,  9,  9,  8, 19, 13, 15, 13, 11,  1, 12,  8, 20,\n",
       "        12, 13,  1,  5,  1,  1, 11, 18, 22, 13, 12,  1,  1,  7, 17,  1,  0,\n",
       "         0,  6,  0,  1,  1,  1,  1,  2,  1, 14,  1,  9,  1,  9,  1,  1]),\n",
       " 'engineered_features_granular_km_labels': array([12, 17,  7,  2, 10,  9, 17, 23, 20, 10, 19,  0,  0, 13,  0, 17, 17,\n",
       "        23,  2,  1,  4, 10,  7, 14, 16,  1,  1,  1, 10,  0,  7,  9, 10, 13,\n",
       "        17,  1, 10, 10, 17,  8, 10, 16,  6,  8,  7,  6, 13,  1,  1,  4,  1,\n",
       "         0, 12,  6, 10, 18,  9, 17, 10,  1, 12,  4, 18, 22,  0, 11, 20,  1,\n",
       "        13, 10,  1,  9, 10, 21,  7,  7, 13, 17,  3, 17,  4, 12,  1, 12, 13,\n",
       "        15,  7,  5,  1,  4,  1,  1,  1,  4,  1, 13, 17,  1,  1, 13, 17],\n",
       "       dtype=int32),\n",
       " 'engineered_features_granular_gmm_probs': array([12, 17,  7,  2, 10,  9, 17, 23, 20, 10, 19,  4,  4,  4,  0, 17,  1,\n",
       "        23,  2, 17,  4, 10,  7, 14, 16, 10, 17, 10, 10,  0,  7,  9, 10, 13,\n",
       "         9, 10, 10, 10, 17,  8, 10, 16,  6,  8,  7,  6, 13, 10, 10,  4,  1,\n",
       "         0, 12,  6, 10,  4,  9, 17, 10, 17, 12,  4, 18, 22,  4, 11, 20,  1,\n",
       "        13, 10, 17,  9, 10, 21,  1,  7, 13, 17,  3, 17,  4, 12, 17, 12, 13,\n",
       "        15,  7,  5, 17,  4, 17, 17, 17,  4, 17,  4, 17, 17, 17,  4, 17]),\n",
       " 'engineered_features_tight_km_labels': array([4, 0, 0, 1, 0, 2, 2, 0, 6, 0, 3, 6, 6, 1, 6, 0, 0, 0, 2, 0, 1, 0,\n",
       "        0, 3, 5, 0, 0, 0, 0, 6, 0, 2, 0, 1, 2, 0, 0, 0, 2, 3, 0, 5, 5, 3,\n",
       "        0, 5, 1, 0, 0, 1, 0, 6, 4, 5, 0, 1, 2, 2, 0, 0, 4, 1, 1, 4, 6, 3,\n",
       "        6, 0, 1, 0, 0, 2, 0, 2, 0, 0, 1, 2, 7, 0, 1, 4, 0, 4, 1, 3, 0, 4,\n",
       "        0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0], dtype=int32),\n",
       " 'engineered_features_tight_gmm_probs': array([4, 2, 0, 2, 2, 2, 2, 0, 6, 2, 0, 6, 6, 2, 6, 2, 2, 0, 2, 2, 2, 2,\n",
       "        0, 7, 5, 2, 2, 2, 2, 6, 0, 2, 2, 0, 2, 2, 2, 2, 2, 0, 2, 5, 5, 0,\n",
       "        0, 5, 2, 2, 2, 2, 0, 6, 7, 5, 2, 2, 2, 2, 2, 2, 4, 2, 2, 6, 6, 0,\n",
       "        6, 2, 0, 2, 2, 2, 2, 2, 0, 0, 0, 2, 7, 2, 2, 4, 2, 7, 0, 0, 0, 4,\n",
       "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]),\n",
       " 'role_labels_km_labels': array([2, 1, 1, 0, 1, 1, 1, 4, 0, 1, 2, 2, 2, 2, 6, 1, 1, 5, 1, 1, 2, 8,\n",
       "        1, 2, 1, 1, 1, 1, 0, 2, 4, 1, 5, 2, 1, 1, 4, 0, 1, 1, 8, 1, 7, 1,\n",
       "        1, 4, 6, 5, 1, 6, 1, 2, 2, 4, 1, 6, 1, 1, 1, 1, 2, 2, 2, 2, 2, 1,\n",
       "        0, 1, 2, 0, 5, 1, 7, 1, 5, 1, 6, 1, 2, 1, 2, 2, 3, 2, 6, 0, 1, 2,\n",
       "        1, 2, 3, 3, 5, 2, 3, 6, 3, 7, 1, 6, 1], dtype=int32),\n",
       " 'role_labels_gmm_probs': array([2, 1, 1, 0, 1, 1, 1, 4, 0, 1, 2, 2, 2, 2, 6, 1, 1, 5, 1, 1, 2, 8,\n",
       "        1, 2, 1, 1, 1, 1, 0, 2, 4, 1, 5, 2, 1, 1, 4, 0, 1, 1, 8, 1, 7, 1,\n",
       "        1, 4, 6, 5, 1, 6, 1, 2, 2, 4, 1, 6, 1, 1, 1, 1, 2, 2, 2, 2, 2, 1,\n",
       "        0, 1, 2, 0, 5, 1, 7, 1, 5, 1, 6, 1, 2, 1, 2, 2, 3, 2, 6, 0, 1, 2,\n",
       "        1, 2, 3, 3, 5, 2, 3, 6, 3, 7, 1, 6, 1]),\n",
       " 'highest_troop_km_labels': array([ 7,  3, 10, 13,  0, 14, 22,  2, 16,  0, 10, 18, 20, 19,  4,  3,  3,\n",
       "        17, 15,  1, 14, 11, 10, 10, 10,  0,  3,  1, 17,  4, 10, 12,  6,  2,\n",
       "        22,  7,  8,  6, 22, 10, 17, 15,  5, 10,  1,  3,  0,  6,  7, 12, 10,\n",
       "         4,  3,  8,  0, 13, 14,  3,  8,  1,  3, 12, 13, 16,  4, 10, 20, 12,\n",
       "         2, 17, 17, 14, 17,  9, 11, 10, 21, 22, 19,  3,  0, 19,  5, 19,  2,\n",
       "        11,  1, 10,  3,  0,  5,  5, 11,  0,  5,  0, 22,  5,  0,  0,  3],\n",
       "       dtype=int32),\n",
       " 'highest_troop_gmm_probs': array([ 7,  3, 10,  5, 22, 22, 22,  2, 16, 22, 10, 18, 20, 19, 20,  3,  3,\n",
       "         5, 15, 19, 22, 11, 10, 10,  2, 22,  3, 19, 17,  4, 10,  1,  6,  2,\n",
       "        22,  7,  8, 11, 22, 10,  5, 15,  5, 10,  1,  3, 22,  6,  7, 12, 10,\n",
       "        20,  3,  8, 22, 22, 14,  3,  8, 19,  3, 12, 22, 16,  4, 10, 20,  1,\n",
       "         2, 17, 14, 22,  5,  9, 11, 10, 21, 22, 19,  3, 22,  3, 17, 19,  2,\n",
       "         5,  1, 10,  3, 22,  5,  5, 11, 22,  5, 22, 22,  5, 22, 22,  3]),\n",
       " 'engineered_and_boolean_km_labels': array([6, 6, 6, 1, 6, 1, 1, 4, 8, 6, 4, 0, 0, 6, 0, 6, 6, 6, 1, 6, 1, 2,\n",
       "        6, 4, 7, 6, 6, 5, 6, 0, 3, 1, 2, 6, 1, 6, 6, 2, 1, 4, 6, 7, 7, 4,\n",
       "        6, 7, 6, 2, 6, 2, 6, 0, 6, 7, 6, 1, 1, 6, 6, 6, 6, 5, 1, 2, 0, 4,\n",
       "        0, 6, 6, 6, 6, 1, 6, 1, 2, 6, 6, 1, 4, 6, 6, 6, 8, 1, 4, 4, 5, 4,\n",
       "        6, 1, 6, 6, 2, 6, 6, 6, 6, 6, 6, 6, 6], dtype=int32),\n",
       " 'engineered_and_boolean_gmm_probs': array([6, 1, 6, 6, 1, 1, 1, 4, 8, 1, 4, 0, 0, 1, 0, 1, 6, 6, 1, 1, 1, 2,\n",
       "        6, 4, 7, 1, 1, 5, 1, 0, 3, 1, 2, 1, 1, 1, 1, 2, 1, 4, 1, 7, 7, 4,\n",
       "        6, 7, 1, 2, 6, 2, 6, 0, 6, 7, 1, 1, 1, 1, 6, 6, 6, 5, 1, 2, 0, 4,\n",
       "        6, 1, 6, 1, 1, 1, 1, 1, 2, 6, 6, 1, 4, 1, 1, 6, 8, 6, 4, 4, 5, 4,\n",
       "        1, 1, 1, 1, 2, 1, 6, 1, 1, 1, 1, 1, 1])}"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "troop_cluster_configs = {\n",
    "    'core_identity': (8, 'dual'),\n",
    "    'combat_core_stats': (12, 'km'),\n",
    "    'targeting_behavior': (3, 'dual'),\n",
    "    'special_attack_mechanics': (18, 'dual'),\n",
    "    'boolean_effects_and_traits': (23, 'dual'),\n",
    "    'engineered_features_granular': (24, 'km'),\n",
    "    'engineered_features_tight': (8, 'km'),\n",
    "    'role_labels': (9, 'dual'),\n",
    "    'highest_troop': (23, 'km'),\n",
    "    'engineered_and_boolean': (9, 'km')\n",
    "}\n",
    "\n",
    "n_clusters = [identity_clusters, combat_core_stats, targeting_behavior, special_attack_mechanics, \n",
    "              boolean_effects_and_traits, engineered_features_granular, engineered_features_tight,\n",
    "              role_labels, highest_troop, engineered_and_boolean_effects_and_traits]\n",
    "\n",
    "dict_clusters = {}\n",
    "for (feature_group_name, (_, model_type)), cluster_result in zip(troop_cluster_configs.items(), n_clusters):\n",
    "    if model_type == 'km':\n",
    "        dict_clusters[f'{feature_group_name}_km_labels'] = cluster_result['km_labels']\n",
    "    if model_type == 'gmm':\n",
    "        dict_clusters[f'{feature_group_name}_gmm_probs'] = cluster_result['gmm_labels']\n",
    "    else: \n",
    "        dict_clusters[f'{feature_group_name}_km_labels'] = cluster_result['km_labels']\n",
    "        dict_clusters[f'{feature_group_name}_gmm_probs'] = cluster_result['gmm_labels']\n",
    "dict_clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "549a8826-31a1-476c-853c-1eae6da8a04c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>playable</th>\n",
       "      <th>aoe_bool</th>\n",
       "      <th>aoe_radius</th>\n",
       "      <th>death_damage_bool</th>\n",
       "      <th>fly_bool</th>\n",
       "      <th>spawn_bool</th>\n",
       "      <th>can_evolve</th>\n",
       "      <th>elixircost</th>\n",
       "      <th>hit_speed</th>\n",
       "      <th>special_damage</th>\n",
       "      <th>count</th>\n",
       "      <th>hitpoints</th>\n",
       "      <th>shield_bool</th>\n",
       "      <th>damage</th>\n",
       "      <th>attack_count</th>\n",
       "      <th>range</th>\n",
       "      <th>affected_crown</th>\n",
       "      <th>has_lifetime</th>\n",
       "      <th>invisible</th>\n",
       "      <th>has_ability</th>\n",
       "      <th>any_target</th>\n",
       "      <th>building_target</th>\n",
       "      <th>ground_target</th>\n",
       "      <th>has_upon_breaking_spawn</th>\n",
       "      <th>has_upon_death_spawn</th>\n",
       "      <th>has_periodic_spawn</th>\n",
       "      <th>single_damage_type</th>\n",
       "      <th>is_troop</th>\n",
       "      <th>is_spell</th>\n",
       "      <th>is_building</th>\n",
       "      <th>is_tower_troop</th>\n",
       "      <th>is_spawned</th>\n",
       "      <th>speed</th>\n",
       "      <th>has_ranged_attack</th>\n",
       "      <th>special_attack_type</th>\n",
       "      <th>has_friendly_buff</th>\n",
       "      <th>is_free_card</th>\n",
       "      <th>no_hit_speed</th>\n",
       "      <th>no_attack</th>\n",
       "      <th>no_hitpoints</th>\n",
       "      <th>damage_per_elixir</th>\n",
       "      <th>damage_per_second</th>\n",
       "      <th>damage_output</th>\n",
       "      <th>hp_per_elixir</th>\n",
       "      <th>damage_by_hitpoints</th>\n",
       "      <th>aoe_by_range</th>\n",
       "      <th>aoe_by_damage</th>\n",
       "      <th>win_con</th>\n",
       "      <th>aoe_per_elixir</th>\n",
       "      <th>control_special</th>\n",
       "      <th>dps_special</th>\n",
       "      <th>air_control</th>\n",
       "      <th>ground_dps</th>\n",
       "      <th>win_con_dmg</th>\n",
       "      <th>high_dps</th>\n",
       "      <th>damage_output_ps</th>\n",
       "      <th>support</th>\n",
       "      <th>mini_tank</th>\n",
       "      <th>core_identity_km_labels</th>\n",
       "      <th>core_identity_gmm_probs</th>\n",
       "      <th>combat_core_stats_km_labels</th>\n",
       "      <th>combat_core_stats_gmm_probs</th>\n",
       "      <th>targeting_behavior_km_labels</th>\n",
       "      <th>targeting_behavior_gmm_probs</th>\n",
       "      <th>special_attack_mechanics_km_labels</th>\n",
       "      <th>special_attack_mechanics_gmm_probs</th>\n",
       "      <th>boolean_effects_and_traits_km_labels</th>\n",
       "      <th>boolean_effects_and_traits_gmm_probs</th>\n",
       "      <th>engineered_features_granular_km_labels</th>\n",
       "      <th>engineered_features_granular_gmm_probs</th>\n",
       "      <th>engineered_features_tight_km_labels</th>\n",
       "      <th>engineered_features_tight_gmm_probs</th>\n",
       "      <th>role_labels_km_labels</th>\n",
       "      <th>role_labels_gmm_probs</th>\n",
       "      <th>highest_troop_km_labels</th>\n",
       "      <th>highest_troop_gmm_probs</th>\n",
       "      <th>engineered_and_boolean_km_labels</th>\n",
       "      <th>engineered_and_boolean_gmm_probs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.00</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>False</td>\n",
       "      <td>225.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.00</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1.2</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>187.500000</td>\n",
       "      <td>225.0</td>\n",
       "      <td>200.000000</td>\n",
       "      <td>0.225000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>187.500000</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.00</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>False</td>\n",
       "      <td>2.0</td>\n",
       "      <td>304.0</td>\n",
       "      <td>False</td>\n",
       "      <td>112.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.00</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1.2</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>37.333333</td>\n",
       "      <td>124.444444</td>\n",
       "      <td>224.0</td>\n",
       "      <td>101.333333</td>\n",
       "      <td>0.368421</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>248.888889</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>3.50</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.3</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1019.5</td>\n",
       "      <td>False</td>\n",
       "      <td>122.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.60</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1.2</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>40.666667</td>\n",
       "      <td>136.000000</td>\n",
       "      <td>366.0</td>\n",
       "      <td>339.833333</td>\n",
       "      <td>0.173387</td>\n",
       "      <td>5.60</td>\n",
       "      <td>427.00</td>\n",
       "      <td>False</td>\n",
       "      <td>1.166667</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>187.500000</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>1.20</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1152.0</td>\n",
       "      <td>False</td>\n",
       "      <td>161.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.50</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1.8</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>40.250000</td>\n",
       "      <td>107.333333</td>\n",
       "      <td>161.0</td>\n",
       "      <td>288.000000</td>\n",
       "      <td>0.139757</td>\n",
       "      <td>4.20</td>\n",
       "      <td>193.20</td>\n",
       "      <td>False</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>107.333333</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.00</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1679.0</td>\n",
       "      <td>False</td>\n",
       "      <td>640.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.10</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1.2</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>128.000000</td>\n",
       "      <td>320.000000</td>\n",
       "      <td>640.0</td>\n",
       "      <td>335.800000</td>\n",
       "      <td>0.381179</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>True</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>320.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.00</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>1.0</td>\n",
       "      <td>906.0</td>\n",
       "      <td>False</td>\n",
       "      <td>194.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.75</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1.8</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>64.666667</td>\n",
       "      <td>194.000000</td>\n",
       "      <td>194.0</td>\n",
       "      <td>302.000000</td>\n",
       "      <td>0.214128</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>194.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.00</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.3</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1019.5</td>\n",
       "      <td>False</td>\n",
       "      <td>240.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.60</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1.2</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>120.000000</td>\n",
       "      <td>136.000000</td>\n",
       "      <td>240.0</td>\n",
       "      <td>509.750000</td>\n",
       "      <td>0.173387</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>187.500000</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.00</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.3</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1164.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.60</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>136.000000</td>\n",
       "      <td>250.0</td>\n",
       "      <td>194.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>187.500000</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.00</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.3</td>\n",
       "      <td>False</td>\n",
       "      <td>5.0</td>\n",
       "      <td>670.0</td>\n",
       "      <td>False</td>\n",
       "      <td>192.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.70</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>1.2</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>38.400000</td>\n",
       "      <td>147.692308</td>\n",
       "      <td>960.0</td>\n",
       "      <td>134.000000</td>\n",
       "      <td>0.286567</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>738.461538</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.00</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.3</td>\n",
       "      <td>False</td>\n",
       "      <td>5.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>False</td>\n",
       "      <td>81.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.20</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>2.4</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>40.500000</td>\n",
       "      <td>62.307692</td>\n",
       "      <td>405.0</td>\n",
       "      <td>40.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>311.538462</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>4.00</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1717.0</td>\n",
       "      <td>False</td>\n",
       "      <td>148.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.60</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1.2</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>98.666667</td>\n",
       "      <td>148.0</td>\n",
       "      <td>429.250000</td>\n",
       "      <td>0.086197</td>\n",
       "      <td>6.40</td>\n",
       "      <td>592.00</td>\n",
       "      <td>False</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>98.666667</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.00</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.3</td>\n",
       "      <td>True</td>\n",
       "      <td>1.0</td>\n",
       "      <td>967.0</td>\n",
       "      <td>False</td>\n",
       "      <td>286.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.50</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1.2</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>71.500000</td>\n",
       "      <td>136.000000</td>\n",
       "      <td>286.0</td>\n",
       "      <td>241.750000</td>\n",
       "      <td>0.295760</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>True</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>187.500000</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.00</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>896.0</td>\n",
       "      <td>False</td>\n",
       "      <td>102.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.80</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1.8</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>51.000000</td>\n",
       "      <td>204.000000</td>\n",
       "      <td>102.0</td>\n",
       "      <td>448.000000</td>\n",
       "      <td>0.113839</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>204.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>1.50</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.8</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1356.0</td>\n",
       "      <td>False</td>\n",
       "      <td>222.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.00</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>55.500000</td>\n",
       "      <td>123.333333</td>\n",
       "      <td>222.0</td>\n",
       "      <td>339.000000</td>\n",
       "      <td>0.163717</td>\n",
       "      <td>9.00</td>\n",
       "      <td>333.00</td>\n",
       "      <td>False</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>123.333333</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>1.50</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.8</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>332.0</td>\n",
       "      <td>False</td>\n",
       "      <td>225.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.50</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1.2</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>112.500000</td>\n",
       "      <td>125.000000</td>\n",
       "      <td>225.0</td>\n",
       "      <td>166.000000</td>\n",
       "      <td>0.677711</td>\n",
       "      <td>6.75</td>\n",
       "      <td>337.50</td>\n",
       "      <td>False</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>125.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.00</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>True</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2624.0</td>\n",
       "      <td>False</td>\n",
       "      <td>268.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.80</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1.8</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>44.666667</td>\n",
       "      <td>223.333333</td>\n",
       "      <td>268.0</td>\n",
       "      <td>437.333333</td>\n",
       "      <td>0.102134</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>223.333333</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.00</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>True</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2081.0</td>\n",
       "      <td>False</td>\n",
       "      <td>289.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.00</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.9</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>57.800000</td>\n",
       "      <td>115.600000</td>\n",
       "      <td>289.0</td>\n",
       "      <td>416.200000</td>\n",
       "      <td>0.138876</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>115.600000</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.00</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>824.0</td>\n",
       "      <td>False</td>\n",
       "      <td>212.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.50</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>70.666667</td>\n",
       "      <td>212.000000</td>\n",
       "      <td>212.0</td>\n",
       "      <td>274.666667</td>\n",
       "      <td>0.257282</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>212.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.00</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1809.0</td>\n",
       "      <td>False</td>\n",
       "      <td>212.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.50</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1.2</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>42.400000</td>\n",
       "      <td>235.555556</td>\n",
       "      <td>212.0</td>\n",
       "      <td>361.800000</td>\n",
       "      <td>0.117192</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>235.555556</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.00</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>824.0</td>\n",
       "      <td>False</td>\n",
       "      <td>212.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.50</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>42.575000</td>\n",
       "      <td>235.555556</td>\n",
       "      <td>212.0</td>\n",
       "      <td>270.666667</td>\n",
       "      <td>0.257282</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>235.555556</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.00</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.2</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2616.0</td>\n",
       "      <td>False</td>\n",
       "      <td>320.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.50</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>42.575000</td>\n",
       "      <td>145.454545</td>\n",
       "      <td>320.0</td>\n",
       "      <td>270.666667</td>\n",
       "      <td>0.122324</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>145.454545</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>3.00</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.3</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1019.5</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.60</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1.2</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>136.000000</td>\n",
       "      <td>250.0</td>\n",
       "      <td>339.833333</td>\n",
       "      <td>0.173387</td>\n",
       "      <td>4.80</td>\n",
       "      <td>0.00</td>\n",
       "      <td>False</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>187.500000</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.00</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2768.0</td>\n",
       "      <td>False</td>\n",
       "      <td>107.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.50</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>42.575000</td>\n",
       "      <td>214.000000</td>\n",
       "      <td>107.0</td>\n",
       "      <td>270.666667</td>\n",
       "      <td>0.038656</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>214.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>1.10</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.3</td>\n",
       "      <td>True</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1440.0</td>\n",
       "      <td>True</td>\n",
       "      <td>266.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.20</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1.2</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>66.500000</td>\n",
       "      <td>204.615385</td>\n",
       "      <td>266.0</td>\n",
       "      <td>360.000000</td>\n",
       "      <td>0.184722</td>\n",
       "      <td>1.32</td>\n",
       "      <td>292.60</td>\n",
       "      <td>False</td>\n",
       "      <td>0.275000</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>204.615385</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.00</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>261.0</td>\n",
       "      <td>False</td>\n",
       "      <td>156.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.50</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2.4</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>52.000000</td>\n",
       "      <td>195.000000</td>\n",
       "      <td>156.0</td>\n",
       "      <td>87.000000</td>\n",
       "      <td>0.597701</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>195.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>3.50</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.3</td>\n",
       "      <td>True</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1019.5</td>\n",
       "      <td>False</td>\n",
       "      <td>81.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.60</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1.2</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>136.000000</td>\n",
       "      <td>243.0</td>\n",
       "      <td>339.833333</td>\n",
       "      <td>0.173387</td>\n",
       "      <td>5.60</td>\n",
       "      <td>283.50</td>\n",
       "      <td>False</td>\n",
       "      <td>1.166667</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>187.500000</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.00</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.1</td>\n",
       "      <td>True</td>\n",
       "      <td>1.0</td>\n",
       "      <td>949.0</td>\n",
       "      <td>False</td>\n",
       "      <td>192.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.50</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1.2</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>38.400000</td>\n",
       "      <td>91.428571</td>\n",
       "      <td>576.0</td>\n",
       "      <td>189.800000</td>\n",
       "      <td>0.202318</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>274.285714</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>3.00</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.1</td>\n",
       "      <td>True</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3855.0</td>\n",
       "      <td>False</td>\n",
       "      <td>163.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.20</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.9</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>23.285714</td>\n",
       "      <td>77.619048</td>\n",
       "      <td>163.0</td>\n",
       "      <td>550.714286</td>\n",
       "      <td>0.042283</td>\n",
       "      <td>3.60</td>\n",
       "      <td>489.00</td>\n",
       "      <td>True</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>77.619048</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.00</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.3</td>\n",
       "      <td>True</td>\n",
       "      <td>1.0</td>\n",
       "      <td>230.0</td>\n",
       "      <td>False</td>\n",
       "      <td>99.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2.50</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2.4</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>136.000000</td>\n",
       "      <td>891.0</td>\n",
       "      <td>230.000000</td>\n",
       "      <td>0.430435</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>187.500000</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.00</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.8</td>\n",
       "      <td>True</td>\n",
       "      <td>1.0</td>\n",
       "      <td>714.0</td>\n",
       "      <td>False</td>\n",
       "      <td>115.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.00</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1.8</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>28.750000</td>\n",
       "      <td>63.888889</td>\n",
       "      <td>230.0</td>\n",
       "      <td>178.500000</td>\n",
       "      <td>0.161064</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>127.777778</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.00</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>False</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1341.0</td>\n",
       "      <td>False</td>\n",
       "      <td>384.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.20</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1.8</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>274.285714</td>\n",
       "      <td>768.0</td>\n",
       "      <td>223.500000</td>\n",
       "      <td>0.286353</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>548.571429</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.00</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.3</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1070.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.60</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>136.000000</td>\n",
       "      <td>250.0</td>\n",
       "      <td>178.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>187.500000</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.00</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.1</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1569.0</td>\n",
       "      <td>False</td>\n",
       "      <td>253.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.80</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.9</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>84.333333</td>\n",
       "      <td>230.000000</td>\n",
       "      <td>253.0</td>\n",
       "      <td>523.000000</td>\n",
       "      <td>0.161249</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>True</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>230.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>1.00</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.4</td>\n",
       "      <td>True</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1280.0</td>\n",
       "      <td>False</td>\n",
       "      <td>168.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.50</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1.2</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>33.600000</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>336.0</td>\n",
       "      <td>256.000000</td>\n",
       "      <td>0.131250</td>\n",
       "      <td>4.50</td>\n",
       "      <td>168.00</td>\n",
       "      <td>False</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>140.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>2.30</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.3</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>230.0</td>\n",
       "      <td>False</td>\n",
       "      <td>207.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.50</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>2.4</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>207.000000</td>\n",
       "      <td>136.000000</td>\n",
       "      <td>207.0</td>\n",
       "      <td>230.000000</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>5.75</td>\n",
       "      <td>476.10</td>\n",
       "      <td>False</td>\n",
       "      <td>2.300000</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>187.500000</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>2.50</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.3</td>\n",
       "      <td>True</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1019.5</td>\n",
       "      <td>False</td>\n",
       "      <td>688.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.60</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1.2</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>172.000000</td>\n",
       "      <td>136.000000</td>\n",
       "      <td>688.0</td>\n",
       "      <td>254.875000</td>\n",
       "      <td>0.173387</td>\n",
       "      <td>4.00</td>\n",
       "      <td>1720.00</td>\n",
       "      <td>False</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>187.500000</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.40</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>True</td>\n",
       "      <td>1.0</td>\n",
       "      <td>304.0</td>\n",
       "      <td>False</td>\n",
       "      <td>64.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.00</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1.8</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>21.333333</td>\n",
       "      <td>21.333333</td>\n",
       "      <td>320.0</td>\n",
       "      <td>101.333333</td>\n",
       "      <td>0.210526</td>\n",
       "      <td>2.40</td>\n",
       "      <td>25.60</td>\n",
       "      <td>False</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>106.666667</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.00</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.3</td>\n",
       "      <td>True</td>\n",
       "      <td>1.0</td>\n",
       "      <td>870.0</td>\n",
       "      <td>False</td>\n",
       "      <td>194.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.20</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1.2</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>64.666667</td>\n",
       "      <td>149.230769</td>\n",
       "      <td>194.0</td>\n",
       "      <td>290.000000</td>\n",
       "      <td>0.222989</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>149.230769</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.00</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.1</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>614.0</td>\n",
       "      <td>False</td>\n",
       "      <td>171.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.00</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1.8</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>42.750000</td>\n",
       "      <td>155.454545</td>\n",
       "      <td>171.0</td>\n",
       "      <td>153.500000</td>\n",
       "      <td>0.278502</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>155.454545</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>3.00</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.3</td>\n",
       "      <td>True</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1019.5</td>\n",
       "      <td>False</td>\n",
       "      <td>115.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.60</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1.2</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>28.750000</td>\n",
       "      <td>136.000000</td>\n",
       "      <td>115.0</td>\n",
       "      <td>254.875000</td>\n",
       "      <td>0.173387</td>\n",
       "      <td>4.80</td>\n",
       "      <td>345.00</td>\n",
       "      <td>False</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>187.500000</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.00</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.8</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>896.0</td>\n",
       "      <td>False</td>\n",
       "      <td>135.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.00</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.9</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>33.750000</td>\n",
       "      <td>75.000000</td>\n",
       "      <td>135.0</td>\n",
       "      <td>224.000000</td>\n",
       "      <td>0.150670</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>75.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.00</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4090.0</td>\n",
       "      <td>False</td>\n",
       "      <td>253.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.20</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.9</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>50.600000</td>\n",
       "      <td>168.666667</td>\n",
       "      <td>253.0</td>\n",
       "      <td>818.000000</td>\n",
       "      <td>0.061858</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>True</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>168.666667</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.00</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>True</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3617.0</td>\n",
       "      <td>False</td>\n",
       "      <td>276.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.80</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1.2</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>46.000000</td>\n",
       "      <td>197.142857</td>\n",
       "      <td>276.0</td>\n",
       "      <td>602.833333</td>\n",
       "      <td>0.076306</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>197.142857</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>2.50</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.3</td>\n",
       "      <td>True</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1019.5</td>\n",
       "      <td>False</td>\n",
       "      <td>179.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.60</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1.2</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>89.500000</td>\n",
       "      <td>136.000000</td>\n",
       "      <td>179.0</td>\n",
       "      <td>509.750000</td>\n",
       "      <td>0.173387</td>\n",
       "      <td>4.00</td>\n",
       "      <td>447.50</td>\n",
       "      <td>False</td>\n",
       "      <td>1.250000</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>187.500000</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>1.50</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.3</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1019.5</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.60</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1.2</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>136.000000</td>\n",
       "      <td>250.0</td>\n",
       "      <td>339.833333</td>\n",
       "      <td>0.173387</td>\n",
       "      <td>2.40</td>\n",
       "      <td>0.00</td>\n",
       "      <td>False</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>187.500000</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.00</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.3</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>780.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.60</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>136.000000</td>\n",
       "      <td>250.0</td>\n",
       "      <td>195.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>187.500000</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>3.00</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.3</td>\n",
       "      <td>True</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1019.5</td>\n",
       "      <td>False</td>\n",
       "      <td>35.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.60</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1.2</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>17.500000</td>\n",
       "      <td>136.000000</td>\n",
       "      <td>210.0</td>\n",
       "      <td>509.750000</td>\n",
       "      <td>0.173387</td>\n",
       "      <td>4.80</td>\n",
       "      <td>105.00</td>\n",
       "      <td>False</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>187.500000</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>1.00</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>True</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1300.0</td>\n",
       "      <td>False</td>\n",
       "      <td>186.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.00</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1.2</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>46.500000</td>\n",
       "      <td>155.000000</td>\n",
       "      <td>186.0</td>\n",
       "      <td>325.000000</td>\n",
       "      <td>0.143077</td>\n",
       "      <td>5.00</td>\n",
       "      <td>186.00</td>\n",
       "      <td>False</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>155.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.00</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.3</td>\n",
       "      <td>True</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1313.0</td>\n",
       "      <td>False</td>\n",
       "      <td>84.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.60</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>136.000000</td>\n",
       "      <td>84.0</td>\n",
       "      <td>328.250000</td>\n",
       "      <td>0.063976</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>187.500000</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.00</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.1</td>\n",
       "      <td>False</td>\n",
       "      <td>6.0</td>\n",
       "      <td>202.0</td>\n",
       "      <td>False</td>\n",
       "      <td>120.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.60</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2.4</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>109.090909</td>\n",
       "      <td>720.0</td>\n",
       "      <td>67.333333</td>\n",
       "      <td>0.594059</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>654.545455</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.00</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3233.0</td>\n",
       "      <td>False</td>\n",
       "      <td>176.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.20</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1.2</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>29.333333</td>\n",
       "      <td>117.333333</td>\n",
       "      <td>528.0</td>\n",
       "      <td>538.833333</td>\n",
       "      <td>0.054439</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>True</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>352.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.00</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.3</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1228.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.60</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>136.000000</td>\n",
       "      <td>250.0</td>\n",
       "      <td>307.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>187.500000</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>1.50</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2304.0</td>\n",
       "      <td>False</td>\n",
       "      <td>212.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.20</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1.2</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>42.400000</td>\n",
       "      <td>176.666667</td>\n",
       "      <td>424.0</td>\n",
       "      <td>460.800000</td>\n",
       "      <td>0.092014</td>\n",
       "      <td>1.80</td>\n",
       "      <td>318.00</td>\n",
       "      <td>False</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>353.333333</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.00</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.1</td>\n",
       "      <td>False</td>\n",
       "      <td>4.0</td>\n",
       "      <td>202.0</td>\n",
       "      <td>False</td>\n",
       "      <td>120.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.50</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>2.4</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>109.090909</td>\n",
       "      <td>480.0</td>\n",
       "      <td>101.000000</td>\n",
       "      <td>0.594059</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>436.363636</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.00</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.8</td>\n",
       "      <td>True</td>\n",
       "      <td>2.0</td>\n",
       "      <td>721.0</td>\n",
       "      <td>False</td>\n",
       "      <td>92.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.50</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1.2</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>18.400000</td>\n",
       "      <td>51.111111</td>\n",
       "      <td>184.0</td>\n",
       "      <td>144.200000</td>\n",
       "      <td>0.127601</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>102.222222</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.00</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>True</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1799.0</td>\n",
       "      <td>False</td>\n",
       "      <td>161.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.20</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1.2</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>40.250000</td>\n",
       "      <td>178.888889</td>\n",
       "      <td>161.0</td>\n",
       "      <td>449.750000</td>\n",
       "      <td>0.089494</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>178.888889</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.00</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5120.0</td>\n",
       "      <td>False</td>\n",
       "      <td>312.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.75</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.9</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>39.000000</td>\n",
       "      <td>124.800000</td>\n",
       "      <td>312.0</td>\n",
       "      <td>640.000000</td>\n",
       "      <td>0.060937</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>True</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>124.800000</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>4.00</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.3</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1019.5</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.60</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1.2</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>136.000000</td>\n",
       "      <td>250.0</td>\n",
       "      <td>203.900000</td>\n",
       "      <td>0.173387</td>\n",
       "      <td>6.40</td>\n",
       "      <td>0.00</td>\n",
       "      <td>False</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>187.500000</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.00</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>3.0</td>\n",
       "      <td>337.0</td>\n",
       "      <td>True</td>\n",
       "      <td>117.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.60</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1.8</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>39.000000</td>\n",
       "      <td>117.000000</td>\n",
       "      <td>351.0</td>\n",
       "      <td>112.333333</td>\n",
       "      <td>0.347181</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>351.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>2.50</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.3</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>230.0</td>\n",
       "      <td>False</td>\n",
       "      <td>110.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.50</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2.4</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>110.000000</td>\n",
       "      <td>136.000000</td>\n",
       "      <td>110.0</td>\n",
       "      <td>230.000000</td>\n",
       "      <td>0.478261</td>\n",
       "      <td>6.25</td>\n",
       "      <td>275.00</td>\n",
       "      <td>False</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>187.500000</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.00</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.6</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1697.0</td>\n",
       "      <td>False</td>\n",
       "      <td>317.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.80</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2.4</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>79.250000</td>\n",
       "      <td>198.125000</td>\n",
       "      <td>317.0</td>\n",
       "      <td>424.250000</td>\n",
       "      <td>0.186800</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>True</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>198.125000</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.30</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.2</td>\n",
       "      <td>True</td>\n",
       "      <td>1.0</td>\n",
       "      <td>885.0</td>\n",
       "      <td>False</td>\n",
       "      <td>84.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>4.00</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1.2</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>38.181818</td>\n",
       "      <td>840.0</td>\n",
       "      <td>221.250000</td>\n",
       "      <td>0.094915</td>\n",
       "      <td>1.20</td>\n",
       "      <td>25.20</td>\n",
       "      <td>False</td>\n",
       "      <td>0.075000</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>381.818182</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.00</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>True</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1315.0</td>\n",
       "      <td>False</td>\n",
       "      <td>84.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.75</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.9</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>42.000000</td>\n",
       "      <td>33.600000</td>\n",
       "      <td>84.0</td>\n",
       "      <td>657.500000</td>\n",
       "      <td>0.063878</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>True</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>33.600000</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>1.50</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.3</td>\n",
       "      <td>True</td>\n",
       "      <td>1.0</td>\n",
       "      <td>230.0</td>\n",
       "      <td>False</td>\n",
       "      <td>110.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.50</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2.4</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>110.000000</td>\n",
       "      <td>136.000000</td>\n",
       "      <td>110.0</td>\n",
       "      <td>230.000000</td>\n",
       "      <td>0.478261</td>\n",
       "      <td>3.75</td>\n",
       "      <td>165.00</td>\n",
       "      <td>False</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>187.500000</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>1.00</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.7</td>\n",
       "      <td>True</td>\n",
       "      <td>1.0</td>\n",
       "      <td>688.0</td>\n",
       "      <td>False</td>\n",
       "      <td>89.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.50</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1.2</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>29.666667</td>\n",
       "      <td>52.352941</td>\n",
       "      <td>89.0</td>\n",
       "      <td>229.333333</td>\n",
       "      <td>0.129360</td>\n",
       "      <td>5.50</td>\n",
       "      <td>89.00</td>\n",
       "      <td>False</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>52.352941</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.00</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>True</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1295.0</td>\n",
       "      <td>False</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.50</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1.2</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>8.750000</td>\n",
       "      <td>87.500000</td>\n",
       "      <td>35.0</td>\n",
       "      <td>323.750000</td>\n",
       "      <td>0.027027</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>87.500000</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.00</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>True</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1748.0</td>\n",
       "      <td>False</td>\n",
       "      <td>43.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.00</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>8.600000</td>\n",
       "      <td>107.500000</td>\n",
       "      <td>43.0</td>\n",
       "      <td>349.600000</td>\n",
       "      <td>0.024600</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>107.500000</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.00</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1766.0</td>\n",
       "      <td>False</td>\n",
       "      <td>202.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.20</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1.2</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>67.333333</td>\n",
       "      <td>168.333333</td>\n",
       "      <td>202.0</td>\n",
       "      <td>588.666667</td>\n",
       "      <td>0.114383</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>168.333333</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.00</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.3</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3581.0</td>\n",
       "      <td>False</td>\n",
       "      <td>53.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.50</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.9</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>7.571429</td>\n",
       "      <td>40.769231</td>\n",
       "      <td>53.0</td>\n",
       "      <td>511.571429</td>\n",
       "      <td>0.014800</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>True</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>40.769231</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>3.50</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.3</td>\n",
       "      <td>True</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1019.5</td>\n",
       "      <td>False</td>\n",
       "      <td>1057.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.60</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1.2</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>176.166667</td>\n",
       "      <td>136.000000</td>\n",
       "      <td>3171.0</td>\n",
       "      <td>169.916667</td>\n",
       "      <td>0.173387</td>\n",
       "      <td>5.60</td>\n",
       "      <td>3699.50</td>\n",
       "      <td>False</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>187.500000</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.00</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>True</td>\n",
       "      <td>1.0</td>\n",
       "      <td>698.0</td>\n",
       "      <td>False</td>\n",
       "      <td>99.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.50</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1.2</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>82.500000</td>\n",
       "      <td>99.0</td>\n",
       "      <td>232.666667</td>\n",
       "      <td>0.141834</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>82.500000</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.00</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1282.0</td>\n",
       "      <td>False</td>\n",
       "      <td>256.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.70</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2.4</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>320.000000</td>\n",
       "      <td>256.0</td>\n",
       "      <td>320.500000</td>\n",
       "      <td>0.199688</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>320.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.25</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.1</td>\n",
       "      <td>True</td>\n",
       "      <td>1.0</td>\n",
       "      <td>529.0</td>\n",
       "      <td>False</td>\n",
       "      <td>133.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.00</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1.2</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>33.250000</td>\n",
       "      <td>120.909091</td>\n",
       "      <td>133.0</td>\n",
       "      <td>132.250000</td>\n",
       "      <td>0.251418</td>\n",
       "      <td>1.75</td>\n",
       "      <td>33.25</td>\n",
       "      <td>False</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>120.909091</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>1.30</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.7</td>\n",
       "      <td>True</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3993.0</td>\n",
       "      <td>False</td>\n",
       "      <td>268.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.20</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1.2</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>38.285714</td>\n",
       "      <td>157.647059</td>\n",
       "      <td>268.0</td>\n",
       "      <td>570.428571</td>\n",
       "      <td>0.067117</td>\n",
       "      <td>1.56</td>\n",
       "      <td>348.40</td>\n",
       "      <td>False</td>\n",
       "      <td>0.185714</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>157.647059</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.00</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>837.0</td>\n",
       "      <td>False</td>\n",
       "      <td>311.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.60</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1.2</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>103.666667</td>\n",
       "      <td>207.333333</td>\n",
       "      <td>311.0</td>\n",
       "      <td>279.000000</td>\n",
       "      <td>0.371565</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>207.333333</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.00</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>True</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2250.0</td>\n",
       "      <td>False</td>\n",
       "      <td>40.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.60</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1.2</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>40.0</td>\n",
       "      <td>562.500000</td>\n",
       "      <td>0.017778</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.00</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.3</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1210.0</td>\n",
       "      <td>False</td>\n",
       "      <td>194.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.20</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1.8</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>64.666667</td>\n",
       "      <td>149.230769</td>\n",
       "      <td>194.0</td>\n",
       "      <td>403.333333</td>\n",
       "      <td>0.160331</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>149.230769</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.00</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.6</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1433.0</td>\n",
       "      <td>False</td>\n",
       "      <td>755.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.80</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1.8</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>188.750000</td>\n",
       "      <td>471.875000</td>\n",
       "      <td>755.0</td>\n",
       "      <td>358.250000</td>\n",
       "      <td>0.526867</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>471.875000</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.00</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.1</td>\n",
       "      <td>False</td>\n",
       "      <td>6.0</td>\n",
       "      <td>230.0</td>\n",
       "      <td>False</td>\n",
       "      <td>117.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.50</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1.8</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>23.400000</td>\n",
       "      <td>106.363636</td>\n",
       "      <td>702.0</td>\n",
       "      <td>46.000000</td>\n",
       "      <td>0.508696</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>638.181818</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.00</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.1</td>\n",
       "      <td>False</td>\n",
       "      <td>3.0</td>\n",
       "      <td>230.0</td>\n",
       "      <td>False</td>\n",
       "      <td>117.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.50</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1.8</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>39.000000</td>\n",
       "      <td>106.363636</td>\n",
       "      <td>351.0</td>\n",
       "      <td>76.666667</td>\n",
       "      <td>0.508696</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>319.090909</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.00</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.3</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1019.5</td>\n",
       "      <td>False</td>\n",
       "      <td>163.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.60</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1.2</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>40.750000</td>\n",
       "      <td>136.000000</td>\n",
       "      <td>250.0</td>\n",
       "      <td>254.875000</td>\n",
       "      <td>0.173387</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>187.500000</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.00</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>True</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2214.0</td>\n",
       "      <td>False</td>\n",
       "      <td>140.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.20</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1.2</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>175.000000</td>\n",
       "      <td>140.0</td>\n",
       "      <td>442.800000</td>\n",
       "      <td>0.063234</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>175.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>2.00</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1369.0</td>\n",
       "      <td>False</td>\n",
       "      <td>266.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.50</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>66.500000</td>\n",
       "      <td>53.200000</td>\n",
       "      <td>266.0</td>\n",
       "      <td>342.250000</td>\n",
       "      <td>0.194302</td>\n",
       "      <td>7.00</td>\n",
       "      <td>532.00</td>\n",
       "      <td>False</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>53.200000</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.00</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>1.0</td>\n",
       "      <td>529.0</td>\n",
       "      <td>False</td>\n",
       "      <td>133.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.50</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1.2</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>33.250000</td>\n",
       "      <td>133.000000</td>\n",
       "      <td>133.0</td>\n",
       "      <td>132.250000</td>\n",
       "      <td>0.251418</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>133.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.00</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>721.0</td>\n",
       "      <td>False</td>\n",
       "      <td>217.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.00</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1.2</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>54.250000</td>\n",
       "      <td>217.000000</td>\n",
       "      <td>217.0</td>\n",
       "      <td>180.250000</td>\n",
       "      <td>0.300971</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>217.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.00</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.3</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>906.0</td>\n",
       "      <td>False</td>\n",
       "      <td>314.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.60</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1.2</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>78.500000</td>\n",
       "      <td>241.538462</td>\n",
       "      <td>314.0</td>\n",
       "      <td>226.500000</td>\n",
       "      <td>0.346578</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>241.538462</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.00</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.8</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3760.0</td>\n",
       "      <td>False</td>\n",
       "      <td>816.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.20</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.9</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>116.571429</td>\n",
       "      <td>453.333333</td>\n",
       "      <td>816.0</td>\n",
       "      <td>537.142857</td>\n",
       "      <td>0.217021</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>453.333333</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.00</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1052.0</td>\n",
       "      <td>False</td>\n",
       "      <td>217.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.60</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1.2</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>54.250000</td>\n",
       "      <td>217.000000</td>\n",
       "      <td>217.0</td>\n",
       "      <td>263.000000</td>\n",
       "      <td>0.206274</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>217.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>3.50</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.3</td>\n",
       "      <td>True</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1019.5</td>\n",
       "      <td>False</td>\n",
       "      <td>92.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.60</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1.2</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>136.000000</td>\n",
       "      <td>736.0</td>\n",
       "      <td>254.875000</td>\n",
       "      <td>0.173387</td>\n",
       "      <td>5.60</td>\n",
       "      <td>322.00</td>\n",
       "      <td>False</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>187.500000</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.00</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>True</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1920.0</td>\n",
       "      <td>False</td>\n",
       "      <td>391.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.60</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1.2</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>78.200000</td>\n",
       "      <td>279.285714</td>\n",
       "      <td>391.0</td>\n",
       "      <td>384.000000</td>\n",
       "      <td>0.203646</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>279.285714</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>2.00</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>261.0</td>\n",
       "      <td>False</td>\n",
       "      <td>168.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.00</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1.2</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>56.000000</td>\n",
       "      <td>56.000000</td>\n",
       "      <td>168.0</td>\n",
       "      <td>87.000000</td>\n",
       "      <td>0.643678</td>\n",
       "      <td>18.00</td>\n",
       "      <td>336.00</td>\n",
       "      <td>False</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>56.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>3.00</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.3</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1019.5</td>\n",
       "      <td>False</td>\n",
       "      <td>179.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.60</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>1.2</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>89.500000</td>\n",
       "      <td>136.000000</td>\n",
       "      <td>179.0</td>\n",
       "      <td>509.750000</td>\n",
       "      <td>0.173387</td>\n",
       "      <td>4.80</td>\n",
       "      <td>537.00</td>\n",
       "      <td>False</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>187.500000</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.00</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.8</td>\n",
       "      <td>True</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1697.0</td>\n",
       "      <td>False</td>\n",
       "      <td>250.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.80</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1.2</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>138.888889</td>\n",
       "      <td>500.0</td>\n",
       "      <td>339.400000</td>\n",
       "      <td>0.147319</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>True</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>277.777778</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.00</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.3</td>\n",
       "      <td>False</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1019.5</td>\n",
       "      <td>False</td>\n",
       "      <td>161.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.60</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1.2</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>32.200000</td>\n",
       "      <td>136.000000</td>\n",
       "      <td>483.0</td>\n",
       "      <td>203.900000</td>\n",
       "      <td>0.173387</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>187.500000</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>2.00</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.3</td>\n",
       "      <td>True</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1019.5</td>\n",
       "      <td>False</td>\n",
       "      <td>1484.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.60</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1.2</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>247.333333</td>\n",
       "      <td>136.000000</td>\n",
       "      <td>1484.0</td>\n",
       "      <td>169.916667</td>\n",
       "      <td>0.173387</td>\n",
       "      <td>3.20</td>\n",
       "      <td>2968.00</td>\n",
       "      <td>False</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>187.500000</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.00</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2921.0</td>\n",
       "      <td>False</td>\n",
       "      <td>109.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.50</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>42.575000</td>\n",
       "      <td>109.000000</td>\n",
       "      <td>109.0</td>\n",
       "      <td>270.666667</td>\n",
       "      <td>0.037316</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>109.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>3.00</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.3</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1019.5</td>\n",
       "      <td>False</td>\n",
       "      <td>437.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.60</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1.2</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>145.666667</td>\n",
       "      <td>136.000000</td>\n",
       "      <td>437.0</td>\n",
       "      <td>339.833333</td>\n",
       "      <td>0.173387</td>\n",
       "      <td>4.80</td>\n",
       "      <td>1311.00</td>\n",
       "      <td>False</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>187.500000</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>1.00</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.8</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1210.0</td>\n",
       "      <td>False</td>\n",
       "      <td>261.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.20</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1.8</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>87.000000</td>\n",
       "      <td>145.000000</td>\n",
       "      <td>261.0</td>\n",
       "      <td>403.333333</td>\n",
       "      <td>0.215702</td>\n",
       "      <td>1.20</td>\n",
       "      <td>261.00</td>\n",
       "      <td>False</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>145.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.00</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.7</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3164.0</td>\n",
       "      <td>False</td>\n",
       "      <td>307.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.00</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.9</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>51.166667</td>\n",
       "      <td>180.588235</td>\n",
       "      <td>307.0</td>\n",
       "      <td>527.333333</td>\n",
       "      <td>0.097029</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>True</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>180.588235</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.00</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>False</td>\n",
       "      <td>4.0</td>\n",
       "      <td>837.0</td>\n",
       "      <td>False</td>\n",
       "      <td>74.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.70</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2.4</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>14.800000</td>\n",
       "      <td>61.666667</td>\n",
       "      <td>296.0</td>\n",
       "      <td>167.400000</td>\n",
       "      <td>0.088411</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>True</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>246.666667</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.00</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.3</td>\n",
       "      <td>False</td>\n",
       "      <td>6.0</td>\n",
       "      <td>787.0</td>\n",
       "      <td>True</td>\n",
       "      <td>133.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.60</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>1.2</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>102.307692</td>\n",
       "      <td>798.0</td>\n",
       "      <td>112.428571</td>\n",
       "      <td>0.168996</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>613.846154</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.00</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2662.0</td>\n",
       "      <td>False</td>\n",
       "      <td>120.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.20</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1.2</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>120.0</td>\n",
       "      <td>665.500000</td>\n",
       "      <td>0.045079</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>True</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.00</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>15.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>False</td>\n",
       "      <td>81.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.50</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1.2</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>81.000000</td>\n",
       "      <td>1215.0</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1215.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>2.00</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.3</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>532.0</td>\n",
       "      <td>False</td>\n",
       "      <td>145.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.35</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1.8</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>48.333333</td>\n",
       "      <td>136.000000</td>\n",
       "      <td>145.0</td>\n",
       "      <td>177.333333</td>\n",
       "      <td>0.272556</td>\n",
       "      <td>0.70</td>\n",
       "      <td>290.00</td>\n",
       "      <td>True</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>187.500000</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>1.00</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.9</td>\n",
       "      <td>False</td>\n",
       "      <td>2.0</td>\n",
       "      <td>560.0</td>\n",
       "      <td>False</td>\n",
       "      <td>161.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.50</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1.8</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>40.250000</td>\n",
       "      <td>84.736842</td>\n",
       "      <td>322.0</td>\n",
       "      <td>140.000000</td>\n",
       "      <td>0.287500</td>\n",
       "      <td>3.50</td>\n",
       "      <td>161.00</td>\n",
       "      <td>False</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>169.473684</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>1.30</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.6</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2298.0</td>\n",
       "      <td>False</td>\n",
       "      <td>204.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.20</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1.2</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>51.000000</td>\n",
       "      <td>127.500000</td>\n",
       "      <td>204.0</td>\n",
       "      <td>574.500000</td>\n",
       "      <td>0.088773</td>\n",
       "      <td>1.56</td>\n",
       "      <td>265.20</td>\n",
       "      <td>False</td>\n",
       "      <td>0.325000</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>127.500000</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.00</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>3.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>False</td>\n",
       "      <td>81.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.50</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>1.8</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>81.000000</td>\n",
       "      <td>81.000000</td>\n",
       "      <td>243.0</td>\n",
       "      <td>81.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>243.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>1.80</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1451.0</td>\n",
       "      <td>False</td>\n",
       "      <td>1331.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.00</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.9</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>221.833333</td>\n",
       "      <td>332.750000</td>\n",
       "      <td>1331.0</td>\n",
       "      <td>241.833333</td>\n",
       "      <td>0.917298</td>\n",
       "      <td>9.00</td>\n",
       "      <td>2395.80</td>\n",
       "      <td>False</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>332.750000</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.00</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.7</td>\n",
       "      <td>False</td>\n",
       "      <td>3.0</td>\n",
       "      <td>133.0</td>\n",
       "      <td>False</td>\n",
       "      <td>81.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.00</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>2.4</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>40.500000</td>\n",
       "      <td>47.647059</td>\n",
       "      <td>243.0</td>\n",
       "      <td>66.500000</td>\n",
       "      <td>0.609023</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>142.941176</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.00</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.1</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1075.0</td>\n",
       "      <td>False</td>\n",
       "      <td>307.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.20</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1.2</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>102.333333</td>\n",
       "      <td>279.090909</td>\n",
       "      <td>307.0</td>\n",
       "      <td>358.333333</td>\n",
       "      <td>0.285581</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>279.090909</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.00</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1254.0</td>\n",
       "      <td>False</td>\n",
       "      <td>307.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.50</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1.2</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>51.166667</td>\n",
       "      <td>219.285714</td>\n",
       "      <td>307.0</td>\n",
       "      <td>209.000000</td>\n",
       "      <td>0.244817</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>219.285714</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.00</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.3</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.80</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1.2</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>136.000000</td>\n",
       "      <td>250.0</td>\n",
       "      <td>40.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>True</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>187.500000</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.00</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.1</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1152.0</td>\n",
       "      <td>False</td>\n",
       "      <td>220.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.50</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>55.000000</td>\n",
       "      <td>200.000000</td>\n",
       "      <td>220.0</td>\n",
       "      <td>288.000000</td>\n",
       "      <td>0.190972</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>200.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.00</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.3</td>\n",
       "      <td>True</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1019.5</td>\n",
       "      <td>False</td>\n",
       "      <td>268.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.60</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1.2</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>134.000000</td>\n",
       "      <td>136.000000</td>\n",
       "      <td>268.0</td>\n",
       "      <td>509.750000</td>\n",
       "      <td>0.173387</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>187.500000</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.00</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>3.0</td>\n",
       "      <td>721.0</td>\n",
       "      <td>False</td>\n",
       "      <td>217.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.00</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1.2</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>24.111111</td>\n",
       "      <td>217.000000</td>\n",
       "      <td>651.0</td>\n",
       "      <td>80.111111</td>\n",
       "      <td>0.300971</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>651.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.00</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.3</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>529.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.60</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>136.000000</td>\n",
       "      <td>250.0</td>\n",
       "      <td>176.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>187.500000</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>5.50</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.3</td>\n",
       "      <td>True</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1019.5</td>\n",
       "      <td>False</td>\n",
       "      <td>84.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.60</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1.2</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>136.000000</td>\n",
       "      <td>84.0</td>\n",
       "      <td>339.833333</td>\n",
       "      <td>0.173387</td>\n",
       "      <td>8.80</td>\n",
       "      <td>462.00</td>\n",
       "      <td>False</td>\n",
       "      <td>1.833333</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>187.500000</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.00</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3052.0</td>\n",
       "      <td>False</td>\n",
       "      <td>109.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.50</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>42.575000</td>\n",
       "      <td>136.250000</td>\n",
       "      <td>109.0</td>\n",
       "      <td>270.666667</td>\n",
       "      <td>0.035714</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>136.250000</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>2.00</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1907.0</td>\n",
       "      <td>False</td>\n",
       "      <td>266.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.20</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1.2</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>66.500000</td>\n",
       "      <td>177.333333</td>\n",
       "      <td>266.0</td>\n",
       "      <td>476.750000</td>\n",
       "      <td>0.139486</td>\n",
       "      <td>2.40</td>\n",
       "      <td>532.00</td>\n",
       "      <td>False</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>177.333333</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>2.50</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.3</td>\n",
       "      <td>True</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1019.5</td>\n",
       "      <td>False</td>\n",
       "      <td>335.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.60</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1.2</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>111.666667</td>\n",
       "      <td>136.000000</td>\n",
       "      <td>335.0</td>\n",
       "      <td>339.833333</td>\n",
       "      <td>0.173387</td>\n",
       "      <td>4.00</td>\n",
       "      <td>837.50</td>\n",
       "      <td>False</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>187.500000</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>2.50</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.3</td>\n",
       "      <td>True</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1019.5</td>\n",
       "      <td>False</td>\n",
       "      <td>960.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.60</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1.2</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>320.000000</td>\n",
       "      <td>136.000000</td>\n",
       "      <td>2880.0</td>\n",
       "      <td>339.833333</td>\n",
       "      <td>0.173387</td>\n",
       "      <td>4.00</td>\n",
       "      <td>2400.00</td>\n",
       "      <td>False</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>187.500000</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>1.50</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.3</td>\n",
       "      <td>False</td>\n",
       "      <td>2.0</td>\n",
       "      <td>330.0</td>\n",
       "      <td>False</td>\n",
       "      <td>391.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.50</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2.4</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>195.500000</td>\n",
       "      <td>136.000000</td>\n",
       "      <td>782.0</td>\n",
       "      <td>165.000000</td>\n",
       "      <td>1.184848</td>\n",
       "      <td>0.75</td>\n",
       "      <td>586.50</td>\n",
       "      <td>True</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>187.500000</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>1.50</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.1</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>839.0</td>\n",
       "      <td>False</td>\n",
       "      <td>135.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.50</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1.2</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>122.727273</td>\n",
       "      <td>135.0</td>\n",
       "      <td>167.800000</td>\n",
       "      <td>0.160906</td>\n",
       "      <td>8.25</td>\n",
       "      <td>202.50</td>\n",
       "      <td>False</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>122.727273</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>1.50</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>755.0</td>\n",
       "      <td>False</td>\n",
       "      <td>281.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.50</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1.2</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>56.200000</td>\n",
       "      <td>200.714286</td>\n",
       "      <td>281.0</td>\n",
       "      <td>151.000000</td>\n",
       "      <td>0.372185</td>\n",
       "      <td>8.25</td>\n",
       "      <td>421.50</td>\n",
       "      <td>False</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>200.714286</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.00</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1600.0</td>\n",
       "      <td>False</td>\n",
       "      <td>43.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11.50</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>7.166667</td>\n",
       "      <td>143.333333</td>\n",
       "      <td>43.0</td>\n",
       "      <td>266.666667</td>\n",
       "      <td>0.026875</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>143.333333</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>2.50</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.3</td>\n",
       "      <td>True</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1019.5</td>\n",
       "      <td>False</td>\n",
       "      <td>192.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.60</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1.2</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>96.000000</td>\n",
       "      <td>136.000000</td>\n",
       "      <td>192.0</td>\n",
       "      <td>509.750000</td>\n",
       "      <td>0.173387</td>\n",
       "      <td>4.00</td>\n",
       "      <td>480.00</td>\n",
       "      <td>False</td>\n",
       "      <td>1.250000</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>187.500000</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.00</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.1</td>\n",
       "      <td>True</td>\n",
       "      <td>3.0</td>\n",
       "      <td>529.0</td>\n",
       "      <td>False</td>\n",
       "      <td>117.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.50</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1.2</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>29.250000</td>\n",
       "      <td>55.714286</td>\n",
       "      <td>351.0</td>\n",
       "      <td>132.250000</td>\n",
       "      <td>0.221172</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>167.142857</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.00</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>False</td>\n",
       "      <td>2.0</td>\n",
       "      <td>304.0</td>\n",
       "      <td>False</td>\n",
       "      <td>256.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.80</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>1.2</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>42.575000</td>\n",
       "      <td>182.857143</td>\n",
       "      <td>512.0</td>\n",
       "      <td>270.666667</td>\n",
       "      <td>0.842105</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>365.714286</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.00</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>629.0</td>\n",
       "      <td>False</td>\n",
       "      <td>53.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.75</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>2.4</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>42.575000</td>\n",
       "      <td>44.166667</td>\n",
       "      <td>53.0</td>\n",
       "      <td>270.666667</td>\n",
       "      <td>0.084261</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>True</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>44.166667</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.00</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.1</td>\n",
       "      <td>False</td>\n",
       "      <td>4.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>False</td>\n",
       "      <td>64.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.80</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>1.8</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>42.575000</td>\n",
       "      <td>58.181818</td>\n",
       "      <td>256.0</td>\n",
       "      <td>270.666667</td>\n",
       "      <td>0.177778</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>True</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>232.727273</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.00</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.1</td>\n",
       "      <td>False</td>\n",
       "      <td>2.0</td>\n",
       "      <td>762.0</td>\n",
       "      <td>False</td>\n",
       "      <td>128.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.80</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>1.2</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>42.575000</td>\n",
       "      <td>116.363636</td>\n",
       "      <td>256.0</td>\n",
       "      <td>270.666667</td>\n",
       "      <td>0.167979</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>True</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>232.727273</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.00</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.1</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1080.0</td>\n",
       "      <td>False</td>\n",
       "      <td>337.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.80</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>1.8</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>42.575000</td>\n",
       "      <td>306.363636</td>\n",
       "      <td>337.0</td>\n",
       "      <td>270.666667</td>\n",
       "      <td>0.312037</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>306.363636</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.00</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>False</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1039.0</td>\n",
       "      <td>False</td>\n",
       "      <td>84.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.9</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>42.575000</td>\n",
       "      <td>33.600000</td>\n",
       "      <td>168.0</td>\n",
       "      <td>270.666667</td>\n",
       "      <td>0.080847</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>True</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>67.200000</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.00</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1600.0</td>\n",
       "      <td>False</td>\n",
       "      <td>202.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.20</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>1.2</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>42.575000</td>\n",
       "      <td>168.333333</td>\n",
       "      <td>202.0</td>\n",
       "      <td>270.666667</td>\n",
       "      <td>0.126250</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>168.333333</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.00</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.7</td>\n",
       "      <td>False</td>\n",
       "      <td>6.0</td>\n",
       "      <td>217.0</td>\n",
       "      <td>False</td>\n",
       "      <td>81.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.60</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>1.2</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>42.575000</td>\n",
       "      <td>47.647059</td>\n",
       "      <td>486.0</td>\n",
       "      <td>270.666667</td>\n",
       "      <td>0.373272</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>285.882353</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.00</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2385.0</td>\n",
       "      <td>False</td>\n",
       "      <td>128.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.20</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1.2</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>42.575000</td>\n",
       "      <td>85.333333</td>\n",
       "      <td>128.0</td>\n",
       "      <td>270.666667</td>\n",
       "      <td>0.053669</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>True</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>85.333333</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.00</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>842.0</td>\n",
       "      <td>False</td>\n",
       "      <td>174.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.60</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>1.2</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>42.575000</td>\n",
       "      <td>174.000000</td>\n",
       "      <td>174.0</td>\n",
       "      <td>270.666667</td>\n",
       "      <td>0.206651</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>174.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.00</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1940.0</td>\n",
       "      <td>False</td>\n",
       "      <td>204.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.80</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1.2</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>42.575000</td>\n",
       "      <td>136.000000</td>\n",
       "      <td>204.0</td>\n",
       "      <td>270.666667</td>\n",
       "      <td>0.105155</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>136.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.00</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>2.0</td>\n",
       "      <td>261.0</td>\n",
       "      <td>False</td>\n",
       "      <td>125.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.00</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1.2</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>42.575000</td>\n",
       "      <td>125.000000</td>\n",
       "      <td>250.0</td>\n",
       "      <td>270.666667</td>\n",
       "      <td>0.478927</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>250.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.00</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.3</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>240.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.60</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>1.2</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>42.575000</td>\n",
       "      <td>136.000000</td>\n",
       "      <td>250.0</td>\n",
       "      <td>270.666667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>187.500000</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     playable  aoe_bool  aoe_radius  death_damage_bool  fly_bool  spawn_bool  \\\n",
       "0        True     False        0.00              False     False       False   \n",
       "1        True     False        0.00              False     False       False   \n",
       "2        True      True        3.50              False     False       False   \n",
       "3        True      True        1.20              False      True       False   \n",
       "4        True     False        0.00               True      True       False   \n",
       "5        True     False        0.00              False     False       False   \n",
       "6        True      True        0.00              False     False        True   \n",
       "7        True     False        0.00              False     False        True   \n",
       "8        True     False        0.00              False     False       False   \n",
       "9        True     False        0.00              False      True       False   \n",
       "10       True      True        4.00              False     False       False   \n",
       "11       True     False        0.00              False     False        True   \n",
       "12       True     False        0.00              False     False       False   \n",
       "13       True      True        1.50               True     False       False   \n",
       "14       True      True        1.50              False     False       False   \n",
       "15       True     False        0.00              False     False       False   \n",
       "16       True      True        0.00              False     False       False   \n",
       "17       True     False        0.00              False     False       False   \n",
       "18       True     False        0.00              False     False       False   \n",
       "19      False     False        0.00              False     False       False   \n",
       "20      False     False        0.00              False     False       False   \n",
       "21       True      True        3.00              False     False        True   \n",
       "22      False     False        0.00              False     False       False   \n",
       "23       True      True        1.10              False     False       False   \n",
       "24       True     False        0.00              False     False       False   \n",
       "25       True      True        3.50              False     False       False   \n",
       "26       True     False        0.00              False      True       False   \n",
       "27       True      True        3.00              False     False       False   \n",
       "28       True     False        0.00              False     False       False   \n",
       "29       True     False        0.00              False     False        True   \n",
       "30       True     False        0.00              False     False       False   \n",
       "31       True     False        0.00              False     False       False   \n",
       "32       True     False        0.00              False     False        True   \n",
       "33       True      True        1.00              False     False       False   \n",
       "34       True      True        2.30              False     False       False   \n",
       "35       True      True        2.50              False     False       False   \n",
       "36       True      True        0.40              False     False       False   \n",
       "37       True     False        0.00              False     False       False   \n",
       "38       True     False        0.00              False      True       False   \n",
       "39       True      True        3.00              False     False       False   \n",
       "40       True     False        0.00              False     False        True   \n",
       "41       True     False        0.00              False     False       False   \n",
       "42       True     False        0.00               True     False       False   \n",
       "43       True      True        2.50              False     False       False   \n",
       "44       True      True        1.50              False     False        True   \n",
       "45       True     False        0.00              False     False        True   \n",
       "46       True      True        3.00              False     False        True   \n",
       "47       True      True        1.00               True     False       False   \n",
       "48       True     False        0.00              False     False        True   \n",
       "49       True     False        0.00              False     False        True   \n",
       "50       True     False        0.00              False     False        True   \n",
       "51       True     False        0.00              False     False        True   \n",
       "52       True      True        1.50              False     False       False   \n",
       "53       True     False        0.00              False     False       False   \n",
       "54       True     False        0.00              False     False       False   \n",
       "55       True     False        0.00              False     False       False   \n",
       "56       True     False        0.00               True     False        True   \n",
       "57       True      True        4.00              False     False        True   \n",
       "58       True     False        0.00              False     False       False   \n",
       "59       True      True        2.50              False     False       False   \n",
       "60       True     False        0.00              False     False       False   \n",
       "61       True      True        0.30              False     False       False   \n",
       "62       True     False        0.00               True     False       False   \n",
       "63       True      True        1.50              False     False       False   \n",
       "64       True      True        1.00              False     False        True   \n",
       "65       True     False        0.00              False      True       False   \n",
       "66       True     False        0.00              False     False       False   \n",
       "67       True     False        0.00              False     False       False   \n",
       "68       True     False        0.00              False      True        True   \n",
       "69       True      True        3.50              False     False       False   \n",
       "70       True     False        0.00              False     False        True   \n",
       "71       True     False        0.00               True     False        True   \n",
       "72       True      True        0.25              False     False       False   \n",
       "73       True      True        1.30              False     False       False   \n",
       "74       True     False        0.00              False      True       False   \n",
       "75       True     False        0.00              False     False       False   \n",
       "76       True     False        0.00              False     False       False   \n",
       "77       True     False        0.00              False     False       False   \n",
       "78       True     False        0.00              False      True       False   \n",
       "79       True     False        0.00              False      True       False   \n",
       "80       True     False        0.00              False     False       False   \n",
       "81       True     False        0.00              False     False       False   \n",
       "82       True      True        2.00              False     False       False   \n",
       "83       True     False        0.00              False     False        True   \n",
       "84       True     False        0.00              False     False       False   \n",
       "85       True     False        0.00              False     False        True   \n",
       "86       True     False        0.00              False     False       False   \n",
       "87       True     False        0.00               True      True        True   \n",
       "88       True      True        3.50              False     False       False   \n",
       "89       True     False        0.00              False     False       False   \n",
       "90       True      True        2.00              False     False       False   \n",
       "91       True      True        3.00              False     False       False   \n",
       "92       True     False        0.00              False     False       False   \n",
       "93       True     False        0.00              False     False        True   \n",
       "94       True      True        2.00              False     False       False   \n",
       "95      False     False        0.00              False     False       False   \n",
       "96       True      True        3.00              False     False        True   \n",
       "97       True      True        1.00              False     False       False   \n",
       "98       True     False        0.00              False     False       False   \n",
       "99       True     False        0.00              False     False       False   \n",
       "100      True     False        0.00              False     False       False   \n",
       "101      True     False        0.00              False     False       False   \n",
       "102      True     False        0.00              False     False       False   \n",
       "103      True      True        2.00               True      True        True   \n",
       "104      True      True        1.00              False      True       False   \n",
       "105      True      True        1.30              False     False        True   \n",
       "106      True     False        0.00              False     False       False   \n",
       "107      True      True        1.80              False     False       False   \n",
       "108      True     False        0.00              False     False       False   \n",
       "109      True     False        0.00              False     False       False   \n",
       "110      True     False        0.00              False      True       False   \n",
       "111      True     False        0.00              False     False       False   \n",
       "112      True     False        0.00              False     False       False   \n",
       "113      True      True        0.00              False     False       False   \n",
       "114      True     False        0.00              False     False       False   \n",
       "115      True     False        0.00              False     False        True   \n",
       "116      True      True        5.50              False     False       False   \n",
       "117     False     False        0.00              False     False       False   \n",
       "118      True      True        2.00              False     False       False   \n",
       "119      True      True        2.50              False     False       False   \n",
       "120      True      True        2.50              False     False       False   \n",
       "121      True      True        1.50              False     False       False   \n",
       "122      True      True        1.50              False     False        True   \n",
       "123      True      True        1.50              False     False       False   \n",
       "124      True     False        0.00              False     False       False   \n",
       "125      True      True        2.50              False     False       False   \n",
       "126      True     False        0.00              False     False       False   \n",
       "127     False     False        0.00              False     False       False   \n",
       "128     False     False        0.00              False     False       False   \n",
       "129     False     False        0.00              False     False       False   \n",
       "130     False     False        0.00              False     False        True   \n",
       "131     False     False        0.00              False     False       False   \n",
       "132     False     False        0.00               True     False       False   \n",
       "133     False     False        0.00              False     False       False   \n",
       "134     False     False        0.00              False      True       False   \n",
       "135     False     False        0.00              False     False       False   \n",
       "136     False     False        0.00              False      True       False   \n",
       "137     False     False        0.00              False     False       False   \n",
       "138     False     False        0.00              False     False       False   \n",
       "139     False     False        0.00              False     False        True   \n",
       "\n",
       "     can_evolve  elixircost  hit_speed  special_damage  count  hitpoints  \\\n",
       "0             0         5.0        1.2           False    1.0     1000.0   \n",
       "1             1         3.0        0.9           False    2.0      304.0   \n",
       "2             0         3.0        1.3           False    1.0     1019.5   \n",
       "3             1         4.0        1.5           False    1.0     1152.0   \n",
       "4             0         5.0        2.0           False    1.0     1679.0   \n",
       "5             0         3.0        1.0            True    1.0      906.0   \n",
       "6             0         2.0        1.3           False    1.0     1019.5   \n",
       "7             0         6.0        1.3           False    1.0     1164.0   \n",
       "8             1         5.0        1.3           False    5.0      670.0   \n",
       "9             1         2.0        1.3           False    5.0       81.0   \n",
       "10            0         4.0        1.5           False    1.0     1717.0   \n",
       "11            1         4.0        1.3            True    1.0      967.0   \n",
       "12            0         2.0        0.5           False    1.0      896.0   \n",
       "13            0         4.0        1.8           False    1.0     1356.0   \n",
       "14            1         2.0        1.8           False    1.0      332.0   \n",
       "15            0         6.0        1.2            True    1.0     2624.0   \n",
       "16            0         5.0        2.5            True    1.0     2081.0   \n",
       "17            1         3.0        1.0           False    1.0      824.0   \n",
       "18            0         5.0        0.9           False    1.0     1809.0   \n",
       "19            0         0.0        0.9           False    1.0      824.0   \n",
       "20            0         0.0        2.2           False    1.0     2616.0   \n",
       "21            0         3.0        1.3           False    1.0     1019.5   \n",
       "22            0         0.0        0.5           False    1.0     2768.0   \n",
       "23            0         4.0        1.3            True    1.0     1440.0   \n",
       "24            1         3.0        0.8           False    1.0      261.0   \n",
       "25            0         3.0        1.3            True    1.0     1019.5   \n",
       "26            1         5.0        2.1            True    1.0      949.0   \n",
       "27            0         7.0        2.1            True    1.0     3855.0   \n",
       "28            0         1.0        1.3            True    1.0      230.0   \n",
       "29            0         4.0        1.8            True    1.0      714.0   \n",
       "30            0         6.0        1.4           False    2.0     1341.0   \n",
       "31            0         6.0        1.3           False    1.0     1070.0   \n",
       "32            0         3.0        1.1           False    1.0     1569.0   \n",
       "33            1         5.0        2.4            True    1.0     1280.0   \n",
       "34            0         1.0        1.3           False    1.0      230.0   \n",
       "35            0         4.0        1.3            True    1.0     1019.5   \n",
       "36            1         3.0        3.0            True    1.0      304.0   \n",
       "37            0         3.0        1.3            True    1.0      870.0   \n",
       "38            0         4.0        1.1           False    1.0      614.0   \n",
       "39            0         4.0        1.3            True    1.0     1019.5   \n",
       "40            1         4.0        1.8           False    1.0      896.0   \n",
       "41            0         5.0        1.5           False    1.0     4090.0   \n",
       "42            0         6.0        1.4            True    1.0     3617.0   \n",
       "43            1         2.0        1.3            True    1.0     1019.5   \n",
       "44            1         3.0        1.3           False    1.0     1019.5   \n",
       "45            1         4.0        1.3           False    1.0      780.0   \n",
       "46            0         2.0        1.3            True    1.0     1019.5   \n",
       "47            0         4.0        1.2            True    1.0     1300.0   \n",
       "48            1         4.0        1.3            True    1.0     1313.0   \n",
       "49            0         3.0        1.1           False    6.0      202.0   \n",
       "50            1         6.0        1.5           False    1.0     3233.0   \n",
       "51            0         4.0        1.3           False    1.0     1228.0   \n",
       "52            0         5.0        1.2           False    1.0     2304.0   \n",
       "53            0         2.0        1.1           False    4.0      202.0   \n",
       "54            0         5.0        1.8            True    2.0      721.0   \n",
       "55            0         4.0        0.9            True    1.0     1799.0   \n",
       "56            0         8.0        2.5           False    1.0     5120.0   \n",
       "57            0         5.0        1.3           False    1.0     1019.5   \n",
       "58            0         3.0        1.0           False    3.0      337.0   \n",
       "59            0         1.0        1.3           False    1.0      230.0   \n",
       "60            0         4.0        1.6           False    1.0     1697.0   \n",
       "61            1         4.0        2.2            True    1.0      885.0   \n",
       "62            0         2.0        2.5            True    1.0     1315.0   \n",
       "63            1         1.0        1.3            True    1.0      230.0   \n",
       "64            0         3.0        1.7            True    1.0      688.0   \n",
       "65            1         4.0        0.4            True    1.0     1295.0   \n",
       "66            0         5.0        0.4            True    1.0     1748.0   \n",
       "67            1         3.0        1.2           False    1.0     1766.0   \n",
       "68            0         7.0        1.3           False    1.0     3581.0   \n",
       "69            0         6.0        1.3            True    1.0     1019.5   \n",
       "70            0         3.0        1.2            True    1.0      698.0   \n",
       "71            1         4.0        0.8           False    1.0     1282.0   \n",
       "72            0         4.0        1.1            True    1.0      529.0   \n",
       "73            1         7.0        1.7            True    1.0     3993.0   \n",
       "74            0         3.0        1.5           False    1.0      837.0   \n",
       "75            0         4.0        0.4            True    1.0     2250.0   \n",
       "76            0         3.0        1.3           False    1.0     1210.0   \n",
       "77            0         4.0        1.6           False    1.0     1433.0   \n",
       "78            0         5.0        1.1           False    6.0      230.0   \n",
       "79            0         3.0        1.1           False    3.0      230.0   \n",
       "80            0         4.0        1.3           False    1.0     1019.5   \n",
       "81            0         5.0        0.8            True    1.0     2214.0   \n",
       "82            1         4.0        5.0           False    1.0     1369.0   \n",
       "83            0         4.0        1.0            True    1.0      529.0   \n",
       "84            1         4.0        1.0           False    1.0      721.0   \n",
       "85            0         4.0        1.3           False    1.0      906.0   \n",
       "86            1         7.0        1.8           False    1.0     3760.0   \n",
       "87            0         4.0        1.0            True    1.0     1052.0   \n",
       "88            0         4.0        1.3            True    1.0     1019.5   \n",
       "89            0         5.0        1.4            True    1.0     1920.0   \n",
       "90            0         3.0        3.0           False    1.0      261.0   \n",
       "91            0         2.0        1.3           False    1.0     1019.5   \n",
       "92            0         5.0        1.8            True    1.0     1697.0   \n",
       "93            0         5.0        1.3           False    3.0     1019.5   \n",
       "94            0         6.0        1.3            True    1.0     1019.5   \n",
       "95            0         0.0        1.0           False    1.0     2921.0   \n",
       "96            0         3.0        1.3           False    1.0     1019.5   \n",
       "97            0         3.0        1.8           False    1.0     1210.0   \n",
       "98            1         6.0        1.7           False    1.0     3164.0   \n",
       "99            0         5.0        1.2           False    4.0      837.0   \n",
       "100           1         7.0        1.3           False    6.0      787.0   \n",
       "101           0         4.0        1.5           False    1.0     2662.0   \n",
       "102           0         3.0        1.0           False   15.0       81.0   \n",
       "103           1         3.0        1.3           False    1.0      532.0   \n",
       "104           0         4.0        1.9           False    2.0      560.0   \n",
       "105           0         4.0        1.6           False    1.0     2298.0   \n",
       "106           1         1.0        1.0           False    3.0       81.0   \n",
       "107           0         6.0        4.0           False    1.0     1451.0   \n",
       "108           0         2.0        1.7           False    3.0      133.0   \n",
       "109           0         3.0        1.1           False    1.0     1075.0   \n",
       "110           0         6.0        1.4           False    1.0     1254.0   \n",
       "111           0         2.0        1.3           False    1.0       81.0   \n",
       "112           1         4.0        1.1           False    1.0     1152.0   \n",
       "113           0         2.0        1.3            True    1.0     1019.5   \n",
       "114           0         9.0        1.0           False    3.0      721.0   \n",
       "115           0         3.0        1.3           False    1.0      529.0   \n",
       "116           0         3.0        1.3            True    1.0     1019.5   \n",
       "117           0         0.0        0.8           False    1.0     3052.0   \n",
       "118           1         4.0        1.5           False    1.0     1907.0   \n",
       "119           0         3.0        1.3            True    1.0     1019.5   \n",
       "120           0         3.0        1.3            True    1.0     1019.5   \n",
       "121           1         2.0        1.3           False    2.0      330.0   \n",
       "122           1         5.0        1.1           False    1.0      839.0   \n",
       "123           1         5.0        1.4           False    1.0      755.0   \n",
       "124           0         6.0        0.3           False    1.0     1600.0   \n",
       "125           1         2.0        1.3            True    1.0     1019.5   \n",
       "126           0         4.0        2.1            True    3.0      529.0   \n",
       "127           0         0.0        1.4           False    2.0      304.0   \n",
       "128           0         0.0        1.2           False    1.0      629.0   \n",
       "129           0         0.0        1.1           False    4.0      360.0   \n",
       "130           0         0.0        1.1           False    2.0      762.0   \n",
       "131           0         0.0        1.1           False    1.0     1080.0   \n",
       "132           0         0.0        2.5           False    2.0     1039.0   \n",
       "133           0         0.0        1.2           False    1.0     1600.0   \n",
       "134           0         0.0        1.7           False    6.0      217.0   \n",
       "135           0         0.0        1.5           False    1.0     2385.0   \n",
       "136           0         0.0        1.0           False    1.0      842.0   \n",
       "137           0         0.0        1.5           False    1.0     1940.0   \n",
       "138           0         0.0        1.0           False    2.0      261.0   \n",
       "139           0         0.0        1.3           False    1.0      240.0   \n",
       "\n",
       "     shield_bool  damage  attack_count  range  affected_crown  has_lifetime  \\\n",
       "0          False   225.0           1.0   5.00           False         False   \n",
       "1          False   112.0           2.0   5.00           False         False   \n",
       "2          False   122.0           3.0   1.60            True         False   \n",
       "3          False   161.0           1.0   3.50           False         False   \n",
       "4          False   640.0           1.0   0.10           False         False   \n",
       "5          False   194.0           1.0   0.75           False         False   \n",
       "6          False   240.0           1.0   1.60           False         False   \n",
       "7          False     0.0           0.0   1.60           False          True   \n",
       "8          False   192.0           5.0   0.70           False         False   \n",
       "9          False    81.0           5.0   1.20           False         False   \n",
       "10         False   148.0           1.0   1.60           False         False   \n",
       "11         False   286.0           1.0   0.50           False         False   \n",
       "12         False   102.0           1.0   0.80           False         False   \n",
       "13         False   222.0           1.0   6.00           False          True   \n",
       "14         False   225.0           1.0   4.50           False         False   \n",
       "15         False   268.0           1.0   0.80           False         False   \n",
       "16         False   289.0           1.0   4.00           False         False   \n",
       "17         False   212.0           1.0   5.50           False          True   \n",
       "18         False   212.0           1.0   5.50           False         False   \n",
       "19         False   212.0           1.0   5.50           False          True   \n",
       "20         False   320.0           1.0   7.50           False         False   \n",
       "21         False     0.0           0.0   1.60           False         False   \n",
       "22         False   107.0           1.0   7.50           False         False   \n",
       "23          True   266.0           1.0   1.20           False         False   \n",
       "24         False   156.0           1.0   6.50           False         False   \n",
       "25         False    81.0           3.0   1.60            True         False   \n",
       "26         False   192.0           3.0   3.50           False         False   \n",
       "27         False   163.0           1.0   1.20            True         False   \n",
       "28         False    99.0           9.0   2.50           False         False   \n",
       "29         False   115.0           2.0   5.00           False         False   \n",
       "30         False   384.0           2.0   1.20           False         False   \n",
       "31         False     0.0           0.0   1.60           False          True   \n",
       "32         False   253.0           1.0   0.80           False         False   \n",
       "33         False   168.0           2.0   4.50           False         False   \n",
       "34         False   207.0           1.0   2.50           False         False   \n",
       "35         False   688.0           1.0   1.60            True         False   \n",
       "36         False    64.0           5.0   6.00           False         False   \n",
       "37         False   194.0           1.0   1.20           False         False   \n",
       "38         False   171.0           1.0   6.00           False         False   \n",
       "39         False   115.0           1.0   1.60            True         False   \n",
       "40         False   135.0           1.0   6.00           False         False   \n",
       "41         False   253.0           1.0   1.20           False         False   \n",
       "42         False   276.0           1.0   0.80            True         False   \n",
       "43         False   179.0           1.0   1.60            True         False   \n",
       "44         False     0.0           0.0   1.60           False         False   \n",
       "45         False     0.0           0.0   1.60           False          True   \n",
       "46         False    35.0           6.0   1.60            True         False   \n",
       "47         False   186.0           1.0   5.00           False          True   \n",
       "48         False    84.0           1.0   1.60            True          True   \n",
       "49         False   120.0           6.0   1.60           False         False   \n",
       "50         False   176.0           3.0   1.20           False         False   \n",
       "51         False     0.0           0.0   1.60           False          True   \n",
       "52         False   212.0           2.0   1.20            True         False   \n",
       "53         False   120.0           4.0   0.50           False         False   \n",
       "54         False    92.0           2.0   5.50            True         False   \n",
       "55         False   161.0           1.0   1.20           False         False   \n",
       "56         False   312.0           1.0   0.75           False         False   \n",
       "57         False     0.0           0.0   1.60           False         False   \n",
       "58          True   117.0           3.0   1.60           False         False   \n",
       "59         False   110.0           1.0   2.50           False         False   \n",
       "60         False   317.0           1.0   0.80           False         False   \n",
       "61         False    84.0          10.0   4.00           False         False   \n",
       "62         False    84.0           1.0   0.75           False         False   \n",
       "63         False   110.0           1.0   2.50           False         False   \n",
       "64         False    89.0           1.0   5.50           False         False   \n",
       "65         False    35.0           1.0   3.50           False         False   \n",
       "66         False    43.0           1.0   6.00           False          True   \n",
       "67         False   202.0           1.0   1.20           False         False   \n",
       "68         False    53.0           1.0   3.50           False         False   \n",
       "69         False  1057.0           3.0   1.60            True         False   \n",
       "70         False    99.0           1.0   5.50           False         False   \n",
       "71         False   256.0           1.0   0.70           False         False   \n",
       "72         False   133.0           1.0   7.00           False         False   \n",
       "73         False   268.0           1.0   1.20           False         False   \n",
       "74         False   311.0           1.0   1.60           False         False   \n",
       "75         False    40.0           1.0   1.60           False         False   \n",
       "76         False   194.0           1.0   1.20            True         False   \n",
       "77         False   755.0           1.0   0.80           False         False   \n",
       "78         False   117.0           6.0   2.50           False         False   \n",
       "79         False   117.0           3.0   2.50           False         False   \n",
       "80         False   163.0           1.0   1.60           False         False   \n",
       "81         False   140.0           1.0   1.20           False         False   \n",
       "82         False   266.0           1.0   3.50           False          True   \n",
       "83         False   133.0           1.0   5.50           False         False   \n",
       "84         False   217.0           1.0   6.00           False         False   \n",
       "85         False   314.0           1.0   1.60           False         False   \n",
       "86         False   816.0           1.0   1.20           False         False   \n",
       "87         False   217.0           1.0   1.60           False         False   \n",
       "88         False    92.0           8.0   1.60            True         False   \n",
       "89         False   391.0           1.0   1.60           False         False   \n",
       "90         False   168.0           1.0   9.00           False         False   \n",
       "91         False   179.0           1.0   1.60            True         False   \n",
       "92         False   250.0           2.0   0.80           False         False   \n",
       "93         False   161.0           3.0   1.60           False         False   \n",
       "94         False  1484.0           1.0   1.60            True         False   \n",
       "95         False   109.0           1.0   7.50           False         False   \n",
       "96         False   437.0           1.0   1.60           False         False   \n",
       "97         False   261.0           1.0   1.20           False         False   \n",
       "98         False   307.0           1.0   5.00           False         False   \n",
       "99         False    74.0           4.0   0.70           False         False   \n",
       "100         True   133.0           6.0   1.60           False         False   \n",
       "101        False   120.0           1.0   1.20           False         False   \n",
       "102        False    81.0          15.0   0.50           False         False   \n",
       "103        False   145.0           1.0   0.35           False         False   \n",
       "104        False   161.0           2.0   3.50           False         False   \n",
       "105        False   204.0           1.0   1.20           False         False   \n",
       "106        False    81.0           3.0   0.50           False         False   \n",
       "107        False  1331.0           1.0   5.00           False         False   \n",
       "108        False    81.0           3.0   5.00           False         False   \n",
       "109        False   307.0           1.0   1.20           False         False   \n",
       "110        False   307.0           1.0   4.50           False         False   \n",
       "111        False     0.0           0.0   0.80           False         False   \n",
       "112        False   220.0           1.0   5.50           False          True   \n",
       "113        False   268.0           1.0   1.60            True         False   \n",
       "114        False   217.0           3.0   6.00           False         False   \n",
       "115        False     0.0           0.0   1.60           False          True   \n",
       "116        False    84.0           1.0   1.60            True         False   \n",
       "117        False   109.0           1.0   7.50           False         False   \n",
       "118        False   266.0           1.0   1.20           False         False   \n",
       "119        False   335.0           1.0   1.60            True         False   \n",
       "120        False   960.0           3.0   1.60            True         False   \n",
       "121        False   391.0           2.0   0.50           False         False   \n",
       "122        False   135.0           1.0   5.50           False         False   \n",
       "123        False   281.0           1.0   5.50           False         False   \n",
       "124        False    43.0           1.0  11.50           False          True   \n",
       "125        False   192.0           1.0   1.60            True         False   \n",
       "126        False   117.0           3.0   4.50           False         False   \n",
       "127        False   256.0           2.0   0.80           False         False   \n",
       "128        False    53.0           1.0   0.75           False         False   \n",
       "129        False    64.0           4.0   0.80           False         False   \n",
       "130        False   128.0           2.0   0.80           False         False   \n",
       "131        False   337.0           1.0   0.80           False         False   \n",
       "132        False    84.0           2.0   0.25           False         False   \n",
       "133        False   202.0           1.0   1.20           False         False   \n",
       "134        False    81.0           6.0   1.60           False         False   \n",
       "135        False   128.0           1.0   1.20           False         False   \n",
       "136        False   174.0           1.0   1.60           False         False   \n",
       "137        False   204.0           1.0   0.80           False         False   \n",
       "138        False   125.0           2.0   5.00           False         False   \n",
       "139        False     0.0           0.0   1.60           False          True   \n",
       "\n",
       "     invisible  has_ability  any_target  building_target  ground_target  \\\n",
       "0         True         True        True            False          False   \n",
       "1        False        False        True            False          False   \n",
       "2        False        False       False            False          False   \n",
       "3        False        False        True            False          False   \n",
       "4        False        False       False             True          False   \n",
       "5         True        False       False             True           True   \n",
       "6        False        False       False            False          False   \n",
       "7        False        False       False            False          False   \n",
       "8        False        False       False             True           True   \n",
       "9        False        False        True            False          False   \n",
       "10       False        False       False             True           True   \n",
       "11       False        False       False             True          False   \n",
       "12       False        False       False             True           True   \n",
       "13       False        False       False             True           True   \n",
       "14       False        False       False             True           True   \n",
       "15        True         True       False             True           True   \n",
       "16       False        False       False             True           True   \n",
       "17       False        False       False             True           True   \n",
       "18       False        False       False             True           True   \n",
       "19       False        False       False             True           True   \n",
       "20       False        False        True            False          False   \n",
       "21       False        False       False            False          False   \n",
       "22       False        False        True            False          False   \n",
       "23       False        False       False             True           True   \n",
       "24       False        False        True            False          False   \n",
       "25       False        False       False            False          False   \n",
       "26       False        False        True            False          False   \n",
       "27       False        False       False             True          False   \n",
       "28       False        False        True            False          False   \n",
       "29       False        False        True            False          False   \n",
       "30       False        False       False             True           True   \n",
       "31       False        False       False            False          False   \n",
       "32       False        False       False             True          False   \n",
       "33       False        False        True            False          False   \n",
       "34       False        False        True            False          False   \n",
       "35       False        False       False            False          False   \n",
       "36       False        False        True            False          False   \n",
       "37       False        False       False             True           True   \n",
       "38       False        False        True            False          False   \n",
       "39       False        False       False            False          False   \n",
       "40       False        False        True            False          False   \n",
       "41       False        False       False             True          False   \n",
       "42       False        False       False             True           True   \n",
       "43       False        False       False            False          False   \n",
       "44       False        False       False            False          False   \n",
       "45       False        False       False            False          False   \n",
       "46       False        False       False            False          False   \n",
       "47       False        False       False             True           True   \n",
       "48       False        False       False            False          False   \n",
       "49       False        False       False             True           True   \n",
       "50       False        False       False             True          False   \n",
       "51       False        False       False            False          False   \n",
       "52       False        False       False             True           True   \n",
       "53       False        False       False             True           True   \n",
       "54       False         True        True            False          False   \n",
       "55       False         True       False             True           True   \n",
       "56       False        False       False             True          False   \n",
       "57       False        False       False            False          False   \n",
       "58       False        False       False             True           True   \n",
       "59       False        False        True            False          False   \n",
       "60       False        False       False             True          False   \n",
       "61       False        False        True            False          False   \n",
       "62       False        False       False             True          False   \n",
       "63       False        False        True            False          False   \n",
       "64       False        False        True            False          False   \n",
       "65       False        False        True            False          False   \n",
       "66       False        False        True            False          False   \n",
       "67       False        False       False             True           True   \n",
       "68       False        False       False             True          False   \n",
       "69       False        False       False            False          False   \n",
       "70       False         True        True            False          False   \n",
       "71       False        False       False             True           True   \n",
       "72       False        False        True            False          False   \n",
       "73       False        False       False             True           True   \n",
       "74       False        False        True            False          False   \n",
       "75       False         True       False             True           True   \n",
       "76       False        False       False             True           True   \n",
       "77       False        False       False             True           True   \n",
       "78       False        False        True            False          False   \n",
       "79       False        False        True            False          False   \n",
       "80       False        False       False            False          False   \n",
       "81       False         True       False             True           True   \n",
       "82       False        False       False             True           True   \n",
       "83       False        False        True            False          False   \n",
       "84       False        False        True            False          False   \n",
       "85       False        False       False             True           True   \n",
       "86       False        False       False             True           True   \n",
       "87       False        False        True            False          False   \n",
       "88       False        False       False            False          False   \n",
       "89       False        False       False             True           True   \n",
       "90       False        False        True            False          False   \n",
       "91       False        False       False            False          False   \n",
       "92       False        False       False             True          False   \n",
       "93       False        False       False             True           True   \n",
       "94       False        False       False            False          False   \n",
       "95       False        False        True            False          False   \n",
       "96       False        False       False            False          False   \n",
       "97        True        False       False             True           True   \n",
       "98       False        False       False             True          False   \n",
       "99       False        False       False             True          False   \n",
       "100      False        False       False             True           True   \n",
       "101      False        False       False             True          False   \n",
       "102      False        False       False             True           True   \n",
       "103      False        False       False             True          False   \n",
       "104      False        False        True            False          False   \n",
       "105      False         True       False             True           True   \n",
       "106      False        False       False             True           True   \n",
       "107      False        False       False             True           True   \n",
       "108      False        False        True            False          False   \n",
       "109      False        False       False             True           True   \n",
       "110      False        False        True            False          False   \n",
       "111       True        False       False             True          False   \n",
       "112      False        False        True            False          False   \n",
       "113      False        False       False            False          False   \n",
       "114      False        False        True            False          False   \n",
       "115      False        False       False            False          False   \n",
       "116      False        False       False            False          False   \n",
       "117      False        False        True            False          False   \n",
       "118      False        False       False             True           True   \n",
       "119      False        False       False            False          False   \n",
       "120      False        False       False            False          False   \n",
       "121      False        False       False             True          False   \n",
       "122      False        False        True            False          False   \n",
       "123      False        False        True            False          False   \n",
       "124      False        False       False             True           True   \n",
       "125      False        False       False            False          False   \n",
       "126      False        False        True            False          False   \n",
       "127      False        False       False             True           True   \n",
       "128      False        False       False             True          False   \n",
       "129      False        False       False             True          False   \n",
       "130      False        False       False             True          False   \n",
       "131      False        False       False             True           True   \n",
       "132      False        False       False             True          False   \n",
       "133      False        False       False             True           True   \n",
       "134      False        False        True            False          False   \n",
       "135      False        False       False             True          False   \n",
       "136      False        False        True            False          False   \n",
       "137      False        False       False             True           True   \n",
       "138      False        False        True            False          False   \n",
       "139      False        False       False            False          False   \n",
       "\n",
       "     has_upon_breaking_spawn  has_upon_death_spawn  has_periodic_spawn  \\\n",
       "0                      False                 False               False   \n",
       "1                      False                 False               False   \n",
       "2                      False                 False               False   \n",
       "3                      False                 False               False   \n",
       "4                      False                 False               False   \n",
       "5                      False                 False               False   \n",
       "6                       True                 False               False   \n",
       "7                      False                  True                True   \n",
       "8                      False                 False               False   \n",
       "9                      False                 False               False   \n",
       "10                     False                 False               False   \n",
       "11                      True                  True               False   \n",
       "12                     False                 False               False   \n",
       "13                     False                 False               False   \n",
       "14                     False                 False               False   \n",
       "15                     False                 False               False   \n",
       "16                     False                 False               False   \n",
       "17                     False                 False               False   \n",
       "18                     False                 False               False   \n",
       "19                     False                 False               False   \n",
       "20                     False                 False               False   \n",
       "21                     False                 False               False   \n",
       "22                     False                 False               False   \n",
       "23                     False                 False               False   \n",
       "24                     False                 False               False   \n",
       "25                     False                 False               False   \n",
       "26                     False                 False               False   \n",
       "27                     False                 False               False   \n",
       "28                     False                 False               False   \n",
       "29                     False                 False               False   \n",
       "30                     False                 False               False   \n",
       "31                     False                 False               False   \n",
       "32                     False                  True               False   \n",
       "33                     False                 False               False   \n",
       "34                     False                 False               False   \n",
       "35                     False                 False               False   \n",
       "36                     False                 False               False   \n",
       "37                     False                 False               False   \n",
       "38                     False                 False               False   \n",
       "39                     False                 False               False   \n",
       "40                     False                 False                True   \n",
       "41                     False                 False               False   \n",
       "42                     False                 False               False   \n",
       "43                     False                 False               False   \n",
       "44                      True                 False               False   \n",
       "45                     False                  True               False   \n",
       "46                     False                 False               False   \n",
       "47                     False                 False               False   \n",
       "48                     False                  True                True   \n",
       "49                     False                 False               False   \n",
       "50                     False                  True               False   \n",
       "51                     False                  True                True   \n",
       "52                     False                 False               False   \n",
       "53                     False                 False               False   \n",
       "54                     False                 False               False   \n",
       "55                     False                 False               False   \n",
       "56                     False                  True               False   \n",
       "57                     False                 False                True   \n",
       "58                     False                 False               False   \n",
       "59                     False                 False               False   \n",
       "60                     False                 False               False   \n",
       "61                     False                 False               False   \n",
       "62                     False                 False               False   \n",
       "63                     False                 False               False   \n",
       "64                     False                 False               False   \n",
       "65                     False                 False               False   \n",
       "66                     False                 False               False   \n",
       "67                     False                 False               False   \n",
       "68                     False                  True               False   \n",
       "69                     False                 False               False   \n",
       "70                     False                 False               False   \n",
       "71                     False                  True               False   \n",
       "72                     False                 False               False   \n",
       "73                     False                 False               False   \n",
       "74                     False                 False               False   \n",
       "75                     False                 False               False   \n",
       "76                     False                 False               False   \n",
       "77                     False                 False               False   \n",
       "78                     False                 False               False   \n",
       "79                     False                 False               False   \n",
       "80                     False                 False               False   \n",
       "81                     False                 False               False   \n",
       "82                     False                 False               False   \n",
       "83                     False                 False               False   \n",
       "84                     False                 False               False   \n",
       "85                     False                  True                True   \n",
       "86                     False                 False               False   \n",
       "87                     False                  True               False   \n",
       "88                     False                 False               False   \n",
       "89                     False                 False               False   \n",
       "90                     False                 False               False   \n",
       "91                     False                 False               False   \n",
       "92                     False                 False               False   \n",
       "93                     False                 False               False   \n",
       "94                     False                 False               False   \n",
       "95                     False                 False               False   \n",
       "96                      True                 False               False   \n",
       "97                     False                 False               False   \n",
       "98                     False                 False               False   \n",
       "99                     False                 False               False   \n",
       "100                    False                 False               False   \n",
       "101                    False                 False               False   \n",
       "102                    False                 False               False   \n",
       "103                    False                  True               False   \n",
       "104                    False                 False               False   \n",
       "105                    False                 False               False   \n",
       "106                    False                 False               False   \n",
       "107                    False                 False               False   \n",
       "108                    False                 False               False   \n",
       "109                    False                 False               False   \n",
       "110                    False                 False               False   \n",
       "111                     True                  True               False   \n",
       "112                    False                 False               False   \n",
       "113                    False                 False               False   \n",
       "114                    False                 False               False   \n",
       "115                    False                  True                True   \n",
       "116                    False                 False               False   \n",
       "117                    False                 False               False   \n",
       "118                    False                 False               False   \n",
       "119                    False                 False               False   \n",
       "120                    False                 False               False   \n",
       "121                    False                 False               False   \n",
       "122                    False                 False                True   \n",
       "123                    False                 False               False   \n",
       "124                    False                 False               False   \n",
       "125                    False                 False               False   \n",
       "126                    False                 False               False   \n",
       "127                    False                 False               False   \n",
       "128                    False                 False               False   \n",
       "129                    False                 False               False   \n",
       "130                    False                  True               False   \n",
       "131                    False                 False               False   \n",
       "132                    False                 False               False   \n",
       "133                    False                 False               False   \n",
       "134                    False                 False               False   \n",
       "135                    False                 False               False   \n",
       "136                    False                 False               False   \n",
       "137                    False                 False               False   \n",
       "138                    False                 False               False   \n",
       "139                    False                 False               False   \n",
       "\n",
       "     single_damage_type  is_troop  is_spell  is_building  is_tower_troop  \\\n",
       "0                  True      True     False        False           False   \n",
       "1                  True      True     False        False           False   \n",
       "2                 False     False      True        False           False   \n",
       "3                  True      True     False        False           False   \n",
       "4                  True      True     False        False           False   \n",
       "5                  True      True     False        False           False   \n",
       "6                  True     False      True        False           False   \n",
       "7                 False     False     False         True           False   \n",
       "8                  True      True     False        False           False   \n",
       "9                  True      True     False        False           False   \n",
       "10                 True      True     False        False           False   \n",
       "11                 True      True     False        False           False   \n",
       "12                 True      True     False        False           False   \n",
       "13                 True     False     False         True           False   \n",
       "14                 True      True     False        False           False   \n",
       "15                 True      True     False        False           False   \n",
       "16                 True      True     False        False           False   \n",
       "17                 True     False     False         True           False   \n",
       "18                 True      True     False        False           False   \n",
       "19                 True     False     False         True           False   \n",
       "20                 True     False     False        False            True   \n",
       "21                False     False      True        False           False   \n",
       "22                 True     False     False        False            True   \n",
       "23                 True      True     False        False           False   \n",
       "24                 True      True     False        False           False   \n",
       "25                False     False      True        False           False   \n",
       "26                False      True     False        False           False   \n",
       "27                 True      True     False        False           False   \n",
       "28                False      True     False        False           False   \n",
       "29                False      True     False        False           False   \n",
       "30                 True      True     False        False           False   \n",
       "31                False     False     False         True           False   \n",
       "32                 True      True     False        False           False   \n",
       "33                False      True     False        False           False   \n",
       "34                 True      True     False        False           False   \n",
       "35                 True     False      True        False           False   \n",
       "36                False      True     False        False           False   \n",
       "37                 True      True     False        False           False   \n",
       "38                 True      True     False        False           False   \n",
       "39                 True     False      True        False           False   \n",
       "40                 True      True     False        False           False   \n",
       "41                 True      True     False        False           False   \n",
       "42                 True      True     False        False           False   \n",
       "43                 True     False      True        False           False   \n",
       "44                False     False      True        False           False   \n",
       "45                False     False     False         True           False   \n",
       "46                False     False      True        False           False   \n",
       "47                 True      True     False        False           False   \n",
       "48                False     False     False         True           False   \n",
       "49                False      True     False        False           False   \n",
       "50                False      True     False        False           False   \n",
       "51                False     False     False         True           False   \n",
       "52                False      True     False        False           False   \n",
       "53                 True      True     False        False           False   \n",
       "54                 True      True     False        False           False   \n",
       "55                 True      True     False        False           False   \n",
       "56                 True      True     False        False           False   \n",
       "57                False     False      True        False           False   \n",
       "58                 True      True     False        False           False   \n",
       "59                 True      True     False        False           False   \n",
       "60                 True      True     False        False           False   \n",
       "61                False      True     False        False           False   \n",
       "62                 True      True     False        False           False   \n",
       "63                 True      True     False        False           False   \n",
       "64                 True      True     False        False           False   \n",
       "65                False      True     False        False           False   \n",
       "66                False     False     False         True           False   \n",
       "67                 True      True     False        False           False   \n",
       "68                 True      True     False        False           False   \n",
       "69                 True     False      True        False           False   \n",
       "70                 True      True     False        False           False   \n",
       "71                 True      True     False        False           False   \n",
       "72                 True      True     False        False           False   \n",
       "73                 True      True     False        False           False   \n",
       "74                 True      True     False        False           False   \n",
       "75                False      True     False        False           False   \n",
       "76                 True      True     False        False           False   \n",
       "77                 True      True     False        False           False   \n",
       "78                 True      True     False        False           False   \n",
       "79                 True      True     False        False           False   \n",
       "80                False     False      True        False           False   \n",
       "81                False      True     False        False           False   \n",
       "82                 True     False     False         True           False   \n",
       "83                 True      True     False        False           False   \n",
       "84                 True      True     False        False           False   \n",
       "85                 True      True     False        False           False   \n",
       "86                 True      True     False        False           False   \n",
       "87                 True      True     False        False           False   \n",
       "88                False     False      True        False           False   \n",
       "89                 True      True     False        False           False   \n",
       "90                 True      True     False        False           False   \n",
       "91                 True     False      True        False           False   \n",
       "92                False      True     False        False           False   \n",
       "93                False      True     False        False           False   \n",
       "94                 True     False      True        False           False   \n",
       "95                 True     False     False        False            True   \n",
       "96                 True     False      True        False           False   \n",
       "97                 True      True     False        False           False   \n",
       "98                 True      True     False        False           False   \n",
       "99                 True      True     False        False           False   \n",
       "100                True      True     False        False           False   \n",
       "101                True      True     False        False           False   \n",
       "102                True      True     False        False           False   \n",
       "103                True      True     False        False           False   \n",
       "104                True      True     False        False           False   \n",
       "105                True      True     False        False           False   \n",
       "106                True      True     False        False           False   \n",
       "107                True      True     False        False           False   \n",
       "108                True      True     False        False           False   \n",
       "109                True      True     False        False           False   \n",
       "110               False      True     False        False           False   \n",
       "111               False      True     False        False           False   \n",
       "112                True     False     False         True           False   \n",
       "113                True     False      True        False           False   \n",
       "114                True      True     False        False           False   \n",
       "115               False     False     False         True           False   \n",
       "116                True     False      True        False           False   \n",
       "117                True     False     False        False            True   \n",
       "118                True      True     False        False           False   \n",
       "119                True     False      True        False           False   \n",
       "120               False     False      True        False           False   \n",
       "121                True      True     False        False           False   \n",
       "122                True      True     False        False           False   \n",
       "123                True      True     False        False           False   \n",
       "124                True     False     False         True           False   \n",
       "125                True     False      True        False           False   \n",
       "126                True      True     False        False           False   \n",
       "127                True      True     False        False           False   \n",
       "128                True      True     False        False           False   \n",
       "129                True      True     False        False           False   \n",
       "130                True      True     False        False           False   \n",
       "131                True      True     False        False           False   \n",
       "132                True      True     False        False           False   \n",
       "133                True      True     False        False           False   \n",
       "134                True      True     False        False           False   \n",
       "135                True      True     False        False           False   \n",
       "136                True      True     False        False           False   \n",
       "137                True      True     False        False           False   \n",
       "138                True      True     False        False           False   \n",
       "139               False     False     False        False           False   \n",
       "\n",
       "     is_spawned  speed  has_ranged_attack  special_attack_type  \\\n",
       "0         False    1.2               True                False   \n",
       "1         False    1.2               True                False   \n",
       "2         False    1.2              False                 True   \n",
       "3         False    1.8               True                False   \n",
       "4         False    1.2              False                False   \n",
       "5         False    1.8              False                False   \n",
       "6         False    1.2              False                False   \n",
       "7         False    0.0              False                False   \n",
       "8          True    1.2              False                False   \n",
       "9          True    2.4              False                False   \n",
       "10        False    1.2              False                False   \n",
       "11        False    1.2              False                False   \n",
       "12        False    1.8              False                False   \n",
       "13        False    0.0               True                False   \n",
       "14        False    1.2               True                False   \n",
       "15        False    1.8              False                False   \n",
       "16        False    0.9               True                False   \n",
       "17        False    0.0               True                False   \n",
       "18        False    1.2               True                False   \n",
       "19        False    0.0               True                False   \n",
       "20        False    0.0               True                False   \n",
       "21        False    1.2              False                False   \n",
       "22        False    0.0               True                False   \n",
       "23        False    1.2              False                False   \n",
       "24        False    2.4               True                False   \n",
       "25        False    1.2              False                 True   \n",
       "26        False    1.2               True                 True   \n",
       "27        False    0.9              False                False   \n",
       "28        False    2.4               True                 True   \n",
       "29        False    1.8               True                 True   \n",
       "30        False    1.8              False                False   \n",
       "31        False    0.0              False                False   \n",
       "32        False    0.9              False                False   \n",
       "33        False    1.2               True                 True   \n",
       "34         True    2.4               True                False   \n",
       "35        False    1.2              False                False   \n",
       "36        False    1.8               True                 True   \n",
       "37        False    1.2              False                False   \n",
       "38        False    1.8               True                False   \n",
       "39        False    1.2              False                False   \n",
       "40        False    0.9               True                False   \n",
       "41        False    0.9              False                False   \n",
       "42        False    1.2              False                False   \n",
       "43        False    1.2              False                False   \n",
       "44        False    1.2              False                False   \n",
       "45        False    0.0              False                False   \n",
       "46        False    1.2              False                 True   \n",
       "47        False    1.2               True                False   \n",
       "48        False    0.0              False                False   \n",
       "49        False    2.4               True                 True   \n",
       "50        False    1.2               True                 True   \n",
       "51        False    0.0               True                False   \n",
       "52        False    1.2               True                 True   \n",
       "53         True    2.4              False                False   \n",
       "54        False    1.2               True                False   \n",
       "55        False    1.2              False                False   \n",
       "56        False    0.9              False                False   \n",
       "57        False    1.2              False                False   \n",
       "58        False    1.8              False                False   \n",
       "59        False    2.4               True                False   \n",
       "60        False    2.4              False                False   \n",
       "61        False    1.2               True                 True   \n",
       "62        False    0.9              False                False   \n",
       "63        False    2.4               True                False   \n",
       "64        False    1.2               True                False   \n",
       "65        False    1.2               True                 True   \n",
       "66        False    0.0               True                 True   \n",
       "67        False    1.2              False                False   \n",
       "68        False    0.9               True                False   \n",
       "69        False    1.2              False                False   \n",
       "70        False    1.2               True                False   \n",
       "71        False    2.4              False                False   \n",
       "72        False    1.2               True                False   \n",
       "73        False    1.2              False                False   \n",
       "74        False    1.2               True                False   \n",
       "75        False    1.2              False                 True   \n",
       "76        False    1.8              False                False   \n",
       "77        False    1.8              False                False   \n",
       "78        False    1.8               True                False   \n",
       "79        False    1.8               True                False   \n",
       "80        False    1.2              False                False   \n",
       "81        False    1.2              False                 True   \n",
       "82        False    0.0               True                False   \n",
       "83        False    1.2               True                False   \n",
       "84        False    1.2               True                False   \n",
       "85        False    1.2              False                False   \n",
       "86        False    0.9              False                False   \n",
       "87        False    1.2              False                False   \n",
       "88        False    1.2              False                 True   \n",
       "89        False    1.2              False                False   \n",
       "90        False    1.2               True                False   \n",
       "91         True    1.2              False                False   \n",
       "92        False    1.2               True                 True   \n",
       "93        False    1.2               True                 True   \n",
       "94        False    1.2              False                False   \n",
       "95        False    0.0               True                False   \n",
       "96        False    1.2              False                False   \n",
       "97        False    1.8              False                False   \n",
       "98        False    0.9               True                False   \n",
       "99        False    2.4              False                False   \n",
       "100        True    1.2              False                False   \n",
       "101       False    1.2              False                False   \n",
       "102       False    1.2              False                False   \n",
       "103       False    1.8              False                False   \n",
       "104       False    1.8               True                False   \n",
       "105       False    1.2              False                False   \n",
       "106        True    1.8              False                False   \n",
       "107       False    0.9               True                False   \n",
       "108        True    2.4               True                False   \n",
       "109       False    1.2              False                False   \n",
       "110       False    1.2               True                False   \n",
       "111       False    1.2              False                False   \n",
       "112       False    0.0               True                False   \n",
       "113       False    1.2              False                False   \n",
       "114       False    1.2               True                False   \n",
       "115       False    0.0              False                False   \n",
       "116       False    1.2              False                False   \n",
       "117       False    0.0               True                False   \n",
       "118       False    1.2              False                False   \n",
       "119       False    1.2              False                False   \n",
       "120       False    1.2              False                 True   \n",
       "121       False    2.4              False                False   \n",
       "122       False    1.2               True                False   \n",
       "123       False    1.2               True                False   \n",
       "124       False    0.0               True                False   \n",
       "125       False    1.2              False                False   \n",
       "126       False    1.2               True                False   \n",
       "127        True    1.2              False                False   \n",
       "128        True    2.4              False                False   \n",
       "129        True    1.8              False                False   \n",
       "130        True    1.2              False                False   \n",
       "131        True    1.8              False                False   \n",
       "132        True    0.9              False                False   \n",
       "133        True    1.2              False                False   \n",
       "134        True    1.2              False                False   \n",
       "135       False    1.2              False                False   \n",
       "136        True    1.2              False                False   \n",
       "137       False    1.2              False                False   \n",
       "138       False    1.2               True                False   \n",
       "139        True    1.2              False                False   \n",
       "\n",
       "     has_friendly_buff  is_free_card  no_hit_speed  no_attack  no_hitpoints  \\\n",
       "0                False         False         False      False         False   \n",
       "1                False         False         False      False         False   \n",
       "2                False         False          True      False          True   \n",
       "3                False         False         False      False         False   \n",
       "4                False         False         False      False         False   \n",
       "5                False         False         False      False         False   \n",
       "6                False         False          True      False          True   \n",
       "7                False         False          True       True         False   \n",
       "8                False         False         False      False         False   \n",
       "9                False         False         False      False         False   \n",
       "10                True         False         False      False         False   \n",
       "11               False         False          True      False         False   \n",
       "12               False         False         False      False         False   \n",
       "13               False         False         False      False         False   \n",
       "14               False         False         False      False         False   \n",
       "15               False         False         False      False         False   \n",
       "16               False         False         False      False         False   \n",
       "17               False         False         False      False         False   \n",
       "18               False         False         False      False         False   \n",
       "19               False          True         False      False         False   \n",
       "20               False          True         False      False         False   \n",
       "21                True         False          True       True          True   \n",
       "22               False          True         False      False         False   \n",
       "23               False         False         False      False         False   \n",
       "24               False         False         False      False         False   \n",
       "25               False         False          True      False          True   \n",
       "26               False         False         False      False         False   \n",
       "27               False         False         False      False         False   \n",
       "28               False         False          True      False         False   \n",
       "29               False         False         False      False         False   \n",
       "30               False         False         False      False         False   \n",
       "31                True         False          True       True         False   \n",
       "32               False         False         False      False         False   \n",
       "33               False         False         False      False         False   \n",
       "34               False         False          True      False         False   \n",
       "35               False         False          True      False          True   \n",
       "36               False         False         False      False         False   \n",
       "37               False         False         False      False         False   \n",
       "38               False         False         False      False         False   \n",
       "39               False         False          True      False          True   \n",
       "40               False         False         False      False         False   \n",
       "41               False         False         False      False         False   \n",
       "42               False         False         False      False         False   \n",
       "43               False         False          True      False          True   \n",
       "44               False         False          True       True          True   \n",
       "45               False         False          True       True         False   \n",
       "46                True         False          True      False          True   \n",
       "47               False         False         False      False         False   \n",
       "48               False         False          True      False         False   \n",
       "49               False         False         False      False         False   \n",
       "50               False         False         False      False         False   \n",
       "51               False         False          True       True         False   \n",
       "52               False         False         False      False         False   \n",
       "53               False         False         False      False         False   \n",
       "54               False         False         False      False         False   \n",
       "55               False         False         False      False         False   \n",
       "56               False         False         False      False         False   \n",
       "57               False         False          True       True          True   \n",
       "58               False         False         False      False         False   \n",
       "59                True         False          True      False         False   \n",
       "60               False         False         False      False         False   \n",
       "61               False         False         False      False         False   \n",
       "62               False         False         False      False         False   \n",
       "63               False         False          True      False         False   \n",
       "64               False         False         False      False         False   \n",
       "65               False         False         False      False         False   \n",
       "66               False         False         False      False         False   \n",
       "67               False         False         False      False         False   \n",
       "68               False         False         False      False         False   \n",
       "69               False         False          True      False          True   \n",
       "70               False         False         False      False         False   \n",
       "71                True         False         False      False         False   \n",
       "72               False         False         False      False         False   \n",
       "73               False         False         False      False         False   \n",
       "74               False         False         False      False         False   \n",
       "75               False         False         False      False         False   \n",
       "76               False         False         False      False         False   \n",
       "77               False         False         False      False         False   \n",
       "78               False         False         False      False         False   \n",
       "79               False         False         False      False         False   \n",
       "80                True         False          True       True          True   \n",
       "81               False         False         False      False         False   \n",
       "82               False         False         False      False         False   \n",
       "83               False         False         False      False         False   \n",
       "84               False         False         False      False         False   \n",
       "85               False         False         False      False         False   \n",
       "86               False         False         False      False         False   \n",
       "87               False         False         False      False         False   \n",
       "88               False         False          True      False          True   \n",
       "89               False         False         False      False         False   \n",
       "90               False         False         False      False         False   \n",
       "91                True         False          True      False          True   \n",
       "92               False         False         False      False         False   \n",
       "93               False         False          True      False          True   \n",
       "94               False         False          True      False          True   \n",
       "95                True          True         False      False         False   \n",
       "96               False         False          True      False          True   \n",
       "97               False         False         False      False         False   \n",
       "98               False         False         False      False         False   \n",
       "99               False         False         False      False         False   \n",
       "100              False         False         False      False         False   \n",
       "101               True         False         False      False         False   \n",
       "102              False         False         False      False         False   \n",
       "103              False         False          True      False         False   \n",
       "104              False         False         False      False         False   \n",
       "105               True         False         False      False         False   \n",
       "106              False         False         False      False         False   \n",
       "107              False         False         False      False         False   \n",
       "108              False         False         False      False         False   \n",
       "109              False         False         False      False         False   \n",
       "110              False         False         False      False         False   \n",
       "111              False         False          True       True         False   \n",
       "112              False         False         False      False         False   \n",
       "113              False         False          True      False          True   \n",
       "114              False         False         False      False         False   \n",
       "115              False         False          True       True         False   \n",
       "116              False         False          True      False          True   \n",
       "117              False          True         False      False         False   \n",
       "118              False         False         False      False         False   \n",
       "119               True         False          True      False          True   \n",
       "120              False         False          True      False          True   \n",
       "121              False         False          True      False         False   \n",
       "122              False         False         False      False         False   \n",
       "123              False         False         False      False         False   \n",
       "124              False         False         False      False         False   \n",
       "125              False         False          True      False          True   \n",
       "126              False         False         False      False         False   \n",
       "127              False          True         False      False         False   \n",
       "128              False          True         False      False         False   \n",
       "129              False          True         False      False         False   \n",
       "130              False          True         False      False         False   \n",
       "131              False          True         False      False         False   \n",
       "132              False          True         False      False         False   \n",
       "133              False          True         False      False         False   \n",
       "134              False          True         False      False         False   \n",
       "135              False          True         False      False         False   \n",
       "136              False          True         False      False         False   \n",
       "137              False          True         False      False         False   \n",
       "138              False          True         False      False         False   \n",
       "139              False          True          True       True         False   \n",
       "\n",
       "     damage_per_elixir  damage_per_second  damage_output  hp_per_elixir  \\\n",
       "0            45.000000         187.500000          225.0     200.000000   \n",
       "1            37.333333         124.444444          224.0     101.333333   \n",
       "2            40.666667         136.000000          366.0     339.833333   \n",
       "3            40.250000         107.333333          161.0     288.000000   \n",
       "4           128.000000         320.000000          640.0     335.800000   \n",
       "5            64.666667         194.000000          194.0     302.000000   \n",
       "6           120.000000         136.000000          240.0     509.750000   \n",
       "7             0.000000         136.000000          250.0     194.000000   \n",
       "8            38.400000         147.692308          960.0     134.000000   \n",
       "9            40.500000          62.307692          405.0      40.500000   \n",
       "10           37.000000          98.666667          148.0     429.250000   \n",
       "11           71.500000         136.000000          286.0     241.750000   \n",
       "12           51.000000         204.000000          102.0     448.000000   \n",
       "13           55.500000         123.333333          222.0     339.000000   \n",
       "14          112.500000         125.000000          225.0     166.000000   \n",
       "15           44.666667         223.333333          268.0     437.333333   \n",
       "16           57.800000         115.600000          289.0     416.200000   \n",
       "17           70.666667         212.000000          212.0     274.666667   \n",
       "18           42.400000         235.555556          212.0     361.800000   \n",
       "19           42.575000         235.555556          212.0     270.666667   \n",
       "20           42.575000         145.454545          320.0     270.666667   \n",
       "21            0.000000         136.000000          250.0     339.833333   \n",
       "22           42.575000         214.000000          107.0     270.666667   \n",
       "23           66.500000         204.615385          266.0     360.000000   \n",
       "24           52.000000         195.000000          156.0      87.000000   \n",
       "25           27.000000         136.000000          243.0     339.833333   \n",
       "26           38.400000          91.428571          576.0     189.800000   \n",
       "27           23.285714          77.619048          163.0     550.714286   \n",
       "28           99.000000         136.000000          891.0     230.000000   \n",
       "29           28.750000          63.888889          230.0     178.500000   \n",
       "30           64.000000         274.285714          768.0     223.500000   \n",
       "31            0.000000         136.000000          250.0     178.333333   \n",
       "32           84.333333         230.000000          253.0     523.000000   \n",
       "33           33.600000          70.000000          336.0     256.000000   \n",
       "34          207.000000         136.000000          207.0     230.000000   \n",
       "35          172.000000         136.000000          688.0     254.875000   \n",
       "36           21.333333          21.333333          320.0     101.333333   \n",
       "37           64.666667         149.230769          194.0     290.000000   \n",
       "38           42.750000         155.454545          171.0     153.500000   \n",
       "39           28.750000         136.000000          115.0     254.875000   \n",
       "40           33.750000          75.000000          135.0     224.000000   \n",
       "41           50.600000         168.666667          253.0     818.000000   \n",
       "42           46.000000         197.142857          276.0     602.833333   \n",
       "43           89.500000         136.000000          179.0     509.750000   \n",
       "44            0.000000         136.000000          250.0     339.833333   \n",
       "45            0.000000         136.000000          250.0     195.000000   \n",
       "46           17.500000         136.000000          210.0     509.750000   \n",
       "47           46.500000         155.000000          186.0     325.000000   \n",
       "48           21.000000         136.000000           84.0     328.250000   \n",
       "49           40.000000         109.090909          720.0      67.333333   \n",
       "50           29.333333         117.333333          528.0     538.833333   \n",
       "51            0.000000         136.000000          250.0     307.000000   \n",
       "52           42.400000         176.666667          424.0     460.800000   \n",
       "53           60.000000         109.090909          480.0     101.000000   \n",
       "54           18.400000          51.111111          184.0     144.200000   \n",
       "55           40.250000         178.888889          161.0     449.750000   \n",
       "56           39.000000         124.800000          312.0     640.000000   \n",
       "57            0.000000         136.000000          250.0     203.900000   \n",
       "58           39.000000         117.000000          351.0     112.333333   \n",
       "59          110.000000         136.000000          110.0     230.000000   \n",
       "60           79.250000         198.125000          317.0     424.250000   \n",
       "61           21.000000          38.181818          840.0     221.250000   \n",
       "62           42.000000          33.600000           84.0     657.500000   \n",
       "63          110.000000         136.000000          110.0     230.000000   \n",
       "64           29.666667          52.352941           89.0     229.333333   \n",
       "65            8.750000          87.500000           35.0     323.750000   \n",
       "66            8.600000         107.500000           43.0     349.600000   \n",
       "67           67.333333         168.333333          202.0     588.666667   \n",
       "68            7.571429          40.769231           53.0     511.571429   \n",
       "69          176.166667         136.000000         3171.0     169.916667   \n",
       "70           33.000000          82.500000           99.0     232.666667   \n",
       "71           64.000000         320.000000          256.0     320.500000   \n",
       "72           33.250000         120.909091          133.0     132.250000   \n",
       "73           38.285714         157.647059          268.0     570.428571   \n",
       "74          103.666667         207.333333          311.0     279.000000   \n",
       "75           10.000000         100.000000           40.0     562.500000   \n",
       "76           64.666667         149.230769          194.0     403.333333   \n",
       "77          188.750000         471.875000          755.0     358.250000   \n",
       "78           23.400000         106.363636          702.0      46.000000   \n",
       "79           39.000000         106.363636          351.0      76.666667   \n",
       "80           40.750000         136.000000          250.0     254.875000   \n",
       "81           28.000000         175.000000          140.0     442.800000   \n",
       "82           66.500000          53.200000          266.0     342.250000   \n",
       "83           33.250000         133.000000          133.0     132.250000   \n",
       "84           54.250000         217.000000          217.0     180.250000   \n",
       "85           78.500000         241.538462          314.0     226.500000   \n",
       "86          116.571429         453.333333          816.0     537.142857   \n",
       "87           54.250000         217.000000          217.0     263.000000   \n",
       "88           23.000000         136.000000          736.0     254.875000   \n",
       "89           78.200000         279.285714          391.0     384.000000   \n",
       "90           56.000000          56.000000          168.0      87.000000   \n",
       "91           89.500000         136.000000          179.0     509.750000   \n",
       "92           50.000000         138.888889          500.0     339.400000   \n",
       "93           32.200000         136.000000          483.0     203.900000   \n",
       "94          247.333333         136.000000         1484.0     169.916667   \n",
       "95           42.575000         109.000000          109.0     270.666667   \n",
       "96          145.666667         136.000000          437.0     339.833333   \n",
       "97           87.000000         145.000000          261.0     403.333333   \n",
       "98           51.166667         180.588235          307.0     527.333333   \n",
       "99           14.800000          61.666667          296.0     167.400000   \n",
       "100          19.000000         102.307692          798.0     112.428571   \n",
       "101          30.000000          80.000000          120.0     665.500000   \n",
       "102          27.000000          81.000000         1215.0      27.000000   \n",
       "103          48.333333         136.000000          145.0     177.333333   \n",
       "104          40.250000          84.736842          322.0     140.000000   \n",
       "105          51.000000         127.500000          204.0     574.500000   \n",
       "106          81.000000          81.000000          243.0      81.000000   \n",
       "107         221.833333         332.750000         1331.0     241.833333   \n",
       "108          40.500000          47.647059          243.0      66.500000   \n",
       "109         102.333333         279.090909          307.0     358.333333   \n",
       "110          51.166667         219.285714          307.0     209.000000   \n",
       "111           0.000000         136.000000          250.0      40.500000   \n",
       "112          55.000000         200.000000          220.0     288.000000   \n",
       "113         134.000000         136.000000          268.0     509.750000   \n",
       "114          24.111111         217.000000          651.0      80.111111   \n",
       "115           0.000000         136.000000          250.0     176.333333   \n",
       "116          28.000000         136.000000           84.0     339.833333   \n",
       "117          42.575000         136.250000          109.0     270.666667   \n",
       "118          66.500000         177.333333          266.0     476.750000   \n",
       "119         111.666667         136.000000          335.0     339.833333   \n",
       "120         320.000000         136.000000         2880.0     339.833333   \n",
       "121         195.500000         136.000000          782.0     165.000000   \n",
       "122          27.000000         122.727273          135.0     167.800000   \n",
       "123          56.200000         200.714286          281.0     151.000000   \n",
       "124           7.166667         143.333333           43.0     266.666667   \n",
       "125          96.000000         136.000000          192.0     509.750000   \n",
       "126          29.250000          55.714286          351.0     132.250000   \n",
       "127          42.575000         182.857143          512.0     270.666667   \n",
       "128          42.575000          44.166667           53.0     270.666667   \n",
       "129          42.575000          58.181818          256.0     270.666667   \n",
       "130          42.575000         116.363636          256.0     270.666667   \n",
       "131          42.575000         306.363636          337.0     270.666667   \n",
       "132          42.575000          33.600000          168.0     270.666667   \n",
       "133          42.575000         168.333333          202.0     270.666667   \n",
       "134          42.575000          47.647059          486.0     270.666667   \n",
       "135          42.575000          85.333333          128.0     270.666667   \n",
       "136          42.575000         174.000000          174.0     270.666667   \n",
       "137          42.575000         136.000000          204.0     270.666667   \n",
       "138          42.575000         125.000000          250.0     270.666667   \n",
       "139          42.575000         136.000000          250.0     270.666667   \n",
       "\n",
       "     damage_by_hitpoints  aoe_by_range  aoe_by_damage  win_con  \\\n",
       "0               0.225000          0.00           0.00    False   \n",
       "1               0.368421          0.00           0.00    False   \n",
       "2               0.173387          5.60         427.00    False   \n",
       "3               0.139757          4.20         193.20    False   \n",
       "4               0.381179          0.00           0.00     True   \n",
       "5               0.214128          0.00           0.00    False   \n",
       "6               0.173387          0.00           0.00    False   \n",
       "7               0.000000          0.00           0.00    False   \n",
       "8               0.286567          0.00           0.00    False   \n",
       "9               1.000000          0.00           0.00    False   \n",
       "10              0.086197          6.40         592.00    False   \n",
       "11              0.295760          0.00           0.00     True   \n",
       "12              0.113839          0.00           0.00    False   \n",
       "13              0.163717          9.00         333.00    False   \n",
       "14              0.677711          6.75         337.50    False   \n",
       "15              0.102134          0.00           0.00    False   \n",
       "16              0.138876          0.00           0.00    False   \n",
       "17              0.257282          0.00           0.00    False   \n",
       "18              0.117192          0.00           0.00    False   \n",
       "19              0.257282          0.00           0.00    False   \n",
       "20              0.122324          0.00           0.00    False   \n",
       "21              0.173387          4.80           0.00    False   \n",
       "22              0.038656          0.00           0.00    False   \n",
       "23              0.184722          1.32         292.60    False   \n",
       "24              0.597701          0.00           0.00    False   \n",
       "25              0.173387          5.60         283.50    False   \n",
       "26              0.202318          0.00           0.00    False   \n",
       "27              0.042283          3.60         489.00     True   \n",
       "28              0.430435          0.00           0.00    False   \n",
       "29              0.161064          0.00           0.00    False   \n",
       "30              0.286353          0.00           0.00    False   \n",
       "31              0.000000          0.00           0.00    False   \n",
       "32              0.161249          0.00           0.00     True   \n",
       "33              0.131250          4.50         168.00    False   \n",
       "34              0.900000          5.75         476.10    False   \n",
       "35              0.173387          4.00        1720.00    False   \n",
       "36              0.210526          2.40          25.60    False   \n",
       "37              0.222989          0.00           0.00    False   \n",
       "38              0.278502          0.00           0.00    False   \n",
       "39              0.173387          4.80         345.00    False   \n",
       "40              0.150670          0.00           0.00    False   \n",
       "41              0.061858          0.00           0.00     True   \n",
       "42              0.076306          0.00           0.00    False   \n",
       "43              0.173387          4.00         447.50    False   \n",
       "44              0.173387          2.40           0.00    False   \n",
       "45              0.000000          0.00           0.00    False   \n",
       "46              0.173387          4.80         105.00    False   \n",
       "47              0.143077          5.00         186.00    False   \n",
       "48              0.063976          0.00           0.00    False   \n",
       "49              0.594059          0.00           0.00    False   \n",
       "50              0.054439          0.00           0.00     True   \n",
       "51              0.000000          0.00           0.00    False   \n",
       "52              0.092014          1.80         318.00    False   \n",
       "53              0.594059          0.00           0.00    False   \n",
       "54              0.127601          0.00           0.00    False   \n",
       "55              0.089494          0.00           0.00    False   \n",
       "56              0.060937          0.00           0.00     True   \n",
       "57              0.173387          6.40           0.00    False   \n",
       "58              0.347181          0.00           0.00    False   \n",
       "59              0.478261          6.25         275.00    False   \n",
       "60              0.186800          0.00           0.00     True   \n",
       "61              0.094915          1.20          25.20    False   \n",
       "62              0.063878          0.00           0.00     True   \n",
       "63              0.478261          3.75         165.00    False   \n",
       "64              0.129360          5.50          89.00    False   \n",
       "65              0.027027          0.00           0.00    False   \n",
       "66              0.024600          0.00           0.00    False   \n",
       "67              0.114383          0.00           0.00    False   \n",
       "68              0.014800          0.00           0.00     True   \n",
       "69              0.173387          5.60        3699.50    False   \n",
       "70              0.141834          0.00           0.00    False   \n",
       "71              0.199688          0.00           0.00    False   \n",
       "72              0.251418          1.75          33.25    False   \n",
       "73              0.067117          1.56         348.40    False   \n",
       "74              0.371565          0.00           0.00    False   \n",
       "75              0.017778          0.00           0.00    False   \n",
       "76              0.160331          0.00           0.00    False   \n",
       "77              0.526867          0.00           0.00    False   \n",
       "78              0.508696          0.00           0.00    False   \n",
       "79              0.508696          0.00           0.00    False   \n",
       "80              0.173387          0.00           0.00    False   \n",
       "81              0.063234          0.00           0.00    False   \n",
       "82              0.194302          7.00         532.00    False   \n",
       "83              0.251418          0.00           0.00    False   \n",
       "84              0.300971          0.00           0.00    False   \n",
       "85              0.346578          0.00           0.00    False   \n",
       "86              0.217021          0.00           0.00    False   \n",
       "87              0.206274          0.00           0.00    False   \n",
       "88              0.173387          5.60         322.00    False   \n",
       "89              0.203646          0.00           0.00    False   \n",
       "90              0.643678         18.00         336.00    False   \n",
       "91              0.173387          4.80         537.00    False   \n",
       "92              0.147319          0.00           0.00     True   \n",
       "93              0.173387          0.00           0.00    False   \n",
       "94              0.173387          3.20        2968.00    False   \n",
       "95              0.037316          0.00           0.00    False   \n",
       "96              0.173387          4.80        1311.00    False   \n",
       "97              0.215702          1.20         261.00    False   \n",
       "98              0.097029          0.00           0.00     True   \n",
       "99              0.088411          0.00           0.00     True   \n",
       "100             0.168996          0.00           0.00    False   \n",
       "101             0.045079          0.00           0.00     True   \n",
       "102             1.000000          0.00           0.00    False   \n",
       "103             0.272556          0.70         290.00     True   \n",
       "104             0.287500          3.50         161.00    False   \n",
       "105             0.088773          1.56         265.20    False   \n",
       "106             1.000000          0.00           0.00    False   \n",
       "107             0.917298          9.00        2395.80    False   \n",
       "108             0.609023          0.00           0.00    False   \n",
       "109             0.285581          0.00           0.00    False   \n",
       "110             0.244817          0.00           0.00    False   \n",
       "111             0.000000          0.00           0.00     True   \n",
       "112             0.190972          0.00           0.00    False   \n",
       "113             0.173387          0.00           0.00    False   \n",
       "114             0.300971          0.00           0.00    False   \n",
       "115             0.000000          0.00           0.00    False   \n",
       "116             0.173387          8.80         462.00    False   \n",
       "117             0.035714          0.00           0.00    False   \n",
       "118             0.139486          2.40         532.00    False   \n",
       "119             0.173387          4.00         837.50    False   \n",
       "120             0.173387          4.00        2400.00    False   \n",
       "121             1.184848          0.75         586.50     True   \n",
       "122             0.160906          8.25         202.50    False   \n",
       "123             0.372185          8.25         421.50    False   \n",
       "124             0.026875          0.00           0.00    False   \n",
       "125             0.173387          4.00         480.00    False   \n",
       "126             0.221172          0.00           0.00    False   \n",
       "127             0.842105          0.00           0.00    False   \n",
       "128             0.084261          0.00           0.00     True   \n",
       "129             0.177778          0.00           0.00     True   \n",
       "130             0.167979          0.00           0.00     True   \n",
       "131             0.312037          0.00           0.00    False   \n",
       "132             0.080847          0.00           0.00     True   \n",
       "133             0.126250          0.00           0.00    False   \n",
       "134             0.373272          0.00           0.00    False   \n",
       "135             0.053669          0.00           0.00     True   \n",
       "136             0.206651          0.00           0.00    False   \n",
       "137             0.105155          0.00           0.00    False   \n",
       "138             0.478927          0.00           0.00    False   \n",
       "139             0.000000          0.00           0.00    False   \n",
       "\n",
       "     aoe_per_elixir  control_special  dps_special  air_control  ground_dps  \\\n",
       "0          0.000000            False        False         True       False   \n",
       "1          0.000000            False        False        False       False   \n",
       "2          1.166667            False        False        False       False   \n",
       "3          0.300000            False        False        False       False   \n",
       "4          0.000000            False        False        False       False   \n",
       "5          0.000000            False        False        False       False   \n",
       "6          0.000000            False        False        False       False   \n",
       "7          0.000000            False        False        False       False   \n",
       "8          0.000000            False        False        False       False   \n",
       "9          0.000000            False        False        False       False   \n",
       "10         1.000000            False        False        False       False   \n",
       "11         0.000000            False         True        False       False   \n",
       "12         0.000000            False        False        False       False   \n",
       "13         0.375000            False        False        False        True   \n",
       "14         0.750000            False        False        False        True   \n",
       "15         0.000000            False         True        False        True   \n",
       "16         0.000000            False         True        False        True   \n",
       "17         0.000000            False        False        False        True   \n",
       "18         0.000000            False        False        False        True   \n",
       "19         0.000000            False        False        False        True   \n",
       "20         0.000000            False        False         True       False   \n",
       "21         1.000000            False        False        False       False   \n",
       "22         0.000000            False        False        False       False   \n",
       "23         0.275000            False         True        False        True   \n",
       "24         0.000000            False        False        False       False   \n",
       "25         1.166667             True        False        False       False   \n",
       "26         0.000000            False        False        False       False   \n",
       "27         0.428571            False        False        False       False   \n",
       "28         0.000000            False        False        False       False   \n",
       "29         0.000000            False        False        False       False   \n",
       "30         0.000000            False        False        False        True   \n",
       "31         0.000000            False        False        False       False   \n",
       "32         0.000000            False        False        False       False   \n",
       "33         0.200000            False        False        False       False   \n",
       "34         2.300000            False        False         True       False   \n",
       "35         0.625000            False         True        False       False   \n",
       "36         0.133333             True        False        False       False   \n",
       "37         0.000000            False        False        False       False   \n",
       "38         0.000000            False        False        False       False   \n",
       "39         0.750000            False        False        False       False   \n",
       "40         0.000000            False        False        False       False   \n",
       "41         0.000000            False        False        False       False   \n",
       "42         0.000000            False         True        False        True   \n",
       "43         1.250000            False        False        False       False   \n",
       "44         0.500000            False        False        False       False   \n",
       "45         0.000000            False        False        False       False   \n",
       "46         1.500000             True        False        False       False   \n",
       "47         0.250000            False        False        False       False   \n",
       "48         0.000000             True        False        False       False   \n",
       "49         0.000000            False        False        False       False   \n",
       "50         0.000000            False        False        False       False   \n",
       "51         0.000000            False        False        False       False   \n",
       "52         0.300000            False        False        False        True   \n",
       "53         0.000000            False        False        False       False   \n",
       "54         0.000000            False        False        False       False   \n",
       "55         0.000000            False        False        False       False   \n",
       "56         0.000000            False        False        False       False   \n",
       "57         0.800000            False        False        False       False   \n",
       "58         0.000000            False        False        False       False   \n",
       "59         2.500000            False        False        False       False   \n",
       "60         0.000000            False        False        False       False   \n",
       "61         0.075000             True        False        False       False   \n",
       "62         0.000000             True        False        False       False   \n",
       "63         1.500000            False        False        False       False   \n",
       "64         0.333333            False        False        False       False   \n",
       "65         0.000000             True        False        False       False   \n",
       "66         0.000000             True        False        False       False   \n",
       "67         0.000000            False        False        False        True   \n",
       "68         0.000000            False        False        False       False   \n",
       "69         0.583333            False         True        False       False   \n",
       "70         0.000000            False        False        False       False   \n",
       "71         0.000000            False        False        False        True   \n",
       "72         0.062500            False        False        False       False   \n",
       "73         0.185714            False         True        False        True   \n",
       "74         0.000000            False        False         True       False   \n",
       "75         0.000000             True        False        False       False   \n",
       "76         0.000000            False        False        False       False   \n",
       "77         0.000000            False        False        False        True   \n",
       "78         0.000000            False        False        False       False   \n",
       "79         0.000000            False        False        False       False   \n",
       "80         0.000000            False        False        False       False   \n",
       "81         0.000000            False        False        False       False   \n",
       "82         0.500000            False        False        False        True   \n",
       "83         0.000000            False        False        False       False   \n",
       "84         0.000000            False        False         True       False   \n",
       "85         0.000000            False        False        False        True   \n",
       "86         0.000000            False        False        False        True   \n",
       "87         0.000000            False         True         True       False   \n",
       "88         0.875000            False        False        False       False   \n",
       "89         0.000000            False         True        False        True   \n",
       "90         0.666667            False        False        False       False   \n",
       "91         1.500000            False        False        False       False   \n",
       "92         0.000000            False         True        False       False   \n",
       "93         0.000000            False        False        False       False   \n",
       "94         0.333333            False         True        False       False   \n",
       "95         0.000000            False        False        False       False   \n",
       "96         1.000000            False        False        False       False   \n",
       "97         0.333333            False        False        False        True   \n",
       "98         0.000000            False        False        False       False   \n",
       "99         0.000000            False        False        False       False   \n",
       "100        0.000000            False        False        False       False   \n",
       "101        0.000000            False        False        False       False   \n",
       "102        0.000000            False        False        False       False   \n",
       "103        0.666667            False        False        False       False   \n",
       "104        0.250000            False        False        False       False   \n",
       "105        0.325000            False        False        False        True   \n",
       "106        0.000000            False        False        False       False   \n",
       "107        0.300000            False        False        False        True   \n",
       "108        0.000000            False        False        False       False   \n",
       "109        0.000000            False        False        False        True   \n",
       "110        0.000000            False        False         True       False   \n",
       "111        0.000000            False        False        False       False   \n",
       "112        0.000000            False        False         True       False   \n",
       "113        0.000000            False         True        False       False   \n",
       "114        0.000000            False        False         True       False   \n",
       "115        0.000000            False        False        False       False   \n",
       "116        1.833333             True        False        False       False   \n",
       "117        0.000000            False        False        False       False   \n",
       "118        0.500000            False        False        False        True   \n",
       "119        0.833333            False         True        False       False   \n",
       "120        0.833333            False         True        False       False   \n",
       "121        0.750000            False        False        False       False   \n",
       "122        0.300000            False        False        False       False   \n",
       "123        0.300000            False        False         True       False   \n",
       "124        0.000000            False        False        False       False   \n",
       "125        1.250000            False        False        False       False   \n",
       "126        0.000000            False        False        False       False   \n",
       "127        0.000000            False        False        False        True   \n",
       "128        0.000000            False        False        False       False   \n",
       "129        0.000000            False        False        False       False   \n",
       "130        0.000000            False        False        False       False   \n",
       "131        0.000000            False        False        False        True   \n",
       "132        0.000000            False        False        False       False   \n",
       "133        0.000000            False        False        False        True   \n",
       "134        0.000000            False        False        False       False   \n",
       "135        0.000000            False        False        False       False   \n",
       "136        0.000000            False        False        False       False   \n",
       "137        0.000000            False        False        False        True   \n",
       "138        0.000000            False        False        False       False   \n",
       "139        0.000000            False        False        False       False   \n",
       "\n",
       "     win_con_dmg  high_dps  damage_output_ps  support  mini_tank  \\\n",
       "0          False      True        187.500000    False      False   \n",
       "1          False     False        248.888889    False      False   \n",
       "2          False     False        187.500000    False      False   \n",
       "3          False     False        107.333333    False      False   \n",
       "4           True      True        320.000000    False      False   \n",
       "5          False     False        194.000000    False      False   \n",
       "6          False      True        187.500000    False      False   \n",
       "7          False     False        187.500000     True      False   \n",
       "8          False     False        738.461538    False      False   \n",
       "9          False     False        311.538462    False      False   \n",
       "10         False     False         98.666667    False       True   \n",
       "11          True      True        187.500000    False      False   \n",
       "12         False     False        204.000000    False      False   \n",
       "13         False      True        123.333333    False      False   \n",
       "14         False      True        125.000000    False      False   \n",
       "15         False      True        223.333333    False      False   \n",
       "16         False      True        115.600000    False      False   \n",
       "17         False      True        212.000000    False      False   \n",
       "18         False      True        235.555556    False      False   \n",
       "19         False      True        235.555556    False      False   \n",
       "20         False      True        145.454545    False      False   \n",
       "21         False     False        187.500000     True      False   \n",
       "22         False     False        214.000000    False      False   \n",
       "23         False      True        204.615385    False       True   \n",
       "24         False     False        195.000000    False      False   \n",
       "25         False     False        187.500000    False      False   \n",
       "26         False     False        274.285714    False      False   \n",
       "27         False     False         77.619048    False      False   \n",
       "28         False     False        187.500000    False      False   \n",
       "29         False     False        127.777778    False      False   \n",
       "30         False      True        548.571429    False      False   \n",
       "31         False     False        187.500000     True      False   \n",
       "32          True      True        230.000000    False       True   \n",
       "33         False     False        140.000000    False      False   \n",
       "34         False      True        187.500000    False      False   \n",
       "35         False      True        187.500000    False      False   \n",
       "36         False     False        106.666667    False      False   \n",
       "37         False     False        149.230769    False      False   \n",
       "38         False     False        155.454545    False      False   \n",
       "39         False     False        187.500000    False      False   \n",
       "40         False     False         75.000000    False      False   \n",
       "41          True      True        168.666667    False      False   \n",
       "42         False      True        197.142857    False      False   \n",
       "43         False     False        187.500000    False      False   \n",
       "44         False     False        187.500000     True      False   \n",
       "45         False     False        187.500000     True      False   \n",
       "46         False     False        187.500000     True      False   \n",
       "47         False     False        155.000000    False       True   \n",
       "48         False     False        187.500000    False      False   \n",
       "49         False     False        654.545455    False      False   \n",
       "50         False     False        352.000000    False      False   \n",
       "51         False     False        187.500000     True      False   \n",
       "52         False      True        353.333333    False      False   \n",
       "53         False     False        436.363636    False      False   \n",
       "54         False     False        102.222222    False      False   \n",
       "55         False     False        178.888889    False       True   \n",
       "56          True      True        124.800000    False      False   \n",
       "57         False     False        187.500000     True      False   \n",
       "58         False     False        351.000000    False      False   \n",
       "59         False     False        187.500000    False      False   \n",
       "60          True      True        198.125000    False       True   \n",
       "61         False     False        381.818182    False      False   \n",
       "62         False     False         33.600000    False       True   \n",
       "63         False     False        187.500000    False      False   \n",
       "64         False     False         52.352941    False      False   \n",
       "65         False     False         87.500000    False       True   \n",
       "66         False     False        107.500000    False      False   \n",
       "67         False      True        168.333333    False       True   \n",
       "68         False     False         40.769231    False      False   \n",
       "69         False      True        187.500000    False      False   \n",
       "70         False     False         82.500000    False      False   \n",
       "71         False      True        320.000000    False       True   \n",
       "72         False     False        120.909091    False      False   \n",
       "73         False      True        157.647059    False      False   \n",
       "74         False      True        207.333333    False      False   \n",
       "75         False     False        100.000000    False       True   \n",
       "76         False     False        149.230769    False      False   \n",
       "77         False      True        471.875000    False       True   \n",
       "78         False     False        638.181818    False      False   \n",
       "79         False     False        319.090909    False      False   \n",
       "80         False     False        187.500000    False      False   \n",
       "81         False     False        175.000000    False      False   \n",
       "82         False      True         53.200000    False      False   \n",
       "83         False     False        133.000000    False      False   \n",
       "84         False      True        217.000000    False      False   \n",
       "85         False      True        241.538462    False      False   \n",
       "86         False      True        453.333333    False      False   \n",
       "87         False      True        217.000000    False      False   \n",
       "88         False     False        187.500000    False      False   \n",
       "89         False      True        279.285714    False      False   \n",
       "90         False     False         56.000000    False      False   \n",
       "91         False     False        187.500000    False      False   \n",
       "92          True      True        277.777778    False      False   \n",
       "93         False     False        187.500000    False      False   \n",
       "94         False      True        187.500000    False      False   \n",
       "95         False     False        109.000000    False      False   \n",
       "96         False      True        187.500000    False      False   \n",
       "97         False      True        145.000000    False      False   \n",
       "98          True      True        180.588235    False      False   \n",
       "99         False     False        246.666667    False      False   \n",
       "100        False     False        613.846154    False      False   \n",
       "101        False     False         80.000000    False       True   \n",
       "102        False     False       1215.000000    False      False   \n",
       "103        False     False        187.500000    False      False   \n",
       "104        False     False        169.473684    False      False   \n",
       "105        False      True        127.500000    False       True   \n",
       "106        False     False        243.000000    False      False   \n",
       "107        False      True        332.750000    False      False   \n",
       "108        False     False        142.941176    False      False   \n",
       "109        False      True        279.090909    False      False   \n",
       "110        False      True        219.285714    False      False   \n",
       "111        False     False        187.500000     True      False   \n",
       "112        False      True        200.000000    False      False   \n",
       "113        False      True        187.500000    False      False   \n",
       "114        False      True        651.000000    False      False   \n",
       "115        False     False        187.500000     True      False   \n",
       "116        False     False        187.500000    False      False   \n",
       "117        False     False        136.250000    False      False   \n",
       "118        False      True        177.333333    False       True   \n",
       "119        False      True        187.500000    False      False   \n",
       "120        False      True        187.500000    False      False   \n",
       "121         True      True        187.500000    False      False   \n",
       "122        False     False        122.727273    False      False   \n",
       "123        False      True        200.714286    False      False   \n",
       "124        False     False        143.333333    False      False   \n",
       "125        False     False        187.500000    False      False   \n",
       "126        False     False        167.142857    False      False   \n",
       "127        False      True        365.714286    False      False   \n",
       "128        False     False         44.166667     True      False   \n",
       "129        False     False        232.727273     True      False   \n",
       "130        False     False        232.727273    False      False   \n",
       "131        False      True        306.363636    False      False   \n",
       "132        False     False         67.200000     True      False   \n",
       "133        False      True        168.333333    False       True   \n",
       "134        False     False        285.882353     True      False   \n",
       "135        False     False         85.333333    False       True   \n",
       "136        False     False        174.000000    False      False   \n",
       "137        False      True        136.000000    False       True   \n",
       "138        False     False        250.000000    False      False   \n",
       "139        False     False        187.500000     True      False   \n",
       "\n",
       "     core_identity_km_labels  core_identity_gmm_probs  \\\n",
       "0                        2.0                      2.0   \n",
       "1                        2.0                      2.0   \n",
       "2                        NaN                      NaN   \n",
       "3                        2.0                      2.0   \n",
       "4                        0.0                      0.0   \n",
       "5                        0.0                      0.0   \n",
       "6                        NaN                      NaN   \n",
       "7                        NaN                      NaN   \n",
       "8                        5.0                      5.0   \n",
       "9                        5.0                      5.0   \n",
       "10                       0.0                      0.0   \n",
       "11                       6.0                      6.0   \n",
       "12                       0.0                      0.0   \n",
       "13                       NaN                      NaN   \n",
       "14                       2.0                      2.0   \n",
       "15                       0.0                      0.0   \n",
       "16                       2.0                      2.0   \n",
       "17                       NaN                      NaN   \n",
       "18                       2.0                      2.0   \n",
       "19                       NaN                      NaN   \n",
       "20                       NaN                      NaN   \n",
       "21                       NaN                      NaN   \n",
       "22                       NaN                      NaN   \n",
       "23                       0.0                      0.0   \n",
       "24                       2.0                      2.0   \n",
       "25                       NaN                      NaN   \n",
       "26                       2.0                      2.0   \n",
       "27                       0.0                      0.0   \n",
       "28                       4.0                      4.0   \n",
       "29                       2.0                      2.0   \n",
       "30                       0.0                      0.0   \n",
       "31                       NaN                      NaN   \n",
       "32                       0.0                      0.0   \n",
       "33                       2.0                      2.0   \n",
       "34                       4.0                      4.0   \n",
       "35                       NaN                      NaN   \n",
       "36                       2.0                      2.0   \n",
       "37                       0.0                      0.0   \n",
       "38                       2.0                      2.0   \n",
       "39                       NaN                      NaN   \n",
       "40                       2.0                      2.0   \n",
       "41                       0.0                      0.0   \n",
       "42                       0.0                      0.0   \n",
       "43                       NaN                      NaN   \n",
       "44                       NaN                      NaN   \n",
       "45                       NaN                      NaN   \n",
       "46                       NaN                      NaN   \n",
       "47                       2.0                      2.0   \n",
       "48                       NaN                      NaN   \n",
       "49                       2.0                      2.0   \n",
       "50                       2.0                      2.0   \n",
       "51                       NaN                      NaN   \n",
       "52                       2.0                      2.0   \n",
       "53                       5.0                      5.0   \n",
       "54                       2.0                      2.0   \n",
       "55                       0.0                      0.0   \n",
       "56                       0.0                      0.0   \n",
       "57                       NaN                      NaN   \n",
       "58                       0.0                      0.0   \n",
       "59                       4.0                      4.0   \n",
       "60                       0.0                      0.0   \n",
       "61                       2.0                      2.0   \n",
       "62                       0.0                      0.0   \n",
       "63                       4.0                      4.0   \n",
       "64                       2.0                      2.0   \n",
       "65                       2.0                      2.0   \n",
       "66                       NaN                      NaN   \n",
       "67                       0.0                      0.0   \n",
       "68                       2.0                      2.0   \n",
       "69                       NaN                      NaN   \n",
       "70                       2.0                      2.0   \n",
       "71                       0.0                      0.0   \n",
       "72                       2.0                      2.0   \n",
       "73                       0.0                      0.0   \n",
       "74                       2.0                      2.0   \n",
       "75                       0.0                      0.0   \n",
       "76                       0.0                      0.0   \n",
       "77                       0.0                      0.0   \n",
       "78                       2.0                      2.0   \n",
       "79                       2.0                      2.0   \n",
       "80                       NaN                      NaN   \n",
       "81                       0.0                      0.0   \n",
       "82                       NaN                      NaN   \n",
       "83                       2.0                      2.0   \n",
       "84                       2.0                      2.0   \n",
       "85                       0.0                      0.0   \n",
       "86                       0.0                      0.0   \n",
       "87                       0.0                      0.0   \n",
       "88                       NaN                      NaN   \n",
       "89                       0.0                      0.0   \n",
       "90                       2.0                      2.0   \n",
       "91                       NaN                      NaN   \n",
       "92                       2.0                      2.0   \n",
       "93                       4.0                      4.0   \n",
       "94                       NaN                      NaN   \n",
       "95                       NaN                      NaN   \n",
       "96                       NaN                      NaN   \n",
       "97                       0.0                      0.0   \n",
       "98                       2.0                      2.0   \n",
       "99                       0.0                      0.0   \n",
       "100                      5.0                      5.0   \n",
       "101                      0.0                      0.0   \n",
       "102                      0.0                      0.0   \n",
       "103                      6.0                      6.0   \n",
       "104                      2.0                      2.0   \n",
       "105                      0.0                      0.0   \n",
       "106                      5.0                      5.0   \n",
       "107                      2.0                      2.0   \n",
       "108                      5.0                      5.0   \n",
       "109                      0.0                      0.0   \n",
       "110                      2.0                      2.0   \n",
       "111                      3.0                      3.0   \n",
       "112                      NaN                      NaN   \n",
       "113                      NaN                      NaN   \n",
       "114                      2.0                      2.0   \n",
       "115                      NaN                      NaN   \n",
       "116                      NaN                      NaN   \n",
       "117                      NaN                      NaN   \n",
       "118                      0.0                      0.0   \n",
       "119                      NaN                      NaN   \n",
       "120                      NaN                      NaN   \n",
       "121                      6.0                      6.0   \n",
       "122                      2.0                      2.0   \n",
       "123                      2.0                      2.0   \n",
       "124                      NaN                      NaN   \n",
       "125                      NaN                      NaN   \n",
       "126                      2.0                      2.0   \n",
       "127                      1.0                      1.0   \n",
       "128                      1.0                      1.0   \n",
       "129                      1.0                      1.0   \n",
       "130                      1.0                      1.0   \n",
       "131                      1.0                      1.0   \n",
       "132                      1.0                      1.0   \n",
       "133                      1.0                      1.0   \n",
       "134                      1.0                      1.0   \n",
       "135                      7.0                      7.0   \n",
       "136                      1.0                      1.0   \n",
       "137                      7.0                      7.0   \n",
       "138                      7.0                      7.0   \n",
       "139                      NaN                      NaN   \n",
       "\n",
       "     combat_core_stats_km_labels  combat_core_stats_gmm_probs  \\\n",
       "0                            4.0                          9.0   \n",
       "1                            4.0                          4.0   \n",
       "2                            NaN                          NaN   \n",
       "3                            4.0                          9.0   \n",
       "4                            9.0                          9.0   \n",
       "5                            7.0                          9.0   \n",
       "6                            NaN                          NaN   \n",
       "7                            NaN                          NaN   \n",
       "8                           11.0                          2.0   \n",
       "9                            2.0                          2.0   \n",
       "10                           1.0                          9.0   \n",
       "11                           1.0                          9.0   \n",
       "12                           7.0                          9.0   \n",
       "13                           NaN                          NaN   \n",
       "14                           4.0                          9.0   \n",
       "15                           1.0                          9.0   \n",
       "16                          10.0                          9.0   \n",
       "17                           NaN                          NaN   \n",
       "18                           4.0                          9.0   \n",
       "19                           NaN                          NaN   \n",
       "20                           NaN                          NaN   \n",
       "21                           NaN                          NaN   \n",
       "22                           NaN                          NaN   \n",
       "23                           1.0                          9.0   \n",
       "24                           7.0                          9.0   \n",
       "25                           NaN                          NaN   \n",
       "26                          10.0                          4.0   \n",
       "27                           0.0                          9.0   \n",
       "28                           8.0                          2.0   \n",
       "29                          10.0                          4.0   \n",
       "30                           1.0                          2.0   \n",
       "31                           NaN                          NaN   \n",
       "32                           1.0                          9.0   \n",
       "33                          10.0                          4.0   \n",
       "34                           7.0                          9.0   \n",
       "35                           NaN                          NaN   \n",
       "36                          10.0                          4.0   \n",
       "37                           1.0                          9.0   \n",
       "38                           4.0                          9.0   \n",
       "39                           NaN                          NaN   \n",
       "40                           4.0                          9.0   \n",
       "41                           0.0                          9.0   \n",
       "42                           0.0                          9.0   \n",
       "43                           NaN                          NaN   \n",
       "44                           NaN                          NaN   \n",
       "45                           NaN                          NaN   \n",
       "46                           NaN                          NaN   \n",
       "47                           4.0                          9.0   \n",
       "48                           NaN                          NaN   \n",
       "49                           2.0                          2.0   \n",
       "50                           0.0                          2.0   \n",
       "51                           NaN                          NaN   \n",
       "52                           1.0                          1.0   \n",
       "53                           2.0                          2.0   \n",
       "54                          10.0                          4.0   \n",
       "55                           1.0                          9.0   \n",
       "56                           0.0                          9.0   \n",
       "57                           NaN                          NaN   \n",
       "58                           2.0                          2.0   \n",
       "59                           7.0                          9.0   \n",
       "60                           7.0                          9.0   \n",
       "61                           8.0                          2.0   \n",
       "62                           5.0                          1.0   \n",
       "63                           7.0                          9.0   \n",
       "64                           4.0                          9.0   \n",
       "65                           4.0                          9.0   \n",
       "66                           NaN                          NaN   \n",
       "67                           1.0                          9.0   \n",
       "68                           0.0                          9.0   \n",
       "69                           NaN                          NaN   \n",
       "70                           4.0                          9.0   \n",
       "71                           7.0                          9.0   \n",
       "72                           4.0                          9.0   \n",
       "73                           0.0                          9.0   \n",
       "74                           1.0                          9.0   \n",
       "75                           1.0                          9.0   \n",
       "76                           7.0                          9.0   \n",
       "77                           9.0                          9.0   \n",
       "78                          11.0                          2.0   \n",
       "79                           2.0                          2.0   \n",
       "80                           NaN                          NaN   \n",
       "81                           1.0                          9.0   \n",
       "82                           NaN                          NaN   \n",
       "83                           4.0                          9.0   \n",
       "84                           4.0                          9.0   \n",
       "85                           1.0                          9.0   \n",
       "86                           9.0                          9.0   \n",
       "87                           1.0                          9.0   \n",
       "88                           NaN                          NaN   \n",
       "89                           1.0                          9.0   \n",
       "90                          10.0                          6.0   \n",
       "91                           NaN                          NaN   \n",
       "92                           1.0                          2.0   \n",
       "93                           1.0                          2.0   \n",
       "94                           NaN                          NaN   \n",
       "95                           NaN                          NaN   \n",
       "96                           NaN                          NaN   \n",
       "97                           1.0                          9.0   \n",
       "98                           0.0                          9.0   \n",
       "99                           2.0                          2.0   \n",
       "100                         11.0                          2.0   \n",
       "101                          1.0                          9.0   \n",
       "102                          3.0                          3.0   \n",
       "103                          7.0                          9.0   \n",
       "104                         10.0                          4.0   \n",
       "105                          1.0                          9.0   \n",
       "106                          2.0                          2.0   \n",
       "107                          6.0                          6.0   \n",
       "108                          7.0                          2.0   \n",
       "109                          1.0                          9.0   \n",
       "110                          4.0                          9.0   \n",
       "111                          5.0                          1.0   \n",
       "112                          NaN                          NaN   \n",
       "113                          NaN                          NaN   \n",
       "114                         11.0                          4.0   \n",
       "115                          NaN                          NaN   \n",
       "116                          NaN                          NaN   \n",
       "117                          NaN                          NaN   \n",
       "118                          1.0                          9.0   \n",
       "119                          NaN                          NaN   \n",
       "120                          NaN                          NaN   \n",
       "121                          7.0                          2.0   \n",
       "122                          4.0                          9.0   \n",
       "123                          4.0                          9.0   \n",
       "124                          NaN                          NaN   \n",
       "125                          NaN                          NaN   \n",
       "126                         10.0                          4.0   \n",
       "127                          5.0                          2.0   \n",
       "128                          7.0                          9.0   \n",
       "129                          2.0                          2.0   \n",
       "130                          5.0                          1.0   \n",
       "131                          5.0                          9.0   \n",
       "132                          5.0                          1.0   \n",
       "133                          5.0                          1.0   \n",
       "134                          2.0                          2.0   \n",
       "135                          5.0                          1.0   \n",
       "136                          5.0                          1.0   \n",
       "137                          5.0                          1.0   \n",
       "138                          4.0                          4.0   \n",
       "139                          NaN                          NaN   \n",
       "\n",
       "     targeting_behavior_km_labels  targeting_behavior_gmm_probs  \\\n",
       "0                             1.0                           1.0   \n",
       "1                             1.0                           1.0   \n",
       "2                             NaN                           NaN   \n",
       "3                             1.0                           1.0   \n",
       "4                             0.0                           0.0   \n",
       "5                             2.0                           2.0   \n",
       "6                             NaN                           NaN   \n",
       "7                             NaN                           NaN   \n",
       "8                             2.0                           2.0   \n",
       "9                             1.0                           1.0   \n",
       "10                            2.0                           2.0   \n",
       "11                            0.0                           0.0   \n",
       "12                            2.0                           2.0   \n",
       "13                            NaN                           NaN   \n",
       "14                            2.0                           2.0   \n",
       "15                            2.0                           2.0   \n",
       "16                            2.0                           2.0   \n",
       "17                            NaN                           NaN   \n",
       "18                            2.0                           2.0   \n",
       "19                            NaN                           NaN   \n",
       "20                            NaN                           NaN   \n",
       "21                            NaN                           NaN   \n",
       "22                            NaN                           NaN   \n",
       "23                            2.0                           2.0   \n",
       "24                            1.0                           1.0   \n",
       "25                            NaN                           NaN   \n",
       "26                            1.0                           1.0   \n",
       "27                            0.0                           0.0   \n",
       "28                            1.0                           1.0   \n",
       "29                            1.0                           1.0   \n",
       "30                            2.0                           2.0   \n",
       "31                            NaN                           NaN   \n",
       "32                            0.0                           0.0   \n",
       "33                            1.0                           1.0   \n",
       "34                            1.0                           1.0   \n",
       "35                            NaN                           NaN   \n",
       "36                            1.0                           1.0   \n",
       "37                            2.0                           2.0   \n",
       "38                            1.0                           1.0   \n",
       "39                            NaN                           NaN   \n",
       "40                            1.0                           1.0   \n",
       "41                            0.0                           0.0   \n",
       "42                            2.0                           2.0   \n",
       "43                            NaN                           NaN   \n",
       "44                            NaN                           NaN   \n",
       "45                            NaN                           NaN   \n",
       "46                            NaN                           NaN   \n",
       "47                            2.0                           2.0   \n",
       "48                            NaN                           NaN   \n",
       "49                            2.0                           2.0   \n",
       "50                            0.0                           0.0   \n",
       "51                            NaN                           NaN   \n",
       "52                            2.0                           2.0   \n",
       "53                            2.0                           2.0   \n",
       "54                            1.0                           1.0   \n",
       "55                            2.0                           2.0   \n",
       "56                            0.0                           0.0   \n",
       "57                            NaN                           NaN   \n",
       "58                            2.0                           2.0   \n",
       "59                            1.0                           1.0   \n",
       "60                            0.0                           0.0   \n",
       "61                            1.0                           1.0   \n",
       "62                            0.0                           0.0   \n",
       "63                            1.0                           1.0   \n",
       "64                            1.0                           1.0   \n",
       "65                            1.0                           1.0   \n",
       "66                            NaN                           NaN   \n",
       "67                            2.0                           2.0   \n",
       "68                            0.0                           0.0   \n",
       "69                            NaN                           NaN   \n",
       "70                            1.0                           1.0   \n",
       "71                            2.0                           2.0   \n",
       "72                            1.0                           1.0   \n",
       "73                            2.0                           2.0   \n",
       "74                            1.0                           1.0   \n",
       "75                            2.0                           2.0   \n",
       "76                            2.0                           2.0   \n",
       "77                            2.0                           2.0   \n",
       "78                            1.0                           1.0   \n",
       "79                            1.0                           1.0   \n",
       "80                            NaN                           NaN   \n",
       "81                            2.0                           2.0   \n",
       "82                            NaN                           NaN   \n",
       "83                            1.0                           1.0   \n",
       "84                            1.0                           1.0   \n",
       "85                            2.0                           2.0   \n",
       "86                            2.0                           2.0   \n",
       "87                            1.0                           1.0   \n",
       "88                            NaN                           NaN   \n",
       "89                            2.0                           2.0   \n",
       "90                            1.0                           1.0   \n",
       "91                            NaN                           NaN   \n",
       "92                            0.0                           0.0   \n",
       "93                            2.0                           2.0   \n",
       "94                            NaN                           NaN   \n",
       "95                            NaN                           NaN   \n",
       "96                            NaN                           NaN   \n",
       "97                            2.0                           2.0   \n",
       "98                            0.0                           0.0   \n",
       "99                            0.0                           0.0   \n",
       "100                           2.0                           2.0   \n",
       "101                           0.0                           0.0   \n",
       "102                           2.0                           2.0   \n",
       "103                           0.0                           0.0   \n",
       "104                           1.0                           1.0   \n",
       "105                           2.0                           2.0   \n",
       "106                           2.0                           2.0   \n",
       "107                           2.0                           2.0   \n",
       "108                           1.0                           1.0   \n",
       "109                           2.0                           2.0   \n",
       "110                           1.0                           1.0   \n",
       "111                           0.0                           0.0   \n",
       "112                           NaN                           NaN   \n",
       "113                           NaN                           NaN   \n",
       "114                           1.0                           1.0   \n",
       "115                           NaN                           NaN   \n",
       "116                           NaN                           NaN   \n",
       "117                           NaN                           NaN   \n",
       "118                           2.0                           2.0   \n",
       "119                           NaN                           NaN   \n",
       "120                           NaN                           NaN   \n",
       "121                           0.0                           0.0   \n",
       "122                           1.0                           1.0   \n",
       "123                           1.0                           1.0   \n",
       "124                           NaN                           NaN   \n",
       "125                           NaN                           NaN   \n",
       "126                           1.0                           1.0   \n",
       "127                           2.0                           2.0   \n",
       "128                           0.0                           0.0   \n",
       "129                           0.0                           0.0   \n",
       "130                           0.0                           0.0   \n",
       "131                           2.0                           2.0   \n",
       "132                           0.0                           0.0   \n",
       "133                           2.0                           2.0   \n",
       "134                           1.0                           1.0   \n",
       "135                           0.0                           0.0   \n",
       "136                           1.0                           1.0   \n",
       "137                           2.0                           2.0   \n",
       "138                           1.0                           1.0   \n",
       "139                           NaN                           NaN   \n",
       "\n",
       "     special_attack_mechanics_km_labels  special_attack_mechanics_gmm_probs  \\\n",
       "0                                  11.0                                11.0   \n",
       "1                                   5.0                                 5.0   \n",
       "2                                   NaN                                 NaN   \n",
       "3                                   8.0                                 8.0   \n",
       "4                                   0.0                                 0.0   \n",
       "5                                   6.0                                 6.0   \n",
       "6                                   NaN                                 NaN   \n",
       "7                                   NaN                                 NaN   \n",
       "8                                   0.0                                 0.0   \n",
       "9                                   0.0                                 0.0   \n",
       "10                                 14.0                                14.0   \n",
       "11                                 10.0                                10.0   \n",
       "12                                  0.0                                 0.0   \n",
       "13                                  NaN                                 NaN   \n",
       "14                                  8.0                                 8.0   \n",
       "15                                 11.0                                11.0   \n",
       "16                                  1.0                                 1.0   \n",
       "17                                  NaN                                 NaN   \n",
       "18                                  5.0                                 5.0   \n",
       "19                                  NaN                                 NaN   \n",
       "20                                  NaN                                 NaN   \n",
       "21                                  NaN                                 NaN   \n",
       "22                                  NaN                                 NaN   \n",
       "23                                 12.0                                12.0   \n",
       "24                                  5.0                                 5.0   \n",
       "25                                  NaN                                 NaN   \n",
       "26                                  9.0                                 9.0   \n",
       "27                                 12.0                                12.0   \n",
       "28                                  9.0                                 9.0   \n",
       "29                                  9.0                                 9.0   \n",
       "30                                  0.0                                 0.0   \n",
       "31                                  NaN                                 NaN   \n",
       "32                                  0.0                                 0.0   \n",
       "33                                  7.0                                 7.0   \n",
       "34                                  8.0                                 8.0   \n",
       "35                                  NaN                                 NaN   \n",
       "36                                  7.0                                 7.0   \n",
       "37                                 10.0                                10.0   \n",
       "38                                  5.0                                 5.0   \n",
       "39                                  NaN                                 NaN   \n",
       "40                                  5.0                                 5.0   \n",
       "41                                  0.0                                 0.0   \n",
       "42                                 10.0                                10.0   \n",
       "43                                  NaN                                 NaN   \n",
       "44                                  NaN                                 NaN   \n",
       "45                                  NaN                                 NaN   \n",
       "46                                  NaN                                 NaN   \n",
       "47                                  1.0                                 1.0   \n",
       "48                                  NaN                                 NaN   \n",
       "49                                  2.0                                 2.0   \n",
       "50                                  2.0                                 2.0   \n",
       "51                                  NaN                                 NaN   \n",
       "52                                  7.0                                 7.0   \n",
       "53                                  0.0                                 0.0   \n",
       "54                                  3.0                                 3.0   \n",
       "55                                  3.0                                 3.0   \n",
       "56                                  0.0                                 0.0   \n",
       "57                                  NaN                                 NaN   \n",
       "58                                  0.0                                 0.0   \n",
       "59                                 14.0                                14.0   \n",
       "60                                  0.0                                 0.0   \n",
       "61                                  7.0                                 7.0   \n",
       "62                                 10.0                                10.0   \n",
       "63                                  1.0                                 1.0   \n",
       "64                                  1.0                                 1.0   \n",
       "65                                  9.0                                 9.0   \n",
       "66                                  NaN                                 NaN   \n",
       "67                                  0.0                                 0.0   \n",
       "68                                  5.0                                 5.0   \n",
       "69                                  NaN                                 NaN   \n",
       "70                                  3.0                                 3.0   \n",
       "71                                  4.0                                 4.0   \n",
       "72                                  1.0                                 1.0   \n",
       "73                                 12.0                                12.0   \n",
       "74                                  5.0                                 5.0   \n",
       "75                                 13.0                                13.0   \n",
       "76                                  0.0                                 0.0   \n",
       "77                                  0.0                                 0.0   \n",
       "78                                  5.0                                 5.0   \n",
       "79                                  5.0                                 5.0   \n",
       "80                                  NaN                                 NaN   \n",
       "81                                 13.0                                13.0   \n",
       "82                                  NaN                                 NaN   \n",
       "83                                 16.0                                16.0   \n",
       "84                                  5.0                                 5.0   \n",
       "85                                  0.0                                 0.0   \n",
       "86                                  0.0                                 0.0   \n",
       "87                                 10.0                                10.0   \n",
       "88                                  NaN                                 NaN   \n",
       "89                                 10.0                                10.0   \n",
       "90                                  8.0                                 8.0   \n",
       "91                                  NaN                                 NaN   \n",
       "92                                  9.0                                 9.0   \n",
       "93                                  2.0                                 2.0   \n",
       "94                                  NaN                                 NaN   \n",
       "95                                  NaN                                 NaN   \n",
       "96                                  NaN                                 NaN   \n",
       "97                                  6.0                                 6.0   \n",
       "98                                  5.0                                 5.0   \n",
       "99                                  0.0                                 0.0   \n",
       "100                                 0.0                                 0.0   \n",
       "101                                 4.0                                 4.0   \n",
       "102                                 0.0                                 0.0   \n",
       "103                                17.0                                17.0   \n",
       "104                                 8.0                                 8.0   \n",
       "105                                15.0                                15.0   \n",
       "106                                 0.0                                 0.0   \n",
       "107                                 8.0                                 8.0   \n",
       "108                                 5.0                                 5.0   \n",
       "109                                 0.0                                 0.0   \n",
       "110                                 5.0                                 5.0   \n",
       "111                                 6.0                                 6.0   \n",
       "112                                 NaN                                 NaN   \n",
       "113                                 NaN                                 NaN   \n",
       "114                                 5.0                                 5.0   \n",
       "115                                 NaN                                 NaN   \n",
       "116                                 NaN                                 NaN   \n",
       "117                                 NaN                                 NaN   \n",
       "118                                17.0                                17.0   \n",
       "119                                 NaN                                 NaN   \n",
       "120                                 NaN                                 NaN   \n",
       "121                                17.0                                17.0   \n",
       "122                                 8.0                                 8.0   \n",
       "123                                 8.0                                 8.0   \n",
       "124                                 NaN                                 NaN   \n",
       "125                                 NaN                                 NaN   \n",
       "126                                16.0                                16.0   \n",
       "127                                 0.0                                 0.0   \n",
       "128                                 0.0                                 0.0   \n",
       "129                                 0.0                                 0.0   \n",
       "130                                 0.0                                 0.0   \n",
       "131                                 0.0                                 0.0   \n",
       "132                                 0.0                                 0.0   \n",
       "133                                 0.0                                 0.0   \n",
       "134                                 0.0                                 0.0   \n",
       "135                                 0.0                                 0.0   \n",
       "136                                 0.0                                 0.0   \n",
       "137                                 0.0                                 0.0   \n",
       "138                                 5.0                                 5.0   \n",
       "139                                 NaN                                 NaN   \n",
       "\n",
       "     boolean_effects_and_traits_km_labels  \\\n",
       "0                                     1.0   \n",
       "1                                    13.0   \n",
       "2                                     NaN   \n",
       "3                                    18.0   \n",
       "4                                    14.0   \n",
       "5                                     1.0   \n",
       "6                                     NaN   \n",
       "7                                     NaN   \n",
       "8                                    13.0   \n",
       "9                                     9.0   \n",
       "10                                   12.0   \n",
       "11                                    3.0   \n",
       "12                                    1.0   \n",
       "13                                    NaN   \n",
       "14                                    0.0   \n",
       "15                                    1.0   \n",
       "16                                   12.0   \n",
       "17                                    NaN   \n",
       "18                                    1.0   \n",
       "19                                    NaN   \n",
       "20                                    NaN   \n",
       "21                                    NaN   \n",
       "22                                    NaN   \n",
       "23                                    5.0   \n",
       "24                                   13.0   \n",
       "25                                    NaN   \n",
       "26                                    7.0   \n",
       "27                                   12.0   \n",
       "28                                    8.0   \n",
       "29                                   20.0   \n",
       "30                                    1.0   \n",
       "31                                    NaN   \n",
       "32                                    2.0   \n",
       "33                                   10.0   \n",
       "34                                   12.0   \n",
       "35                                    NaN   \n",
       "36                                   10.0   \n",
       "37                                    1.0   \n",
       "38                                    9.0   \n",
       "39                                    NaN   \n",
       "40                                    6.0   \n",
       "41                                    1.0   \n",
       "42                                   14.0   \n",
       "43                                    NaN   \n",
       "44                                    NaN   \n",
       "45                                    NaN   \n",
       "46                                    NaN   \n",
       "47                                    4.0   \n",
       "48                                    NaN   \n",
       "49                                   20.0   \n",
       "50                                   21.0   \n",
       "51                                    NaN   \n",
       "52                                   10.0   \n",
       "53                                    1.0   \n",
       "54                                    1.0   \n",
       "55                                    1.0   \n",
       "56                                   16.0   \n",
       "57                                    NaN   \n",
       "58                                    5.0   \n",
       "59                                   12.0   \n",
       "60                                    1.0   \n",
       "61                                   10.0   \n",
       "62                                   14.0   \n",
       "63                                    0.0   \n",
       "64                                   22.0   \n",
       "65                                    7.0   \n",
       "66                                    NaN   \n",
       "67                                   13.0   \n",
       "68                                    2.0   \n",
       "69                                    NaN   \n",
       "70                                   19.0   \n",
       "71                                   16.0   \n",
       "72                                   12.0   \n",
       "73                                    0.0   \n",
       "74                                    9.0   \n",
       "75                                    8.0   \n",
       "76                                    1.0   \n",
       "77                                    1.0   \n",
       "78                                    9.0   \n",
       "79                                    9.0   \n",
       "80                                    NaN   \n",
       "81                                    8.0   \n",
       "82                                    NaN   \n",
       "83                                   19.0   \n",
       "84                                   13.0   \n",
       "85                                   15.0   \n",
       "86                                   13.0   \n",
       "87                                   11.0   \n",
       "88                                    NaN   \n",
       "89                                    1.0   \n",
       "90                                   12.0   \n",
       "91                                    NaN   \n",
       "92                                    8.0   \n",
       "93                                   20.0   \n",
       "94                                    NaN   \n",
       "95                                    NaN   \n",
       "96                                    NaN   \n",
       "97                                   12.0   \n",
       "98                                   13.0   \n",
       "99                                    1.0   \n",
       "100                                   5.0   \n",
       "101                                   1.0   \n",
       "102                                   1.0   \n",
       "103                                  11.0   \n",
       "104                                  18.0   \n",
       "105                                  22.0   \n",
       "106                                  13.0   \n",
       "107                                  12.0   \n",
       "108                                   1.0   \n",
       "109                                   1.0   \n",
       "110                                   7.0   \n",
       "111                                  17.0   \n",
       "112                                   NaN   \n",
       "113                                   NaN   \n",
       "114                                   1.0   \n",
       "115                                   NaN   \n",
       "116                                   NaN   \n",
       "117                                   NaN   \n",
       "118                                   0.0   \n",
       "119                                   NaN   \n",
       "120                                   NaN   \n",
       "121                                   0.0   \n",
       "122                                   6.0   \n",
       "123                                   0.0   \n",
       "124                                   NaN   \n",
       "125                                   NaN   \n",
       "126                                   1.0   \n",
       "127                                   1.0   \n",
       "128                                   1.0   \n",
       "129                                   1.0   \n",
       "130                                   2.0   \n",
       "131                                   1.0   \n",
       "132                                  14.0   \n",
       "133                                   1.0   \n",
       "134                                   9.0   \n",
       "135                                   1.0   \n",
       "136                                   9.0   \n",
       "137                                   1.0   \n",
       "138                                   1.0   \n",
       "139                                   NaN   \n",
       "\n",
       "     boolean_effects_and_traits_gmm_probs  \\\n",
       "0                                     1.0   \n",
       "1                                    13.0   \n",
       "2                                     NaN   \n",
       "3                                    18.0   \n",
       "4                                    14.0   \n",
       "5                                     1.0   \n",
       "6                                     NaN   \n",
       "7                                     NaN   \n",
       "8                                    13.0   \n",
       "9                                     9.0   \n",
       "10                                   12.0   \n",
       "11                                    3.0   \n",
       "12                                    1.0   \n",
       "13                                    NaN   \n",
       "14                                    0.0   \n",
       "15                                    1.0   \n",
       "16                                   12.0   \n",
       "17                                    NaN   \n",
       "18                                    1.0   \n",
       "19                                    NaN   \n",
       "20                                    NaN   \n",
       "21                                    NaN   \n",
       "22                                    NaN   \n",
       "23                                    5.0   \n",
       "24                                   13.0   \n",
       "25                                    NaN   \n",
       "26                                    7.0   \n",
       "27                                   12.0   \n",
       "28                                    8.0   \n",
       "29                                   20.0   \n",
       "30                                    1.0   \n",
       "31                                    NaN   \n",
       "32                                    2.0   \n",
       "33                                   10.0   \n",
       "34                                   12.0   \n",
       "35                                    NaN   \n",
       "36                                   10.0   \n",
       "37                                    1.0   \n",
       "38                                    9.0   \n",
       "39                                    NaN   \n",
       "40                                    6.0   \n",
       "41                                    1.0   \n",
       "42                                   14.0   \n",
       "43                                    NaN   \n",
       "44                                    NaN   \n",
       "45                                    NaN   \n",
       "46                                    NaN   \n",
       "47                                    4.0   \n",
       "48                                    NaN   \n",
       "49                                   20.0   \n",
       "50                                   21.0   \n",
       "51                                    NaN   \n",
       "52                                   10.0   \n",
       "53                                    1.0   \n",
       "54                                    1.0   \n",
       "55                                    1.0   \n",
       "56                                   16.0   \n",
       "57                                    NaN   \n",
       "58                                    5.0   \n",
       "59                                   12.0   \n",
       "60                                    1.0   \n",
       "61                                   10.0   \n",
       "62                                   14.0   \n",
       "63                                    0.0   \n",
       "64                                   22.0   \n",
       "65                                    7.0   \n",
       "66                                    NaN   \n",
       "67                                   13.0   \n",
       "68                                    2.0   \n",
       "69                                    NaN   \n",
       "70                                   19.0   \n",
       "71                                   16.0   \n",
       "72                                   12.0   \n",
       "73                                    0.0   \n",
       "74                                    9.0   \n",
       "75                                    8.0   \n",
       "76                                    1.0   \n",
       "77                                    1.0   \n",
       "78                                    9.0   \n",
       "79                                    9.0   \n",
       "80                                    NaN   \n",
       "81                                    8.0   \n",
       "82                                    NaN   \n",
       "83                                   19.0   \n",
       "84                                   13.0   \n",
       "85                                   15.0   \n",
       "86                                   13.0   \n",
       "87                                   11.0   \n",
       "88                                    NaN   \n",
       "89                                    1.0   \n",
       "90                                   12.0   \n",
       "91                                    NaN   \n",
       "92                                    8.0   \n",
       "93                                   20.0   \n",
       "94                                    NaN   \n",
       "95                                    NaN   \n",
       "96                                    NaN   \n",
       "97                                   12.0   \n",
       "98                                   13.0   \n",
       "99                                    1.0   \n",
       "100                                   5.0   \n",
       "101                                   1.0   \n",
       "102                                   1.0   \n",
       "103                                  11.0   \n",
       "104                                  18.0   \n",
       "105                                  22.0   \n",
       "106                                  13.0   \n",
       "107                                  12.0   \n",
       "108                                   1.0   \n",
       "109                                   1.0   \n",
       "110                                   7.0   \n",
       "111                                  17.0   \n",
       "112                                   NaN   \n",
       "113                                   NaN   \n",
       "114                                   1.0   \n",
       "115                                   NaN   \n",
       "116                                   NaN   \n",
       "117                                   NaN   \n",
       "118                                   0.0   \n",
       "119                                   NaN   \n",
       "120                                   NaN   \n",
       "121                                   0.0   \n",
       "122                                   6.0   \n",
       "123                                   0.0   \n",
       "124                                   NaN   \n",
       "125                                   NaN   \n",
       "126                                   1.0   \n",
       "127                                   1.0   \n",
       "128                                   1.0   \n",
       "129                                   1.0   \n",
       "130                                   2.0   \n",
       "131                                   1.0   \n",
       "132                                  14.0   \n",
       "133                                   1.0   \n",
       "134                                   9.0   \n",
       "135                                   1.0   \n",
       "136                                   9.0   \n",
       "137                                   1.0   \n",
       "138                                   1.0   \n",
       "139                                   NaN   \n",
       "\n",
       "     engineered_features_granular_km_labels  \\\n",
       "0                                      12.0   \n",
       "1                                      17.0   \n",
       "2                                       NaN   \n",
       "3                                       7.0   \n",
       "4                                       2.0   \n",
       "5                                      10.0   \n",
       "6                                       NaN   \n",
       "7                                       NaN   \n",
       "8                                       9.0   \n",
       "9                                      17.0   \n",
       "10                                     23.0   \n",
       "11                                     20.0   \n",
       "12                                     10.0   \n",
       "13                                      NaN   \n",
       "14                                     19.0   \n",
       "15                                      0.0   \n",
       "16                                      0.0   \n",
       "17                                      NaN   \n",
       "18                                     13.0   \n",
       "19                                      NaN   \n",
       "20                                      NaN   \n",
       "21                                      NaN   \n",
       "22                                      NaN   \n",
       "23                                      0.0   \n",
       "24                                     17.0   \n",
       "25                                      NaN   \n",
       "26                                     17.0   \n",
       "27                                     23.0   \n",
       "28                                      2.0   \n",
       "29                                      1.0   \n",
       "30                                      4.0   \n",
       "31                                      NaN   \n",
       "32                                     10.0   \n",
       "33                                      7.0   \n",
       "34                                     14.0   \n",
       "35                                      NaN   \n",
       "36                                     16.0   \n",
       "37                                      1.0   \n",
       "38                                      1.0   \n",
       "39                                      NaN   \n",
       "40                                      1.0   \n",
       "41                                     10.0   \n",
       "42                                      0.0   \n",
       "43                                      NaN   \n",
       "44                                      NaN   \n",
       "45                                      NaN   \n",
       "46                                      NaN   \n",
       "47                                      7.0   \n",
       "48                                      NaN   \n",
       "49                                      9.0   \n",
       "50                                     10.0   \n",
       "51                                      NaN   \n",
       "52                                     13.0   \n",
       "53                                     17.0   \n",
       "54                                      1.0   \n",
       "55                                     10.0   \n",
       "56                                     10.0   \n",
       "57                                      NaN   \n",
       "58                                     17.0   \n",
       "59                                      8.0   \n",
       "60                                     10.0   \n",
       "61                                     16.0   \n",
       "62                                      6.0   \n",
       "63                                      8.0   \n",
       "64                                      7.0   \n",
       "65                                      6.0   \n",
       "66                                      NaN   \n",
       "67                                     13.0   \n",
       "68                                      1.0   \n",
       "69                                      NaN   \n",
       "70                                      1.0   \n",
       "71                                      4.0   \n",
       "72                                      1.0   \n",
       "73                                      0.0   \n",
       "74                                     12.0   \n",
       "75                                      6.0   \n",
       "76                                     10.0   \n",
       "77                                     18.0   \n",
       "78                                      9.0   \n",
       "79                                     17.0   \n",
       "80                                      NaN   \n",
       "81                                     10.0   \n",
       "82                                      NaN   \n",
       "83                                      1.0   \n",
       "84                                     12.0   \n",
       "85                                      4.0   \n",
       "86                                     18.0   \n",
       "87                                     22.0   \n",
       "88                                      NaN   \n",
       "89                                      0.0   \n",
       "90                                     11.0   \n",
       "91                                      NaN   \n",
       "92                                     20.0   \n",
       "93                                      1.0   \n",
       "94                                      NaN   \n",
       "95                                      NaN   \n",
       "96                                      NaN   \n",
       "97                                     13.0   \n",
       "98                                     10.0   \n",
       "99                                      1.0   \n",
       "100                                     9.0   \n",
       "101                                    10.0   \n",
       "102                                    21.0   \n",
       "103                                     7.0   \n",
       "104                                     7.0   \n",
       "105                                    13.0   \n",
       "106                                    17.0   \n",
       "107                                     3.0   \n",
       "108                                    17.0   \n",
       "109                                     4.0   \n",
       "110                                    12.0   \n",
       "111                                     1.0   \n",
       "112                                     NaN   \n",
       "113                                     NaN   \n",
       "114                                    12.0   \n",
       "115                                     NaN   \n",
       "116                                     NaN   \n",
       "117                                     NaN   \n",
       "118                                    13.0   \n",
       "119                                     NaN   \n",
       "120                                     NaN   \n",
       "121                                    15.0   \n",
       "122                                     7.0   \n",
       "123                                     5.0   \n",
       "124                                     NaN   \n",
       "125                                     NaN   \n",
       "126                                     1.0   \n",
       "127                                     4.0   \n",
       "128                                     1.0   \n",
       "129                                     1.0   \n",
       "130                                     1.0   \n",
       "131                                     4.0   \n",
       "132                                     1.0   \n",
       "133                                    13.0   \n",
       "134                                    17.0   \n",
       "135                                     1.0   \n",
       "136                                     1.0   \n",
       "137                                    13.0   \n",
       "138                                    17.0   \n",
       "139                                     NaN   \n",
       "\n",
       "     engineered_features_granular_gmm_probs  \\\n",
       "0                                      12.0   \n",
       "1                                      17.0   \n",
       "2                                       NaN   \n",
       "3                                       7.0   \n",
       "4                                       2.0   \n",
       "5                                      10.0   \n",
       "6                                       NaN   \n",
       "7                                       NaN   \n",
       "8                                       9.0   \n",
       "9                                      17.0   \n",
       "10                                     23.0   \n",
       "11                                     20.0   \n",
       "12                                     10.0   \n",
       "13                                      NaN   \n",
       "14                                     19.0   \n",
       "15                                      4.0   \n",
       "16                                      4.0   \n",
       "17                                      NaN   \n",
       "18                                      4.0   \n",
       "19                                      NaN   \n",
       "20                                      NaN   \n",
       "21                                      NaN   \n",
       "22                                      NaN   \n",
       "23                                      0.0   \n",
       "24                                     17.0   \n",
       "25                                      NaN   \n",
       "26                                      1.0   \n",
       "27                                     23.0   \n",
       "28                                      2.0   \n",
       "29                                     17.0   \n",
       "30                                      4.0   \n",
       "31                                      NaN   \n",
       "32                                     10.0   \n",
       "33                                      7.0   \n",
       "34                                     14.0   \n",
       "35                                      NaN   \n",
       "36                                     16.0   \n",
       "37                                     10.0   \n",
       "38                                     17.0   \n",
       "39                                      NaN   \n",
       "40                                     10.0   \n",
       "41                                     10.0   \n",
       "42                                      0.0   \n",
       "43                                      NaN   \n",
       "44                                      NaN   \n",
       "45                                      NaN   \n",
       "46                                      NaN   \n",
       "47                                      7.0   \n",
       "48                                      NaN   \n",
       "49                                      9.0   \n",
       "50                                     10.0   \n",
       "51                                      NaN   \n",
       "52                                     13.0   \n",
       "53                                      9.0   \n",
       "54                                     10.0   \n",
       "55                                     10.0   \n",
       "56                                     10.0   \n",
       "57                                      NaN   \n",
       "58                                     17.0   \n",
       "59                                      8.0   \n",
       "60                                     10.0   \n",
       "61                                     16.0   \n",
       "62                                      6.0   \n",
       "63                                      8.0   \n",
       "64                                      7.0   \n",
       "65                                      6.0   \n",
       "66                                      NaN   \n",
       "67                                     13.0   \n",
       "68                                     10.0   \n",
       "69                                      NaN   \n",
       "70                                     10.0   \n",
       "71                                      4.0   \n",
       "72                                      1.0   \n",
       "73                                      0.0   \n",
       "74                                     12.0   \n",
       "75                                      6.0   \n",
       "76                                     10.0   \n",
       "77                                      4.0   \n",
       "78                                      9.0   \n",
       "79                                     17.0   \n",
       "80                                      NaN   \n",
       "81                                     10.0   \n",
       "82                                      NaN   \n",
       "83                                     17.0   \n",
       "84                                     12.0   \n",
       "85                                      4.0   \n",
       "86                                     18.0   \n",
       "87                                     22.0   \n",
       "88                                      NaN   \n",
       "89                                      4.0   \n",
       "90                                     11.0   \n",
       "91                                      NaN   \n",
       "92                                     20.0   \n",
       "93                                      1.0   \n",
       "94                                      NaN   \n",
       "95                                      NaN   \n",
       "96                                      NaN   \n",
       "97                                     13.0   \n",
       "98                                     10.0   \n",
       "99                                     17.0   \n",
       "100                                     9.0   \n",
       "101                                    10.0   \n",
       "102                                    21.0   \n",
       "103                                     1.0   \n",
       "104                                     7.0   \n",
       "105                                    13.0   \n",
       "106                                    17.0   \n",
       "107                                     3.0   \n",
       "108                                    17.0   \n",
       "109                                     4.0   \n",
       "110                                    12.0   \n",
       "111                                    17.0   \n",
       "112                                     NaN   \n",
       "113                                     NaN   \n",
       "114                                    12.0   \n",
       "115                                     NaN   \n",
       "116                                     NaN   \n",
       "117                                     NaN   \n",
       "118                                    13.0   \n",
       "119                                     NaN   \n",
       "120                                     NaN   \n",
       "121                                    15.0   \n",
       "122                                     7.0   \n",
       "123                                     5.0   \n",
       "124                                     NaN   \n",
       "125                                     NaN   \n",
       "126                                    17.0   \n",
       "127                                     4.0   \n",
       "128                                    17.0   \n",
       "129                                    17.0   \n",
       "130                                    17.0   \n",
       "131                                     4.0   \n",
       "132                                    17.0   \n",
       "133                                     4.0   \n",
       "134                                    17.0   \n",
       "135                                    17.0   \n",
       "136                                    17.0   \n",
       "137                                     4.0   \n",
       "138                                    17.0   \n",
       "139                                     NaN   \n",
       "\n",
       "     engineered_features_tight_km_labels  engineered_features_tight_gmm_probs  \\\n",
       "0                                    4.0                                  4.0   \n",
       "1                                    0.0                                  2.0   \n",
       "2                                    NaN                                  NaN   \n",
       "3                                    0.0                                  0.0   \n",
       "4                                    1.0                                  2.0   \n",
       "5                                    0.0                                  2.0   \n",
       "6                                    NaN                                  NaN   \n",
       "7                                    NaN                                  NaN   \n",
       "8                                    2.0                                  2.0   \n",
       "9                                    2.0                                  2.0   \n",
       "10                                   0.0                                  0.0   \n",
       "11                                   6.0                                  6.0   \n",
       "12                                   0.0                                  2.0   \n",
       "13                                   NaN                                  NaN   \n",
       "14                                   3.0                                  0.0   \n",
       "15                                   6.0                                  6.0   \n",
       "16                                   6.0                                  6.0   \n",
       "17                                   NaN                                  NaN   \n",
       "18                                   1.0                                  2.0   \n",
       "19                                   NaN                                  NaN   \n",
       "20                                   NaN                                  NaN   \n",
       "21                                   NaN                                  NaN   \n",
       "22                                   NaN                                  NaN   \n",
       "23                                   6.0                                  6.0   \n",
       "24                                   0.0                                  2.0   \n",
       "25                                   NaN                                  NaN   \n",
       "26                                   0.0                                  2.0   \n",
       "27                                   0.0                                  0.0   \n",
       "28                                   2.0                                  2.0   \n",
       "29                                   0.0                                  2.0   \n",
       "30                                   1.0                                  2.0   \n",
       "31                                   NaN                                  NaN   \n",
       "32                                   0.0                                  2.0   \n",
       "33                                   0.0                                  0.0   \n",
       "34                                   3.0                                  7.0   \n",
       "35                                   NaN                                  NaN   \n",
       "36                                   5.0                                  5.0   \n",
       "37                                   0.0                                  2.0   \n",
       "38                                   0.0                                  2.0   \n",
       "39                                   NaN                                  NaN   \n",
       "40                                   0.0                                  2.0   \n",
       "41                                   0.0                                  2.0   \n",
       "42                                   6.0                                  6.0   \n",
       "43                                   NaN                                  NaN   \n",
       "44                                   NaN                                  NaN   \n",
       "45                                   NaN                                  NaN   \n",
       "46                                   NaN                                  NaN   \n",
       "47                                   0.0                                  0.0   \n",
       "48                                   NaN                                  NaN   \n",
       "49                                   2.0                                  2.0   \n",
       "50                                   0.0                                  2.0   \n",
       "51                                   NaN                                  NaN   \n",
       "52                                   1.0                                  0.0   \n",
       "53                                   2.0                                  2.0   \n",
       "54                                   0.0                                  2.0   \n",
       "55                                   0.0                                  2.0   \n",
       "56                                   0.0                                  2.0   \n",
       "57                                   NaN                                  NaN   \n",
       "58                                   2.0                                  2.0   \n",
       "59                                   3.0                                  0.0   \n",
       "60                                   0.0                                  2.0   \n",
       "61                                   5.0                                  5.0   \n",
       "62                                   5.0                                  5.0   \n",
       "63                                   3.0                                  0.0   \n",
       "64                                   0.0                                  0.0   \n",
       "65                                   5.0                                  5.0   \n",
       "66                                   NaN                                  NaN   \n",
       "67                                   1.0                                  2.0   \n",
       "68                                   0.0                                  2.0   \n",
       "69                                   NaN                                  NaN   \n",
       "70                                   0.0                                  2.0   \n",
       "71                                   1.0                                  2.0   \n",
       "72                                   0.0                                  0.0   \n",
       "73                                   6.0                                  6.0   \n",
       "74                                   4.0                                  7.0   \n",
       "75                                   5.0                                  5.0   \n",
       "76                                   0.0                                  2.0   \n",
       "77                                   1.0                                  2.0   \n",
       "78                                   2.0                                  2.0   \n",
       "79                                   2.0                                  2.0   \n",
       "80                                   NaN                                  NaN   \n",
       "81                                   0.0                                  2.0   \n",
       "82                                   NaN                                  NaN   \n",
       "83                                   0.0                                  2.0   \n",
       "84                                   4.0                                  4.0   \n",
       "85                                   1.0                                  2.0   \n",
       "86                                   1.0                                  2.0   \n",
       "87                                   4.0                                  6.0   \n",
       "88                                   NaN                                  NaN   \n",
       "89                                   6.0                                  6.0   \n",
       "90                                   3.0                                  0.0   \n",
       "91                                   NaN                                  NaN   \n",
       "92                                   6.0                                  6.0   \n",
       "93                                   0.0                                  2.0   \n",
       "94                                   NaN                                  NaN   \n",
       "95                                   NaN                                  NaN   \n",
       "96                                   NaN                                  NaN   \n",
       "97                                   1.0                                  0.0   \n",
       "98                                   0.0                                  2.0   \n",
       "99                                   0.0                                  2.0   \n",
       "100                                  2.0                                  2.0   \n",
       "101                                  0.0                                  2.0   \n",
       "102                                  2.0                                  2.0   \n",
       "103                                  0.0                                  0.0   \n",
       "104                                  0.0                                  0.0   \n",
       "105                                  1.0                                  0.0   \n",
       "106                                  2.0                                  2.0   \n",
       "107                                  7.0                                  7.0   \n",
       "108                                  0.0                                  2.0   \n",
       "109                                  1.0                                  2.0   \n",
       "110                                  4.0                                  4.0   \n",
       "111                                  0.0                                  2.0   \n",
       "112                                  NaN                                  NaN   \n",
       "113                                  NaN                                  NaN   \n",
       "114                                  4.0                                  7.0   \n",
       "115                                  NaN                                  NaN   \n",
       "116                                  NaN                                  NaN   \n",
       "117                                  NaN                                  NaN   \n",
       "118                                  1.0                                  0.0   \n",
       "119                                  NaN                                  NaN   \n",
       "120                                  NaN                                  NaN   \n",
       "121                                  3.0                                  0.0   \n",
       "122                                  0.0                                  0.0   \n",
       "123                                  4.0                                  4.0   \n",
       "124                                  NaN                                  NaN   \n",
       "125                                  NaN                                  NaN   \n",
       "126                                  0.0                                  2.0   \n",
       "127                                  1.0                                  2.0   \n",
       "128                                  0.0                                  2.0   \n",
       "129                                  0.0                                  2.0   \n",
       "130                                  0.0                                  2.0   \n",
       "131                                  1.0                                  2.0   \n",
       "132                                  0.0                                  2.0   \n",
       "133                                  1.0                                  2.0   \n",
       "134                                  0.0                                  2.0   \n",
       "135                                  0.0                                  2.0   \n",
       "136                                  0.0                                  2.0   \n",
       "137                                  1.0                                  2.0   \n",
       "138                                  0.0                                  2.0   \n",
       "139                                  NaN                                  NaN   \n",
       "\n",
       "     role_labels_km_labels  role_labels_gmm_probs  highest_troop_km_labels  \\\n",
       "0                      2.0                    2.0                      7.0   \n",
       "1                      1.0                    1.0                      3.0   \n",
       "2                      NaN                    NaN                      NaN   \n",
       "3                      1.0                    1.0                     10.0   \n",
       "4                      0.0                    0.0                     13.0   \n",
       "5                      1.0                    1.0                      0.0   \n",
       "6                      NaN                    NaN                      NaN   \n",
       "7                      NaN                    NaN                      NaN   \n",
       "8                      1.0                    1.0                     14.0   \n",
       "9                      1.0                    1.0                     22.0   \n",
       "10                     4.0                    4.0                      2.0   \n",
       "11                     0.0                    0.0                     16.0   \n",
       "12                     1.0                    1.0                      0.0   \n",
       "13                     NaN                    NaN                      NaN   \n",
       "14                     2.0                    2.0                     10.0   \n",
       "15                     2.0                    2.0                     18.0   \n",
       "16                     2.0                    2.0                     20.0   \n",
       "17                     NaN                    NaN                      NaN   \n",
       "18                     2.0                    2.0                     19.0   \n",
       "19                     NaN                    NaN                      NaN   \n",
       "20                     NaN                    NaN                      NaN   \n",
       "21                     NaN                    NaN                      NaN   \n",
       "22                     NaN                    NaN                      NaN   \n",
       "23                     6.0                    6.0                      4.0   \n",
       "24                     1.0                    1.0                      3.0   \n",
       "25                     NaN                    NaN                      NaN   \n",
       "26                     1.0                    1.0                      3.0   \n",
       "27                     5.0                    5.0                     17.0   \n",
       "28                     1.0                    1.0                     15.0   \n",
       "29                     1.0                    1.0                      1.0   \n",
       "30                     2.0                    2.0                     14.0   \n",
       "31                     NaN                    NaN                      NaN   \n",
       "32                     8.0                    8.0                     11.0   \n",
       "33                     1.0                    1.0                     10.0   \n",
       "34                     2.0                    2.0                     10.0   \n",
       "35                     NaN                    NaN                      NaN   \n",
       "36                     1.0                    1.0                     10.0   \n",
       "37                     1.0                    1.0                      0.0   \n",
       "38                     1.0                    1.0                      3.0   \n",
       "39                     NaN                    NaN                      NaN   \n",
       "40                     1.0                    1.0                      1.0   \n",
       "41                     0.0                    0.0                     17.0   \n",
       "42                     2.0                    2.0                      4.0   \n",
       "43                     NaN                    NaN                      NaN   \n",
       "44                     NaN                    NaN                      NaN   \n",
       "45                     NaN                    NaN                      NaN   \n",
       "46                     NaN                    NaN                      NaN   \n",
       "47                     4.0                    4.0                     10.0   \n",
       "48                     NaN                    NaN                      NaN   \n",
       "49                     1.0                    1.0                     12.0   \n",
       "50                     5.0                    5.0                      6.0   \n",
       "51                     NaN                    NaN                      NaN   \n",
       "52                     2.0                    2.0                      2.0   \n",
       "53                     1.0                    1.0                     22.0   \n",
       "54                     1.0                    1.0                      7.0   \n",
       "55                     4.0                    4.0                      8.0   \n",
       "56                     0.0                    0.0                      6.0   \n",
       "57                     NaN                    NaN                      NaN   \n",
       "58                     1.0                    1.0                     22.0   \n",
       "59                     1.0                    1.0                     10.0   \n",
       "60                     8.0                    8.0                     17.0   \n",
       "61                     1.0                    1.0                     15.0   \n",
       "62                     7.0                    7.0                      5.0   \n",
       "63                     1.0                    1.0                     10.0   \n",
       "64                     1.0                    1.0                      1.0   \n",
       "65                     4.0                    4.0                      3.0   \n",
       "66                     NaN                    NaN                      NaN   \n",
       "67                     6.0                    6.0                      0.0   \n",
       "68                     5.0                    5.0                      6.0   \n",
       "69                     NaN                    NaN                      NaN   \n",
       "70                     1.0                    1.0                      7.0   \n",
       "71                     6.0                    6.0                     12.0   \n",
       "72                     1.0                    1.0                     10.0   \n",
       "73                     2.0                    2.0                      4.0   \n",
       "74                     2.0                    2.0                      3.0   \n",
       "75                     4.0                    4.0                      8.0   \n",
       "76                     1.0                    1.0                      0.0   \n",
       "77                     6.0                    6.0                     13.0   \n",
       "78                     1.0                    1.0                     14.0   \n",
       "79                     1.0                    1.0                      3.0   \n",
       "80                     NaN                    NaN                      NaN   \n",
       "81                     1.0                    1.0                      8.0   \n",
       "82                     NaN                    NaN                      NaN   \n",
       "83                     1.0                    1.0                      1.0   \n",
       "84                     2.0                    2.0                      3.0   \n",
       "85                     2.0                    2.0                     12.0   \n",
       "86                     2.0                    2.0                     13.0   \n",
       "87                     2.0                    2.0                     16.0   \n",
       "88                     NaN                    NaN                      NaN   \n",
       "89                     2.0                    2.0                      4.0   \n",
       "90                     1.0                    1.0                     10.0   \n",
       "91                     NaN                    NaN                      NaN   \n",
       "92                     0.0                    0.0                     20.0   \n",
       "93                     1.0                    1.0                     12.0   \n",
       "94                     NaN                    NaN                      NaN   \n",
       "95                     NaN                    NaN                      NaN   \n",
       "96                     NaN                    NaN                      NaN   \n",
       "97                     2.0                    2.0                      2.0   \n",
       "98                     0.0                    0.0                     17.0   \n",
       "99                     5.0                    5.0                     17.0   \n",
       "100                    1.0                    1.0                     14.0   \n",
       "101                    7.0                    7.0                     17.0   \n",
       "102                    1.0                    1.0                      9.0   \n",
       "103                    5.0                    5.0                     11.0   \n",
       "104                    1.0                    1.0                     10.0   \n",
       "105                    6.0                    6.0                     21.0   \n",
       "106                    1.0                    1.0                     22.0   \n",
       "107                    2.0                    2.0                     19.0   \n",
       "108                    1.0                    1.0                      3.0   \n",
       "109                    2.0                    2.0                      0.0   \n",
       "110                    2.0                    2.0                     19.0   \n",
       "111                    3.0                    3.0                      5.0   \n",
       "112                    NaN                    NaN                      NaN   \n",
       "113                    NaN                    NaN                      NaN   \n",
       "114                    2.0                    2.0                     19.0   \n",
       "115                    NaN                    NaN                      NaN   \n",
       "116                    NaN                    NaN                      NaN   \n",
       "117                    NaN                    NaN                      NaN   \n",
       "118                    6.0                    6.0                      2.0   \n",
       "119                    NaN                    NaN                      NaN   \n",
       "120                    NaN                    NaN                      NaN   \n",
       "121                    0.0                    0.0                     11.0   \n",
       "122                    1.0                    1.0                      1.0   \n",
       "123                    2.0                    2.0                     10.0   \n",
       "124                    NaN                    NaN                      NaN   \n",
       "125                    NaN                    NaN                      NaN   \n",
       "126                    1.0                    1.0                      3.0   \n",
       "127                    2.0                    2.0                      0.0   \n",
       "128                    3.0                    3.0                      5.0   \n",
       "129                    3.0                    3.0                      5.0   \n",
       "130                    5.0                    5.0                     11.0   \n",
       "131                    2.0                    2.0                      0.0   \n",
       "132                    3.0                    3.0                      5.0   \n",
       "133                    6.0                    6.0                      0.0   \n",
       "134                    3.0                    3.0                     22.0   \n",
       "135                    7.0                    7.0                      5.0   \n",
       "136                    1.0                    1.0                      0.0   \n",
       "137                    6.0                    6.0                      0.0   \n",
       "138                    1.0                    1.0                      3.0   \n",
       "139                    NaN                    NaN                      NaN   \n",
       "\n",
       "     highest_troop_gmm_probs  engineered_and_boolean_km_labels  \\\n",
       "0                        7.0                               6.0   \n",
       "1                        3.0                               6.0   \n",
       "2                        NaN                               NaN   \n",
       "3                       10.0                               6.0   \n",
       "4                        5.0                               1.0   \n",
       "5                       22.0                               6.0   \n",
       "6                        NaN                               NaN   \n",
       "7                        NaN                               NaN   \n",
       "8                       22.0                               1.0   \n",
       "9                       22.0                               1.0   \n",
       "10                       2.0                               4.0   \n",
       "11                      16.0                               8.0   \n",
       "12                      22.0                               6.0   \n",
       "13                       NaN                               NaN   \n",
       "14                      10.0                               4.0   \n",
       "15                      18.0                               0.0   \n",
       "16                      20.0                               0.0   \n",
       "17                       NaN                               NaN   \n",
       "18                      19.0                               6.0   \n",
       "19                       NaN                               NaN   \n",
       "20                       NaN                               NaN   \n",
       "21                       NaN                               NaN   \n",
       "22                       NaN                               NaN   \n",
       "23                      20.0                               0.0   \n",
       "24                       3.0                               6.0   \n",
       "25                       NaN                               NaN   \n",
       "26                       3.0                               6.0   \n",
       "27                       5.0                               6.0   \n",
       "28                      15.0                               1.0   \n",
       "29                      19.0                               6.0   \n",
       "30                      22.0                               1.0   \n",
       "31                       NaN                               NaN   \n",
       "32                      11.0                               2.0   \n",
       "33                      10.0                               6.0   \n",
       "34                      10.0                               4.0   \n",
       "35                       NaN                               NaN   \n",
       "36                       2.0                               7.0   \n",
       "37                      22.0                               6.0   \n",
       "38                       3.0                               6.0   \n",
       "39                       NaN                               NaN   \n",
       "40                      19.0                               5.0   \n",
       "41                      17.0                               6.0   \n",
       "42                       4.0                               0.0   \n",
       "43                       NaN                               NaN   \n",
       "44                       NaN                               NaN   \n",
       "45                       NaN                               NaN   \n",
       "46                       NaN                               NaN   \n",
       "47                      10.0                               3.0   \n",
       "48                       NaN                               NaN   \n",
       "49                       1.0                               1.0   \n",
       "50                       6.0                               2.0   \n",
       "51                       NaN                               NaN   \n",
       "52                       2.0                               6.0   \n",
       "53                      22.0                               1.0   \n",
       "54                       7.0                               6.0   \n",
       "55                       8.0                               6.0   \n",
       "56                      11.0                               2.0   \n",
       "57                       NaN                               NaN   \n",
       "58                      22.0                               1.0   \n",
       "59                      10.0                               4.0   \n",
       "60                       5.0                               6.0   \n",
       "61                      15.0                               7.0   \n",
       "62                       5.0                               7.0   \n",
       "63                      10.0                               4.0   \n",
       "64                       1.0                               6.0   \n",
       "65                       3.0                               7.0   \n",
       "66                       NaN                               NaN   \n",
       "67                      22.0                               6.0   \n",
       "68                       6.0                               2.0   \n",
       "69                       NaN                               NaN   \n",
       "70                       7.0                               6.0   \n",
       "71                      12.0                               2.0   \n",
       "72                      10.0                               6.0   \n",
       "73                      20.0                               0.0   \n",
       "74                       3.0                               6.0   \n",
       "75                       8.0                               7.0   \n",
       "76                      22.0                               6.0   \n",
       "77                      22.0                               1.0   \n",
       "78                      14.0                               1.0   \n",
       "79                       3.0                               6.0   \n",
       "80                       NaN                               NaN   \n",
       "81                       8.0                               6.0   \n",
       "82                       NaN                               NaN   \n",
       "83                      19.0                               6.0   \n",
       "84                       3.0                               6.0   \n",
       "85                      12.0                               5.0   \n",
       "86                      22.0                               1.0   \n",
       "87                      16.0                               2.0   \n",
       "88                       NaN                               NaN   \n",
       "89                       4.0                               0.0   \n",
       "90                      10.0                               4.0   \n",
       "91                       NaN                               NaN   \n",
       "92                      20.0                               0.0   \n",
       "93                       1.0                               6.0   \n",
       "94                       NaN                               NaN   \n",
       "95                       NaN                               NaN   \n",
       "96                       NaN                               NaN   \n",
       "97                       2.0                               6.0   \n",
       "98                      17.0                               6.0   \n",
       "99                      14.0                               6.0   \n",
       "100                     22.0                               1.0   \n",
       "101                      5.0                               6.0   \n",
       "102                      9.0                               1.0   \n",
       "103                     11.0                               2.0   \n",
       "104                     10.0                               6.0   \n",
       "105                     21.0                               6.0   \n",
       "106                     22.0                               1.0   \n",
       "107                     19.0                               4.0   \n",
       "108                      3.0                               6.0   \n",
       "109                     22.0                               6.0   \n",
       "110                      3.0                               6.0   \n",
       "111                     17.0                               8.0   \n",
       "112                      NaN                               NaN   \n",
       "113                      NaN                               NaN   \n",
       "114                     19.0                               1.0   \n",
       "115                      NaN                               NaN   \n",
       "116                      NaN                               NaN   \n",
       "117                      NaN                               NaN   \n",
       "118                      2.0                               4.0   \n",
       "119                      NaN                               NaN   \n",
       "120                      NaN                               NaN   \n",
       "121                      5.0                               4.0   \n",
       "122                      1.0                               5.0   \n",
       "123                     10.0                               4.0   \n",
       "124                      NaN                               NaN   \n",
       "125                      NaN                               NaN   \n",
       "126                      3.0                               6.0   \n",
       "127                     22.0                               1.0   \n",
       "128                      5.0                               6.0   \n",
       "129                      5.0                               6.0   \n",
       "130                     11.0                               2.0   \n",
       "131                     22.0                               6.0   \n",
       "132                      5.0                               6.0   \n",
       "133                     22.0                               6.0   \n",
       "134                     22.0                               6.0   \n",
       "135                      5.0                               6.0   \n",
       "136                     22.0                               6.0   \n",
       "137                     22.0                               6.0   \n",
       "138                      3.0                               6.0   \n",
       "139                      NaN                               NaN   \n",
       "\n",
       "     engineered_and_boolean_gmm_probs  \n",
       "0                                 6.0  \n",
       "1                                 1.0  \n",
       "2                                 NaN  \n",
       "3                                 6.0  \n",
       "4                                 6.0  \n",
       "5                                 1.0  \n",
       "6                                 NaN  \n",
       "7                                 NaN  \n",
       "8                                 1.0  \n",
       "9                                 1.0  \n",
       "10                                4.0  \n",
       "11                                8.0  \n",
       "12                                1.0  \n",
       "13                                NaN  \n",
       "14                                4.0  \n",
       "15                                0.0  \n",
       "16                                0.0  \n",
       "17                                NaN  \n",
       "18                                1.0  \n",
       "19                                NaN  \n",
       "20                                NaN  \n",
       "21                                NaN  \n",
       "22                                NaN  \n",
       "23                                0.0  \n",
       "24                                1.0  \n",
       "25                                NaN  \n",
       "26                                6.0  \n",
       "27                                6.0  \n",
       "28                                1.0  \n",
       "29                                1.0  \n",
       "30                                1.0  \n",
       "31                                NaN  \n",
       "32                                2.0  \n",
       "33                                6.0  \n",
       "34                                4.0  \n",
       "35                                NaN  \n",
       "36                                7.0  \n",
       "37                                1.0  \n",
       "38                                1.0  \n",
       "39                                NaN  \n",
       "40                                5.0  \n",
       "41                                1.0  \n",
       "42                                0.0  \n",
       "43                                NaN  \n",
       "44                                NaN  \n",
       "45                                NaN  \n",
       "46                                NaN  \n",
       "47                                3.0  \n",
       "48                                NaN  \n",
       "49                                1.0  \n",
       "50                                2.0  \n",
       "51                                NaN  \n",
       "52                                1.0  \n",
       "53                                1.0  \n",
       "54                                1.0  \n",
       "55                                1.0  \n",
       "56                                2.0  \n",
       "57                                NaN  \n",
       "58                                1.0  \n",
       "59                                4.0  \n",
       "60                                1.0  \n",
       "61                                7.0  \n",
       "62                                7.0  \n",
       "63                                4.0  \n",
       "64                                6.0  \n",
       "65                                7.0  \n",
       "66                                NaN  \n",
       "67                                1.0  \n",
       "68                                2.0  \n",
       "69                                NaN  \n",
       "70                                6.0  \n",
       "71                                2.0  \n",
       "72                                6.0  \n",
       "73                                0.0  \n",
       "74                                6.0  \n",
       "75                                7.0  \n",
       "76                                1.0  \n",
       "77                                1.0  \n",
       "78                                1.0  \n",
       "79                                1.0  \n",
       "80                                NaN  \n",
       "81                                6.0  \n",
       "82                                NaN  \n",
       "83                                6.0  \n",
       "84                                6.0  \n",
       "85                                5.0  \n",
       "86                                1.0  \n",
       "87                                2.0  \n",
       "88                                NaN  \n",
       "89                                0.0  \n",
       "90                                4.0  \n",
       "91                                NaN  \n",
       "92                                6.0  \n",
       "93                                1.0  \n",
       "94                                NaN  \n",
       "95                                NaN  \n",
       "96                                NaN  \n",
       "97                                6.0  \n",
       "98                                1.0  \n",
       "99                                1.0  \n",
       "100                               1.0  \n",
       "101                               1.0  \n",
       "102                               1.0  \n",
       "103                               2.0  \n",
       "104                               6.0  \n",
       "105                               6.0  \n",
       "106                               1.0  \n",
       "107                               4.0  \n",
       "108                               1.0  \n",
       "109                               1.0  \n",
       "110                               6.0  \n",
       "111                               8.0  \n",
       "112                               NaN  \n",
       "113                               NaN  \n",
       "114                               6.0  \n",
       "115                               NaN  \n",
       "116                               NaN  \n",
       "117                               NaN  \n",
       "118                               4.0  \n",
       "119                               NaN  \n",
       "120                               NaN  \n",
       "121                               4.0  \n",
       "122                               5.0  \n",
       "123                               4.0  \n",
       "124                               NaN  \n",
       "125                               NaN  \n",
       "126                               1.0  \n",
       "127                               1.0  \n",
       "128                               1.0  \n",
       "129                               1.0  \n",
       "130                               2.0  \n",
       "131                               1.0  \n",
       "132                               6.0  \n",
       "133                               1.0  \n",
       "134                               1.0  \n",
       "135                               1.0  \n",
       "136                               1.0  \n",
       "137                               1.0  \n",
       "138                               1.0  \n",
       "139                               NaN  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def add_flat_clusters(cards_df, cluster_dict):\n",
    "    \"\"\"\n",
    "    Adds cluster labels (KM or GMM argmax) to the `cards_df` DataFrame.\n",
    "    Assumes that `cards_df.index` are troop card names and cluster arrays match troop card count.\n",
    "    \"\"\"\n",
    "    troop_index = cards_df[cards_df['is_troop']].index\n",
    "    cluster_cols = []\n",
    "\n",
    "    for key, values in cluster_dict.items():\n",
    "        if len(values) != len(troop_index):\n",
    "            raise ValueError(f\"Length mismatch for {key}: {len(values)} values vs {len(troop_index)} troop cards\")\n",
    "\n",
    "        # Convert to Series with troop_index so we can safely reindex\n",
    "        series = pd.Series(values, index=troop_index, name=key)\n",
    "        cluster_cols.append(series.reindex(cards_df.index))  # NaN for non-troops\n",
    "\n",
    "    # Combine all columns\n",
    "    cluster_df = pd.concat(cluster_cols, axis=1)\n",
    "\n",
    "    # Drop existing cluster columns if they overlap\n",
    "    overlap = cards_df.columns.intersection(cluster_df.columns)\n",
    "    cards_df = cards_df.drop(columns=overlap)\n",
    "\n",
    "    # Join and return\n",
    "    return cards_df.join(cluster_df)\n",
    "cards = add_flat_clusters(cards, dict_clusters)\n",
    "cards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "791b7085-fece-4d4a-9fc8-723c13ccfbd2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>special_damage</th>\n",
       "      <th>special_attack_type</th>\n",
       "      <th>has_ranged_attack</th>\n",
       "      <th>has_ability</th>\n",
       "      <th>has_friendly_buff</th>\n",
       "      <th>invisible</th>\n",
       "      <th>aoe_bool</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     special_damage  special_attack_type  has_ranged_attack  has_ability  \\\n",
       "0             False                False               True         True   \n",
       "1             False                False               True        False   \n",
       "2             False                 True              False        False   \n",
       "3             False                False               True        False   \n",
       "4             False                False              False        False   \n",
       "5              True                False              False        False   \n",
       "6             False                False              False        False   \n",
       "7             False                False              False        False   \n",
       "8             False                False              False        False   \n",
       "9             False                False              False        False   \n",
       "10            False                False              False        False   \n",
       "11             True                False              False        False   \n",
       "12            False                False              False        False   \n",
       "13            False                False               True        False   \n",
       "14            False                False               True        False   \n",
       "15             True                False              False         True   \n",
       "16             True                False               True        False   \n",
       "17            False                False               True        False   \n",
       "18            False                False               True        False   \n",
       "19            False                False               True        False   \n",
       "20            False                False               True        False   \n",
       "21            False                False              False        False   \n",
       "22            False                False               True        False   \n",
       "23             True                False              False        False   \n",
       "24            False                False               True        False   \n",
       "25             True                 True              False        False   \n",
       "26             True                 True               True        False   \n",
       "27             True                False              False        False   \n",
       "28             True                 True               True        False   \n",
       "29             True                 True               True        False   \n",
       "30            False                False              False        False   \n",
       "31            False                False              False        False   \n",
       "32            False                False              False        False   \n",
       "33             True                 True               True        False   \n",
       "34            False                False               True        False   \n",
       "35             True                False              False        False   \n",
       "36             True                 True               True        False   \n",
       "37             True                False              False        False   \n",
       "38            False                False               True        False   \n",
       "39             True                False              False        False   \n",
       "40            False                False               True        False   \n",
       "41            False                False              False        False   \n",
       "42             True                False              False        False   \n",
       "43             True                False              False        False   \n",
       "44            False                False              False        False   \n",
       "45            False                False              False        False   \n",
       "46             True                 True              False        False   \n",
       "47             True                False               True        False   \n",
       "48             True                False              False        False   \n",
       "49            False                 True               True        False   \n",
       "50            False                 True               True        False   \n",
       "51            False                False               True        False   \n",
       "52            False                 True               True        False   \n",
       "53            False                False              False        False   \n",
       "54             True                False               True         True   \n",
       "55             True                False              False         True   \n",
       "56            False                False              False        False   \n",
       "57            False                False              False        False   \n",
       "58            False                False              False        False   \n",
       "59            False                False               True        False   \n",
       "60            False                False              False        False   \n",
       "61             True                 True               True        False   \n",
       "62             True                False              False        False   \n",
       "63             True                False               True        False   \n",
       "64             True                False               True        False   \n",
       "65             True                 True               True        False   \n",
       "66             True                 True               True        False   \n",
       "67            False                False              False        False   \n",
       "68            False                False               True        False   \n",
       "69             True                False              False        False   \n",
       "70             True                False               True         True   \n",
       "71            False                False              False        False   \n",
       "72             True                False               True        False   \n",
       "73             True                False              False        False   \n",
       "74            False                False               True        False   \n",
       "75             True                 True              False         True   \n",
       "76            False                False              False        False   \n",
       "77            False                False              False        False   \n",
       "78            False                False               True        False   \n",
       "79            False                False               True        False   \n",
       "80            False                False              False        False   \n",
       "81             True                 True              False         True   \n",
       "82            False                False               True        False   \n",
       "83             True                False               True        False   \n",
       "84            False                False               True        False   \n",
       "85            False                False              False        False   \n",
       "86            False                False              False        False   \n",
       "87             True                False              False        False   \n",
       "88             True                 True              False        False   \n",
       "89             True                False              False        False   \n",
       "90            False                False               True        False   \n",
       "91            False                False              False        False   \n",
       "92             True                 True               True        False   \n",
       "93            False                 True               True        False   \n",
       "94             True                False              False        False   \n",
       "95            False                False               True        False   \n",
       "96            False                False              False        False   \n",
       "97            False                False              False        False   \n",
       "98            False                False               True        False   \n",
       "99            False                False              False        False   \n",
       "100           False                False              False        False   \n",
       "101           False                False              False        False   \n",
       "102           False                False              False        False   \n",
       "103           False                False              False        False   \n",
       "104           False                False               True        False   \n",
       "105           False                False              False         True   \n",
       "106           False                False              False        False   \n",
       "107           False                False               True        False   \n",
       "108           False                False               True        False   \n",
       "109           False                False              False        False   \n",
       "110           False                False               True        False   \n",
       "111           False                False              False        False   \n",
       "112           False                False               True        False   \n",
       "113            True                False              False        False   \n",
       "114           False                False               True        False   \n",
       "115           False                False              False        False   \n",
       "116            True                False              False        False   \n",
       "117           False                False               True        False   \n",
       "118           False                False              False        False   \n",
       "119            True                False              False        False   \n",
       "120            True                 True              False        False   \n",
       "121           False                False              False        False   \n",
       "122           False                False               True        False   \n",
       "123           False                False               True        False   \n",
       "124           False                False               True        False   \n",
       "125            True                False              False        False   \n",
       "126            True                False               True        False   \n",
       "127           False                False              False        False   \n",
       "128           False                False              False        False   \n",
       "129           False                False              False        False   \n",
       "130           False                False              False        False   \n",
       "131           False                False              False        False   \n",
       "132           False                False              False        False   \n",
       "133           False                False              False        False   \n",
       "134           False                False              False        False   \n",
       "135           False                False              False        False   \n",
       "136           False                False              False        False   \n",
       "137           False                False              False        False   \n",
       "138           False                False               True        False   \n",
       "139           False                False              False        False   \n",
       "\n",
       "     has_friendly_buff  invisible  aoe_bool  \n",
       "0                False       True     False  \n",
       "1                False      False     False  \n",
       "2                False      False      True  \n",
       "3                False      False      True  \n",
       "4                False      False     False  \n",
       "5                False       True     False  \n",
       "6                False      False      True  \n",
       "7                False      False     False  \n",
       "8                False      False     False  \n",
       "9                False      False     False  \n",
       "10                True      False      True  \n",
       "11               False      False     False  \n",
       "12               False      False     False  \n",
       "13               False      False      True  \n",
       "14               False      False      True  \n",
       "15               False       True     False  \n",
       "16               False      False      True  \n",
       "17               False      False     False  \n",
       "18               False      False     False  \n",
       "19               False      False     False  \n",
       "20               False      False     False  \n",
       "21                True      False      True  \n",
       "22               False      False     False  \n",
       "23               False      False      True  \n",
       "24               False      False     False  \n",
       "25               False      False      True  \n",
       "26               False      False     False  \n",
       "27               False      False      True  \n",
       "28               False      False     False  \n",
       "29               False      False     False  \n",
       "30               False      False     False  \n",
       "31                True      False     False  \n",
       "32               False      False     False  \n",
       "33               False      False      True  \n",
       "34               False      False      True  \n",
       "35               False      False      True  \n",
       "36               False      False      True  \n",
       "37               False      False     False  \n",
       "38               False      False     False  \n",
       "39               False      False      True  \n",
       "40               False      False     False  \n",
       "41               False      False     False  \n",
       "42               False      False     False  \n",
       "43               False      False      True  \n",
       "44               False      False      True  \n",
       "45               False      False     False  \n",
       "46                True      False      True  \n",
       "47               False      False      True  \n",
       "48               False      False     False  \n",
       "49               False      False     False  \n",
       "50               False      False     False  \n",
       "51               False      False     False  \n",
       "52               False      False      True  \n",
       "53               False      False     False  \n",
       "54               False      False     False  \n",
       "55               False      False     False  \n",
       "56               False      False     False  \n",
       "57               False      False      True  \n",
       "58               False      False     False  \n",
       "59                True      False      True  \n",
       "60               False      False     False  \n",
       "61               False      False      True  \n",
       "62               False      False     False  \n",
       "63               False      False      True  \n",
       "64               False      False      True  \n",
       "65               False      False     False  \n",
       "66               False      False     False  \n",
       "67               False      False     False  \n",
       "68               False      False     False  \n",
       "69               False      False      True  \n",
       "70               False      False     False  \n",
       "71                True      False     False  \n",
       "72               False      False      True  \n",
       "73               False      False      True  \n",
       "74               False      False     False  \n",
       "75               False      False     False  \n",
       "76               False      False     False  \n",
       "77               False      False     False  \n",
       "78               False      False     False  \n",
       "79               False      False     False  \n",
       "80                True      False     False  \n",
       "81               False      False     False  \n",
       "82               False      False      True  \n",
       "83               False      False     False  \n",
       "84               False      False     False  \n",
       "85               False      False     False  \n",
       "86               False      False     False  \n",
       "87               False      False     False  \n",
       "88               False      False      True  \n",
       "89               False      False     False  \n",
       "90               False      False      True  \n",
       "91                True      False      True  \n",
       "92               False      False     False  \n",
       "93               False      False     False  \n",
       "94               False      False      True  \n",
       "95                True      False     False  \n",
       "96               False      False      True  \n",
       "97               False       True      True  \n",
       "98               False      False     False  \n",
       "99               False      False     False  \n",
       "100              False      False     False  \n",
       "101               True      False     False  \n",
       "102              False      False     False  \n",
       "103              False      False      True  \n",
       "104              False      False      True  \n",
       "105               True      False      True  \n",
       "106              False      False     False  \n",
       "107              False      False      True  \n",
       "108              False      False     False  \n",
       "109              False      False     False  \n",
       "110              False      False     False  \n",
       "111              False       True     False  \n",
       "112              False      False     False  \n",
       "113              False      False      True  \n",
       "114              False      False     False  \n",
       "115              False      False     False  \n",
       "116              False      False      True  \n",
       "117              False      False     False  \n",
       "118              False      False      True  \n",
       "119               True      False      True  \n",
       "120              False      False      True  \n",
       "121              False      False      True  \n",
       "122              False      False      True  \n",
       "123              False      False      True  \n",
       "124              False      False     False  \n",
       "125              False      False      True  \n",
       "126              False      False     False  \n",
       "127              False      False     False  \n",
       "128              False      False     False  \n",
       "129              False      False     False  \n",
       "130              False      False     False  \n",
       "131              False      False     False  \n",
       "132              False      False     False  \n",
       "133              False      False     False  \n",
       "134              False      False     False  \n",
       "135              False      False     False  \n",
       "136              False      False     False  \n",
       "137              False      False     False  \n",
       "138              False      False     False  \n",
       "139              False      False     False  "
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cards[feature_groups['special_attack_mechanics']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "c28203e2-2bc0-4b0b-ab22-33cc5e610387",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Bowler', 'Goblin Demolisher', 'Ice Spirit', 'Ice Wizard', 'Magic Archer']"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "special_attack_mechanics['km_clusters'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "9162a7d1-0331-4daf-a886-d3e55dfad957",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_groups_spell = {\n",
    "    'core_identity': [\n",
    "        'spawn_bool', 'has_friendly_buff',\n",
    "        'no_hit_speed', 'no_attack', 'single_damage_type'\n",
    "    ],\n",
    "    'combat_core_stats': [\n",
    "        'elixircost', 'damage', 'attack_count',\n",
    "        'speed', 'aoe_radius'\n",
    "    ],\n",
    "    'use_behavior': [\n",
    "        'affected_crown', 'special_attack_type', 'single_damage_type', 'aoe_bool'\n",
    "    ],\n",
    "    'special_attack_mechanics': [\n",
    "        'special_damage', 'special_attack_type', 'has_ranged_attack',\n",
    "        'has_friendly_buff', 'invisible', 'aoe_bool'\n",
    "    ],\n",
    "    'engineered_features': [\n",
    "        'damage_per_elixir', 'damage_output',\n",
    "        'aoe_by_damage', 'aoe_per_elixir'\n",
    "    ],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "f0096399-2bbf-4e73-b7fe-b9845d2b0b3c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>playable</th>\n",
       "      <th>aoe_bool</th>\n",
       "      <th>aoe_radius</th>\n",
       "      <th>death_damage_bool</th>\n",
       "      <th>fly_bool</th>\n",
       "      <th>spawn_bool</th>\n",
       "      <th>can_evolve</th>\n",
       "      <th>elixircost</th>\n",
       "      <th>hit_speed</th>\n",
       "      <th>special_damage</th>\n",
       "      <th>count</th>\n",
       "      <th>hitpoints</th>\n",
       "      <th>shield_bool</th>\n",
       "      <th>damage</th>\n",
       "      <th>attack_count</th>\n",
       "      <th>range</th>\n",
       "      <th>affected_crown</th>\n",
       "      <th>has_lifetime</th>\n",
       "      <th>invisible</th>\n",
       "      <th>has_ability</th>\n",
       "      <th>any_target</th>\n",
       "      <th>building_target</th>\n",
       "      <th>ground_target</th>\n",
       "      <th>has_upon_breaking_spawn</th>\n",
       "      <th>has_upon_death_spawn</th>\n",
       "      <th>has_periodic_spawn</th>\n",
       "      <th>single_damage_type</th>\n",
       "      <th>is_troop</th>\n",
       "      <th>is_spell</th>\n",
       "      <th>is_building</th>\n",
       "      <th>is_tower_troop</th>\n",
       "      <th>is_spawned</th>\n",
       "      <th>speed</th>\n",
       "      <th>has_ranged_attack</th>\n",
       "      <th>special_attack_type</th>\n",
       "      <th>has_friendly_buff</th>\n",
       "      <th>is_free_card</th>\n",
       "      <th>no_hit_speed</th>\n",
       "      <th>no_attack</th>\n",
       "      <th>no_hitpoints</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Archer Queen</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1.2</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>1000</td>\n",
       "      <td>False</td>\n",
       "      <td>225</td>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1.2</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Archers</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.9</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "      <td>304</td>\n",
       "      <td>False</td>\n",
       "      <td>112</td>\n",
       "      <td>2</td>\n",
       "      <td>5.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1.2</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Baby Dragon</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>1.2</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1.5</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>1152</td>\n",
       "      <td>False</td>\n",
       "      <td>161</td>\n",
       "      <td>1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1.8</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Balloon</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>1679</td>\n",
       "      <td>False</td>\n",
       "      <td>640</td>\n",
       "      <td>1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1.2</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Bandit</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>906</td>\n",
       "      <td>False</td>\n",
       "      <td>194</td>\n",
       "      <td>1</td>\n",
       "      <td>0.75</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1.8</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Barbarians</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1.3</td>\n",
       "      <td>False</td>\n",
       "      <td>5</td>\n",
       "      <td>670</td>\n",
       "      <td>False</td>\n",
       "      <td>192</td>\n",
       "      <td>5</td>\n",
       "      <td>0.7</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>1.2</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Bats</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>False</td>\n",
       "      <td>5</td>\n",
       "      <td>81</td>\n",
       "      <td>False</td>\n",
       "      <td>81</td>\n",
       "      <td>5</td>\n",
       "      <td>1.2</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>2.4</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Battle Healer</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>4.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1.5</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>1717</td>\n",
       "      <td>False</td>\n",
       "      <td>148</td>\n",
       "      <td>1</td>\n",
       "      <td>1.6</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1.2</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Battle Ram</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>967</td>\n",
       "      <td>False</td>\n",
       "      <td>286</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1.2</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Berserker</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.5</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>896</td>\n",
       "      <td>False</td>\n",
       "      <td>102</td>\n",
       "      <td>1</td>\n",
       "      <td>0.8</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1.8</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Bomber</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>1.5</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1.8</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>332</td>\n",
       "      <td>False</td>\n",
       "      <td>225</td>\n",
       "      <td>1</td>\n",
       "      <td>4.5</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1.2</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Boss Bandit</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>1.2</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>2624</td>\n",
       "      <td>False</td>\n",
       "      <td>268</td>\n",
       "      <td>1</td>\n",
       "      <td>0.8</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1.8</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Bowler</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>2081</td>\n",
       "      <td>False</td>\n",
       "      <td>289</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.9</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Cannon Cart</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.9</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>1809</td>\n",
       "      <td>False</td>\n",
       "      <td>212</td>\n",
       "      <td>1</td>\n",
       "      <td>5.5</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1.2</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Dark Prince</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>1.1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1.3</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>1440</td>\n",
       "      <td>True</td>\n",
       "      <td>266</td>\n",
       "      <td>1</td>\n",
       "      <td>1.2</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1.2</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Dart Goblin</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.8</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>261</td>\n",
       "      <td>False</td>\n",
       "      <td>156</td>\n",
       "      <td>1</td>\n",
       "      <td>6.5</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2.4</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Electro Dragon</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2.1</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>949</td>\n",
       "      <td>False</td>\n",
       "      <td>192</td>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1.2</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Electro Giant</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>3.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>2.1</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>3855</td>\n",
       "      <td>False</td>\n",
       "      <td>163</td>\n",
       "      <td>1</td>\n",
       "      <td>1.2</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.9</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Electro Spirit</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>230</td>\n",
       "      <td>False</td>\n",
       "      <td>99</td>\n",
       "      <td>9</td>\n",
       "      <td>2.5</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2.4</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Electro Wizard</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1.8</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>714</td>\n",
       "      <td>False</td>\n",
       "      <td>115</td>\n",
       "      <td>2</td>\n",
       "      <td>5.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1.8</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Elite Barbarians</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "      <td>1341</td>\n",
       "      <td>False</td>\n",
       "      <td>384</td>\n",
       "      <td>2</td>\n",
       "      <td>1.2</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1.8</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Elixir Golem</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1.1</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>1569</td>\n",
       "      <td>False</td>\n",
       "      <td>253</td>\n",
       "      <td>1</td>\n",
       "      <td>0.8</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.9</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Executioner</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2.4</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>1280</td>\n",
       "      <td>False</td>\n",
       "      <td>168</td>\n",
       "      <td>2</td>\n",
       "      <td>4.5</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1.2</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Fire Spirit</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>2.3</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>230</td>\n",
       "      <td>False</td>\n",
       "      <td>207</td>\n",
       "      <td>1</td>\n",
       "      <td>2.5</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>2.4</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Firecracker</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.4</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>304</td>\n",
       "      <td>False</td>\n",
       "      <td>64</td>\n",
       "      <td>5</td>\n",
       "      <td>6.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1.8</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Fisherman</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1.3</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>870</td>\n",
       "      <td>False</td>\n",
       "      <td>194</td>\n",
       "      <td>1</td>\n",
       "      <td>1.2</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1.2</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Flying Machine</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1.1</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>614</td>\n",
       "      <td>False</td>\n",
       "      <td>171</td>\n",
       "      <td>1</td>\n",
       "      <td>6.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1.8</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>Furnace</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1.8</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>896</td>\n",
       "      <td>False</td>\n",
       "      <td>135</td>\n",
       "      <td>1</td>\n",
       "      <td>6.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.9</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>Giant</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1.5</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>4090</td>\n",
       "      <td>False</td>\n",
       "      <td>253</td>\n",
       "      <td>1</td>\n",
       "      <td>1.2</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.9</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>Giant Skeleton</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>3617</td>\n",
       "      <td>False</td>\n",
       "      <td>276</td>\n",
       "      <td>1</td>\n",
       "      <td>0.8</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1.2</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>Goblin Demolisher</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1.2</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>1300</td>\n",
       "      <td>False</td>\n",
       "      <td>186</td>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1.2</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>Goblin Gang</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1.1</td>\n",
       "      <td>False</td>\n",
       "      <td>6</td>\n",
       "      <td>202</td>\n",
       "      <td>False</td>\n",
       "      <td>120</td>\n",
       "      <td>6</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2.4</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>Goblin Giant</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1.5</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>3233</td>\n",
       "      <td>False</td>\n",
       "      <td>176</td>\n",
       "      <td>3</td>\n",
       "      <td>1.2</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1.2</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>Goblin Machine</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>1.5</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1.2</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>2304</td>\n",
       "      <td>False</td>\n",
       "      <td>212</td>\n",
       "      <td>2</td>\n",
       "      <td>1.2</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1.2</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>Goblins</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.1</td>\n",
       "      <td>False</td>\n",
       "      <td>4</td>\n",
       "      <td>202</td>\n",
       "      <td>False</td>\n",
       "      <td>120</td>\n",
       "      <td>4</td>\n",
       "      <td>0.5</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>2.4</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>Goblinstein</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1.8</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "      <td>721</td>\n",
       "      <td>False</td>\n",
       "      <td>92</td>\n",
       "      <td>2</td>\n",
       "      <td>5.5</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1.2</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>Golden Knight</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>1799</td>\n",
       "      <td>False</td>\n",
       "      <td>161</td>\n",
       "      <td>1</td>\n",
       "      <td>1.2</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1.2</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>Golem</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>2.5</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>5120</td>\n",
       "      <td>False</td>\n",
       "      <td>312</td>\n",
       "      <td>1</td>\n",
       "      <td>0.75</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.9</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>Guards</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "      <td>337</td>\n",
       "      <td>True</td>\n",
       "      <td>117</td>\n",
       "      <td>3</td>\n",
       "      <td>1.6</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1.8</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>Heal Spirit</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>2.5</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>230</td>\n",
       "      <td>False</td>\n",
       "      <td>110</td>\n",
       "      <td>1</td>\n",
       "      <td>2.5</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2.4</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>Hog Rider</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1.6</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>1697</td>\n",
       "      <td>False</td>\n",
       "      <td>317</td>\n",
       "      <td>1</td>\n",
       "      <td>0.8</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2.4</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>Hunter</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.3</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2.2</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>885</td>\n",
       "      <td>False</td>\n",
       "      <td>84</td>\n",
       "      <td>10</td>\n",
       "      <td>4.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1.2</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>Ice Golem</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2.5</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>1315</td>\n",
       "      <td>False</td>\n",
       "      <td>84</td>\n",
       "      <td>1</td>\n",
       "      <td>0.75</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.9</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>Ice Spirit</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>1.5</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>230</td>\n",
       "      <td>False</td>\n",
       "      <td>110</td>\n",
       "      <td>1</td>\n",
       "      <td>2.5</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2.4</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>Ice Wizard</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1.7</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>688</td>\n",
       "      <td>False</td>\n",
       "      <td>89</td>\n",
       "      <td>1</td>\n",
       "      <td>5.5</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1.2</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>Inferno Dragon</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>1295</td>\n",
       "      <td>False</td>\n",
       "      <td>35</td>\n",
       "      <td>1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1.2</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>Knight</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1.2</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>1766</td>\n",
       "      <td>False</td>\n",
       "      <td>202</td>\n",
       "      <td>1</td>\n",
       "      <td>1.2</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1.2</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>Lava Hound</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>1.3</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>3581</td>\n",
       "      <td>False</td>\n",
       "      <td>53</td>\n",
       "      <td>1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.9</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>Little Prince</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1.2</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>698</td>\n",
       "      <td>False</td>\n",
       "      <td>99</td>\n",
       "      <td>1</td>\n",
       "      <td>5.5</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1.2</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>Lumberjack</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.8</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>1282</td>\n",
       "      <td>False</td>\n",
       "      <td>256</td>\n",
       "      <td>1</td>\n",
       "      <td>0.7</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2.4</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>Magic Archer</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.25</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1.1</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>529</td>\n",
       "      <td>False</td>\n",
       "      <td>133</td>\n",
       "      <td>1</td>\n",
       "      <td>7.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1.2</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>Mega Knight</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>1.3</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>1.7</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>3993</td>\n",
       "      <td>False</td>\n",
       "      <td>268</td>\n",
       "      <td>1</td>\n",
       "      <td>1.2</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1.2</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>Mega Minion</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1.5</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>837</td>\n",
       "      <td>False</td>\n",
       "      <td>311</td>\n",
       "      <td>1</td>\n",
       "      <td>1.6</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1.2</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>Mighty Miner</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>2250</td>\n",
       "      <td>False</td>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "      <td>1.6</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1.2</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>Miner</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1.3</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>1210</td>\n",
       "      <td>False</td>\n",
       "      <td>194</td>\n",
       "      <td>1</td>\n",
       "      <td>1.2</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1.8</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>Mini P.E.K.K.A</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1.6</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>1433</td>\n",
       "      <td>False</td>\n",
       "      <td>755</td>\n",
       "      <td>1</td>\n",
       "      <td>0.8</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1.8</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>Minion Horde</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1.1</td>\n",
       "      <td>False</td>\n",
       "      <td>6</td>\n",
       "      <td>230</td>\n",
       "      <td>False</td>\n",
       "      <td>117</td>\n",
       "      <td>6</td>\n",
       "      <td>2.5</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1.8</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>Minions</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1.1</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "      <td>230</td>\n",
       "      <td>False</td>\n",
       "      <td>117</td>\n",
       "      <td>3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1.8</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>Monk</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.8</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>2214</td>\n",
       "      <td>False</td>\n",
       "      <td>140</td>\n",
       "      <td>1</td>\n",
       "      <td>1.2</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1.2</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>Mother Witch</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>529</td>\n",
       "      <td>False</td>\n",
       "      <td>133</td>\n",
       "      <td>1</td>\n",
       "      <td>5.5</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1.2</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>Musketeer</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>721</td>\n",
       "      <td>False</td>\n",
       "      <td>217</td>\n",
       "      <td>1</td>\n",
       "      <td>6.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1.2</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>Night Witch</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1.3</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>906</td>\n",
       "      <td>False</td>\n",
       "      <td>314</td>\n",
       "      <td>1</td>\n",
       "      <td>1.6</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1.2</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>P.E.K.K.A</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>1.8</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>3760</td>\n",
       "      <td>False</td>\n",
       "      <td>816</td>\n",
       "      <td>1</td>\n",
       "      <td>1.2</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.9</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>Phoenix</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>1052</td>\n",
       "      <td>False</td>\n",
       "      <td>217</td>\n",
       "      <td>1</td>\n",
       "      <td>1.6</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1.2</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>Prince</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>1920</td>\n",
       "      <td>False</td>\n",
       "      <td>391</td>\n",
       "      <td>1</td>\n",
       "      <td>1.6</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1.2</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>Princess</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>2.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>261</td>\n",
       "      <td>False</td>\n",
       "      <td>168</td>\n",
       "      <td>1</td>\n",
       "      <td>9.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1.2</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>Ram Rider</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1.8</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>1697</td>\n",
       "      <td>False</td>\n",
       "      <td>250</td>\n",
       "      <td>2</td>\n",
       "      <td>0.8</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1.2</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>Rascals</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>False</td>\n",
       "      <td>161</td>\n",
       "      <td>3</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1.2</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Royal Ghost</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1.8</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>1210</td>\n",
       "      <td>False</td>\n",
       "      <td>261</td>\n",
       "      <td>1</td>\n",
       "      <td>1.2</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1.8</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Royal Giant</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1.7</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>3164</td>\n",
       "      <td>False</td>\n",
       "      <td>307</td>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.9</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Royal Hogs</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1.2</td>\n",
       "      <td>False</td>\n",
       "      <td>4</td>\n",
       "      <td>837</td>\n",
       "      <td>False</td>\n",
       "      <td>74</td>\n",
       "      <td>4</td>\n",
       "      <td>0.7</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2.4</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>Royal Recruits</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>1.3</td>\n",
       "      <td>False</td>\n",
       "      <td>6</td>\n",
       "      <td>787</td>\n",
       "      <td>True</td>\n",
       "      <td>133</td>\n",
       "      <td>6</td>\n",
       "      <td>1.6</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>1.2</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>Rune Giant</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1.5</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>2662</td>\n",
       "      <td>False</td>\n",
       "      <td>120</td>\n",
       "      <td>1</td>\n",
       "      <td>1.2</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1.2</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>Skeleton Army</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>15</td>\n",
       "      <td>81</td>\n",
       "      <td>False</td>\n",
       "      <td>81</td>\n",
       "      <td>15</td>\n",
       "      <td>0.5</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>Skeleton Barrel</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>2.0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>532</td>\n",
       "      <td>False</td>\n",
       "      <td>145</td>\n",
       "      <td>1</td>\n",
       "      <td>0.35</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1.8</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>Skeleton Dragons</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1.9</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "      <td>560</td>\n",
       "      <td>False</td>\n",
       "      <td>161</td>\n",
       "      <td>2</td>\n",
       "      <td>3.5</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1.8</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>Skeleton King</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>1.3</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1.6</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>2298</td>\n",
       "      <td>False</td>\n",
       "      <td>204</td>\n",
       "      <td>1</td>\n",
       "      <td>1.2</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1.2</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>Skeletons</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "      <td>81</td>\n",
       "      <td>False</td>\n",
       "      <td>81</td>\n",
       "      <td>3</td>\n",
       "      <td>0.5</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>1.8</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>Sparky</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>1.8</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>4.0</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>1451</td>\n",
       "      <td>False</td>\n",
       "      <td>1331</td>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.9</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>Spear Goblins</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.7</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "      <td>133</td>\n",
       "      <td>False</td>\n",
       "      <td>81</td>\n",
       "      <td>3</td>\n",
       "      <td>5.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>2.4</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>Spirit Empress (Melee)</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1.1</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>1075</td>\n",
       "      <td>False</td>\n",
       "      <td>307</td>\n",
       "      <td>1</td>\n",
       "      <td>1.2</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>Spirit Empress (Ranged)</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>1254</td>\n",
       "      <td>False</td>\n",
       "      <td>307</td>\n",
       "      <td>1</td>\n",
       "      <td>4.5</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1.2</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>Suspicious Bush</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>81</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1.2</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>Three Musketeers</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "      <td>721</td>\n",
       "      <td>False</td>\n",
       "      <td>217</td>\n",
       "      <td>3</td>\n",
       "      <td>6.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1.2</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>Valkyrie</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>2.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1.5</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>1907</td>\n",
       "      <td>False</td>\n",
       "      <td>266</td>\n",
       "      <td>1</td>\n",
       "      <td>1.2</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1.2</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>Wall Breakers</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>1.5</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "      <td>330</td>\n",
       "      <td>False</td>\n",
       "      <td>391</td>\n",
       "      <td>2</td>\n",
       "      <td>0.5</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2.4</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>Witch</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>1.5</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1.1</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>839</td>\n",
       "      <td>False</td>\n",
       "      <td>135</td>\n",
       "      <td>1</td>\n",
       "      <td>5.5</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1.2</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>Wizard</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>1.5</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>755</td>\n",
       "      <td>False</td>\n",
       "      <td>281</td>\n",
       "      <td>1</td>\n",
       "      <td>5.5</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1.2</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>Zappies</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2.1</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "      <td>529</td>\n",
       "      <td>False</td>\n",
       "      <td>117</td>\n",
       "      <td>3</td>\n",
       "      <td>4.5</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1.2</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>Bush Goblins</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "      <td>304</td>\n",
       "      <td>False</td>\n",
       "      <td>256</td>\n",
       "      <td>2</td>\n",
       "      <td>0.8</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>1.2</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>Cursed Hog</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>629</td>\n",
       "      <td>False</td>\n",
       "      <td>53</td>\n",
       "      <td>1</td>\n",
       "      <td>0.75</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>2.4</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>Elixir Blob</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.1</td>\n",
       "      <td>False</td>\n",
       "      <td>4</td>\n",
       "      <td>360</td>\n",
       "      <td>False</td>\n",
       "      <td>64</td>\n",
       "      <td>4</td>\n",
       "      <td>0.8</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>1.8</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>Elixir Golemite</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.1</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "      <td>762</td>\n",
       "      <td>False</td>\n",
       "      <td>128</td>\n",
       "      <td>2</td>\n",
       "      <td>0.8</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>1.2</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>Goblin Brawler</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.1</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>1080</td>\n",
       "      <td>False</td>\n",
       "      <td>337</td>\n",
       "      <td>1</td>\n",
       "      <td>0.8</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>1.8</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>Golemite</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "      <td>1039</td>\n",
       "      <td>False</td>\n",
       "      <td>84</td>\n",
       "      <td>2</td>\n",
       "      <td>0.25</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.9</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>Guardienne</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>1600</td>\n",
       "      <td>False</td>\n",
       "      <td>202</td>\n",
       "      <td>1</td>\n",
       "      <td>1.2</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>1.2</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>Lava Pup</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.7</td>\n",
       "      <td>False</td>\n",
       "      <td>6</td>\n",
       "      <td>217</td>\n",
       "      <td>False</td>\n",
       "      <td>81</td>\n",
       "      <td>6</td>\n",
       "      <td>1.6</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>1.2</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>Monster</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>2385</td>\n",
       "      <td>False</td>\n",
       "      <td>128</td>\n",
       "      <td>1</td>\n",
       "      <td>1.2</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1.2</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>Reborn Phoenix</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>842</td>\n",
       "      <td>False</td>\n",
       "      <td>174</td>\n",
       "      <td>1</td>\n",
       "      <td>1.6</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>1.2</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>Rascal Boy</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>1940</td>\n",
       "      <td>False</td>\n",
       "      <td>204</td>\n",
       "      <td>1</td>\n",
       "      <td>0.8</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1.2</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>Rascal Girl</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "      <td>261</td>\n",
       "      <td>False</td>\n",
       "      <td>125</td>\n",
       "      <td>2</td>\n",
       "      <td>5.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1.2</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        name  playable  aoe_bool  aoe_radius  \\\n",
       "0               Archer Queen      True     False         0.0   \n",
       "1                    Archers      True     False         0.0   \n",
       "3                Baby Dragon      True      True         1.2   \n",
       "4                    Balloon      True     False         0.0   \n",
       "5                     Bandit      True     False         0.0   \n",
       "8                 Barbarians      True     False         0.0   \n",
       "9                       Bats      True     False         0.0   \n",
       "10             Battle Healer      True      True         4.0   \n",
       "11                Battle Ram      True     False         0.0   \n",
       "12                 Berserker      True     False         0.0   \n",
       "14                    Bomber      True      True         1.5   \n",
       "15               Boss Bandit      True     False         0.0   \n",
       "16                    Bowler      True      True         0.0   \n",
       "18               Cannon Cart      True     False         0.0   \n",
       "23               Dark Prince      True      True         1.1   \n",
       "24               Dart Goblin      True     False         0.0   \n",
       "26            Electro Dragon      True     False         0.0   \n",
       "27             Electro Giant      True      True         3.0   \n",
       "28            Electro Spirit      True     False         0.0   \n",
       "29            Electro Wizard      True     False         0.0   \n",
       "30          Elite Barbarians      True     False         0.0   \n",
       "32              Elixir Golem      True     False         0.0   \n",
       "33               Executioner      True      True         1.0   \n",
       "34               Fire Spirit      True      True         2.3   \n",
       "36               Firecracker      True      True         0.4   \n",
       "37                 Fisherman      True     False         0.0   \n",
       "38            Flying Machine      True     False         0.0   \n",
       "40                   Furnace      True     False         0.0   \n",
       "41                     Giant      True     False         0.0   \n",
       "42            Giant Skeleton      True     False         0.0   \n",
       "47         Goblin Demolisher      True      True         1.0   \n",
       "49               Goblin Gang      True     False         0.0   \n",
       "50              Goblin Giant      True     False         0.0   \n",
       "52            Goblin Machine      True      True         1.5   \n",
       "53                   Goblins      True     False         0.0   \n",
       "54               Goblinstein      True     False         0.0   \n",
       "55             Golden Knight      True     False         0.0   \n",
       "56                     Golem      True     False         0.0   \n",
       "58                    Guards      True     False         0.0   \n",
       "59               Heal Spirit      True      True         2.5   \n",
       "60                 Hog Rider      True     False         0.0   \n",
       "61                    Hunter      True      True         0.3   \n",
       "62                 Ice Golem      True     False         0.0   \n",
       "63                Ice Spirit      True      True         1.5   \n",
       "64                Ice Wizard      True      True         1.0   \n",
       "65            Inferno Dragon      True     False         0.0   \n",
       "67                    Knight      True     False         0.0   \n",
       "68                Lava Hound      True     False         0.0   \n",
       "70             Little Prince      True     False         0.0   \n",
       "71                Lumberjack      True     False         0.0   \n",
       "72              Magic Archer      True      True        0.25   \n",
       "73               Mega Knight      True      True         1.3   \n",
       "74               Mega Minion      True     False         0.0   \n",
       "75              Mighty Miner      True     False         0.0   \n",
       "76                     Miner      True     False         0.0   \n",
       "77            Mini P.E.K.K.A      True     False         0.0   \n",
       "78              Minion Horde      True     False         0.0   \n",
       "79                   Minions      True     False         0.0   \n",
       "81                      Monk      True     False         0.0   \n",
       "83              Mother Witch      True     False         0.0   \n",
       "84                 Musketeer      True     False         0.0   \n",
       "85               Night Witch      True     False         0.0   \n",
       "86                 P.E.K.K.A      True     False         0.0   \n",
       "87                   Phoenix      True     False         0.0   \n",
       "89                    Prince      True     False         0.0   \n",
       "90                  Princess      True      True         2.0   \n",
       "92                 Ram Rider      True     False         0.0   \n",
       "93                   Rascals      True     False         0.0   \n",
       "97               Royal Ghost      True      True         1.0   \n",
       "98               Royal Giant      True     False         0.0   \n",
       "99                Royal Hogs      True     False         0.0   \n",
       "100           Royal Recruits      True     False         0.0   \n",
       "101               Rune Giant      True     False         0.0   \n",
       "102            Skeleton Army      True     False         0.0   \n",
       "103          Skeleton Barrel      True      True         2.0   \n",
       "104         Skeleton Dragons      True      True         1.0   \n",
       "105            Skeleton King      True      True         1.3   \n",
       "106                Skeletons      True     False         0.0   \n",
       "107                   Sparky      True      True         1.8   \n",
       "108            Spear Goblins      True     False         0.0   \n",
       "109   Spirit Empress (Melee)      True     False         0.0   \n",
       "110  Spirit Empress (Ranged)      True     False         0.0   \n",
       "111          Suspicious Bush      True     False         0.0   \n",
       "114         Three Musketeers      True     False         0.0   \n",
       "118                 Valkyrie      True      True         2.0   \n",
       "121            Wall Breakers      True      True         1.5   \n",
       "122                    Witch      True      True         1.5   \n",
       "123                   Wizard      True      True         1.5   \n",
       "126                  Zappies      True     False         0.0   \n",
       "127             Bush Goblins     False     False         0.0   \n",
       "128               Cursed Hog     False     False         0.0   \n",
       "129              Elixir Blob     False     False         0.0   \n",
       "130          Elixir Golemite     False     False         0.0   \n",
       "131           Goblin Brawler     False     False         0.0   \n",
       "132                 Golemite     False     False         0.0   \n",
       "133               Guardienne     False     False         0.0   \n",
       "134                 Lava Pup     False     False         0.0   \n",
       "135                  Monster     False     False         0.0   \n",
       "136           Reborn Phoenix     False     False         0.0   \n",
       "137               Rascal Boy     False     False         0.0   \n",
       "138              Rascal Girl     False     False         0.0   \n",
       "\n",
       "     death_damage_bool  fly_bool  spawn_bool  can_evolve  elixircost  \\\n",
       "0                False     False       False           0           5   \n",
       "1                False     False       False           1           3   \n",
       "3                False      True       False           1           4   \n",
       "4                 True      True       False           0           5   \n",
       "5                False     False       False           0           3   \n",
       "8                False     False       False           1           5   \n",
       "9                False      True       False           1           2   \n",
       "10               False     False       False           0           4   \n",
       "11               False     False        True           1           4   \n",
       "12               False     False       False           0           2   \n",
       "14               False     False       False           1           2   \n",
       "15               False     False       False           0           6   \n",
       "16               False     False       False           0           5   \n",
       "18               False     False       False           0           5   \n",
       "23               False     False       False           0           4   \n",
       "24               False     False       False           1           3   \n",
       "26               False      True       False           1           5   \n",
       "27               False     False       False           0           7   \n",
       "28               False     False       False           0           1   \n",
       "29               False     False        True           0           4   \n",
       "30               False     False       False           0           6   \n",
       "32               False     False        True           0           3   \n",
       "33               False     False       False           1           5   \n",
       "34               False     False       False           0           1   \n",
       "36               False     False       False           1           3   \n",
       "37               False     False       False           0           3   \n",
       "38               False      True       False           0           4   \n",
       "40               False     False        True           1           4   \n",
       "41               False     False       False           0           5   \n",
       "42                True     False       False           0           6   \n",
       "47                True     False       False           0           4   \n",
       "49               False     False        True           0           3   \n",
       "50               False     False        True           1           6   \n",
       "52               False     False       False           0           5   \n",
       "53               False     False       False           0           2   \n",
       "54               False     False       False           0           5   \n",
       "55               False     False       False           0           4   \n",
       "56                True     False        True           0           8   \n",
       "58               False     False       False           0           3   \n",
       "59               False     False       False           0           1   \n",
       "60               False     False       False           0           4   \n",
       "61               False     False       False           1           4   \n",
       "62                True     False       False           0           2   \n",
       "63               False     False       False           1           1   \n",
       "64               False     False        True           0           3   \n",
       "65               False      True       False           1           4   \n",
       "67               False     False       False           1           3   \n",
       "68               False      True        True           0           7   \n",
       "70               False     False        True           0           3   \n",
       "71                True     False        True           1           4   \n",
       "72               False     False       False           0           4   \n",
       "73               False     False       False           1           7   \n",
       "74               False      True       False           0           3   \n",
       "75               False     False       False           0           4   \n",
       "76               False     False       False           0           3   \n",
       "77               False     False       False           0           4   \n",
       "78               False      True       False           0           5   \n",
       "79               False      True       False           0           3   \n",
       "81               False     False       False           0           5   \n",
       "83               False     False        True           0           4   \n",
       "84               False     False       False           1           4   \n",
       "85               False     False        True           0           4   \n",
       "86               False     False       False           1           7   \n",
       "87                True      True        True           0           4   \n",
       "89               False     False       False           0           5   \n",
       "90               False     False       False           0           3   \n",
       "92               False     False       False           0           5   \n",
       "93               False     False        True           0           5   \n",
       "97               False     False       False           0           3   \n",
       "98               False     False       False           1           6   \n",
       "99               False     False       False           0           5   \n",
       "100              False     False       False           1           7   \n",
       "101              False     False       False           0           4   \n",
       "102              False     False       False           0           3   \n",
       "103               True      True        True           1           3   \n",
       "104              False      True       False           0           4   \n",
       "105              False     False        True           0           4   \n",
       "106              False     False       False           1           1   \n",
       "107              False     False       False           0           6   \n",
       "108              False     False       False           0           2   \n",
       "109              False     False       False           0           3   \n",
       "110              False      True       False           0           6   \n",
       "111              False     False       False           0           2   \n",
       "114              False     False       False           0           9   \n",
       "118              False     False       False           1           4   \n",
       "121              False     False       False           1           2   \n",
       "122              False     False        True           1           5   \n",
       "123              False     False       False           1           5   \n",
       "126              False     False       False           0           4   \n",
       "127              False     False       False           0           0   \n",
       "128              False     False       False           0           0   \n",
       "129              False     False       False           0           0   \n",
       "130              False     False        True           0           0   \n",
       "131              False     False       False           0           0   \n",
       "132               True     False       False           0           0   \n",
       "133              False     False       False           0           0   \n",
       "134              False      True       False           0           0   \n",
       "135              False     False       False           0           0   \n",
       "136              False      True       False           0           0   \n",
       "137              False     False       False           0           0   \n",
       "138              False     False       False           0           0   \n",
       "\n",
       "     hit_speed  special_damage  count  hitpoints  shield_bool  damage  \\\n",
       "0          1.2           False      1       1000        False     225   \n",
       "1          0.9           False      2        304        False     112   \n",
       "3          1.5           False      1       1152        False     161   \n",
       "4          2.0           False      1       1679        False     640   \n",
       "5          1.0            True      1        906        False     194   \n",
       "8          1.3           False      5        670        False     192   \n",
       "9          1.3           False      5         81        False      81   \n",
       "10         1.5           False      1       1717        False     148   \n",
       "11        <NA>            True      1        967        False     286   \n",
       "12         0.5           False      1        896        False     102   \n",
       "14         1.8           False      1        332        False     225   \n",
       "15         1.2            True      1       2624        False     268   \n",
       "16         2.5            True      1       2081        False     289   \n",
       "18         0.9           False      1       1809        False     212   \n",
       "23         1.3            True      1       1440         True     266   \n",
       "24         0.8           False      1        261        False     156   \n",
       "26         2.1            True      1        949        False     192   \n",
       "27         2.1            True      1       3855        False     163   \n",
       "28        <NA>            True      1        230        False      99   \n",
       "29         1.8            True      1        714        False     115   \n",
       "30         1.4           False      2       1341        False     384   \n",
       "32         1.1           False      1       1569        False     253   \n",
       "33         2.4            True      1       1280        False     168   \n",
       "34        <NA>           False      1        230        False     207   \n",
       "36         3.0            True      1        304        False      64   \n",
       "37         1.3            True      1        870        False     194   \n",
       "38         1.1           False      1        614        False     171   \n",
       "40         1.8           False      1        896        False     135   \n",
       "41         1.5           False      1       4090        False     253   \n",
       "42         1.4            True      1       3617        False     276   \n",
       "47         1.2            True      1       1300        False     186   \n",
       "49         1.1           False      6        202        False     120   \n",
       "50         1.5           False      1       3233        False     176   \n",
       "52         1.2           False      1       2304        False     212   \n",
       "53         1.1           False      4        202        False     120   \n",
       "54         1.8            True      2        721        False      92   \n",
       "55         0.9            True      1       1799        False     161   \n",
       "56         2.5           False      1       5120        False     312   \n",
       "58         1.0           False      3        337         True     117   \n",
       "59        <NA>           False      1        230        False     110   \n",
       "60         1.6           False      1       1697        False     317   \n",
       "61         2.2            True      1        885        False      84   \n",
       "62         2.5            True      1       1315        False      84   \n",
       "63        <NA>            True      1        230        False     110   \n",
       "64         1.7            True      1        688        False      89   \n",
       "65         0.4            True      1       1295        False      35   \n",
       "67         1.2           False      1       1766        False     202   \n",
       "68         1.3           False      1       3581        False      53   \n",
       "70         1.2            True      1        698        False      99   \n",
       "71         0.8           False      1       1282        False     256   \n",
       "72         1.1            True      1        529        False     133   \n",
       "73         1.7            True      1       3993        False     268   \n",
       "74         1.5           False      1        837        False     311   \n",
       "75         0.4            True      1       2250        False      40   \n",
       "76         1.3           False      1       1210        False     194   \n",
       "77         1.6           False      1       1433        False     755   \n",
       "78         1.1           False      6        230        False     117   \n",
       "79         1.1           False      3        230        False     117   \n",
       "81         0.8            True      1       2214        False     140   \n",
       "83         1.0            True      1        529        False     133   \n",
       "84         1.0           False      1        721        False     217   \n",
       "85         1.3           False      1        906        False     314   \n",
       "86         1.8           False      1       3760        False     816   \n",
       "87         1.0            True      1       1052        False     217   \n",
       "89         1.4            True      1       1920        False     391   \n",
       "90         3.0           False      1        261        False     168   \n",
       "92         1.8            True      1       1697        False     250   \n",
       "93        <NA>           False      3       <NA>        False     161   \n",
       "97         1.8           False      1       1210        False     261   \n",
       "98         1.7           False      1       3164        False     307   \n",
       "99         1.2           False      4        837        False      74   \n",
       "100        1.3           False      6        787         True     133   \n",
       "101        1.5           False      1       2662        False     120   \n",
       "102        1.0           False     15         81        False      81   \n",
       "103       <NA>           False      1        532        False     145   \n",
       "104        1.9           False      2        560        False     161   \n",
       "105        1.6           False      1       2298        False     204   \n",
       "106        1.0           False      3         81        False      81   \n",
       "107        4.0           False      1       1451        False    1331   \n",
       "108        1.7           False      3        133        False      81   \n",
       "109        1.1           False      1       1075        False     307   \n",
       "110        1.4           False      1       1254        False     307   \n",
       "111       <NA>           False      1         81        False       0   \n",
       "114        1.0           False      3        721        False     217   \n",
       "118        1.5           False      1       1907        False     266   \n",
       "121       <NA>           False      2        330        False     391   \n",
       "122        1.1           False      1        839        False     135   \n",
       "123        1.4           False      1        755        False     281   \n",
       "126        2.1            True      3        529        False     117   \n",
       "127        1.4           False      2        304        False     256   \n",
       "128        1.2           False      1        629        False      53   \n",
       "129        1.1           False      4        360        False      64   \n",
       "130        1.1           False      2        762        False     128   \n",
       "131        1.1           False      1       1080        False     337   \n",
       "132        2.5           False      2       1039        False      84   \n",
       "133        1.2           False      1       1600        False     202   \n",
       "134        1.7           False      6        217        False      81   \n",
       "135        1.5           False      1       2385        False     128   \n",
       "136        1.0           False      1        842        False     174   \n",
       "137        1.5           False      1       1940        False     204   \n",
       "138        1.0           False      2        261        False     125   \n",
       "\n",
       "     attack_count  range  affected_crown  has_lifetime  invisible  \\\n",
       "0               1    5.0           False         False       True   \n",
       "1               2    5.0           False         False      False   \n",
       "3               1    3.5           False         False      False   \n",
       "4               1    0.1           False         False      False   \n",
       "5               1   0.75           False         False       True   \n",
       "8               5    0.7           False         False      False   \n",
       "9               5    1.2           False         False      False   \n",
       "10              1    1.6           False         False      False   \n",
       "11              1    0.5           False         False      False   \n",
       "12              1    0.8           False         False      False   \n",
       "14              1    4.5           False         False      False   \n",
       "15              1    0.8           False         False       True   \n",
       "16              1    4.0           False         False      False   \n",
       "18              1    5.5           False         False      False   \n",
       "23              1    1.2           False         False      False   \n",
       "24              1    6.5           False         False      False   \n",
       "26              3    3.5           False         False      False   \n",
       "27              1    1.2            True         False      False   \n",
       "28              9    2.5           False         False      False   \n",
       "29              2    5.0           False         False      False   \n",
       "30              2    1.2           False         False      False   \n",
       "32              1    0.8           False         False      False   \n",
       "33              2    4.5           False         False      False   \n",
       "34              1    2.5           False         False      False   \n",
       "36              5    6.0           False         False      False   \n",
       "37              1    1.2           False         False      False   \n",
       "38              1    6.0           False         False      False   \n",
       "40              1    6.0           False         False      False   \n",
       "41              1    1.2           False         False      False   \n",
       "42              1    0.8            True         False      False   \n",
       "47              1    5.0           False          True      False   \n",
       "49              6   <NA>           False         False      False   \n",
       "50              3    1.2           False         False      False   \n",
       "52              2    1.2            True         False      False   \n",
       "53              4    0.5           False         False      False   \n",
       "54              2    5.5            True         False      False   \n",
       "55              1    1.2           False         False      False   \n",
       "56              1   0.75           False         False      False   \n",
       "58              3    1.6           False         False      False   \n",
       "59              1    2.5           False         False      False   \n",
       "60              1    0.8           False         False      False   \n",
       "61             10    4.0           False         False      False   \n",
       "62              1   0.75           False         False      False   \n",
       "63              1    2.5           False         False      False   \n",
       "64              1    5.5           False         False      False   \n",
       "65              1    3.5           False         False      False   \n",
       "67              1    1.2           False         False      False   \n",
       "68              1    3.5           False         False      False   \n",
       "70              1    5.5           False         False      False   \n",
       "71              1    0.7           False         False      False   \n",
       "72              1    7.0           False         False      False   \n",
       "73              1    1.2           False         False      False   \n",
       "74              1    1.6           False         False      False   \n",
       "75              1    1.6           False         False      False   \n",
       "76              1    1.2            True         False      False   \n",
       "77              1    0.8           False         False      False   \n",
       "78              6    2.5           False         False      False   \n",
       "79              3    2.5           False         False      False   \n",
       "81              1    1.2           False         False      False   \n",
       "83              1    5.5           False         False      False   \n",
       "84              1    6.0           False         False      False   \n",
       "85              1    1.6           False         False      False   \n",
       "86              1    1.2           False         False      False   \n",
       "87              1    1.6           False         False      False   \n",
       "89              1    1.6           False         False      False   \n",
       "90              1    9.0           False         False      False   \n",
       "92              2    0.8           False         False      False   \n",
       "93              3   <NA>           False         False      False   \n",
       "97              1    1.2           False         False       True   \n",
       "98              1    5.0           False         False      False   \n",
       "99              4    0.7           False         False      False   \n",
       "100             6    1.6           False         False      False   \n",
       "101             1    1.2           False         False      False   \n",
       "102            15    0.5           False         False      False   \n",
       "103             1   0.35           False         False      False   \n",
       "104             2    3.5           False         False      False   \n",
       "105             1    1.2           False         False      False   \n",
       "106             3    0.5           False         False      False   \n",
       "107             1    5.0           False         False      False   \n",
       "108             3    5.0           False         False      False   \n",
       "109             1    1.2           False         False      False   \n",
       "110             1    4.5           False         False      False   \n",
       "111             0    0.8           False         False       True   \n",
       "114             3    6.0           False         False      False   \n",
       "118             1    1.2           False         False      False   \n",
       "121             2    0.5           False         False      False   \n",
       "122             1    5.5           False         False      False   \n",
       "123             1    5.5           False         False      False   \n",
       "126             3    4.5           False         False      False   \n",
       "127             2    0.8           False         False      False   \n",
       "128             1   0.75           False         False      False   \n",
       "129             4    0.8           False         False      False   \n",
       "130             2    0.8           False         False      False   \n",
       "131             1    0.8           False         False      False   \n",
       "132             2   0.25           False         False      False   \n",
       "133             1    1.2           False         False      False   \n",
       "134             6    1.6           False         False      False   \n",
       "135             1    1.2           False         False      False   \n",
       "136             1    1.6           False         False      False   \n",
       "137             1    0.8           False         False      False   \n",
       "138             2    5.0           False         False      False   \n",
       "\n",
       "     has_ability  any_target  building_target  ground_target  \\\n",
       "0           True        True            False          False   \n",
       "1          False        True            False          False   \n",
       "3          False        True            False          False   \n",
       "4          False       False             True          False   \n",
       "5          False       False             True           True   \n",
       "8          False       False             True           True   \n",
       "9          False        True            False          False   \n",
       "10         False       False             True           True   \n",
       "11         False       False             True          False   \n",
       "12         False       False             True           True   \n",
       "14         False       False             True           True   \n",
       "15          True       False             True           True   \n",
       "16         False       False             True           True   \n",
       "18         False       False             True           True   \n",
       "23         False       False             True           True   \n",
       "24         False        True            False          False   \n",
       "26         False        True            False          False   \n",
       "27         False       False             True          False   \n",
       "28         False        True            False          False   \n",
       "29         False        True            False          False   \n",
       "30         False       False             True           True   \n",
       "32         False       False             True          False   \n",
       "33         False        True            False          False   \n",
       "34         False        True            False          False   \n",
       "36         False        True            False          False   \n",
       "37         False       False             True           True   \n",
       "38         False        True            False          False   \n",
       "40         False        True            False          False   \n",
       "41         False       False             True          False   \n",
       "42         False       False             True           True   \n",
       "47         False       False             True           True   \n",
       "49         False       False             True           True   \n",
       "50         False       False             True          False   \n",
       "52         False       False             True           True   \n",
       "53         False       False             True           True   \n",
       "54          True        True            False          False   \n",
       "55          True       False             True           True   \n",
       "56         False       False             True          False   \n",
       "58         False       False             True           True   \n",
       "59         False        True            False          False   \n",
       "60         False       False             True          False   \n",
       "61         False        True            False          False   \n",
       "62         False       False             True          False   \n",
       "63         False        True            False          False   \n",
       "64         False        True            False          False   \n",
       "65         False        True            False          False   \n",
       "67         False       False             True           True   \n",
       "68         False       False             True          False   \n",
       "70          True        True            False          False   \n",
       "71         False       False             True           True   \n",
       "72         False        True            False          False   \n",
       "73         False       False             True           True   \n",
       "74         False        True            False          False   \n",
       "75          True       False             True           True   \n",
       "76         False       False             True           True   \n",
       "77         False       False             True           True   \n",
       "78         False        True            False          False   \n",
       "79         False        True            False          False   \n",
       "81          True       False             True           True   \n",
       "83         False        True            False          False   \n",
       "84         False        True            False          False   \n",
       "85         False       False             True           True   \n",
       "86         False       False             True           True   \n",
       "87         False        True            False          False   \n",
       "89         False       False             True           True   \n",
       "90         False        True            False          False   \n",
       "92         False       False             True          False   \n",
       "93         False       False             True           True   \n",
       "97         False       False             True           True   \n",
       "98         False       False             True          False   \n",
       "99         False       False             True          False   \n",
       "100        False       False             True           True   \n",
       "101        False       False             True          False   \n",
       "102        False       False             True           True   \n",
       "103        False       False             True          False   \n",
       "104        False        True            False          False   \n",
       "105         True       False             True           True   \n",
       "106        False       False             True           True   \n",
       "107        False       False             True           True   \n",
       "108        False        True            False          False   \n",
       "109        False       False             True           True   \n",
       "110        False        True            False          False   \n",
       "111        False       False             True          False   \n",
       "114        False        True            False          False   \n",
       "118        False       False             True           True   \n",
       "121        False       False             True          False   \n",
       "122        False        True            False          False   \n",
       "123        False        True            False          False   \n",
       "126        False        True            False          False   \n",
       "127        False       False             True           True   \n",
       "128        False       False             True          False   \n",
       "129        False       False             True          False   \n",
       "130        False       False             True          False   \n",
       "131        False       False             True           True   \n",
       "132        False       False             True          False   \n",
       "133        False       False             True           True   \n",
       "134        False        True            False          False   \n",
       "135        False       False             True          False   \n",
       "136        False        True            False          False   \n",
       "137        False       False             True           True   \n",
       "138        False        True            False          False   \n",
       "\n",
       "     has_upon_breaking_spawn  has_upon_death_spawn  has_periodic_spawn  \\\n",
       "0                      False                 False               False   \n",
       "1                      False                 False               False   \n",
       "3                      False                 False               False   \n",
       "4                      False                 False               False   \n",
       "5                      False                 False               False   \n",
       "8                      False                 False               False   \n",
       "9                      False                 False               False   \n",
       "10                     False                 False               False   \n",
       "11                      True                  True               False   \n",
       "12                     False                 False               False   \n",
       "14                     False                 False               False   \n",
       "15                     False                 False               False   \n",
       "16                     False                 False               False   \n",
       "18                     False                 False               False   \n",
       "23                     False                 False               False   \n",
       "24                     False                 False               False   \n",
       "26                     False                 False               False   \n",
       "27                     False                 False               False   \n",
       "28                     False                 False               False   \n",
       "29                     False                 False               False   \n",
       "30                     False                 False               False   \n",
       "32                     False                  True               False   \n",
       "33                     False                 False               False   \n",
       "34                     False                 False               False   \n",
       "36                     False                 False               False   \n",
       "37                     False                 False               False   \n",
       "38                     False                 False               False   \n",
       "40                     False                 False                True   \n",
       "41                     False                 False               False   \n",
       "42                     False                 False               False   \n",
       "47                     False                 False               False   \n",
       "49                     False                 False               False   \n",
       "50                     False                  True               False   \n",
       "52                     False                 False               False   \n",
       "53                     False                 False               False   \n",
       "54                     False                 False               False   \n",
       "55                     False                 False               False   \n",
       "56                     False                  True               False   \n",
       "58                     False                 False               False   \n",
       "59                     False                 False               False   \n",
       "60                     False                 False               False   \n",
       "61                     False                 False               False   \n",
       "62                     False                 False               False   \n",
       "63                     False                 False               False   \n",
       "64                     False                 False               False   \n",
       "65                     False                 False               False   \n",
       "67                     False                 False               False   \n",
       "68                     False                  True               False   \n",
       "70                     False                 False               False   \n",
       "71                     False                  True               False   \n",
       "72                     False                 False               False   \n",
       "73                     False                 False               False   \n",
       "74                     False                 False               False   \n",
       "75                     False                 False               False   \n",
       "76                     False                 False               False   \n",
       "77                     False                 False               False   \n",
       "78                     False                 False               False   \n",
       "79                     False                 False               False   \n",
       "81                     False                 False               False   \n",
       "83                     False                 False               False   \n",
       "84                     False                 False               False   \n",
       "85                     False                  True                True   \n",
       "86                     False                 False               False   \n",
       "87                     False                  True               False   \n",
       "89                     False                 False               False   \n",
       "90                     False                 False               False   \n",
       "92                     False                 False               False   \n",
       "93                     False                 False               False   \n",
       "97                     False                 False               False   \n",
       "98                     False                 False               False   \n",
       "99                     False                 False               False   \n",
       "100                    False                 False               False   \n",
       "101                    False                 False               False   \n",
       "102                    False                 False               False   \n",
       "103                    False                  True               False   \n",
       "104                    False                 False               False   \n",
       "105                    False                 False               False   \n",
       "106                    False                 False               False   \n",
       "107                    False                 False               False   \n",
       "108                    False                 False               False   \n",
       "109                    False                 False               False   \n",
       "110                    False                 False               False   \n",
       "111                     True                  True               False   \n",
       "114                    False                 False               False   \n",
       "118                    False                 False               False   \n",
       "121                    False                 False               False   \n",
       "122                    False                 False                True   \n",
       "123                    False                 False               False   \n",
       "126                    False                 False               False   \n",
       "127                    False                 False               False   \n",
       "128                    False                 False               False   \n",
       "129                    False                 False               False   \n",
       "130                    False                  True               False   \n",
       "131                    False                 False               False   \n",
       "132                    False                 False               False   \n",
       "133                    False                 False               False   \n",
       "134                    False                 False               False   \n",
       "135                    False                 False               False   \n",
       "136                    False                 False               False   \n",
       "137                    False                 False               False   \n",
       "138                    False                 False               False   \n",
       "\n",
       "     single_damage_type  is_troop  is_spell  is_building  is_tower_troop  \\\n",
       "0                  True      True     False        False           False   \n",
       "1                  True      True     False        False           False   \n",
       "3                  True      True     False        False           False   \n",
       "4                  True      True     False        False           False   \n",
       "5                  True      True     False        False           False   \n",
       "8                  True      True     False        False           False   \n",
       "9                  True      True     False        False           False   \n",
       "10                 True      True     False        False           False   \n",
       "11                 True      True     False        False           False   \n",
       "12                 True      True     False        False           False   \n",
       "14                 True      True     False        False           False   \n",
       "15                 True      True     False        False           False   \n",
       "16                 True      True     False        False           False   \n",
       "18                 True      True     False        False           False   \n",
       "23                 True      True     False        False           False   \n",
       "24                 True      True     False        False           False   \n",
       "26                False      True     False        False           False   \n",
       "27                 True      True     False        False           False   \n",
       "28                False      True     False        False           False   \n",
       "29                False      True     False        False           False   \n",
       "30                 True      True     False        False           False   \n",
       "32                 True      True     False        False           False   \n",
       "33                False      True     False        False           False   \n",
       "34                 True      True     False        False           False   \n",
       "36                False      True     False        False           False   \n",
       "37                 True      True     False        False           False   \n",
       "38                 True      True     False        False           False   \n",
       "40                 True      True     False        False           False   \n",
       "41                 True      True     False        False           False   \n",
       "42                 True      True     False        False           False   \n",
       "47                 True      True     False        False           False   \n",
       "49                False      True     False        False           False   \n",
       "50                False      True     False        False           False   \n",
       "52                False      True     False        False           False   \n",
       "53                 True      True     False        False           False   \n",
       "54                 True      True     False        False           False   \n",
       "55                 True      True     False        False           False   \n",
       "56                 True      True     False        False           False   \n",
       "58                 True      True     False        False           False   \n",
       "59                 True      True     False        False           False   \n",
       "60                 True      True     False        False           False   \n",
       "61                False      True     False        False           False   \n",
       "62                 True      True     False        False           False   \n",
       "63                 True      True     False        False           False   \n",
       "64                 True      True     False        False           False   \n",
       "65                False      True     False        False           False   \n",
       "67                 True      True     False        False           False   \n",
       "68                 True      True     False        False           False   \n",
       "70                 True      True     False        False           False   \n",
       "71                 True      True     False        False           False   \n",
       "72                 True      True     False        False           False   \n",
       "73                 True      True     False        False           False   \n",
       "74                 True      True     False        False           False   \n",
       "75                False      True     False        False           False   \n",
       "76                 True      True     False        False           False   \n",
       "77                 True      True     False        False           False   \n",
       "78                 True      True     False        False           False   \n",
       "79                 True      True     False        False           False   \n",
       "81                False      True     False        False           False   \n",
       "83                 True      True     False        False           False   \n",
       "84                 True      True     False        False           False   \n",
       "85                 True      True     False        False           False   \n",
       "86                 True      True     False        False           False   \n",
       "87                 True      True     False        False           False   \n",
       "89                 True      True     False        False           False   \n",
       "90                 True      True     False        False           False   \n",
       "92                False      True     False        False           False   \n",
       "93                False      True     False        False           False   \n",
       "97                 True      True     False        False           False   \n",
       "98                 True      True     False        False           False   \n",
       "99                 True      True     False        False           False   \n",
       "100                True      True     False        False           False   \n",
       "101                True      True     False        False           False   \n",
       "102                True      True     False        False           False   \n",
       "103                True      True     False        False           False   \n",
       "104                True      True     False        False           False   \n",
       "105                True      True     False        False           False   \n",
       "106                True      True     False        False           False   \n",
       "107                True      True     False        False           False   \n",
       "108                True      True     False        False           False   \n",
       "109                True      True     False        False           False   \n",
       "110               False      True     False        False           False   \n",
       "111               False      True     False        False           False   \n",
       "114                True      True     False        False           False   \n",
       "118                True      True     False        False           False   \n",
       "121                True      True     False        False           False   \n",
       "122                True      True     False        False           False   \n",
       "123                True      True     False        False           False   \n",
       "126                True      True     False        False           False   \n",
       "127                True      True     False        False           False   \n",
       "128                True      True     False        False           False   \n",
       "129                True      True     False        False           False   \n",
       "130                True      True     False        False           False   \n",
       "131                True      True     False        False           False   \n",
       "132                True      True     False        False           False   \n",
       "133                True      True     False        False           False   \n",
       "134                True      True     False        False           False   \n",
       "135                True      True     False        False           False   \n",
       "136                True      True     False        False           False   \n",
       "137                True      True     False        False           False   \n",
       "138                True      True     False        False           False   \n",
       "\n",
       "     is_spawned  speed  has_ranged_attack  special_attack_type  \\\n",
       "0         False    1.2               True                False   \n",
       "1         False    1.2               True                False   \n",
       "3         False    1.8               True                False   \n",
       "4         False    1.2              False                False   \n",
       "5         False    1.8              False                False   \n",
       "8          True    1.2              False                False   \n",
       "9          True    2.4              False                False   \n",
       "10        False    1.2              False                False   \n",
       "11        False    1.2              False                False   \n",
       "12        False    1.8              False                False   \n",
       "14        False    1.2               True                False   \n",
       "15        False    1.8              False                False   \n",
       "16        False    0.9               True                False   \n",
       "18        False    1.2               True                False   \n",
       "23        False    1.2              False                False   \n",
       "24        False    2.4               True                False   \n",
       "26        False    1.2               True                 True   \n",
       "27        False    0.9              False                False   \n",
       "28        False    2.4               True                 True   \n",
       "29        False    1.8               True                 True   \n",
       "30        False    1.8              False                False   \n",
       "32        False    0.9              False                False   \n",
       "33        False    1.2               True                 True   \n",
       "34         True    2.4               True                False   \n",
       "36        False    1.8               True                 True   \n",
       "37        False    1.2              False                False   \n",
       "38        False    1.8               True                False   \n",
       "40        False    0.9               True                False   \n",
       "41        False    0.9              False                False   \n",
       "42        False    1.2              False                False   \n",
       "47        False    1.2               True                False   \n",
       "49        False    2.4               True                 True   \n",
       "50        False    1.2               True                 True   \n",
       "52        False    1.2               True                 True   \n",
       "53         True    2.4              False                False   \n",
       "54        False    1.2               True                False   \n",
       "55        False    1.2              False                False   \n",
       "56        False    0.9              False                False   \n",
       "58        False    1.8              False                False   \n",
       "59        False    2.4               True                False   \n",
       "60        False    2.4              False                False   \n",
       "61        False    1.2               True                 True   \n",
       "62        False    0.9              False                False   \n",
       "63        False    2.4               True                False   \n",
       "64        False    1.2               True                False   \n",
       "65        False    1.2               True                 True   \n",
       "67        False    1.2              False                False   \n",
       "68        False    0.9               True                False   \n",
       "70        False    1.2               True                False   \n",
       "71        False    2.4              False                False   \n",
       "72        False    1.2               True                False   \n",
       "73        False    1.2              False                False   \n",
       "74        False    1.2               True                False   \n",
       "75        False    1.2              False                 True   \n",
       "76        False    1.8              False                False   \n",
       "77        False    1.8              False                False   \n",
       "78        False    1.8               True                False   \n",
       "79        False    1.8               True                False   \n",
       "81        False    1.2              False                 True   \n",
       "83        False    1.2               True                False   \n",
       "84        False    1.2               True                False   \n",
       "85        False    1.2              False                False   \n",
       "86        False    0.9              False                False   \n",
       "87        False    1.2              False                False   \n",
       "89        False    1.2              False                False   \n",
       "90        False    1.2               True                False   \n",
       "92        False    1.2               True                 True   \n",
       "93        False    1.2               True                 True   \n",
       "97        False    1.8              False                False   \n",
       "98        False    0.9               True                False   \n",
       "99        False    2.4              False                False   \n",
       "100        True    1.2              False                False   \n",
       "101       False    1.2              False                False   \n",
       "102       False   <NA>              False                False   \n",
       "103       False    1.8              False                False   \n",
       "104       False    1.8               True                False   \n",
       "105       False    1.2              False                False   \n",
       "106        True    1.8              False                False   \n",
       "107       False    0.9               True                False   \n",
       "108        True    2.4               True                False   \n",
       "109       False   <NA>              False                False   \n",
       "110       False    1.2               True                False   \n",
       "111       False    1.2              False                False   \n",
       "114       False    1.2               True                False   \n",
       "118       False    1.2              False                False   \n",
       "121       False    2.4              False                False   \n",
       "122       False    1.2               True                False   \n",
       "123       False    1.2               True                False   \n",
       "126       False    1.2               True                False   \n",
       "127        True    1.2              False                False   \n",
       "128        True    2.4              False                False   \n",
       "129        True    1.8              False                False   \n",
       "130        True    1.2              False                False   \n",
       "131        True    1.8              False                False   \n",
       "132        True    0.9              False                False   \n",
       "133        True    1.2              False                False   \n",
       "134        True    1.2              False                False   \n",
       "135       False    1.2              False                False   \n",
       "136        True    1.2              False                False   \n",
       "137       False    1.2              False                False   \n",
       "138       False    1.2               True                False   \n",
       "\n",
       "     has_friendly_buff  is_free_card  no_hit_speed  no_attack  no_hitpoints  \n",
       "0                False         False         False      False         False  \n",
       "1                False         False         False      False         False  \n",
       "3                False         False         False      False         False  \n",
       "4                False         False         False      False         False  \n",
       "5                False         False         False      False         False  \n",
       "8                False         False         False      False         False  \n",
       "9                False         False         False      False         False  \n",
       "10                True         False         False      False         False  \n",
       "11               False         False          True      False         False  \n",
       "12               False         False         False      False         False  \n",
       "14               False         False         False      False         False  \n",
       "15               False         False         False      False         False  \n",
       "16               False         False         False      False         False  \n",
       "18               False         False         False      False         False  \n",
       "23               False         False         False      False         False  \n",
       "24               False         False         False      False         False  \n",
       "26               False         False         False      False         False  \n",
       "27               False         False         False      False         False  \n",
       "28               False         False          True      False         False  \n",
       "29               False         False         False      False         False  \n",
       "30               False         False         False      False         False  \n",
       "32               False         False         False      False         False  \n",
       "33               False         False         False      False         False  \n",
       "34               False         False          True      False         False  \n",
       "36               False         False         False      False         False  \n",
       "37               False         False         False      False         False  \n",
       "38               False         False         False      False         False  \n",
       "40               False         False         False      False         False  \n",
       "41               False         False         False      False         False  \n",
       "42               False         False         False      False         False  \n",
       "47               False         False         False      False         False  \n",
       "49               False         False         False      False         False  \n",
       "50               False         False         False      False         False  \n",
       "52               False         False         False      False         False  \n",
       "53               False         False         False      False         False  \n",
       "54               False         False         False      False         False  \n",
       "55               False         False         False      False         False  \n",
       "56               False         False         False      False         False  \n",
       "58               False         False         False      False         False  \n",
       "59                True         False          True      False         False  \n",
       "60               False         False         False      False         False  \n",
       "61               False         False         False      False         False  \n",
       "62               False         False         False      False         False  \n",
       "63               False         False          True      False         False  \n",
       "64               False         False         False      False         False  \n",
       "65               False         False         False      False         False  \n",
       "67               False         False         False      False         False  \n",
       "68               False         False         False      False         False  \n",
       "70               False         False         False      False         False  \n",
       "71                True         False         False      False         False  \n",
       "72               False         False         False      False         False  \n",
       "73               False         False         False      False         False  \n",
       "74               False         False         False      False         False  \n",
       "75               False         False         False      False         False  \n",
       "76               False         False         False      False         False  \n",
       "77               False         False         False      False         False  \n",
       "78               False         False         False      False         False  \n",
       "79               False         False         False      False         False  \n",
       "81               False         False         False      False         False  \n",
       "83               False         False         False      False         False  \n",
       "84               False         False         False      False         False  \n",
       "85               False         False         False      False         False  \n",
       "86               False         False         False      False         False  \n",
       "87               False         False         False      False         False  \n",
       "89               False         False         False      False         False  \n",
       "90               False         False         False      False         False  \n",
       "92               False         False         False      False         False  \n",
       "93               False         False          True      False          True  \n",
       "97               False         False         False      False         False  \n",
       "98               False         False         False      False         False  \n",
       "99               False         False         False      False         False  \n",
       "100              False         False         False      False         False  \n",
       "101               True         False         False      False         False  \n",
       "102              False         False         False      False         False  \n",
       "103              False         False          True      False         False  \n",
       "104              False         False         False      False         False  \n",
       "105               True         False         False      False         False  \n",
       "106              False         False         False      False         False  \n",
       "107              False         False         False      False         False  \n",
       "108              False         False         False      False         False  \n",
       "109              False         False         False      False         False  \n",
       "110              False         False         False      False         False  \n",
       "111              False         False          True       True         False  \n",
       "114              False         False         False      False         False  \n",
       "118              False         False         False      False         False  \n",
       "121              False         False          True      False         False  \n",
       "122              False         False         False      False         False  \n",
       "123              False         False         False      False         False  \n",
       "126              False         False         False      False         False  \n",
       "127              False          True         False      False         False  \n",
       "128              False          True         False      False         False  \n",
       "129              False          True         False      False         False  \n",
       "130              False          True         False      False         False  \n",
       "131              False          True         False      False         False  \n",
       "132              False          True         False      False         False  \n",
       "133              False          True         False      False         False  \n",
       "134              False          True         False      False         False  \n",
       "135              False          True         False      False         False  \n",
       "136              False          True         False      False         False  \n",
       "137              False          True         False      False         False  \n",
       "138              False          True         False      False         False  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "card_names[(card_names['is_troop'] == True)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "6d6e17a7-ffd1-40fe-a748-c076661d8d12",
   "metadata": {},
   "outputs": [],
   "source": [
    "troop_cluster_configs = {\n",
    "    'core_identity': (8, 'dual'),\n",
    "    'combat_core_stats': (12, 'km'),\n",
    "    'targeting_behavior': (3, 'dual'),\n",
    "    'special_attack_mechanics': (18, 'dual'),\n",
    "    'boolean_effects_and_traits': (23, 'dual'),\n",
    "    'engineered_features_granular': (24, 'km'),\n",
    "    'engineered_features_tight': (8, 'km'),\n",
    "    'role_labels': (9, 'dual'),\n",
    "    'highest_troop': (23, 'km'),\n",
    "    'engineered_and_boolean': (9, 'km')\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96cd7bb5-c69a-44e7-8a7e-f4303e9a3a96",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "clash-py311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
